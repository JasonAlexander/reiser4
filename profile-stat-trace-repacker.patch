
diff -rupN reiser4-release/Kconfig.reiser4 reiser4-full/Kconfig.reiser4

 Kconfig                                                             |   66 
 Makefile                                                            |   71 
 as_ops.c                                                            |   15 
 block_alloc.c                                                       |   92 
 block_alloc.h                                                       |   10 
 carry.c                                                             |   59 
 carry.h                                                             |   23 
 carry_ops.c                                                         |   59 
 cluster.h                                                           |    8 
 context.c                                                           |   29 
 context.h                                                           |   39 
 coord.c                                                             |   46 
 coord.h                                                             |    6 
 debug.h                                                             |  214 
 diskmap.c                                                           |   76 
 diskmap.h                                                           |   52 
 doc/directory-service                                               |  203 
 doc/metadata-in-pagecache                                           |   57 
 doc/oid-locid                                                       |  108 
 doc/page-cache-for-formatted-nodes                                  |   60 
 doc/plugin.inheritance                                              |  119 
 doc/readdir-problems-and-implementations                            |   12 
 doc/reiser4.writeback.overview                                      |   68 
 doc/set-theoretic-stuff.tex                                         |   82 
 doc/syntax.alg                                                      |  152 
 doc/wander.txt                                                      |  184 
 emergency_flush.c                                                   |   24 
 entd.c                                                              |    2 
 eottl.c                                                             |    2 
 estimate.c                                                          |    6 
 file_ops.c                                                          |   36 
 flush.c                                                             |  189 
 flush.h                                                             |    6 
 flush_queue.c                                                       |    6 
 init_super.c                                                        |   53 
 inode.c                                                             |   14 
 inode.h                                                             |    6 
 inode_ops.c                                                         |   58 
 jnode.c                                                             |   99 
 jnode.h                                                             |   27 
 kassign.c                                                           |   47 
 kassign.h                                                           |    3 
 kattr.h                                                             |   70 
 kcond.c                                                             |   17 
 kcond.h                                                             |    3 
 key.c                                                               |    4 
 key.h                                                               |    2 
 ktxnmgrd.c                                                          |    2 
 lnode.h                                                             |  122 
 lock.c                                                              |   95 
 lock.h                                                              |   20 
 log.h                                                               |  122 
 not-for-inclusion/interpolate.c                                     |   20 
 not-for-inclusion/linux-5_reiser4_syscall.patch                     |   38 
 not-for-inclusion/parser/Makefile                                   |   35 
 not-for-inclusion/parser/lex.l                                      |   65 
 not-for-inclusion/parser/lib.h                                      |   84 
 not-for-inclusion/parser/pars.yacc.h                                |   66 
 not-for-inclusion/parser/parser.tab.c                               |  194 
 not-for-inclusion/parser/parser.tab.h                               |   40 
 not-for-inclusion/parser/parser.y                                   |  175 
 not-for-inclusion/parser/tmp.c                                      |   32 
 not-for-inclusion/parser/yacc_reiser4.patch                         |  127 
 not-for-inclusion/plugin/name/invterp.c                             |   11 
 not-for-inclusion/reiser4-for-2.6.9.patch                           |  186 
 not-for-inclusion/sys_reiser4.c                                     |  106 
 not-for-inclusion/ulevel/bench/README                               |   20 
 not-for-inclusion/ulevel/bench/driver.sh                            |   59 
 not-for-inclusion/ulevel/bench/functions.sh                         |  115 
 not-for-inclusion/ulevel/bench/kernel                               |    1 
 not-for-inclusion/ulevel/bench/rc1.d.sample                         |   65 
 not-for-inclusion/ulevel/bench/start-bench.sh                       |    7 
 not-for-inclusion/ulevel/bench/template/mongo/ext3.htree.mkfs       |    1 
 not-for-inclusion/ulevel/bench/template/mongo/options               |   23 
 not-for-inclusion/ulevel/bench/template/mongo/run.me                |   87 
 not-for-inclusion/ulevel/bench/template/mongo/stage                 |    1 
 not-for-inclusion/ulevel/bench/template/mongo/v4.ext.mkfs           |    1 
 not-for-inclusion/ulevel/bench/template/read-write/ext2/options     |    8 
 not-for-inclusion/ulevel/bench/template/read-write/ext2/run.me      |  159 
 not-for-inclusion/ulevel/bench/template/read-write/ext2/stage       |    1 
 not-for-inclusion/ulevel/bench/template/read-write/reiser4/options  |    8 
 not-for-inclusion/ulevel/bench/template/read-write/reiser4/run.me   |  159 
 not-for-inclusion/ulevel/bench/template/read-write/reiser4/stage    |    1 
 not-for-inclusion/ulevel/bench/template/read-write/reiserfs/options |    9 
 not-for-inclusion/ulevel/bench/template/read-write/reiserfs/run.me  |  159 
 not-for-inclusion/ulevel/bench/template/read-write/reiserfs/stage   |    1 
 not-for-inclusion/ulevel/bench/template/read-write/run.me           |  159 
 not-for-inclusion/ulevel/bench/template/reiserfs/run.me             |  159 
 not-for-inclusion/ulevel/bench/template/run.me                      |  159 
 not-for-inclusion/ulevel/bench/template/untar-build/ext3/run.me     |  150 
 not-for-inclusion/ulevel/bench/template/untar-build/ext3/stage      |    1 
 not-for-inclusion/ulevel/bio-out.py                                 |   78 
 not-for-inclusion/ulevel/bio-out.sh                                 |    4 
 not-for-inclusion/ulevel/cp-r                                       |    7 
 not-for-inclusion/ulevel/driller.c                                  |   45 
 not-for-inclusion/ulevel/loid.c                                     |  206 
 not-for-inclusion/ulevel/make-teeny-files.c                         |  102 
 not-for-inclusion/ulevel/massage-lockmeter-output                   |   17 
 not-for-inclusion/ulevel/puncher.sh                                 |   23 
 not-for-inclusion/ulevel/readdir.c                                  |   43 
 not-for-inclusion/ulevel/seek-info.sh                               |    3 
 not-for-inclusion/ulevel/seeks.sh                                   |   73 
 not-for-inclusion/ulevel/shortlived                                 |   72 
 not-for-inclusion/ulevel/show-stats.sh                              |   27 
 not-for-inclusion/ulevel/sleep-info-parse                           |    4 
 not-for-inclusion/ulevel/stripspaces                                |   14 
 not-for-inclusion/ulevel/syscalltest.c                              |   20 
 not-for-inclusion/yet_unneeded_abstractions/oid/oid.c               |  172 
 not-for-inclusion/yet_unneeded_abstractions/oid/oid.h               |   54 
 not-for-inclusion/yet_unneeded_abstractions/oid/oid40.c             |  170 
 not-for-inclusion/yet_unneeded_abstractions/oid/oid40.h             |   57 
 page_cache.c                                                        |   87 
 page_cache.h                                                        |   10 
 plugin/compress/compress.c                                          |    4 
 plugin/cryptcompress.c                                              |   51 
 plugin/cryptcompress.h                                              |    9 
 plugin/dir/dir.c                                                    |   53 
 plugin/dir/hashed_dir.c                                             |   41 
 plugin/disk_format/disk_format40.c                                  |    7 
 plugin/file/funcs.h                                                 |    1 
 plugin/file/pseudo.c                                                |    2 
 plugin/file/tail_conversion.c                                       |   22 
 plugin/hash.c                                                       |    1 
 plugin/item/blackbox.c                                              |    6 
 plugin/item/cde.c                                                   |   28 
 plugin/item/ctail.c                                                 |   36 
 plugin/item/ctail.h                                                 |    2 
 plugin/item/extent.c                                                |   15 
 plugin/item/extent.h                                                |    2 
 plugin/item/extent_file_ops.c                                       |   52 
 plugin/item/extent_flush_ops.c                                      |  105 
 plugin/item/extent_item_ops.c                                       |    8 
 plugin/item/internal.c                                              |   13 
 plugin/item/item.c                                                  |   29 
 plugin/item/item.h                                                  |   12 
 plugin/item/sde.c                                                   |    2 
 plugin/item/static_stat.c                                           |    9 
 plugin/item/tail.c                                                  |   24 
 plugin/node/node.h                                                  |   32 
 plugin/node/node40.c                                                |  168 
 plugin/node/node40.h                                                |    5 
 plugin/object.c                                                     |   12 
 plugin/object.h                                                     |    2 
 plugin/plugin.c                                                     |   27 
 plugin/plugin.h                                                     |    8 
 plugin/plugin_set.c                                                 |   41 
 plugin/plugin_set.h                                                 |    4 
 plugin/pseudo/pseudo.c                                              |   10 
 plugin/space/bitmap.c                                               |   23 
 plugin/space/bitmap.h                                               |    3 
 pool.c                                                              |   14 
 pool.h                                                              |    1 
 prof.h                                                              |  130 
 readahead.c                                                         |    4 
 repacker.h                                                          |   22 
 safe_link.c                                                         |    4 
 safe_link.h                                                         |    5 
 seal.c                                                              |    4 
 seal.h                                                              |    5 
 search.c                                                            |  114 
 spinprof.h                                                          |  131 
 statcnt.h                                                           |  113 
 super.c                                                             |   75 
 super.h                                                             |   59 
 tap.c                                                               |   13 
 tap.h                                                               |    2 
 tree.c                                                              |   32 
 tree.h                                                              |   12 
 tree_walk.c                                                         |    9 
 tree_walk.h                                                         |    2 
 txnmgr.h                                                            |   16 
 type_safe_hash.h                                                    |   16 
 vfs_ops.c                                                           |  122 
 wander.c                                                            |   66 
 znode.h                                                             |   39 

diff -puN Kconfig~profile-stat-trace-repacker Kconfig


 Kconfig                                                             |   66 
 Makefile                                                            |   71 
 as_ops.c                                                            |   15 
 block_alloc.c                                                       |   92 
 block_alloc.h                                                       |   10 
 carry.c                                                             |   59 
 carry.h                                                             |   23 
 carry_ops.c                                                         |   59 
 cluster.h                                                           |    8 
 context.c                                                           |   29 
 context.h                                                           |   39 
 coord.c                                                             |   46 
 coord.h                                                             |    6 
 debug.c                                                             |  343 +
 debug.h                                                             |  214 
 diskmap.c                                                           |   76 
 diskmap.h                                                           |   52 
 doc/directory-service                                               |  203 
 doc/lock-ordering                                                   |  601 ++
 doc/lock-ordering.dot                                               |  276 +
 doc/metadata-in-pagecache                                           |   57 
 doc/oid-locid                                                       |  108 
 doc/page-cache-for-formatted-nodes                                  |   60 
 doc/plugin.inheritance                                              |  119 
 doc/readdir-problems-and-implementations                            |   12 
 doc/reiser4.writeback.overview                                      |   68 
 doc/reiser4_roadmap.html                                            | 1120 +++++
 doc/set-theoretic-stuff.tex                                         |   82 
 doc/syntax.alg                                                      |  152 
 doc/sys-reiser4-implemenation-overview                              |  222 +
 doc/wander.txt                                                      |  184 
 emergency_flush.c                                                   |   24 
 entd.c                                                              |    2 
 eottl.c                                                             |    2 
 estimate.c                                                          |    6 
 file_ops.c                                                          |   36 
 flush.c                                                             |  189 
 flush.h                                                             |    6 
 flush_queue.c                                                       |    6 
 init_super.c                                                        |   53 
 inode.c                                                             |   14 
 inode.h                                                             |    6 
 inode_ops.c                                                         |   58 
 jnode.c                                                             |   99 
 jnode.h                                                             |   28 
 kassign.c                                                           |   47 
 kassign.h                                                           |    3 
 kattr.c                                                             |  641 ++
 kattr.h                                                             |   70 
 kcond.c                                                             |   17 
 kcond.h                                                             |    3 
 key.c                                                               |    4 
 key.h                                                               |    2 
 ktxnmgrd.c                                                          |    2 
 lnode.c                                                             |  431 +
 lnode.h                                                             |  122 
 lock.c                                                              |  103 
 lock.h                                                              |   20 
 log.c                                                               |  522 ++
 log.h                                                               |  122 
 not-for-inclusion/dont-use-rwlocks.patch                            |  358 +
 not-for-inclusion/interpolate.c                                     |   20 
 not-for-inclusion/linux-5_reiser4_syscall.patch                     |   38 
 not-for-inclusion/parser/Makefile                                   |   35 
 not-for-inclusion/parser/lex.l                                      |   65 
 not-for-inclusion/parser/lib.c                                      | 2187 ++++++++++
 not-for-inclusion/parser/lib.h                                      |   84 
 not-for-inclusion/parser/pars.cls.h                                 |  242 +
 not-for-inclusion/parser/pars.yacc.h                                |   66 
 not-for-inclusion/parser/parser.code.c                              |  484 ++
 not-for-inclusion/parser/parser.doc                                 |  473 ++
 not-for-inclusion/parser/parser.h                                   |  345 +
 not-for-inclusion/parser/parser.tab.c                               |  194 
 not-for-inclusion/parser/parser.tab.h                               |   40 
 not-for-inclusion/parser/parser.y                                   |  175 
 not-for-inclusion/parser/tmp.c                                      |   32 
 not-for-inclusion/parser/yacc_reiser4.patch                         |  127 
 not-for-inclusion/plugin/name/invterp.c                             |   11 
 not-for-inclusion/reiser4-for-2.6.9.patch                           |  186 
 not-for-inclusion/sys_reiser4.c                                     |  106 
 not-for-inclusion/sys_reiser4_2.c                                   | 1174 +++++
 not-for-inclusion/ulevel/bench/README                               |   20 
 not-for-inclusion/ulevel/bench/driver.sh                            |   59 
 not-for-inclusion/ulevel/bench/functions.sh                         |  115 
 not-for-inclusion/ulevel/bench/kernel                               |    1 
 not-for-inclusion/ulevel/bench/rc1.d.sample                         |   65 
 not-for-inclusion/ulevel/bench/start-bench.sh                       |    7 
 not-for-inclusion/ulevel/bench/template/mongo/ext3.htree.mkfs       |    1 
 not-for-inclusion/ulevel/bench/template/mongo/options               |   23 
 not-for-inclusion/ulevel/bench/template/mongo/run.me                |   87 
 not-for-inclusion/ulevel/bench/template/mongo/stage                 |    1 
 not-for-inclusion/ulevel/bench/template/mongo/v4.ext.mkfs           |    1 
 not-for-inclusion/ulevel/bench/template/read-write/ext2/options     |    8 
 not-for-inclusion/ulevel/bench/template/read-write/ext2/run.me      |  159 
 not-for-inclusion/ulevel/bench/template/read-write/ext2/stage       |    1 
 not-for-inclusion/ulevel/bench/template/read-write/reiser4/options  |    8 
 not-for-inclusion/ulevel/bench/template/read-write/reiser4/run.me   |  159 
 not-for-inclusion/ulevel/bench/template/read-write/reiser4/stage    |    1 
 not-for-inclusion/ulevel/bench/template/read-write/reiserfs/options |    9 
 not-for-inclusion/ulevel/bench/template/read-write/reiserfs/run.me  |  159 
 not-for-inclusion/ulevel/bench/template/read-write/reiserfs/stage   |    1 
 not-for-inclusion/ulevel/bench/template/read-write/run.me           |  159 
 not-for-inclusion/ulevel/bench/template/reiserfs/run.me             |  159 
 not-for-inclusion/ulevel/bench/template/run.me                      |  159 
 not-for-inclusion/ulevel/bench/template/untar-build/ext3/run.me     |  150 
 not-for-inclusion/ulevel/bench/template/untar-build/ext3/stage      |    1 
 not-for-inclusion/ulevel/bio-out.py                                 |   78 
 not-for-inclusion/ulevel/bio-out.sh                                 |    4 
 not-for-inclusion/ulevel/cp-r                                       |    7 
 not-for-inclusion/ulevel/driller.c                                  |   45 
 not-for-inclusion/ulevel/loid.c                                     |  206 
 not-for-inclusion/ulevel/make-teeny-files.c                         |  102 
 not-for-inclusion/ulevel/massage-lockmeter-output                   |   17 
 not-for-inclusion/ulevel/nfs_fh_stale.c                             | 1065 ++++
 not-for-inclusion/ulevel/puncher.sh                                 |   23 
 not-for-inclusion/ulevel/readdir.c                                  |   43 
 not-for-inclusion/ulevel/seek-info.sh                               |    3 
 not-for-inclusion/ulevel/seeks.sh                                   |   73 
 not-for-inclusion/ulevel/shortlived                                 |   72 
 not-for-inclusion/ulevel/show-stats.sh                              |   27 
 not-for-inclusion/ulevel/sleep-info-parse                           |    4 
 not-for-inclusion/ulevel/stripspaces                                |   14 
 not-for-inclusion/ulevel/syscalltest.c                              |   20 
 not-for-inclusion/yet_unneeded_abstractions/oid/oid.c               |  172 
 not-for-inclusion/yet_unneeded_abstractions/oid/oid.h               |   54 
 not-for-inclusion/yet_unneeded_abstractions/oid/oid40.c             |  170 
 not-for-inclusion/yet_unneeded_abstractions/oid/oid40.h             |   57 
 page_cache.c                                                        |   87 
 page_cache.h                                                        |   10 
 plugin/compress/compress.c                                          |    4 
 plugin/cryptcompress.c                                              |   51 
 plugin/cryptcompress.h                                              |    9 
 plugin/dir/dir.c                                                    |   53 
 plugin/dir/hashed_dir.c                                             |   41 
 plugin/disk_format/disk_format40.c                                  |    7 
 plugin/file/file.c                                                  |   99 
 plugin/file/funcs.h                                                 |    1 
 plugin/file/pseudo.c                                                |    2 
 plugin/file/tail_conversion.c                                       |   22 
 plugin/hash.c                                                       |    1 
 plugin/item/blackbox.c                                              |    6 
 plugin/item/cde.c                                                   |   28 
 plugin/item/ctail.c                                                 |   36 
 plugin/item/ctail.h                                                 |    2 
 plugin/item/extent.c                                                |   15 
 plugin/item/extent.h                                                |    2 
 plugin/item/extent_file_ops.c                                       |   50 
 plugin/item/extent_flush_ops.c                                      |  105 
 plugin/item/extent_item_ops.c                                       |    8 
 plugin/item/extent_repack_ops.c                                     |  447 ++
 plugin/item/internal.c                                              |   13 
 plugin/item/item.c                                                  |   29 
 plugin/item/item.h                                                  |   12 
 plugin/item/sde.c                                                   |    2 
 plugin/item/static_stat.c                                           |    9 
 plugin/item/tail.c                                                  |   24 
 plugin/node/node.c                                                  |  248 +
 plugin/node/node.h                                                  |   32 
 plugin/node/node40.c                                                |  168 
 plugin/node/node40.h                                                |    5 
 plugin/object.c                                                     |   12 
 plugin/object.h                                                     |    2 
 plugin/plugin.c                                                     |   27 
 plugin/plugin.h                                                     |    8 
 plugin/plugin_set.c                                                 |   41 
 plugin/plugin_set.h                                                 |    4 
 plugin/pseudo/pseudo.c                                              |   10 
 plugin/space/bitmap.c                                               |   23 
 plugin/space/bitmap.h                                               |    3 
 pool.c                                                              |   14 
 pool.h                                                              |    1 
 prof.c                                                              |  273 +
 prof.h                                                              |  130 
 readahead.c                                                         |    4 
 reiser4.h                                                           |  236 +
 repacker.c                                                          |  661 +++
 repacker.h                                                          |   22 
 safe_link.c                                                         |    4 
 seal.c                                                              |    4 
 seal.h                                                              |    6 
 search.c                                                            |  114 
 spin_macros.h                                                       |  400 +
 spinprof.c                                                          |  553 ++
 spinprof.h                                                          |  131 
 statcnt.h                                                           |  113 
 stats.c                                                             |  639 ++
 stats.h                                                             |  769 +++
 super.c                                                             |   75 
 super.h                                                             |   59 
 tap.c                                                               |   13 
 tap.h                                                               |    2 
 tree.c                                                              |   32 
 tree.h                                                              |   12 
 tree_walk.c                                                         |    9 
 tree_walk.h                                                         |    2 
 txnmgr.c                                                            |  225 -
 txnmgr.h                                                            |   16 
 type_safe_hash.h                                                    |   16 
 vfs_ops.c                                                           |  122 
 wander.c                                                            |   66 
 znode.c                                                             |  305 +
 znode.h                                                             |   39 
 202 files changed, 23673 insertions(+), 473 deletions(-)

diff -puN as_ops.c~profile-stat-trace-repacker as_ops.c
--- reiser4/as_ops.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/as_ops.c	2005-02-01 12:00:42.000000000 +0300
@@ -18,12 +18,14 @@
 #include "znode.h"
 #include "block_alloc.h"
 #include "tree.h"
+#include "log.h"
 #include "vfs_ops.h"
 #include "inode.h"
 #include "page_cache.h"
 #include "ktxnmgrd.h"
 #include "super.h"
 #include "reiser4.h"
+#include "kattr.h"
 #include "entd.h"
 #include "emergency_flush.h"
 
@@ -294,6 +296,7 @@ reiser4_lblock_to_blocknr(struct address
 	reiser4_context ctx;
 
 	init_context(&ctx, mapping->host->i_sb);
+	reiser4_stat_inc(vfs_calls.bmap);
 
 	fplug = inode_file_plugin(mapping->host);
 	if (fplug && fplug->get_block) {
@@ -436,6 +439,7 @@ releasable(const jnode *node /* node to 
 	/* is some thread is currently using jnode page, later cannot be
 	 * detached */
 	if (atomic_read(&node->d_count) != 0) {
+		INC_NSTAT(node, vm.release.loaded);
 		return 0;
 	}
 
@@ -445,12 +449,14 @@ releasable(const jnode *node /* node to 
 	 * otherwise next jload() would load obsolete data from disk
 	 * (up-to-date version may still be in memory). */
 	if (is_cced(node)) {
+		INC_NSTAT(node, vm.release.copy);
 		return 0;
 	}
 
 	/* emergency flushed page can be released. This is what emergency
 	 * flush is all about after all. */
 	if (JF_ISSET(node, JNODE_EFLUSH)) {
+		INC_NSTAT(node, vm.release.eflushed);
 		return 1; /* yeah! */
 	}
 
@@ -459,31 +465,37 @@ releasable(const jnode *node /* node to 
 	   node to be clean, not it atom yet, and still having fake block
 	   number. For example, node just created in jinit_new(). */
 	if (blocknr_is_fake(jnode_get_block(node))) {
+ 		INC_NSTAT(node, vm.release.fake);
 		return 0;
 	}
 	/* dirty jnode cannot be released. It can however be submitted to disk
 	 * as part of early flushing, but only after getting flush-prepped. */
 	if (jnode_is_dirty(node)) {
+ 		INC_NSTAT(node, vm.release.dirty);
 		return 0;
 	}
 	/* overwrite set is only written by log writer. */
 	if (JF_ISSET(node, JNODE_OVRWR)) {
+ 		INC_NSTAT(node, vm.release.ovrwr);
 		return 0;
 	}
 	/* jnode is already under writeback */
 	if (JF_ISSET(node, JNODE_WRITEBACK)) {
+ 		INC_NSTAT(node, vm.release.writeback);
 		return 0;
 	}
 #if 0
 	/* page was modified through mmap, but its jnode is not yet
 	 * captured. Don't discard modified data. */
 	if (jnode_is_unformatted(node) && JF_ISSET(node, JNODE_KEEPME)) {
+		INC_NSTAT(node, vm.release.keepme);
 		return 0;
 	}
 #endif
 	BUG_ON(JF_ISSET(node, JNODE_KEEPME));
 	/* don't flush bitmaps or journal records */
 	if (!jnode_is_znode(node) && !jnode_is_unformatted(node)) {
+ 		INC_NSTAT(node, vm.release.bitmap);
 		return 0;
 	}
 	return 1;
@@ -525,6 +537,8 @@ reiser4_releasepage(struct page *page, i
 	assert("reiser4-4", page->mapping != NULL);
 	assert("reiser4-5", page->mapping->host != NULL);
 
+	INC_STAT(page, node, vm.release.try);
+
 	oid = (void *)(unsigned long)get_inode_oid(page->mapping->host);
 
 	/* is_page_cache_freeable() check
@@ -543,6 +557,7 @@ reiser4_releasepage(struct page *page, i
 		struct address_space *mapping;
 
 		mapping = page->mapping;
+		INC_STAT(page, node, vm.release.ok);
 		jref(node);
 		/* there is no need to synchronize against
 		 * jnode_extent_write() here, because pages seen by
diff -puN block_alloc.c~profile-stat-trace-repacker block_alloc.c
--- reiser4/block_alloc.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/block_alloc.c	2005-02-01 11:51:11.000000000 +0300
@@ -123,7 +123,7 @@
 reiser4_internal void
 blocknr_hint_init(reiser4_blocknr_hint * hint)
 {
-	memset(hint, 0, sizeof (reiser4_blocknr_hint));
+	xmemset(hint, 0, sizeof (reiser4_blocknr_hint));
 }
 
 /* Release any resources of a blocknr hint. */
@@ -151,6 +151,8 @@ blocknr_is_fake(const reiser4_block_nr *
 static void
 sub_from_ctx_grabbed(reiser4_context *ctx, __u64 count)
 {
+	if (ctx->grabbed_blocks < count)
+		print_clog();
 	BUG_ON(ctx->grabbed_blocks < count);
 	assert("zam-527", ctx->grabbed_blocks >= count);
 	ctx->grabbed_blocks -= count;
@@ -248,6 +250,35 @@ check_block_counters(const struct super_
 	return 1;
 }
 
+#if REISER4_DEBUG_OUTPUT
+reiser4_internal void
+print_block_counters(const char *prefix,
+		     const struct super_block *super, txn_atom *atom)
+{
+	if (super == NULL)
+		super = reiser4_get_current_sb();
+	printk("%s:\tsuper: G: %llu, F: %llu, D: %llu, U: %llu + %llu, R: %llu, C: %llu, T: %llu\n",
+	       prefix,
+	       reiser4_grabbed_blocks(super),
+	       reiser4_free_blocks(super),
+	       reiser4_data_blocks(super),
+	       reiser4_fake_allocated(super),
+	       reiser4_fake_allocated_unformatted(super),
+	       flush_reserved(super),
+	       reiser4_clustered_blocks(super),
+	       reiser4_block_count(super));
+	printk("\tcontext: G: %llu",
+	       get_current_context()->grabbed_blocks);
+	if (atom == NULL)
+		atom = get_current_atom_locked_nocheck();
+	if (atom != NULL) {
+		printk("\tatom: R: %llu", atom->flush_reserved);
+		UNLOCK_ATOM(atom);
+	}
+	printk("\n");
+}
+#endif
+
 /* Adjust "working" free blocks counter for number of blocks we are going to
    allocate.  Record number of grabbed blocks in fs-wide and per-thread
    counters.  This function should be called before bitmap scanning or
@@ -281,9 +312,14 @@ reiser4_grab(reiser4_context *ctx, __u64
 
 	free_blocks = sbinfo->blocks_free;
 
+	ON_TRACE(TRACE_ALLOC, "reiser4_grab: free_blocks %llu\n", free_blocks);
+
 	if ((use_reserved && free_blocks < count) ||
 	    (!use_reserved && free_blocks < count + sbinfo->blocks_reserved)) {
 		ret = RETERR(-ENOSPC);
+
+		ON_TRACE(TRACE_ALLOC, "reiser4_grab: ENOSPC: count %llu\n", count);
+
 		goto unlock_and_ret;
 	}
 
@@ -294,10 +330,14 @@ reiser4_grab(reiser4_context *ctx, __u64
 
 #if REISER4_DEBUG
 	ctx->grabbed_initially = count;
+	fill_backtrace(&ctx->grabbed_at, REISER4_BACKTRACE_DEPTH, 0);
 #endif
 
 	assert("nikita-2986", check_block_counters(ctx->super));
 
+	ON_TRACE(TRACE_ALLOC, "%s: grabbed %llu, free blocks left %llu\n",
+		 __FUNCTION__, count, reiser4_free_blocks (ctx->super));
+
 	/* disable grab space in current context */
 	ctx->grab_enabled = 0;
 
@@ -315,8 +355,11 @@ reiser4_grab_space(__u64 count, reiser4_
 
 	assert("nikita-2964", ergo(flags & BA_CAN_COMMIT,
 				   lock_stack_isclean(get_current_lock_stack())));
+	ON_TRACE(TRACE_RESERVE, "grab_space: %llu block(s).", count);
+
 	ctx = get_current_context();
 	if (!(flags & BA_FORCE) && !is_grab_enabled(ctx)) {
+		ON_TRACE(TRACE_RESERVE, "grab disabled and not forced!\n");
 		return 0;
 	}
 
@@ -325,11 +368,16 @@ reiser4_grab_space(__u64 count, reiser4_
 
 		/* Trying to commit the all transactions if BA_CAN_COMMIT flag present */
 		if (flags & BA_CAN_COMMIT) {
+
+			ON_TRACE(TRACE_RESERVE, "force commit!..");
+
 			txnmgr_force_commit_all(ctx->super, 0);
+
 			ctx->grab_enabled = 1;
 			ret = reiser4_grab(ctx, count, flags);
 		}
 	}
+	ON_TRACE(TRACE_RESERVE, "%s(%d)\n", (ret == 0) ? "ok" : "failed", ret);
 	/*
 	 * allocation from reserved pool cannot fail. This is severe error.
 	 */
@@ -524,6 +572,8 @@ static inline void assign_fake_blocknr(r
 reiser4_internal int
 assign_fake_blocknr_formatted(reiser4_block_nr *blocknr)
 {
+	ON_TRACE(TRACE_RESERVE, "assign_fake_blocknr_formatted: moving 1 grabbed block to fake allocated formatted\n");
+
 	assign_fake_blocknr(blocknr);
 	grabbed2fake_allocated_formatted();
 
@@ -536,6 +586,8 @@ fake_blocknr_unformatted(void)
 {
 	reiser4_block_nr blocknr;
 
+	ON_TRACE(TRACE_RESERVE, "fake_blocknr_unformatted: moving 1 grabbed block to fake allocated unformatted\n");
+
 	assign_fake_blocknr(&blocknr);
 	grabbed2fake_allocated_unformatted();
 
@@ -658,9 +710,18 @@ reiser4_alloc_blocks(reiser4_blocknr_hin
 	ctx = get_current_context();
 	sbinfo = get_super_private(ctx->super);
 
+	ON_TRACE(TRACE_RESERVE, "reiser4_alloc_blocks: needed %llu..", needed);
+
+	assert("vpf-339", hint != NULL);
+
+	ON_TRACE(TRACE_ALLOC,
+		 "alloc_blocks: requested %llu, search from %llu\n",
+		 (unsigned long long) *len, (unsigned long long) (hint ? hint->blk : ~0ull));
+
 	/* For write-optimized data we use default search start value, which is
 	 * close to last write location. */
 	if (flags & BA_USE_DEFAULT_SEARCH_START) {
+		reiser4_stat_inc(block_alloc.nohint);
 		get_blocknr_hint_default(&hint->blk);
 	}
 
@@ -688,14 +749,17 @@ reiser4_alloc_blocks(reiser4_blocknr_hin
 		switch (hint->block_stage) {
 		case BLOCK_NOT_COUNTED:
 		case BLOCK_GRABBED:
+			ON_TRACE(TRACE_RESERVE, "ok. %llu blocks grabbed to used.\n", *len);
 			grabbed2used(ctx, sbinfo, *len);
 			break;
 		case BLOCK_UNALLOCATED:
+			ON_TRACE(TRACE_RESERVE, "ok. %llu blocks fake allocated to used.\n", *len);
 			fake_allocated2used(sbinfo, *len, flags);
 			break;
 		case BLOCK_FLUSH_RESERVED:
+			ON_TRACE(TRACE_RESERVE, "ok. %llu flush reserved to used (get wandered?)\n", *len);
 			{
-				txn_atom *atom = get_current_atom_locked ();
+				txn_atom * atom = get_current_atom_locked ();
 				flush_reserved2used(atom, *len);
 				UNLOCK_ATOM (atom);
 			}
@@ -780,6 +844,8 @@ fake_allocated2free(__u64 count, reiser4
 	ctx = get_current_context();
 	sbinfo = get_super_private(ctx->super);
 
+	ON_TRACE(TRACE_RESERVE, "fake_allocated2free %llu blocks\n", count);
+
 	fake_allocated2grabbed(ctx, sbinfo, count, flags);
 	grabbed2free(ctx, sbinfo, count);
 }
@@ -804,6 +870,8 @@ reiser4_internal void
 grabbed2free(reiser4_context *ctx, reiser4_super_info_data *sbinfo,
 	       __u64 count)
 {
+	ON_TRACE(TRACE_RESERVE, "grabbed2free: %llu\n", count);
+
 	sub_from_ctx_grabbed(ctx, count);
 
 
@@ -838,6 +906,9 @@ grabbed2flush_reserved_nolock(txn_atom *
 
 	assert ("vpf-292", check_block_counters(ctx->super));
 
+	ON_TRACE(TRACE_RESERVE, "__grabbed2flush_reserved_nolock %llu blocks: atom %u has %llu flush reserved blocks\n",
+		 count, atom->atom_id, atom->flush_reserved);
+
 	reiser4_spin_unlock_sb(sbinfo);
 }
 
@@ -846,6 +917,8 @@ grabbed2flush_reserved(__u64 count)
 {
 	txn_atom * atom = get_current_atom_locked ();
 
+	ON_TRACE(TRACE_RESERVE, "__grabbed2flush_reserved\n");
+
 	grabbed2flush_reserved_nolock (atom, count);
 
 	UNLOCK_ATOM (atom);
@@ -958,6 +1031,8 @@ reiser4_dealloc_blocks(const reiser4_blo
 	reiser4_context *ctx;
 	reiser4_super_info_data *sbinfo;
 
+	ON_TRACE(TRACE_RESERVE, "reiser4_dealloc_blocks: %llu blocks", *len);
+
 	ctx = get_current_context();
 	sbinfo = get_super_private(ctx->super);
 
@@ -974,6 +1049,8 @@ reiser4_dealloc_blocks(const reiser4_blo
 	if (flags & BA_DEFER) {
 		blocknr_set_entry *bsep = NULL;
 
+		ON_TRACE(TRACE_RESERVE, "put on delete set\n");
+
 		/* storing deleted block numbers in a blocknr set
 		   datastructure for further actual deletion */
 		do {
@@ -1008,21 +1085,32 @@ reiser4_dealloc_blocks(const reiser4_blo
 		switch (target_stage) {
 		case BLOCK_NOT_COUNTED:
 			assert("vs-960", flags & BA_FORMATTED);
+
+			ON_TRACE(TRACE_RESERVE, "moved from used to free\n");
+
 			/* VITALY: This is what was grabbed for internal/tx-lists/similar only */
 			used2free(sbinfo, *len);
 			break;
 
 		case BLOCK_GRABBED:
+
+			ON_TRACE(TRACE_RESERVE, "moved from used to grabbed\n");
+
 			used2grabbed(ctx, sbinfo, *len);
 			break;
 
 		case BLOCK_UNALLOCATED:
+
+			ON_TRACE(TRACE_RESERVE, "moved from used to fake allocated\n");
+
 			used2fake_allocated(sbinfo, *len, flags & BA_FORMATTED);
 			break;
 
 		case BLOCK_FLUSH_RESERVED: {
 			txn_atom *atom;
 
+			ON_TRACE(TRACE_RESERVE, "moved from used to flush reserved\n");
+
 			atom = get_current_atom_locked();
 			used2flush_reserved(sbinfo, atom, *len, flags & BA_FORMATTED);
 			UNLOCK_ATOM(atom);
diff -puN block_alloc.h~profile-stat-trace-repacker block_alloc.h
--- reiser4/block_alloc.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/block_alloc.h	2005-02-01 11:51:11.000000000 +0300
@@ -150,14 +150,24 @@ extern int check_block_counters(const st
 
 #if REISER4_DEBUG
 
+extern void reiser4_check_blocks(const reiser4_block_nr *, const reiser4_block_nr *, int);
 extern void reiser4_check_block(const reiser4_block_nr *, int);
 
 #else
 
+#  define reiser4_check_blocks(beg, len, val)  noop
 #  define reiser4_check_block(beg, val)        noop
 
 #endif
 
+#if REISER4_DEBUG_OUTPUT
+extern void print_block_counters(const char *,
+				 const struct super_block *,
+				 txn_atom *atom);
+#else
+#define print_block_counters(p, s, a) noop
+#endif
+
 extern int pre_commit_hook(void);
 extern void post_commit_hook(void);
 extern void post_write_back_hook(void);
diff -puN carry.c~profile-stat-trace-repacker carry.c
--- reiser4/carry.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/carry.c	2005-02-01 11:51:11.000000000 +0300
@@ -146,6 +146,7 @@ I feel uneasy about this pool.  It adds 
 #include "carry_ops.h"
 #include "super.h"
 #include "reiser4.h"
+#include "prof.h"
 
 #include <linux/types.h>
 
@@ -161,8 +162,6 @@ int lock_carry_node_tail(carry_node * no
 /* carry processing proper */
 static int carry_on_level(carry_level * doing, carry_level * todo);
 
-static carry_op *add_op(carry_level * level, pool_ordering order, carry_op * reference);
-
 /* handlers for carry operations. */
 
 static void fatal_carry_error(carry_level * doing, int ecode);
@@ -170,8 +169,6 @@ static int add_new_root(carry_level * le
 
 static int carry_estimate_reserve(carry_level * level);
 
-static void print_level(const char *prefix, carry_level * level);
-
 #if REISER4_DEBUG
 typedef enum {
 	CARRY_TODO,
@@ -207,6 +204,8 @@ carry(carry_level * doing /* set of carr
 
 	assert("nikita-888", doing != NULL);
 
+	trace_stamp(TRACE_CARRY);
+
 	todo = &todo_area;
 	init_carry_level(todo, doing->pool);
 	if (done == NULL) {
@@ -222,9 +221,11 @@ carry(carry_level * doing /* set of carr
 		return result;
 
 	/* iterate until there is nothing more to do */
-	while (result == 0 && doing->ops_num > 0) {
+	while (result == 0 && carry_op_num(doing) > 0) {
 		carry_level *tmp;
 
+		ON_STATS(todo->level_no = doing->level_no + 1);
+
 		/* at this point @done is locked. */
 		/* repeat lock/do/unlock while
 
@@ -265,11 +266,12 @@ carry(carry_level * doing /* set of carr
 				fatal_carry_error(doing, result);
 				return result;
 			}
+			reiser4_stat_level_inc(doing, carry_restart);
 			unlock_carry_level(doing, 1);
 		}
 		/* at this point @done can be safely unlocked */
 		done_carry_level(done);
-
+		reiser4_stat_level_inc(doing, carry_done);
 		/* cyclically shift queues */
 		tmp = done;
 		done = doing;
@@ -321,6 +323,11 @@ carry_on_level(carry_level * doing	/* qu
 	assert("nikita-1034", doing != NULL);
 	assert("nikita-1035", todo != NULL);
 
+	trace_stamp(TRACE_CARRY);
+
+	/* node can be inconsistent while in-transit */
+	DISABLE_NODE_CHECK;
+
 	/* @doing->nodes are locked. */
 
 	/* This function can be split into two phases: analysis and modification.
@@ -381,6 +388,7 @@ carry_on_level(carry_level * doing	/* qu
 			}
 		}
 	}
+	ENABLE_NODE_CHECK;
 	return result;
 }
 
@@ -431,6 +439,13 @@ post_carry(carry_level * level	/* queue 
 	return result;
 }
 
+/* number of carry operations in a @level */
+reiser4_internal int
+carry_op_num(const carry_level * level)
+{
+	return level->ops_num;
+}
+
 /* initialise carry queue */
 reiser4_internal void
 init_carry_level(carry_level * level /* level to initialise */ ,
@@ -440,7 +455,7 @@ init_carry_level(carry_level * level /* 
 	assert("nikita-1045", level != NULL);
 	assert("nikita-967", pool != NULL);
 
-	memset(level, 0, sizeof *level);
+	xmemset(level, 0, sizeof *level);
 	level->pool = pool;
 
 	pool_level_list_init(&level->nodes);
@@ -493,6 +508,7 @@ add_carry_skip(carry_level * level	/* &c
 {
 	ON_DEBUG(carry_node * orig_ref = reference);
 
+	trace_stamp(TRACE_CARRY);
 	if (order == POOLO_BEFORE) {
 		reference = find_left_carry(reference, level);
 		if (reference == NULL)
@@ -537,7 +553,7 @@ add_carry(carry_level * level	/* &carry_
    @order and @reference parameters.
 
 */
-static carry_op *
+reiser4_internal carry_op *
 add_op(carry_level * level /* &carry_level to add node to */ ,
        pool_ordering order	/* where to insert: at the beginning of
 				 * @level, before @reference, after
@@ -546,6 +562,7 @@ add_op(carry_level * level /* &carry_lev
 {
 	carry_op *result;
 
+	trace_stamp(TRACE_CARRY);
 	result = (carry_op *) add_obj(&level->pool->op_pool, &level->ops, order, &reference->header);
 	if (!IS_ERR(result) && (result != NULL))
 		++level->ops_num;
@@ -561,7 +578,7 @@ add_op(carry_level * level /* &carry_lev
    parent, it has corresponding bit (JNODE_ORPHAN) set in zstate.
 
 */
-static carry_node *
+reiser4_internal carry_node *
 find_begetting_brother(carry_node * node	/* node to start search
 						 * from */ ,
 		       carry_level * kin UNUSED_ARG	/* level to
@@ -647,7 +664,7 @@ insert_carry_node(carry_level * doing, c
 	return scan;
 }
 
-static carry_node *
+reiser4_internal carry_node *
 add_carry_atplace(carry_level *doing, carry_level *todo, znode *node)
 {
 	carry_node *reference;
@@ -713,6 +730,8 @@ lock_carry_level(carry_level * level /* 
 	assert("nikita-881", level != NULL);
 	assert("nikita-2229", carry_level_invariant(level, CARRY_TODO));
 
+	trace_stamp(TRACE_CARRY);
+
 	/* lock nodes from left to right */
 	result = 0;
 	for_all_nodes(level, node, tmp_node) {
@@ -805,6 +824,8 @@ unlock_carry_level(carry_level * level /
 
 	assert("nikita-889", level != NULL);
 
+	trace_stamp(TRACE_CARRY);
+
 	if (!failure) {
 		znode *spot;
 
@@ -827,6 +848,8 @@ unlock_carry_level(carry_level * level /
 		   parents at this moment. */
 		assert("nikita-1631", ergo(!failure, !ZF_ISSET(carry_real(node),
 							       JNODE_ORPHAN)));
+		if (!failure)
+			node_check(carry_real(node), REISER4_NODE_DKEYS);
 		ON_DEBUG(check_dkeys(carry_real(node)));
 		unlock_carry_node(level, node, failure);
 	}
@@ -846,6 +869,8 @@ done_carry_level(carry_level * level /* 
 
 	assert("nikita-1076", level != NULL);
 
+	trace_stamp(TRACE_CARRY);
+
 	unlock_carry_level(level, 0);
 	for_all_nodes(level, node, tmp_node) {
 		assert("nikita-2113", locks_list_is_clean(&node->lock_handle));
@@ -914,6 +939,8 @@ lock_carry_node(carry_level * level /* l
 	assert("nikita-887", level != NULL);
 	assert("nikita-882", node != NULL);
 
+	trace_stamp(TRACE_CARRY);
+
 	result = 0;
 	reference_point = node->node;
 	init_lh(&lh);
@@ -1009,6 +1036,8 @@ unlock_carry_node(carry_level * level,
 
 	assert("nikita-884", node != NULL);
 
+	trace_stamp(TRACE_CARRY);
+
 	real_node = carry_real(node);
 	/* pair to zload() in lock_carry_node_tail() */
 	zrelse(real_node);
@@ -1275,7 +1304,9 @@ carry_level_invariant(carry_level * leve
 			if (!keyle(leftmost_key_in_node(left, &lkey),
 				   leftmost_key_in_node(right, &rkey))) {
 				print_znode("left", left);
+				print_node_content("left", left, ~0);
 				print_znode("right", right);
+				print_node_content("right", right, ~0);
 				return 0;
 			}
 		}
@@ -1284,6 +1315,7 @@ carry_level_invariant(carry_level * leve
 }
 #endif
 
+#if REISER4_DEBUG_OUTPUT
 /* get symbolic name for boolean */
 static const char *
 tf(int boolean /* truth value */ )
@@ -1321,7 +1353,7 @@ carry_op_name(carry_opcode op /* carry o
 }
 
 /* dump information about carry node */
-static void
+reiser4_internal void
 print_carry(const char *prefix /* prefix to print */ ,
 	    carry_node * node /* node to print */ )
 {
@@ -1336,7 +1368,7 @@ print_carry(const char *prefix /* prefix
 }
 
 /* dump information about carry operation */
-static void
+reiser4_internal void
 print_op(const char *prefix /* prefix to print */ ,
 	 carry_op * op /* operation to print */ )
 {
@@ -1375,7 +1407,7 @@ print_op(const char *prefix /* prefix to
 }
 
 /* dump information about all nodes and operations in a @level */
-static void
+reiser4_internal void
 print_level(const char *prefix /* prefix to print */ ,
 	    carry_level * level /* level to print */ )
 {
@@ -1396,6 +1428,7 @@ print_level(const char *prefix /* prefix
 	for_all_ops(level, op, tmp_op)
 	    print_op("\tcarry op", op);
 }
+#endif
 
 /* Make Linus happy.
    Local variables:
diff -puN carry.h~profile-stat-trace-repacker carry.h
--- reiser4/carry.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/carry.h	2005-02-01 11:51:11.000000000 +0300
@@ -317,6 +317,9 @@ struct carry_level {
 	/* lock handle supplied by user that we are tracking. See
 	   above. */
 	lock_handle *tracked;
+#if REISER4_STATS
+	tree_level level_no;
+#endif
 };
 
 /* information carry passes to plugin methods that may add new operations to
@@ -330,10 +333,16 @@ int carry(carry_level * doing, carry_lev
 
 carry_node *add_carry(carry_level * level, pool_ordering order, carry_node * reference);
 carry_node *add_carry_skip(carry_level * level, pool_ordering order, carry_node * reference);
+carry_op *add_op(carry_level * level, pool_ordering order, carry_op * reference);
 
 extern carry_node *insert_carry_node(carry_level * doing,
 				     carry_level * todo, const znode * node);
 
+extern carry_node *add_carry_atplace(carry_level *doing,
+				     carry_level *todo, znode *node);
+
+extern carry_node *find_begetting_brother(carry_node * node, carry_level * kin);
+
 extern carry_pool *init_carry_pool(void);
 extern void done_carry_pool(carry_pool * pool);
 
@@ -342,6 +351,8 @@ extern void init_carry_level(carry_level
 extern carry_op *post_carry(carry_level * level, carry_opcode op, znode * node, int apply_to_parent);
 extern carry_op *node_post_carry(carry_plugin_info * info, carry_opcode op, znode * node, int apply_to_parent_p);
 
+extern int carry_op_num(const carry_level * level);
+
 carry_node *add_new_znode(znode * brother, carry_node * reference, carry_level * doing, carry_level * todo);
 
 carry_node *find_carry_node(carry_level * level, const znode * node);
@@ -401,6 +412,18 @@ for( node = carry_node_back( level ),		\
      tmp = carry_node_prev( node ) ; ! carry_node_end( level, node ) ;		\
      node = tmp, tmp = carry_node_prev( node ) )
 
+/* debugging function */
+
+#if REISER4_DEBUG_OUTPUT
+extern void print_carry(const char *prefix, carry_node * node);
+extern void print_op(const char *prefix, carry_op * op);
+extern void print_level(const char *prefix, carry_level * level);
+#else
+#define print_carry( p, n ) noop
+#define print_op( p, o ) noop
+#define print_level( p, l ) noop
+#endif
+
 /* __FS_REISER4_CARRY_H__ */
 #endif
 
diff -puN carry_ops.c~profile-stat-trace-repacker carry_ops.c
--- reiser4/carry_ops.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/carry_ops.c	2005-02-01 11:51:11.000000000 +0300
@@ -62,6 +62,7 @@ find_left_neighbor(carry_op * op	/* node
 				assert("nikita-3408", !carry_node_end(doing,
 								      left));
 			} while (carry_real(left) == carry_real(node));
+			reiser4_stat_level_inc(doing, carry_left_in_carry);
 			return left;
 		}
 	}
@@ -86,9 +87,14 @@ find_left_neighbor(carry_op * op	/* node
 		result = lock_carry_node_tail(left);
 		if (result != 0)
 			left = ERR_PTR(result);
+		reiser4_stat_level_inc(doing, carry_left_in_cache);
 	} else if (result == -E_NO_NEIGHBOR || result == -ENOENT) {
 		/* node is leftmost node in a tree, or neighbor wasn't in
 		   cache, or there is an extent on the left. */
+		if (REISER4_STATS && (result == -ENOENT))
+			reiser4_stat_level_inc(doing, carry_left_missed);
+		if (REISER4_STATS && (result == -E_NO_NEIGHBOR))
+			reiser4_stat_level_inc(doing, carry_left_not_avail);
 		reiser4_pool_free(&doing->pool->node_pool, &left->header);
 		left = NULL;
 	} else if (doing->restartable) {
@@ -104,6 +110,7 @@ find_left_neighbor(carry_op * op	/* node
 		   ignore left neighbor. */
 		reiser4_pool_free(&doing->pool->node_pool, &left->header);
 		left = NULL;
+		reiser4_stat_level_inc(doing, carry_left_refuse);
 	}
 	return left;
 }
@@ -190,6 +197,7 @@ find_right_neighbor(carry_op * op	/* nod
 				assert("nikita-3408", !carry_node_end(doing,
 								      right));
 			} while (carry_real(right) == carry_real(node));
+			reiser4_stat_level_inc(doing, carry_right_in_carry);
 			return right;
 		}
 	}
@@ -205,6 +213,7 @@ find_right_neighbor(carry_op * op	/* nod
 					    ZNODE_WRITE_LOCK, flags);
 	if (result == 0) {
 		/* ok, node found and locked. */
+		reiser4_stat_level_inc(doing, carry_right_in_cache);
 		right = add_carry_skip(doing, POOLO_AFTER, node);
 		if (!IS_ERR(right)) {
 			right->node = lh.node;
@@ -218,6 +227,10 @@ find_right_neighbor(carry_op * op	/* nod
 		/* node is rightmost node in a tree, or neighbor wasn't in
 		   cache, or there is an extent on the right. */
 		right = NULL;
+		if (REISER4_STATS && (result == -ENOENT))
+			reiser4_stat_level_inc(doing, carry_right_missed);
+		if (REISER4_STATS && (result == -E_NO_NEIGHBOR))
+			reiser4_stat_level_inc(doing, carry_right_not_avail);
 	} else
 		right = ERR_PTR(result);
 	done_lh(&lh);
@@ -302,6 +315,8 @@ find_new_child_coord(carry_op * op	/* CO
 	assert("nikita-941", op != NULL);
 	assert("nikita-942", op->op == COP_INSERT);
 
+	trace_stamp(TRACE_CARRY);
+
 	node = carry_real(op->node);
 	assert("nikita-943", node != NULL);
 	assert("nikita-944", node_plugin_by_node(node) != NULL);
@@ -381,6 +396,9 @@ make_space_tail(carry_op * op, carry_lev
 		init_lh(doing->tracked);
 		result = longterm_lock_znode(doing->tracked, node,
 					     ZNODE_WRITE_LOCK, ZNODE_LOCK_HIPRI);
+		reiser4_stat_level_inc(doing, track_lh);
+		ON_TRACE(TRACE_CARRY, "tracking: %i: %p -> %p\n",
+			 tracking, orig_node, node);
 	} else
 		result = 0;
 	return result;
@@ -419,6 +437,8 @@ make_space(carry_op * op /* carry operat
 	assert("nikita-1607",
 	       carry_real(op->node) == op->u.insert.d->coord->node);
 
+	trace_stamp(TRACE_CARRY);
+
 	flags = op->u.insert.flags;
 
 	/* NOTE check that new node can only be allocated after checking left
@@ -451,6 +471,7 @@ make_space(carry_op * op /* carry operat
 		carry_node *left;
 		/* make note in statistics of an attempt to move
 		   something into the left neighbor */
+		reiser4_stat_level_inc(doing, insert_looking_left);
 		left = find_left_neighbor(op, doing);
 		if (unlikely(IS_ERR(left))) {
 			if (PTR_ERR(left) == -E_REPEAT)
@@ -490,6 +511,7 @@ make_space(carry_op * op /* carry operat
 	if (not_enough_space > 0 && !(flags & COPI_DONT_SHIFT_RIGHT)) {
 		carry_node *right;
 
+		reiser4_stat_level_inc(doing, insert_looking_right);
 		right = find_right_neighbor(op, doing);
 		if (IS_ERR(right)) {
 			warning("nikita-1065",
@@ -530,6 +552,10 @@ make_space(carry_op * op /* carry operat
 		unsigned int gointo;	/* whether insertion point should move
 					 * into newly allocated node */
 
+		reiser4_stat_level_inc(doing, insert_alloc_new);
+		if (blk_alloc > 0)
+			reiser4_stat_level_inc(doing, insert_alloc_many);
+
 		/* allocate new node on the right of @node. Znode and disk
 		   fake block number for new node are allocated.
 
@@ -668,6 +694,8 @@ insert_paste_common(carry_op * op	/* car
 	assert("nikita-980", todo != NULL);
 	assert("nikita-979", (op->op == COP_INSERT) || (op->op == COP_PASTE) || (op->op == COP_EXTENT));
 
+	trace_stamp(TRACE_CARRY);
+
 	if (op->u.insert.type == COPT_PASTE_RESTARTED) {
 		/* nothing to do. Fall through to make_space(). */
 		;
@@ -821,6 +849,9 @@ carry_insert(carry_op * op /* operation 
 	assert("nikita-1037", todo != NULL);
 	assert("nikita-1038", op->op == COP_INSERT);
 
+	trace_stamp(TRACE_CARRY);
+	reiser4_stat_level_inc(doing, insert);
+
 	coord_init_zero(&coord);
 
 	/* perform common functionality of insert and paste. */
@@ -1212,6 +1243,8 @@ carry_delete(carry_op * op /* operation 
 	assert("nikita-893", op != NULL);
 	assert("nikita-894", todo != NULL);
 	assert("nikita-895", op->op == COP_DELETE);
+	trace_stamp(TRACE_CARRY);
+	reiser4_stat_level_inc(doing, delete);
 
 	coord_init_zero(&coord);
 	coord_init_zero(&coord2);
@@ -1320,6 +1353,8 @@ carry_cut(carry_op * op /* operation to 
 	assert("nikita-896", op != NULL);
 	assert("nikita-897", todo != NULL);
 	assert("nikita-898", op->op == COP_CUT);
+	trace_stamp(TRACE_CARRY);
+	reiser4_stat_level_inc(doing, cut);
 
 	info.doing = doing;
 	info.todo = todo;
@@ -1443,6 +1478,9 @@ carry_paste(carry_op * op /* operation t
 	assert("nikita-983", todo != NULL);
 	assert("nikita-984", op->op == COP_PASTE);
 
+	trace_stamp(TRACE_CARRY);
+	reiser4_stat_level_inc(doing, paste);
+
 	coord_init_zero(&dcoord);
 
 	result = insert_paste_common(op, doing, todo, &cdata, &dcoord, &data);
@@ -1456,6 +1494,7 @@ carry_paste(carry_op * op /* operation t
 	if (!can_paste(coord, op->u.insert.d->key, op->u.insert.d->data)) {
 		op->op = COP_INSERT;
 		op->u.insert.type = COPT_PASTE_RESTARTED;
+		reiser4_stat_level_inc(doing, paste_restarted);
 		result = op_dispatch_table[COP_INSERT].handler(op, doing, todo);
 
 		return result;
@@ -1521,6 +1560,9 @@ carry_extent(carry_op * op /* operation 
 	assert("nikita-1752", todo != NULL);
 	assert("nikita-1753", op->op == COP_EXTENT);
 
+	trace_stamp(TRACE_CARRY);
+	reiser4_stat_level_inc(doing, extent);
+
 	/* extent insertion overview:
 
 	   extents live on the TWIG LEVEL, which is level one above the leaf
@@ -1737,6 +1779,8 @@ carry_update(carry_op * op /* operation 
 	assert("nikita-902", op != NULL);
 	assert("nikita-903", todo != NULL);
 	assert("nikita-904", op->op == COP_UPDATE);
+	trace_stamp(TRACE_CARRY);
+	reiser4_stat_level_inc(doing, update);
 
 	lchild = op->u.update.left;
 	rchild = op->node;
@@ -1751,6 +1795,21 @@ carry_update(carry_op * op /* operation 
 	tree = znode_get_tree(rchild->node);
 	RLOCK_TREE(tree);
 	right = znode_parent(rchild->node);
+	if (REISER4_STATS) {
+		znode *old_right;
+		if (rchild != NULL) {
+			assert("nikita-1000", rchild->parent);
+			assert("nikita-1002", !rchild->left);
+			old_right = carry_real(rchild);
+		} else
+			old_right = NULL;
+		if (znode_parent(rchild->node) != old_right)
+			/* parent node was split, and pointer to @rchild was
+			   inserted/moved into new node. Wonders of balkancing
+			   (sic.).
+			*/
+			reiser4_stat_level_inc(doing, half_split_race);
+	}
 	RUNLOCK_TREE(tree);
 
 	if (right != NULL) {
diff -puN cluster.h~profile-stat-trace-repacker cluster.h
--- reiser4/cluster.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/cluster.h	2005-02-01 11:51:11.000000000 +0300
@@ -193,13 +193,13 @@ fsize_to_count(reiser4_cluster_t * clust
 static inline void
 reiser4_slide_init (reiser4_slide_t * win){
 	assert("edward-1084", win != NULL);
-	memset(win, 0, sizeof *win);
+	xmemset(win, 0, sizeof *win);
 }
 
 static inline void
 reiser4_cluster_init (reiser4_cluster_t * clust, reiser4_slide_t * window){
 	assert("edward-84", clust != NULL);
-	memset(clust, 0, sizeof *clust);
+	xmemset(clust, 0, sizeof *clust);
 	clust->dstat = INVAL_DISK_CLUSTER;
 	clust->win = window;
 }
@@ -219,6 +219,10 @@ set_dc_item_stat(hint_t * hint, dc_item_
 }
 
 int inflate_cluster(reiser4_cluster_t *, struct inode *);
+int find_cluster_item(hint_t * hint, const reiser4_key *key, int check_key,
+		      znode_lock_mode lock_mode, ra_info_t *ra_info,
+		      lookup_bias bias, __u32 flags);
+int page_of_cluster(struct page *, reiser4_cluster_t *, struct inode *);
 int find_cluster(reiser4_cluster_t *, struct inode *, int read, int write);
 void forget_cluster_pages(struct page ** page, int nrpages);
 int flush_cluster_pages(reiser4_cluster_t *, jnode *, struct inode *);
diff -puN context.c~profile-stat-trace-repacker context.c
--- reiser4/context.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/context.c	2005-02-01 11:51:11.000000000 +0300
@@ -40,10 +40,9 @@
 #include <linux/writeback.h> /* balance_dirty_pages() */
 #include <linux/hardirq.h>
 
-#if REISER4_DEBUG
-
+#if REISER4_DEBUG_CONTEXTS
 /* List of all currently active contexts, used for debugging purposes.  */
-static context_list_head active_contexts;
+context_list_head active_contexts;
 /* lock protecting access to active_contexts. */
 spinlock_t active_contexts_lock;
 
@@ -58,8 +57,8 @@ check_contexts(void)
 	}
 	spin_unlock(&active_contexts_lock);
 }
-
-#endif /* REISER4_DEBUG */
+/* REISER4_DEBUG_CONTEXTS */
+#endif
 
 /* initialise context and bind it to the current thread
 
@@ -77,7 +76,7 @@ init_context(reiser4_context * context	/
 	assert("nikita-3357", super != NULL);
 	assert("nikita-3358", super->s_op == NULL || is_reiser4_super(super));
 
-	memset(context, 0, sizeof *context);
+	xmemset(context, 0, sizeof *context);
 
 	if (is_in_reiser4_context()) {
 		reiser4_context *parent;
@@ -105,12 +104,14 @@ init_context(reiser4_context * context	/
 	context->parent = context;
 	tap_list_init(&context->taps);
 #if REISER4_DEBUG
+#if REISER4_DEBUG_CONTEXTS
 	context_list_clean(context);	/* to satisfy assertion */
 	spin_lock(&active_contexts_lock);
 	context_list_check(&active_contexts);
 	context_list_push_front(&active_contexts, context);
 	/*check_contexts();*/
 	spin_unlock(&active_contexts_lock);
+#endif
 	context->task = current;
 #endif
 	grab_space_enable();
@@ -243,7 +244,7 @@ done_context(reiser4_context * context /
 		spin_lock_stack(&context->stack);
 		spin_unlock_stack(&context->stack);
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_CONTEXTS
 		/* remove from active contexts */
 		spin_lock(&active_contexts_lock);
 		/*check_contexts();*/
@@ -265,29 +266,35 @@ done_context(reiser4_context * context /
 reiser4_internal int
 init_context_mgr(void)
 {
-#if REISER4_DEBUG
+#if REISER4_DEBUG_CONTEXTS
 	spin_lock_init(&active_contexts_lock);
 	context_list_init(&active_contexts);
 #endif
 	return 0;
 }
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 /* debugging function: output reiser4 context contexts in the human readable
  * form  */
-static void
+reiser4_internal void
 print_context(const char *prefix, reiser4_context * context)
 {
 	if (context == NULL) {
 		printk("%s: null context\n", prefix);
 		return;
 	}
+#if REISER4_TRACE
+	printk("%s: trace_flags: %x\n", prefix, context->trace_flags);
+#endif
 	print_lock_counters("\tlocks", &context->locks);
+#if REISER4_DEBUG
 	printk("pid: %i, comm: %s\n", context->task->pid, context->task->comm);
+#endif
 	print_lock_stack("\tlock stack", &context->stack);
 	info_atom("\tatom", context->trans_in_ctx.atom);
 }
 
+#if REISER4_DEBUG_CONTEXTS
 /* debugging: dump contents of all active contexts */
 void
 print_contexts(void)
@@ -302,7 +309,7 @@ print_contexts(void)
 
 	spin_unlock(&active_contexts_lock);
 }
-
+#endif
 #endif
 
 /* Make Linus happy.
diff -puN context.h~profile-stat-trace-repacker context.h
--- reiser4/context.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/context.h	2005-02-01 11:51:11.000000000 +0300
@@ -20,7 +20,7 @@
 #include <linux/sched.h>	/* for struct task_struct */
 
 /* list of active lock stacks */
-#if REISER4_DEBUG
+#if REISER4_DEBUG_CONTEXTS
 TYPE_SAFE_LIST_DECLARE(context);
 #endif
 
@@ -136,6 +136,9 @@ struct reiser4_context {
 	/* how many disk blocks were grabbed by the first call to
 	 * reiser4_grab_space() in this context */
 	reiser4_block_nr grabbed_initially;
+	/* stack back-trace of the first call to reiser4_grab_space() in this
+	 * context */
+	backtrace_path   grabbed_at;
 
 	/* list of all threads doing flush currently */
 	flushers_list_link  flushers_link;
@@ -144,10 +147,26 @@ struct reiser4_context {
 	/* information about delayed stat data updates. See above. */
 	dirty_inode_info dirty;
 #endif
+
+#if REISER4_TRACE
+	/* per-thread tracing flags. Use reiser4_trace_flags enum to set
+	   bits in it. */
+	__u32 trace_flags;
+#endif
+#if REISER4_DEBUG_NODE
+	/*
+	 * don't perform node consistency checks while this is greater than
+	 * zero. Used during operations that temporary violate node
+	 * consistency.
+	 */
+	int disable_node_check;
+#endif
 };
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_CONTEXTS
 TYPE_SAFE_LIST_DEFINE(context, reiser4_context, contexts_link);
+#endif
+#if REISER4_DEBUG
 TYPE_SAFE_LIST_DEFINE(flushers, reiser4_context, flushers_link);
 #endif
 
@@ -155,8 +174,22 @@ extern reiser4_context *get_context_by_l
 
 /* Debugging helps. */
 extern int init_context_mgr(void);
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
+extern void print_context(const char *prefix, reiser4_context * ctx);
+#else
+#define print_context(p,c) noop
+#endif
+
+#if REISER4_DEBUG_CONTEXTS && REISER4_DEBUG_OUTPUT
 extern void print_contexts(void);
+#else
+#define print_contexts() noop
+#endif
+
+#if REISER4_DEBUG_CONTEXTS
+extern void check_contexts(void);
+#else
+#define check_contexts() noop
 #endif
 
 #define current_tree (&(get_super_private(reiser4_get_current_sb())->tree))
diff -puN coord.c~profile-stat-trace-repacker coord.c
--- reiser4/coord.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/coord.c	2005-02-01 11:51:11.000000000 +0300
@@ -167,7 +167,7 @@ coord_init_after_item(coord_t * coord)
 reiser4_internal void
 coord_init_zero(coord_t * coord)
 {
-	memset(coord, 0, sizeof (*coord));
+	xmemset(coord, 0, sizeof (*coord));
 }
 
 /* Return the number of units at the present item.  Asserts coord_is_existing_item(). */
@@ -206,6 +206,7 @@ coord_is_existing_item(const coord_t * c
 		return coord->item_pos < coord_num_items(coord);
 	}
 
+	IF_TRACE(TRACE_COORDS, print_coord("unreachable", coord, 0));
 	impossible("jmacd-9900", "unreachable coord: %p", coord);
 	return 0;
 }
@@ -611,6 +612,49 @@ coords_equal(const coord_t * c1, const c
 		c1->between == c2->between;
 }
 
+/* Returns true if two coordinates are consider equal.  Coordinates that are between units
+   or items are considered equal. */
+/* Audited by: green(2002.06.15) */
+reiser4_internal int
+coord_eq(const coord_t * c1, const coord_t * c2)
+{
+	assert("nikita-1807", c1 != NULL);
+	assert("nikita-1808", c2 != NULL);
+
+	if (coords_equal(c1, c2)) {
+		return 1;
+	}
+	if (c1->node != c2->node) {
+		return 0;
+	}
+
+	switch (c1->between) {
+	case INVALID_COORD:
+	case EMPTY_NODE:
+	case AT_UNIT:
+		return 0;
+
+	case BEFORE_UNIT:
+		/* c2 must be after the previous unit. */
+		return (c1->item_pos == c2->item_pos && c2->between == AFTER_UNIT && c2->unit_pos == c1->unit_pos - 1);
+
+	case AFTER_UNIT:
+		/* c2 must be before the next unit. */
+		return (c1->item_pos == c2->item_pos && c2->between == BEFORE_UNIT && c2->unit_pos == c1->unit_pos + 1);
+
+	case BEFORE_ITEM:
+		/* c2 must be after the previous item. */
+		return (c1->item_pos == c2->item_pos - 1 && c2->between == AFTER_ITEM);
+
+	case AFTER_ITEM:
+		/* c2 must be before the next item. */
+		return (c1->item_pos == c2->item_pos + 1 && c2->between == BEFORE_ITEM);
+	}
+
+	impossible("jmacd-9906", "unreachable");
+	return 0;
+}
+
 /* If coord_is_after_rightmost return NCOORD_ON_THE_RIGHT, if coord_is_after_leftmost
    return NCOORD_ON_THE_LEFT, otherwise return NCOORD_INSIDE. */
 /* Audited by: green(2002.06.15) */
diff -puN coord.h~profile-stat-trace-repacker coord.h
--- reiser4/coord.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/coord.h	2005-02-01 11:51:11.000000000 +0300
@@ -215,6 +215,10 @@ coord_update_v(coord_t * coord)
 
 extern int coords_equal(const coord_t * c1, const coord_t * c2);
 
+/* Returns true if two coordinates are consider equal.  Coordinates that are between units
+   or items are considered equal. */
+extern int coord_eq(const coord_t * c1, const coord_t * c2);
+
 extern void print_coord(const char *mes, const coord_t * coord, int print_node);
 
 /* If coord_is_after_rightmost return NCOORD_ON_THE_RIGHT, if coord_is_after_leftmost
@@ -313,7 +317,7 @@ extern int coord_sideof_unit(coord_t * c
 	for( coord_init_before_first_item( ( coord ), ( node ) ) ; 	\
 	     coord_next_item( coord ) == 0 ; )
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 extern const char *coord_tween_tostring(between_enum n);
 #endif
 
diff -puN debug.c~profile-stat-trace-repacker debug.c
--- reiser4/debug.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/debug.c	2005-02-01 11:51:11.000000000 +0300
@@ -28,6 +28,7 @@
  *
  */
 
+#include "kattr.h"
 #include "reiser4.h"
 #include "context.h"
 #include "super.h"
@@ -45,12 +46,6 @@
 #include <linux/sysctl.h>
 #include <linux/hardirq.h>
 
-#if REISER4_DEBUG
-static void report_err(void);
-#else
-#define report_err() noop
-#endif
-
 /*
  * global buffer where message given to reiser4_panic is formatted.
  */
@@ -97,7 +92,6 @@ reiser4_do_panic(const char *format /* f
 		 */
 		DEBUGON(1);
 
-#if REISER4_DEBUG
 		if (get_current_context_check() != NULL) {
 			struct super_block *super;
 			reiser4_context *ctx;
@@ -107,15 +101,16 @@ reiser4_do_panic(const char *format /* f
 			 */
 
 			/* lock counters... */
-			ON_DEBUG(print_lock_counters("pins held", lock_counters()));
+			print_lock_counters("pins held", lock_counters());
 			/* other active contexts... */
-			ON_DEBUG(print_contexts());
+			print_contexts();
 			ctx = get_current_context();
 			super = ctx->super;
 			if (get_super_private(super) != NULL &&
 			    reiser4_is_debugged(super, REISER4_VERBOSE_PANIC))
 				/* znodes... */
 				print_znodes("znodes", current_tree);
+#if REISER4_DEBUG_CONTEXTS
 			{
 				extern spinlock_t active_contexts_lock;
 
@@ -130,8 +125,8 @@ reiser4_do_panic(const char *format /* f
 				context_list_remove(ctx->parent);
 				spin_unlock(&active_contexts_lock);
 			}
-		}
 #endif
+		}
 	}
 	BUG();
 	/* to make gcc happy about noreturn attribute */
@@ -184,7 +179,7 @@ int schedulable(void)
 }
 #endif
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_SPIN_LOCKS
 /* Debugging aid: return struct where information about locks taken by current
    thread is accumulated. This can be used to formulate lock ordering
    constraints and various assertions.
@@ -198,6 +193,7 @@ lock_counters(void)
 	return &ctx->locks;
 }
 
+#if REISER4_DEBUG_OUTPUT
 /*
  * print human readable information about locks held by the reiser4 context.
  */
@@ -303,10 +299,23 @@ commit_check_locks(void)
 	return result;
 }
 
-/* REISER4_DEBUG */
+/* REISER4_DEBUG_OUTPUT */
+#endif
+
+/* REISER4_DEBUG_SPIN_LOCKS */
 #endif
 
 /*
+ * check that all bits specified by @flags are set in ->debug_flags of the
+ * super block.
+ */
+reiser4_internal int
+reiser4_are_all_debugged(struct super_block *super, __u32 flags)
+{
+	return (get_super_private(super)->debug_flags & flags) == flags;
+}
+
+/*
  * check that some bits specified by @flags are set in ->debug_flags of the
  * super block.
  */
@@ -316,6 +325,55 @@ reiser4_is_debugged(struct super_block *
 	return get_super_private(super)->debug_flags & flag;
 }
 
+#if REISER4_TRACE
+/* tracing setup: global trace flags stored in global variable plus
+   per-thread trace flags plus per-fs trace flags.
+   */
+__u32 get_current_trace_flags(void)
+{
+	__u32 flags;
+	reiser4_context *ctx;
+
+	flags = 0;
+	ctx = get_current_context_check();
+	if (ctx) {
+		flags |= ctx->trace_flags;
+		flags |= get_super_private(ctx->super)->trace_flags;
+	}
+	return flags;
+}
+#endif
+
+#if REISER4_LOG
+
+/* log flags are stored in super block */
+__u32 get_current_log_flags(void)
+{
+	__u32 flags;
+	reiser4_context *ctx;
+
+	flags = 0;
+	ctx = get_current_context_check();
+	if (ctx)
+		flags = get_super_private(ctx->super)->log_flags;
+	return flags;
+}
+
+/* oid of file page events of which are to be logged */
+__u32 get_current_oid_to_log(void)
+{
+	__u32 oid;
+	reiser4_context *ctx;
+
+	oid = 0;
+	ctx = get_current_context_check();
+	if (ctx)
+		oid = get_super_private(ctx->super)->oid_to_log;
+	return oid;
+}
+
+#endif
+
 /* allocate memory. This calls kmalloc(), performs some additional checks, and
    keeps track of how many memory was allocated on behalf of current super
    block. */
@@ -328,17 +386,20 @@ reiser4_kmalloc(size_t size /* number of
 	assert("nikita-3009", ergo(gfp_flag & __GFP_WAIT, schedulable()));
 
 	result = kmalloc(size, gfp_flag);
-#if REISER4_DEBUG
-	if (result != NULL) {
+	if (REISER4_DEBUG && result != NULL) {
+		unsigned int usedsize;
 		reiser4_super_info_data *sbinfo;
 
+		usedsize = ksize(result);
+
 		sbinfo = get_current_super_private();
+
+		assert("nikita-3459", usedsize >= size);
 		assert("nikita-1407", sbinfo != NULL);
 		reiser4_spin_lock_sb(sbinfo);
-		sbinfo->kmallocs ++;
+		ON_DEBUG(sbinfo->kmalloc_allocated += usedsize);
 		reiser4_spin_unlock_sb(sbinfo);
 	}
-#endif
 	return result;
 }
 
@@ -357,20 +418,30 @@ reiser4_internal void
 reiser4_kfree_in_sb(void *area /* memory to from */, struct super_block *sb)
 {
 	assert("nikita-2729", area != NULL);
-#if REISER4_DEBUG
-	{
+	if (REISER4_DEBUG) {
+		unsigned int size;
 		reiser4_super_info_data *sbinfo;
 
+		size = ksize(area);
+
 		sbinfo = get_super_private(sb);
+
 		reiser4_spin_lock_sb(sbinfo);
-		assert("nikita-2730", sbinfo->kmallocs > 0);
-		sbinfo->kmallocs --;
+		assert("nikita-2730", sbinfo->kmalloc_allocated >= (int) size);
+		ON_DEBUG(sbinfo->kmalloc_allocated -= size);
 		reiser4_spin_unlock_sb(sbinfo);
 	}
-#endif
 	kfree(area);
 }
 
+
+#if defined(CONFIG_REISER4_NOOPT)
+void __you_cannot_kmalloc_that_much(void)
+{
+	BUG();
+}
+#endif
+
 #if REISER4_DEBUG
 
 /*
@@ -384,6 +455,8 @@ return_err(int code, const char *file, i
 		reiser4_context *ctx = get_current_context();
 
 		if (ctx != NULL) {
+			fill_backtrace(&ctx->err.path,
+				       REISER4_BACKTRACE_DEPTH, 0);
 			ctx->err.code = code;
 			ctx->err.file = file;
 			ctx->err.line = line;
@@ -394,20 +467,148 @@ return_err(int code, const char *file, i
 /*
  * report error information recorder by return_err().
  */
-static void
+void
 report_err(void)
 {
 	reiser4_context *ctx = get_current_context_check();
 
 	if (ctx != NULL) {
 		if (ctx->err.code != 0) {
+#ifdef CONFIG_FRAME_POINTER
+			int i;
+			for (i = 0; i < REISER4_BACKTRACE_DEPTH ; ++ i)
+				printk("0x%p ", ctx->err.path.trace[i]);
+			printk("\n");
+#endif
 			printk("code: %i at %s:%i\n",
 			       ctx->err.code, ctx->err.file, ctx->err.line);
 		}
 	}
 }
 
-#endif /* REISER4_DEBUG */
+#ifdef CONFIG_FRAME_POINTER
+
+extern int kswapd(void *);
+
+#include <linux/personality.h>
+#include "ktxnmgrd.h"
+#include "repacker.h"
+
+/*
+ * true iff @addr is between @start and @end
+ */
+static int is_addr_in(void *addr, void *start, void *end)
+{
+	return start < addr && addr < end;
+}
+
+/*
+ * stack back-tracing. Also see comments before REISER4_BACKTRACE_DEPTH in
+ * debug.h.
+ *
+ * Stack beck-trace is collected through __builtin_return_address() gcc
+ * builtin, which requires kernel to be compiled with frame pointers
+ * (CONFIG_FRAME_POINTER). Unfortunately, __builtin_return_address() doesn't
+ * provide means to detect when bottom of the stack is reached, and just
+ * crashed when trying to access non-existent frame.
+ *
+ * is_last_frame() function works around this (also see more advanced version
+ * in the proc-sleep patch that requires modification of core kernel code).
+ *
+ * This functions checks for common cases trying to detect that last stack
+ * frame was reached.
+ */
+static int is_last_frame(void *addr)
+{
+	if (addr == NULL)
+		return 1;
+	if (is_addr_in(addr, kswapd, wakeup_kswapd))
+		return 1;
+	else if (is_addr_in(addr, reiser4_repacker, repacker_d))
+		return 1;
+	else if (is_addr_in(addr, init_ktxnmgrd_context, ktxnmgrd_kick))
+		return 1;
+	else if (is_addr_in(addr, init_entd_context, done_entd_context))
+		return 1;
+	else if (!kernel_text_address((unsigned long)addr))
+		return 1;
+	else
+		return 0;
+}
+
+/*
+ * fill stack back-trace.
+ */
+reiser4_internal void
+fill_backtrace(backtrace_path *path, int depth, int shift)
+{
+	int i;
+	void *addr;
+
+	cassert(REISER4_BACKTRACE_DEPTH == 4);
+	assert("nikita-3229", shift < 6);
+
+	/* long live Duff! */
+
+#define FRAME(nr)						\
+	case (nr):						\
+		addr  = __builtin_return_address((nr) + 2);	\
+		break
+
+	xmemset(path, 0, sizeof *path);
+	addr = NULL;
+	/*
+	 * we need this silly loop, because __builtin_return_address() only
+	 * accepts _constant_ arguments. It reminds of the duff device
+	 * (http://www.faqs.org/docs/jargon/D/Duff's-device.html) which
+	 * explains the reference above.
+	 */
+	for (i = 0; i < depth; ++ i) {
+		switch(i + shift) {
+			FRAME(0);
+			FRAME(1);
+			FRAME(2);
+			FRAME(3);
+			FRAME(4);
+			FRAME(5);
+			FRAME(6);
+			FRAME(7);
+			FRAME(8);
+			FRAME(9);
+			FRAME(10);
+		default:
+			impossible("nikita-3230", "everything is wrong");
+		}
+		path->trace[i] = addr;
+		if (is_last_frame(addr))
+			break;
+	}
+}
+#endif
+
+/*
+ * assert() macro calls this function on each invocation. This is convenient
+ * place to put some debugging code that has to be executed very
+ * frequently. _Very_.
+ */
+void call_on_each_assert(void)
+{
+	return;
+	/*
+	 * DON'T USE ASSERTIONS HERE :)
+	 */
+	if (is_in_reiser4_context()) {
+		reiser4_super_info_data *sinfo;
+		reiser4_context *ctx;
+
+		ctx = (reiser4_context *) current->journal_info;
+		sinfo = ctx->super->s_fs_info;
+		/* put checks here */
+	}
+}
+
+/* REISER4_DEBUG */
+#endif
 
 #if KERNEL_DEBUGGER
 /*
@@ -424,6 +625,102 @@ void debugtrap(void)
 }
 #endif
 
+
+/* debugging tool
+   use clog_op to make a record
+   use print_clog to see last CLOG_LENGTH record
+ */
+#define CLOG_LENGTH 256
+static spinlock_t clog_lock = SPIN_LOCK_UNLOCKED;
+
+typedef struct {
+	int id;
+	pid_t pid;
+	int op;
+	void *data1;
+	void *data2;
+} clog_t;
+
+clog_t clog[CLOG_LENGTH];
+
+int clog_start = 0;
+int clog_length = 0;
+int clog_id = 0;
+
+void
+clog_op(int op, void *data1, void *data2)
+{
+	int slot;
+
+	spin_lock(&clog_lock);
+
+	if (clog_length == CLOG_LENGTH) {
+		slot = clog_start;
+
+		clog_start ++;
+		clog_start %= CLOG_LENGTH;
+	} else {
+		assert("vs-1672", clog_start == 0);
+
+		slot = clog_length;
+
+		clog_length ++;
+	}
+	assert("vs-1718", slot < CLOG_LENGTH && slot >= 0);
+	clog[slot].id = clog_id ++;
+	clog[slot].op = op;
+	clog[slot].pid = current->pid;
+	clog[slot].data1 = data1;
+	clog[slot].data2 = data2;
+
+	spin_unlock(&clog_lock);
+}
+
+static const char *
+op2str(int op)
+{
+	static const char *op_names[OP_NUM] = {
+		"unmap",
+		"add-rmap",
+		"get-user-page"
+	};
+	assert("vs-1673", op < OP_NUM);
+	return op_names[op];
+}
+
+void
+print_clog(void)
+{
+	int i, j;
+
+	j = clog_start;
+	for (i = 0; i < clog_length; i ++) {
+		printk("%d(%d): id %d: pid %d, op %s, "
+		       "data1 %u, data2 %u\n",
+		       i, j, clog[j].id, clog[j].pid, op2str(clog[j].op),
+		       (unsigned)clog[j].data1, (unsigned)clog[j].data2);
+		j ++;
+		j %= CLOG_LENGTH;
+	}
+	printk("clog length %d\n", clog_length);
+}
+
+#if 0
+void
+print_symname(unsigned long address)
+{
+	char         *module;
+	const char   *name;
+	char          namebuf[128];
+	unsigned long offset;
+	unsigned long size;
+
+	name = kallsyms_lookup(address, &size, &offset, &module, namebuf);
+	if (name != NULL)
+		printk("  %s[%lx/%lx]", name, offset, size);
+}
+#endif
+
 /* Make Linus happy.
    Local variables:
    c-indentation-style: "K&R"
diff -puN debug.h~profile-stat-trace-repacker debug.h
--- reiser4/debug.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/debug.h	2005-02-01 11:51:11.000000000 +0300
@@ -61,6 +61,7 @@
 		 * warnings for things like assert(a = b); */			\
 		;								\
 	} else {								\
+		print_clog();							\
 		DEBUGON(1);							\
 		reiser4_panic(label, "assertion failed: %s", #cond);		\
 	}									\
@@ -86,7 +87,7 @@ extern void call_on_each_assert(void);
 /* REISER4_DEBUG */
 #endif
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_SPIN_LOCKS
 /* per-thread information about lock acquired by this thread. Used by lock
  * ordering checking in spin_macros.h */
 typedef struct lock_counters_info {
@@ -145,20 +146,52 @@ extern lock_counters_info *lock_counters
  * assertions */
 #define LOCK_CNT_GTZ(counter) IN_CONTEXT(lock_counters()->counter > 0, 1)
 
-#else /* REISER4_DEBUG */
+/* REISER4_DEBUG_SPIN_LOCKS */
+#else
 
 /* no-op versions on the above */
 
 typedef struct lock_counters_info {
 } lock_counters_info;
-
 #define lock_counters() ((lock_counters_info *)NULL)
 #define LOCK_CNT_INC(counter) noop
 #define LOCK_CNT_DEC(counter) noop
 #define LOCK_CNT_NIL(counter) (1)
 #define LOCK_CNT_GTZ(counter) (1)
+/* REISER4_DEBUG_SPIN_LOCKS */
+#endif
+
+/*
+ * back-trace recording. In several places in reiser4 we want to record stack
+ * back-trace for debugging purposes. This functionality is only supported
+ * when kernel was configured with CONFIG_FRAME_POINTER option.
+ */
 
-#endif /* REISER4_DEBUG */
+#ifdef CONFIG_FRAME_POINTER
+
+/*
+ * how many stack frames to record in back-trace.
+ *
+ * update debug.c:fill_backtrace() if you change this
+ */
+#define REISER4_BACKTRACE_DEPTH (4)
+
+/*
+ * data type to store stack back-trace
+ */
+typedef struct {
+	void *trace[REISER4_BACKTRACE_DEPTH];
+} backtrace_path;
+
+extern void fill_backtrace(backtrace_path *path, int depth, int shift);
+#else
+
+/* no-op versions on the above */
+
+typedef struct {} backtrace_path;
+#define fill_backtrace(path, depth, shift) noop
+
+#endif
 
 
 /* flags controlling debugging behavior. Are set through debug_flags=N mount
@@ -176,6 +209,7 @@ typedef enum {
 	REISER4_CHECK_NODE = 0x00000008
 } reiser4_debug_flags;
 
+extern int reiser4_are_all_debugged(struct super_block *super, __u32 flags);
 extern int reiser4_is_debugged(struct super_block *super, __u32 flag);
 
 extern int is_in_reiser4_context(void);
@@ -194,6 +228,15 @@ extern int is_in_reiser4_context(void);
  */
 #define ON_DEBUG_CONTEXT( e ) ON_DEBUG( ON_CONTEXT( e ) )
 
+#if REISER4_DEBUG_MODIFY
+/*
+ * evaluate expression @exp only if REISER4_DEBUG_MODIFY mode is on.
+ */
+#define ON_DEBUG_MODIFY( exp ) exp
+#else
+#define ON_DEBUG_MODIFY( exp )
+#endif
+
 /*
  * complain about unexpected function result and crash. Used in "default"
  * branches of switch statements and alike to assert that invalid results are
@@ -211,6 +254,125 @@ extern int is_in_reiser4_context(void);
 #define not_yet( label, format, ... )				\
 	reiser4_panic( label, "NOT YET IMPLEMENTED: " format , ## __VA_ARGS__ )
 
+#if REISER4_TRACE
+/* helper macro for tracing, see trace_stamp() below. */
+#define IF_TRACE(flags, e) 							\
+	if(get_current_trace_flags() & (flags)) e
+#else
+#define IF_TRACE(flags, e) noop
+#endif
+
+/* just print where we are: file, function, line */
+#define trace_stamp( f )   IF_TRACE( f, reiser4_log( "trace", "" ) )
+/* print value of "var" */
+#define trace_var( f, format, var ) 				\
+        IF_TRACE( f, reiser4_log( "trace", #var ": " format, var ) )
+/* print output only if appropriate trace flag(s) is on */
+#define ON_TRACE( f, ... )   IF_TRACE(f, printk(__VA_ARGS__))
+
+/* tracing flags. */
+typedef enum {
+	/* trace nothing */
+	NO_TRACE = 0,
+	/* trace vfs interaction functions from vfs_ops.c */
+	TRACE_VFS_OPS = (1 << 0),	/* 0x00000001 */
+	/* trace plugin handling functions */
+	TRACE_PLUGINS = (1 << 1),	/* 0x00000002 */
+	/* trace tree traversals */
+	TRACE_TREE = (1 << 2),	/* 0x00000004 */
+	/* trace znode manipulation functions */
+	TRACE_ZNODES = (1 << 3),	/* 0x00000008 */
+	/* trace node layout functions */
+	TRACE_NODES = (1 << 4),	/* 0x00000010 */
+	/* trace directory functions */
+	TRACE_DIR = (1 << 5),	/* 0x00000020 */
+	/* trace flush code verbosely */
+	TRACE_FLUSH_VERB = (1 << 6),	/* 0x00000040 */
+	/* trace flush code */
+	TRACE_FLUSH = (1 << 7),	/* 0x00000080 */
+	/* trace carry */
+	TRACE_CARRY = (1 << 8),	/* 0x00000100 */
+	/* trace how tree (web) of znodes if maintained through tree
+	   balancings. */
+	TRACE_ZWEB = (1 << 9),	/* 0x00000200 */
+	/* trace transactions. */
+	TRACE_TXN = (1 << 10),	/* 0x00000400 */
+	/* trace object id allocation/releasing */
+	TRACE_OIDS = (1 << 11),	/* 0x00000800 */
+	/* trace item shifts */
+	TRACE_SHIFT = (1 << 12),	/* 0x00001000 */
+	/* trace page cache */
+	TRACE_PCACHE = (1 << 13),	/* 0x00002000 */
+	/* trace extents */
+	TRACE_EXTENTS = (1 << 14),	/* 0x00004000 */
+	/* trace locks */
+	TRACE_LOCKS = (1 << 15),	/* 0x00008000 */
+	/* trace coords */
+	TRACE_COORDS = (1 << 16),	/* 0x00010000 */
+	/* trace read-IO functions */
+	TRACE_IO_R = (1 << 17),	/* 0x00020000 */
+	/* trace write-IO functions */
+	TRACE_IO_W = (1 << 18),	/* 0x00040000 */
+
+	/* trace log writing */
+	TRACE_LOG = (1 << 19),	/* 0x00080000 */
+
+	/* trace journal replaying */
+	TRACE_REPLAY = (1 << 20),	/* 0x00100000 */
+
+	/* trace space allocation */
+	TRACE_ALLOC = (1 << 21),	/* 0x00200000 */
+
+	/* trace space reservation */
+	TRACE_RESERVE = (1 << 22),	/* 0x00400000 */
+
+	/* trace emergency flush */
+	TRACE_EFLUSH  = (1 << 23),	/* 0x00800000 */
+
+	/* trace ctails */
+	TRACE_CTAIL = (1 << 24),       /* 0x01000000 */
+
+	TRACE_PARSE = (1 << 25),       /* 0x02000000 */
+
+	TRACE_CAPTURE_COPY = (1 << 26), /* 0x04000000 */
+
+	TRACE_EXTENT_ALLOC = (1 << 27),      /* 0x08000000 */
+
+	TRACE_CAPTURE_ANONYMOUS = (1 << 28), /* 0x10000000 */
+
+	TRACE_UNIX_FILE_OPS = (1 << 29), /* 0x20000000 */
+
+	/* vague section: used to trace bugs. Use it to issue optional prints
+	   at arbitrary points of code. */
+	TRACE_BUG = (1 << 31),	/* 0x80000000 */
+
+	/* trace everything above */
+	TRACE_ALL = 0xffffffffu
+} reiser4_trace_flags;
+
+#if REISER4_LOG
+/* helper macro for tracing, see trace_stamp() below. */
+#define IF_LOG(flags, e) 							\
+	if(get_current_log_flags() & (flags)) e
+#else
+#define IF_LOG(flags, e) noop
+#endif
+
+/* log only if appropriate log flag(s) is on */
+#define ON_LOG( f, ... )   IF_LOG(f, printk(__VA_ARGS__))
+
+typedef enum {
+	WRITE_NODE_LOG = (1 << 0),      /* log [zj]node operations */
+	WRITE_PAGE_LOG = (1 << 1),	/* log make_extent calls */
+	WRITE_IO_LOG = (1 << 2), 	/* log i/o requests */
+	WRITE_TREE_LOG = (1 << 3), 	/* log internal tree operations */
+	WRITE_SYSCALL_LOG = (1 << 4),   /* log system calls */
+	READAHEAD_LOG = (1 << 5),       /* log read-ahead activity */
+	ALLOC_EXTENT_LOG = (1 << 6),    /* log extent allocation */
+	LOG_FILE_PAGE_EVENT = (1 << 7)	/* log events happened to certain file */
+} reiser4_log_flags;
+
+
 extern void reiser4_do_panic(const char *format, ...)
 __attribute__ ((noreturn, format(printf, 1, 2)));
 
@@ -224,17 +386,33 @@ extern void reiser4_print_stats(void);
 extern void *reiser4_kmalloc(size_t size, int gfp_flag);
 extern void reiser4_kfree(void *area);
 extern void reiser4_kfree_in_sb(void *area, struct super_block *sb);
+extern __u32 get_current_trace_flags(void);
+extern __u32 get_current_log_flags(void);
+extern __u32 get_current_oid_to_log(void);
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT && REISER4_DEBUG_SPIN_LOCKS
 extern void print_lock_counters(const char *prefix,
-                                const lock_counters_info * info);
+				const lock_counters_info * info);
 extern int no_counters_are_held(void);
 extern int commit_check_locks(void);
 #else
+#define print_lock_counters(p, i) noop
 #define no_counters_are_held() (1)
 #define commit_check_locks() (1)
 #endif
 
+#define REISER4_STACK_ABORT          (8192 - sizeof(struct thread_info) - 30)
+#define REISER4_STACK_GAP            (REISER4_STACK_ABORT - 100)
+
+#if REISER4_DEBUG_MEMCPY
+extern void *xmemcpy(void *dest, const void *src, size_t n);
+extern void *xmemmove(void *dest, const void *src, size_t n);
+extern void *xmemset(void *s, int c, size_t n);
+#else
+#define xmemcpy( d, s, n ) memcpy( ( d ), ( s ), ( n ) )
+#define xmemmove( d, s, n ) memmove( ( d ), ( s ), ( n ) )
+#define xmemset( s, c, n ) memset( ( s ), ( c ), ( n ) )
+#endif
 
 /* true if @i is power-of-two. Useful for rate-limited warnings, etc. */
 #define IS_POW(i) 				\
@@ -298,12 +476,14 @@ extern int commit_check_locks(void);
  * data-type to store information about where error happened ("error site").
  */
 typedef struct err_site {
+	backtrace_path path; /* stack back trace of error */
 	int            code; /* error code */
 	const char    *file; /* source file, filled by __FILE__ */
 	int            line; /* source file line, filled by __LINE__ */
 } err_site;
 
 extern void return_err(int code, const char *file, int line);
+extern void report_err(void);
 
 /*
  * fill &get_current_context()->err_site with error information.
@@ -325,6 +505,7 @@ extern void return_err(int code, const c
 
 typedef struct err_site {} err_site;
 #define RETERR(code) code
+#define report_err() noop
 #endif
 
 #if REISER4_LARGE_KEY
@@ -336,7 +517,28 @@ typedef struct err_site {} err_site;
 #define ON_LARGE_KEY(...)
 #endif
 
+#if REISER4_ALL_IN_ONE
+/*
+ * declarator used by REISER4_ALL_IN_ONE mode. Every reiser4 function that is
+ * not used externally (that is, not used by non-reiser4 code) should be
+ * tagged with this. Normally it expands to nothing. In REISER4_ALL_IN_ONE
+ * expands to statics allowing compiler to perform better optimization.
+ */
+#define reiser4_internal static
+#else
 #define reiser4_internal
+#endif
+
+/* operations to clog */
+/* debugging capture_anonymous_pages */
+#define CLOG_UNMAP 0 /* try_to_unmap - swap_success */
+#define CLOG_ADD_RMAP 1 /* page_add_file_rmap */
+#define CLOG_FILEMAP_NOPAGE 2 /* unix_file_filemap_nopage */
+
+#define OP_NUM 3
+
+void clog_op(int op, void *, void *);
+void print_clog(void);
 
 /* __FS_REISER4_DEBUG_H__ */
 #endif
diff -puN /dev/null diskmap.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/diskmap.c	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,76 @@
+/* Copyright 2003 by Hans Reiser, licensing governed by reiser4/README */
+/* Functions to deal with diskmap storage - read-only storage (currently can only be
+   set via fs-creation process) for use by various plugins */
+
+
+#include "debug.h"
+#include "super.h"
+#include "diskmap.h"
+
+#include <linux/fs.h>
+
+/* Looks through chain of diskmap blocks, looking for table entry where label and parameter
+   patch passed in "label" and "parameter"
+   Returns 0 on success, -1 if nothing was found or error have occurred. */
+reiser4_internal int
+reiser4_get_diskmap_value( u32 label, u32 parameter, u64 *value)
+{
+	struct super_block *sb = reiser4_get_current_sb();
+	int retval = -1;
+
+	assert("green-2006", label != REISER4_FIXMAP_END_LABEL && label != REISER4_FIXMAP_NEXT_LABEL);
+
+	if ( get_super_private(sb)->diskmap_block ) { /* If there is diskmap table, we need to read and parse it */
+		struct buffer_head *diskmap_bh;
+		struct reiser4_diskmap *diskmap;
+		int i = 0;
+
+		diskmap_bh = sb_bread(sb, get_super_private(sb)->diskmap_block);
+search_table:
+		if ( !diskmap_bh ) {
+			warning("green-2005", "Cannot read diskmap while doing bitmap checks");
+			return -1;
+		}
+
+		diskmap = (struct reiser4_diskmap *) diskmap_bh->b_data;
+		if ( strncmp(diskmap->magic, REISER4_FIXMAP_MAGIC, sizeof(REISER4_FIXMAP_MAGIC)-1 ) ) {
+			/* Wrong magic */
+			brelse(diskmap_bh);
+			warning("green-2004", "diskmap is specified, but its magic is wrong");
+			return -1;
+		}
+
+		/* Since entries in tables are sorted, we iterate until we hit item that we are looking for,
+		   or we reach end of whole fixmap or end of current block */
+		while (((d32tocpu(&diskmap->table[i].label) <= label) &&
+		       (d32tocpu(&diskmap->table[i].parameter) < parameter)) &&
+			/* Also check that we do not fall out of current block */
+			((sb->s_blocksize - sizeof(diskmap->magic))/sizeof(diskmap->table[0]) >= i))
+			i++;
+
+		if ( i > (sb->s_blocksize - sizeof(diskmap->magic))/sizeof(diskmap->table[0]) ) {
+			warning("green-2004", "diskmap block %Ld is not properly terminated", (long long)diskmap_bh->b_blocknr);
+			brelse(diskmap_bh);
+			return -1;
+		}
+
+		/* Is this last entry in current table that holds disk block with more data ? */
+		if ( d32tocpu(&diskmap->table[i].label) == REISER4_FIXMAP_NEXT_LABEL ) { /* Need to load next diskmap block */
+			sector_t next_diskmap_block = d64tocpu(&diskmap->table[i].value);
+			brelse(diskmap_bh);
+			diskmap_bh = sb_bread(sb, next_diskmap_block);
+			i = 0;
+			goto search_table;
+		}
+
+		/* See if we have found table entry we are looking for */
+		if ( (d32tocpu(&diskmap->table[i].label) == label) &&
+		     (d32tocpu(&diskmap->table[i].parameter) == parameter) ) {
+			*value = d64tocpu(&diskmap->table[i].value);
+			retval = 0;
+		}
+		brelse(diskmap_bh);
+	}
+
+	return retval;
+}
diff -puN /dev/null diskmap.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/diskmap.h	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,52 @@
+#if !defined (__REISER4_DISKMAP_H__)
+#define __REISER4_DISKMAP_H__
+
+/*
+ * Disk map.
+ *
+ * Disk map is a special data structure used by reiser4 as an optional
+ * "anchor" of other meta-data. That is, disk map (if present) may contain
+ * disk addresses of the rest of meta-data for this file system: master
+ * super-block, bitmaps, journal header and footer, etc. Disk map is used to
+ * avoid dependency on fixed disk addresses, with the following goals:
+ *
+ *     1. allow users to experiment with tuning their file system layout, and,
+ *     more importantly,
+ *
+ *     2. allow reiser4 to be survive bad blocks in critical disk locations.
+ *
+ * That is, disk map allows to "relocate" meta-data structures if their
+ * default disk addresses is not accessible.
+ *
+ * More generally, disk map can be used as a generic table used to store
+ * persistent parameters.
+ *
+ * Currently disk map is read-only for the kernel. It can only be
+ * constructed/modified by user-level utilities.
+ *
+ */
+
+#include "dformat.h"
+
+#define REISER4_FIXMAP_MAGIC "R4FiXMaPv1.0"
+
+#define REISER4_FIXMAP_END_LABEL -2
+#define REISER4_FIXMAP_NEXT_LABEL -1
+
+/* This is diskmap table, it's entries must be sorted ascending first in label
+   order, then in parameter order.  End of table is marked with label
+   REISER4_FIXMAP_END_LABEL label REISER4_FIXMAP_NEXT_LABEL means that value
+   in this row contains disk block of next diskmap in diskmaps chain */
+struct reiser4_diskmap {
+	char magic[16];
+	struct {
+		d32 label;
+		d32 parameter;
+		d64 value;
+	} table[0];
+};
+
+int reiser4_get_diskmap_value(u32, u32, u64 *);
+
+
+#endif
diff -puN /dev/null doc/directory-service
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/directory-service	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,203 @@
+
+					  DIRECTORY SERVICE IN REISER4
+
+Directory is mapping from file name to file itself. This mapping is
+implemented through reiser4 internal balanced tree. Single global tree
+is used as global index of all directories as opposed to having tree per
+directory. Unfortunately file names cannot be used as keys until keys of
+variable length are implemented, or unreasonable limitations on maximal
+file name length are imposed. To work around this file name is hashed
+and hash is used as key in a tree. No hash function is perfect and there
+always be hash collisions, that is, file names having the same value of
+a hash. Previous versions of reiserfs (3.5 and 3.6) used "generation
+counter" to overcome this problem: keys for file names having the same
+hash value were distinguished by having different generation
+counters. This allowed to amortize hash collisions at the cost of
+reducing number of bits used for hashing. This "generation counter"
+technique is actually some ad hoc form of support for non-unique
+keys. Keeping in mind that some form of this have to be implemented
+anyway, it seems justifiable to implement more regular support for
+non-unique keys in reiser4.
+
+NON-UNIQUE KEYS
+
+1.
+
+Non-unique keys require changes in both tree lookup and tree update
+code. In addition some new API to iterate through items with identical
+keys is required.
+
+Before going into detail let's note that non-unique keys weakens
+traditional search tree invariant. Search tree with unique keys, keys of
+all items in a left sub-tree of given delimiting key are less than, and
+in the right sub-tree greater than or equal to the said key. In a search
+tree with non-unique keys both inequalities are not strict.
+
+2.
+
+Tree lookups: we require that node layout ->lookup() methods always
+return leftmost item with the key looked for. The same for item
+->lookup() method for items supporting units with non-unique
+keys. Standard node40 layout plugin handles this, see
+fs/reiser4/plugin/node/node40.c:node40_lookup().
+
+3.
+
+Tree balancing: it seems that only change here is the handling of
+weakened search tree invariant. This can be gathered from the
+observation that balancing never even compares keys, only tests them for
+equality. More thought/research is required though. Looking at the
+existing implementations (like Berkeley db) would be useful also.
+
+4.
+
+Iteration through items/unit with identical keys. There are two
+interfaces to iterating abstraction known as "external" (also known as
+"enumeration") and "internal" iterators.
+
+External iterator:
+
+external_iterator {
+  start();
+  next();
+  has_more_p();
+};
+
+external_iterator eit;
+
+for( eit.start() ; eit.has_more_p() ; ) {
+    object = eit.next();
+    ... do stuff with object ...
+}
+
+Internal operator:
+
+internal_iterator {
+    iterate( int ( *function )( object *obj ) );
+};
+
+internal_iterator iit;
+
+int do_stuff( object *obj )
+{
+   ... do stuff with obj ...
+}
+
+iit( &do_stuff );
+
+External iterator seems easier to use, but they are known to be hard to
+implement, especially for complex data-structures like trees (this is
+because of the amount of state that should be maintained in "eit"
+between its invocations).
+
+Internal iterators are harder to use in C, because new function has to
+be declared to perform actions on objects in sequence, but are obviously
+easier to implement.
+
+Given that in 4.0 version there will be only one client of this
+iteration API (viz. directory lookup routine), it seems that internal
+style is preferable for now. Later, external iterator interface can be
+added if necessary.
+
+IMPLEMENTATION OF DIRECTORIES:
+
+1.
+
+There will be many various directory services implemented through
+different plugins. Default directory plugin uses hashing techniques
+described above. Let's code-name in hdir.
+
+2.
+
+Directory consists of directory entries, stored in a tree in a form of
+directory items. Question about whether each directory entry should be
+separate item or they can be compressed into items is left open by now.
+First this decision is purely per-plugin decidable, second, compression
+is good for performance, but harder to implement.
+
+Single directory entry is binding between file-system object and
+directory. In hdir plugin it consists of full name of a file bound and
+key (or part thereof) of file's stat-data:
+
+typedef struct hdir_entry {
+    /**
+     * key of object stat-data. It's not necessary to store
+     * whole key here, because it's always key of stat-data, so minor packing
+     * locality and offset can be omitted here. But this relies on
+     * particular key allocation scheme for stat-data, so, for extensibility
+     * sake, whole key can be stored here.
+     *
+     * We store key as array of bytes, because we don't want 8-byte alignment
+     * of dir entries.
+     */
+    d8 sdkey[ sizeof( reiser4_key ) ];
+    /**
+     * file name. Null terminated string.
+     */
+    d8 name[ 0 ];
+} hdir_entry;
+
+4.
+
+On creation/linking/lookup of object "bar" in directory "foo" (foo/bar),
+we compose key of directory entry for this object. Key has the form
+
+/*
+ * XXX this should be discussed
+ */
+dirent_k = (locality=foo_object_id, objectid=???, offset=hash("bar"));
+
+Major packing locality of dirent_k is set to foo_object_id so that all
+objects (files) in this directory and their bodies are close to
+respective directory entries.
+
+It seems that no single key allocation policy for directory entries fits
+everyone's needs, so, this can be implemented as method of directory
+plugin. No then less, choice of default key allocation policy is still
+important decision, although not that important as in plugin-less
+file-system.
+
+4.
+
+Function
+
+int hdir_find_entry( inode *dir, const hdir_entry *entry,
+                     tween_coord *coord, lock_handle *lh );
+
+iterates through all directory entries in @dir that have the same key as
+@entry (scans hash-bucket), looking for exact match for entry->name.
+
+5.
+
+During ->create()/->link() hdir_find_entry() is used to find place to insert new
+item (and to check for -EEXIST).
+
+During ->lookup() hdir_find_entry() is used find entry for the file
+being looked for and to load stat-data afterwards.
+
+During ->unlink() hdir_find_entry() is used to find unit/item to be
+removed.
+
+NOTE ON ->lookup():
+
+VFS implements following protocol when creating new
+file (fs/namei.c:open_namei()):
+
+dentry hash is searched. If search is unsuccessful, file system
+->lookup() is called.
+If lookup didn't find name, call ->create()
+
+While this protocol spares file system from dealing with dcache locking,
+for reiserfs it means that tree traversal is performed twice during file
+creation/deletion. Possible solution is to cache results of ->lookup()
+(e.g, pointer to znode) in dentry and reuse then in ->create(). On the
+other hand, point cache have more or less the same effect and is more
+general.
+
+
+^ Local variables:
+^ mode-name: "Design Document"
+^ indent-tabs-mode: nil
+^ tab-width: 4
+^ eval: (progn (flyspell-mode) (flyspell-buffer))
+^ End:
diff -puN /dev/null doc/lock-ordering
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/lock-ordering	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,601 @@
+---------------------------------INTRODUCTION-----------------------------------
+
+This document tries to provide concise description of various "locking" issues
+in reiser4 code. There are two major areas here:
+
+1. locking as a device for the concurrency control: various synchronization
+objects are used to maintain integrity of shared data structures.
+
+2. (induced by the former) deadlocks, livelocks, missed wake ups, and alikes.
+
+"Locks" above means both standard synchronization primitives like mutexes,
+semaphores, condition variables and so on, and any other kind of object on
+which thread execution may "block". Waiting on io completion is not considered
+here, because hardware errors barred, it will ultimately finish regardless of
+any other threads and locks in the system (This only holds if io completion
+handlers don't acquire locks themselves.).
+
+-------------------------------LOCKS IN REISER4---------------------------------
+
+Reiser4 introduces following locks:
+
+1.  Per-super-block tree spin lock                              (tree_lock*)
+
+2.  Per-super-block delimiting key spin lock                    (dk_lock*)
+
+3.  Per-jnode spin lock                                         (jnode_lock*)
+
+4.  Per-znode lock with deadlock detection                      (longterm_lock)
+
+5.  Per-reiser4-inode spin lock                                 (inode_guard*)
+
+6.  Per-atom spin lock                                          (atom_lock*)
+
+7.  Per-transaction-handle spin lock                            (txnh_lock*)
+
+8.  Per-transaction-manager spin lock                           (txnmgr_lock*)
+
+9.  Per-lock-stack spin-lock                                    (stack_lock*)
+
+10. Per-inode read-write lock                                   (inode_rw_lock)
+
+11. Per-super-block spin lock                                   (super_guard*+)
+
+12. Per-flushing-thread spin lock                               (ktxnmgrd_lock)
+
+13. Global lnode hash table lock                                (lnode_guard+)
+
+14. Per-super-block cbk cache spin lock                         (cbk_guard)
+
+15. Per-jnode spin lock used by debugging code to access and
+    modify check sum                                            (cksum_guard+)
+
+16. Per-super-block oid map spin lock                           (oid_guard+)
+
+17. Per-super-block spin lock used by "test" disk format plugin to serialize
+    block allocation                                            (test_lock+)
+
+18. Per-condition-variable spin lock                            (kcond_lock+)
+
+19. Single spin lock used to serialize fake block allocation    (fake_lock+)
+
+20. Single spin lock used to serialize calls to reiser4_panic   (panic_guard+)
+
+21. Single spin lock used by debugging code to keep track of all active
+    reiser4_context instances                                   (contexts_lock+)
+
+22. Per-lnode condition variable used by wait for completion of "incompatible
+    access mode"                                                (lnode_kcond)
+
+23. Per-flushing-thread condition variable for startup waiting  (ktxnmgrd_start)
+
+24. Per-flushing-thread condition variable                      (ktxnmgrd_wait)
+
+25. Per-lock-stack wakeup semaphore                             (stack_sema)
+
+26. Per-super-block flush serializing semaphore                 (flush_sema)
+
+27. Per-transaction-manager commit semaphore                    (commit_sema)
+
+28. Per-super-block semaphore used to arbitrate use of 5%       (delete_sema)
+    reserved disk space
+
+30. Global spin lock used to serialize calls to panic           (panic_guard+)
+
+31. Global spin lock used to protect plugin set hash table      (pset_guard+)
+
+32. Global spin lock used to protect phash hash table           (phash_guard+)
+
+33. Per-bitmap-block semaphore used to serialize bitmap loading (bnode_sema+)
+
+34. Per-super-block epoch lock, protecting updates to           (epoch_lock*)
+    znode_epoch field, used to implement seals (seal.[ch])
+    efficiently.
+
+35. Per-atom "event". This is not really lock. Rather, this is an event
+    signaled each time atom changes its state.                  (atom_event)
+
+36. Per-znode spin lock used to protect long term locking
+    structures                                                  (zlock*)
+
+37. Per flush queue lock                                        (fq_lock*)
+
+38. Per-super-block zgen lock, protecting znode generation      (zgen*)
+    counter
+
+39. Per-jnode spin lock used to synchronize jload() with        (jload_lock*)
+    ->releasepage().
+
+40. Per-atom imaginary read-write semaphore handle_sema         (handle_sema)
+
+    let's pretend for the sake of simplicity that there is special per-atom
+    read-write semaphore that threads can claim. Call it
+    handle_sema. This semaphore is acquired on read when thread captures first
+    block and is released when thread's reiser4_context is closed. Formally
+    thread holds this semaphore on read exactly when
+    get_current_context()->trans->atom != NULL, i.e., when thread is
+    associated with atom. Logic behind introducing this imaginary semaphore is
+    that while some thread is associated with an atom (that is, keeps
+    transaction handle opened), this atom cannot commit. In particular, other
+    threads waiting on fusion with atom that is in CAPTURE_WAIT stage wait
+    until this atom commits, that is wait (at least) until there are no opened
+    transaction handles for this atom. Effectively such threads wait until
+    handle_semaphore is free, that is, they in some sense are trying to
+    acquire handle_semaphore in write mode.  So, this circumferential
+    description allows one to reduce (at least partially) problem of waiting
+    on atom fusion to the lock ordering.
+
+41. Per-super-block spin lock protecting consistency of emergency flush hash
+    table, ->eflushed, and ->eflushed_anon counters in inode, and ->flushed
+    counter in atom.                                            (eflush_guard)
+
+42. Per-super-block spin lock protecting detached directory cursors for
+    stateless readdir                                           (d_lock)
+
+99. Various locks used by the user level simulator
+
+Locks marked by (*) after label, are accessed through spin lock macros,
+defined in reiser4.h. For them, locking ordering is checked at the runtime (at
+least in the principle) when REISER4_DEBUG is on(e).
+
+Locks marked by (+) after label exist only for serializing concurrent access
+to the shared data and are not supposed to be used in conjunction with any
+other locks. They are omitted from locking ordering below to simplify the
+picture. One can imaging them to be rightmost in the ordering.
+
+All locks, spin locks, and semaphores, except for stack_sema are subject to
+normal protocol: thread that grabbed the lock will release it. stack_sema is
+described in more details below.
+
+Also, following kernel locks are used by our code:
+
+1. Per-page lock                                                (page_lock)
+
+2. Per-page writeback bit                                       (page_write)
+
+3. Per-inode semaphore                                          (i_sem)
+
+4. Per-inode I_LOCK bit-lock                                    (I_LOCK)
+
+Thread also can block on the following "objects" that are not really locks:
+
+1. Page fault                                                   (pfault)
+
+2. Memory allocation                                            (kalloc)
+
+3. Dirtying a page (through balance_dirty_pages())              (page_dirty)
+
+----------------------------------LOCK SCOPE------------------------------------
+
+Section describing what data are protected by what locks. TBD.
+
+----------------------------------INVARIANTS------------------------------------
+
+Invariants are some (formal or informal) properties of data structures. For
+example, for well-formed doubly linked list, following holds:
+
+item->next->prev == item && item->prev->next == item
+
+In most cases, invariants only hold under proper locks.
+
+LABEL AND DESCRIPTION                                 LOCKS
+
+[inode->eflushed]                                     inode_guard
+
+    inode->eflushed > 0, iff there are emergency flushed jnodes belonging to
+    this inode. Also, each emergency flushed jnode is counted as increase in
+    inode->i_count.
+
+[cbk-cache-invariant]                                 cbk_guard
+
+    If cbk cache is traversed in LRU order, first go all used slots (with
+    slot->node != NULL), then, all unused. All used slots have unique
+    slot->node. (Checked by cbk_cache_invariant().)
+
+[znode-fake]                                          jnode_lock, tree_lock
+
+    /* fake znode doesn't have a parent, and */
+    znode_get_level(node) == 0 => znode_parent(node) == NULL, and
+    /* there is another way to express this very check, and */
+    znode_above_root(node)     => znode_parent(node) == NULL, and
+    /* it has special block number, and */
+    znode_get_level(node) == 0 => *znode_get_block(node) == FAKE_TREE_ADDR, and
+    /* it is the only znode with such block number, and */
+    !znode_above_root(node) && znode_is_loaded(node) =>
+                                  *znode_get_block(node) != FAKE_TREE_ADDR
+    /* it is parent of the tree root node */
+    znode_is_true_root(node)   => znode_above_root(znode_parent(node))
+
+    (Checked by znode_invariant_f().)
+
+[znode-level]                                         jnode_lock, tree_lock
+
+    /* level of parent znode is one larger than that of child, except for the
+       fake znode */
+    znode_parent(node) != NULL && !znode_above_root(znode_parent(node)) =>
+                znode_get_level(znode_parent(node)) == znode_get_level(node) + 1
+    /* left neighbor is at the same level, and */
+    znode_is_left_connected(node) && node->left != NULL =>
+                znode_get_level(node) == znode_get_level(node->left))
+    /* right neighbor is at the same level */
+    znode_is_right_connected(node) && node->right != NULL =>
+                znode_get_level(node) == znode_get_level(node->right)
+
+    (Checked by znode_invariant_f().)
+
+[znode-connected]
+
+     /* ->left, ->right pointers form a valid list and are consistent with
+     JNODE_{LEFT,RIGHT}_CONNECTED bits */
+
+     node->left != NULL => znode_is_left_connected(node)
+     node->right != NULL => znode_is_right_connected(node)
+     node->left != NULL =>
+		      znode_is_right_connected(node->left) &&
+		      node->left->right == node
+     node->right != NULL =>
+		      znode_is_left_connected(node->right) &&
+		      node->right->left == node
+
+[znode-c_count]                                       jnode_lock, tree_lock
+
+    /* for any znode, c_count of its parent is greater than 0, and */
+    znode_parent(node) != NULL && !znode_above_root(znode_parent(node)) =>
+                atomic_read(&znode_parent(node)->c_count) > 0), and
+    /* leaves don't have children */
+    znode_get_level(node) == LEAF_LEVEL => atomic_read(&node->c_count) == 0
+
+    (Checked by znode_invariant_f().)
+
+[znode-modify]                                        zlock_lock(read),
+                                                      jnode_lock, tree_lock
+
+    /* if znode is not write-locked, its checksum remains
+     * invariant */
+	!znode_is_wlocked(node) => znode_at_read(node)
+
+    (Checked by znode_invariant_f().)
+
+[znode-refs]                                          jnode_lock, tree_lock
+
+    /* only referenced znode can be long-term locked */
+    znode_is_locked(node) => atomic_read(&ZJNODE(node)->x_count) != 0
+
+    (Checked by znode_invariant_f().)
+
+[jnode-oid]                                           jnode_lock, tree_lock
+
+    /* for unformatted node ->objectid and ->mapping fields are
+     * consistent */
+    jnode_is_unformatted(node) && node->key.j.mapping != NULL =>
+        node->key.j.objectid == get_inode_oid(node->key.j.mapping->host)
+
+    (Checked by znode_invariant_f().)
+
+[jnode-refs]                                          jnode_lock, tree_lock
+
+    /* only referenced jnode can be loaded */
+    atomic_read(&node->x_count) >= node->d_count
+
+    (Checked by jnode_invariant_f().)
+
+[jnode-dirty]                                         jnode_lock, tree_lock
+
+    /* dirty inode is part of atom */
+    jnode_is_dirty(node) => node->atom != NULL
+
+    (Checked by jnode_invariant_f().)
+
+[jnode-queued]                                         jnode_lock, tree_lock
+
+    /* only relocated node can be queued, except that when znode
+     * is being deleted, its JNODE_RELOC bit is cleared */
+    JF_ISSET(node, JNODE_FLUSH_QUEUED) =>
+		      JF_ISSET(node, JNODE_RELOC) || JF_ISSET(node, JNODE_HEARD_BANSHEE)
+
+    (Checked by jnode_invariant_f().)
+
+[jnode-atom-valid]                                     jnode_lock, tree_lock
+
+    /* node atom has valid state */
+    node->atom != NULL => node->atom->stage != ASTAGE_INVALID
+
+    (Checked by jnode_invariant_f().)
+
+[jnode-page-binding]                                    jnode_lock, tree_lock
+
+    /* if node points to page, it points back to node */
+    node->pg != NULL => node->pg->private == node
+
+    (Checked by jnode_invariant_f().)
+
+[sb-block-counts]                                     super_guard
+
+	reiser4_block_count(super) = reiser4_grabbed_blocks(super) +
+                                 reiser4_free_blocks(super) +
+                                 reiser4_data_blocks(super) +
+                                 reiser4_fake_allocated(super) +
+                                 reiser4_fake_allocated_unformatted(super) +
+                                 reiser4_flush_reserved(super)
+
+    (Checked by check_block_counters().)
+
+[sb-grabbed]                                          super_guard
+
+    reiser4_grabbed_blocks(super) equals the sum of ctx->grabbed_blocks for
+    all grabbed contexts
+
+[sb-fake-allocated]                                   txnmgr_lock, atom_lock
+
+    When all atoms and transaction manager are locked,
+    reiser4_flush_reserved(super) equals to sum of atom->flush_reserved for
+    all atoms.
+
+[tap-sane]
+
+    tap->mode is one of {ZNODE_NO_LOCK, ZNODE_READ_LOCK, ZNODE_WRITE_LOCK}, and
+	tap->coord != NULL, and
+	tap->lh != NULL, and
+	tap->loaded > 0 => znode_is_loaded(tap->coord->node), and
+	tap->coord->node == tap->lh->node
+
+    (Checked by tap_invariant().)
+
+--------------------------------LOCK ORDERING-----------------------------------
+
+Lock ordering for kernel locks is taken from mm/filemap.c. Locks can be taken
+from the left to the right. Locks on the same indentation level are unordered
+with respect to each other. Any spin lock is righter than any long term lock,
+obviously.
+
+i_sem
+..inode_rw_lock <-------DEAD1-----+
+....handle_sema                   |
+......I_LOCK                      |
+......delete_sema                 |
+......flush_sema                  |
+........atom_event                |
+........longterm_lock <---DEAD2-+ |
+......commit_sema               | |
+..........page_lock             | |
+............pfault              | |
+..............mm->mmap_sem------+-+                   [do_page_fault]
+..................ktxnmgrd_lock
+................mapping->i_shared_sem
+................kalloc
+....................inode_guard
+......................d_lock
+....................txnmgr_lock
+......................atom_lock
+..........................super_guard
+........................jnode_lock            [->vm_writeback()->jget()]
+................................eflush_guard
+..........................txnh_lock
+............................zlock
+........................fq_lock
+..............................stack_lock
+..................dk_lock
+..............................tree_lock
+................................cbk_guard
+................................epoch_lock
+................................zgen_lock
+..........................jload_lock
+....................mm->page_table_lock
+......................mapping->private_lock
+........................swaplock
+..........................swap_device_lock
+..........................&inode_lock
+............................&sb_lock
+............................mapping->page_lock
+..............................zone->lru_lock
+                  ^
+                  +-- spin locks are starting here. Don't schedule rightward.
+
+NOT FINISHED.
+
+..............&cache_chain_sem
+......................cachep->spinlock
+......................zone->lock
+
+page_dirty
+....&inode_lock
+....&sb_lock
+....mapping->page_lock [mpage_writepages]
+..page_lock
+..longterm_lock        [__set_page_dirty_buffers->__mark_inode_dirty]
+
+Nice and clear picture with all reiser4 locks totally ordered, right?
+
+Unfortunately, it is not always possible to adhere to this ordering. When it
+is necessary to take locks "decreasing" order, standard trylock-and-repeat
+loop is employed. See:
+
+   atom_get_locked_with_txnh_locked(),
+   atom_get_locked_by_jnode(),
+   atom_free(), and
+   jnode_lock_page()
+
+functions for examples of this.
+
+The only exception from the above locking oder is when thread wants to lock
+object it is just created and hasn't yet announced to other threads (by means
+of placing it into some shared data structure like hash table or list). There
+is special spin lock macro spin_lock_foo_no_ord() defined in reiser4.h for
+this purpose.
+
+pfault and kalloc are something special: when page fault occurs at the page
+occupied by mmapped from reiser4 file, reiser4_readpage() is invoked that
+starts taking locks from the very beginning.
+
+DEAD1
+
+   Scenario:
+
+      process has mmapped reiser4 regular file and then does write(2) into
+      this file from buffer that is in mmaped area. copy_from_user() causes
+      page fault:
+
+         sys_write()
+           reiser4_write()
+             unix_file_write() [inode_rw_lock]
+                         .
+                         .
+                         .
+                 __copy_from_user()
+                         .
+                         .
+                         .
+                   handle_page_fault()
+                     handle_mm_fault()
+                       handle_pte_fault()
+                         do_no_page()
+                           unix_file_filemap_nopage() [inode_rw_lock]
+
+   This is safe, because inode_rw_lock is read-taken by both read/write and
+   unix_file_filemap_nopage(). It is only write-taken during tail<->extent
+   conversion and if file is mmaped is was already converted to extents.
+
+DEAD2
+
+   is safe, because copy_from_user is used only for tails and extents:
+
+    . extent: extent_write_flow() releases longterm_lock before calling
+      copy_from_user.
+
+    . tail: during copying into tail, only node containing this tail is long
+      term locked. It is easy to see, that ->readpage serving page fault (that
+      is, readpage for unformatted data) will never attempt to lock said node.
+
+When memory allocation tries to free some memory it
+
+1. asynchronously launches kswapd that will ultimately call
+   reiser4_writepage().
+
+2. calls reiser4_writepage() synchronously.
+
+----------------------------------LOCK PATTERNS---------------------------------
+
+This section describes where in the code what locks sequences are held. This
+places restrictions on modifications to the lock ordering above and enumerates
+pieces of the code that should be revised if modification of the lock ordering
+is necessary.
+
+flush_sema
+
+    jnode_flush()
+
+        to serialize flushing. This behavior can be disabled with mtflush
+        mount option.
+
+atom_lock->jnode_lock
+
+    uncapture_block()
+
+atom_lock->tree_lock && jnode_lock && page_lock
+
+    uncapture_block() calls jput()
+
+delete_sema
+
+    common_unlink(), shorten_file()->unlink_check_and_grab()
+
+        to serialize access to reserved 5% of disk only used by unlinks. (This
+        is necessary so that it is always possible to unlink something and
+        free more space on file-system.)
+
+delete_sema->flush_sema || commit_sema
+
+    reiser4_release_reserved() calls txnmgr_force_commit_current_atom() under
+    delete_sema
+
+inode_rw_lock->delete_sema
+
+    unix_file_truncate()->shorten_file() takes delete_sema from under write
+    mode of inode_rw_lock
+
+kalloc->jnode_lock
+
+    emergency_flush() takes jnode spin lock
+
+jnode_lock->(mapping->page_lock)
+
+    jnode_set_dirty()->__set_page_dirty_nobuffers()
+
+jnode_lock->(zone->lru_lock)
+
+    jnode_set_dirty()->mark_page_accessed()
+
+
+I_LOCK->longterm_lock
+
+    reiser4_iget()
+
+tree_lock->epoch_lock
+
+    zget() calls znode_build_version()
+
+jnode_lock->stack_lock
+
+    longterm_lock_znode(), longterm_unlock_znode(), wake_up_all_lopri_owners()
+
+tree_lock->cbk_guard
+
+    znode_remove() calls cbk_cache_invalidate()
+
+zlock->stack_lock
+
+    wake_up_all_lopri_owners()
+
+atom->stack_lock
+
+    check_not_fused_lock_owners()
+
+txnh->stack_lock
+
+    check_not_fused_lock_owners()
+
+jnode_lock->jload_lock
+
+    reiser4_releasepage(), emergency_flush(). But this can actually be made
+    other way around.
+
+jnode_lock->eflush_guard
+
+    eflush_add(), eflush_del()
+
+atom_lock->super_guard
+
+    grabbed2flush_reserved_nolock()
+
+inode_guard->d_lock
+
+    detach_fsdata()
+
+----------------------------------DEADLOCKS-------------------------------------
+
+Big section describing found/possible/already-worked-around deadlocks.
+
+1. Locking during tree traversal.
+
+2. Locking during balancing.
+
+3. Locking during squalloc.
+
+4. Page locking.
+
+5. Atom fusion.
+
+Please, fill gaps up.
+
+TBD.
+
+2002.09.19. Nikita.
+
+--------------------------------------------------------------------------------
+
+^ Local variables:
+^ mode-name: "Memo"
+^ indent-tabs-mode: nil
+^ tab-width: 4
+^ eval: (progn (flyspell-mode) (flyspell-buffer))
+^ End:
diff -puN /dev/null doc/lock-ordering.dot
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/lock-ordering.dot	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,276 @@
+/* this is dot(1) input file for lock-ordering diagram */
+/* it should be passed through C preprocessor first */
+/* cpp -P -DFITPAGE lock-ordering.dot | tred | dot -Tps | gv -media a4 - */
+
+#define CATTR fontsize=14, fontname=Helvetica
+#define NATTR CATTR
+#define EATTR CATTR
+
+#define SYSATTR color=yellow, style=filled
+#define PSEUDOATTR color=pink, style=filled, peripheries=2
+
+#define LONGATTR shape=ellipse
+#define SPINATTR shape=box
+
+#define CONDATTR color=blue, peripheries=2, LONGATTR
+
+#define MARKLONG(name) name -> schedulable [style=invis, weight=0]
+
+#define SYSLONG(name, l) name [label=l, NATTR, LONGATTR, SYSATTR]; MARKLONG(name)
+#define SYSPSEUDO(name) name [NATTR, LONGATTR, PSEUDOATTR]; MARKLONG(name)
+#define RLONG(name) name [NATTR, LONGATTR]; MARKLONG(name)
+
+#define RCOND(name, l) name [label=l, NATTR, CONDATTR]; MARKLONG(name)
+
+#define MARKSPIN(name) schedulable -> name [style=invis, weight=0]
+
+#define SYSSPIN(name, l) name [label=l, NATTR, SYSATTR, SPINATTR]; MARKSPIN(name)
+#define RSPIN(name) name [NATTR, SPINATTR]; MARKSPIN(name)
+
+#define ARC(from, to, func, ...) from -> to [EATTR, label=func, ## __VA_ARGS__]
+
+digraph locks {
+
+//clusterrank=none
+#if defined(FITPAGE)
+size="7.5, 10.5";
+ratio=compress;
+center=true;
+#endif
+
+subgraph long {
+	/* reiser4 long term locks */
+	RLONG(longterm_lock);
+	RLONG(inode_rw_lock);
+	RLONG(stack_sema);
+	RLONG(flush_sema);
+	RLONG(commit_sema);
+	RLONG(delete_sema);
+    /* txncommit is a synonym for flush_sema and commit_sema */
+	txncommit [LONGATTR, PSEUDOATTR]; MARKLONG(txncommit);
+	txncommit -> flush_sema [style=dotted, dir=both];
+	txncommit -> commit_sema [style=dotted, dir=both];
+
+    /* atom_event is not really a lock: you can wait on it, but cannot "own"
+       it. */
+	RCOND(atom_event,atom_event);
+
+	//RLONG(lnode_kcond);
+	//RLONG(ktxnmgrd_start);
+	//RLONG(ktxnmgrd_wait);
+	//RLONG(bnode_sema);
+
+	/* pseudo locks */
+	SYSPSEUDO(pfault);
+	SYSPSEUDO(kalloc);
+	SYSPSEUDO(schedulable);
+
+	/* system long term locks */
+	SYSLONG(page_write, page_write);
+	SYSLONG(mm_mmap_sem, "mm->mmap_sem");
+	SYSLONG(mapping_i_shared_sem, "mapping->i_shared_sem");
+
+	SYSLONG(i_sem, i_sem);
+	SYSLONG(page_lock, page_lock);
+	SYSLONG(cache_chain_sem, "&cache_chain_sem");
+	SYSLONG(I_LOCK, "I_LOCK");
+
+	SYSLONG(namespace_sem, "namespace->sem");
+	// SYSLONG(bdev_bd_sem, "bdev->bd_sem");
+	SYSLONG(sb_s_lock, "sb->s_lock");
+	SYSLONG(sb_s_umount, "sb->s_umount");
+}
+
+subgraph spin {
+
+	/* reiser4 spin locks */
+
+	RSPIN(tree_lock);
+	RSPIN(dk_lock);
+	RSPIN(jnode_lock);
+	RSPIN(inode_guard);
+	RSPIN(atom_lock);
+	RSPIN(txnh_lock);
+	RSPIN(txnmgr_lock);
+	RSPIN(ktxnmgrd_lock);
+	RSPIN(cbk_guard);
+	RSPIN(epoch_lock);
+	RSPIN(zgen_lock);
+	RSPIN(stack_lock);
+	RSPIN(zlock);
+	RSPIN(fq_lock);
+	RSPIN(jload_lock);
+	RSPIN(super_guard);
+    RSPIN(eflush_guard);
+    RSPIN(d_lock);
+
+	//RSPIN(stack_lock);
+	//RSPIN(lnode_guard);
+	//RSPIN(cksum_guard);
+	//RSPIN(oid_guard);
+	//RSPIN(test_lock);
+	//RSPIN(kcond_lock);
+	//RSPIN(fake_lock);
+	//RSPIN(panic_guard);
+	//RSPIN(contexts_lock);
+	//RSPIN(pset_guard);
+	//RSPIN(phash_guard);
+
+	/* system spin locks */
+	SYSSPIN(bkl, "BKL");
+	SYSSPIN(cachep_spinlock, "cachep->spinlock");
+	SYSSPIN(zone_lock, "zone->lock");
+	SYSSPIN(swaplock, "&swaplock");
+	SYSSPIN(zone_lru_lock, "zone->lru_lock");
+	SYSSPIN(mapping_private_lock, "mapping->private_lock");
+	SYSSPIN(mapping_page_lock, "mapping->page_lock");
+	SYSSPIN(inode_lock, "&inode_lock");
+	SYSSPIN(swap_device_lock, "swap->device_lock");
+	SYSSPIN(mm_page_table_lock, "mm->page_table_lock");
+	SYSSPIN(sb_lock, "&sb_lock");
+	SYSSPIN(page_chain_lock, "page->chain_lock");
+    //removed at 2003.04.04 by akpm@digeo.com
+	//SYSSPIN(dparent_lock, "dparent_lock");
+	SYSSPIN(dcache_lock, "dcache_lock");
+	SYSSPIN(fs_struct_lock, "fs_struct->lock");
+	SYSSPIN(tasklist_lock, "&tasklist_lock");
+	SYSSPIN(sig_siglock, "sig->siglock");
+	SYSSPIN(fown_lock, "fown->lock");
+	SYSSPIN(task_switch_lock, "task->switch_lock");
+	SYSSPIN(task_proc_lock, "task->proc_lock");
+	SYSSPIN(task_alloc_lock, "task->alloc_lock");
+	/* rq->lock is special: it can be unlocked by thread different from locker */
+	SYSSPIN(rq_lock, "rq->lock");
+	SYSSPIN(task_capability_lock, "&task_capability_lock");
+    SYSSPIN(mmlist_lock, "&mmlist_lock");
+	SYSSPIN(files_file_lock, "files->file_lock");
+	SYSSPIN(dn_lock, "&dn_lock");
+	//SYSSPIN(bdev_lock, "&bdev_lock");
+	SYSSPIN(suspend_pagedir_lock, "&suspend_pagedir_lock")
+}
+
+/* dependencies */
+
+ARC(inode_guard, tree_lock, "update_sd_at()");
+ARC(inode_guard, jnode_lock, "update_sd_at()");
+ARC(inode_guard, atom_lock, "update_sd_at()");
+ARC(atom_lock, jnode_lock, "uncapture_block()"); //capture_fuse_jnode_lists()
+ARC(jnode_lock, txnh_lock, "try_capture_block()");
+//alredy covered
+ARC(atom_lock, txnh_lock, "capture_fuse_txnh_lists()");
+ARC(jnode_lock, tree_lock, "jdrop_in_tree()");
+ARC(tree_lock, cbk_guard, "cbk_cache_invalidate()");
+ARC(dk_lock, tree_lock, "sync_dkeys()");
+ARC(txnmgr_lock, atom_lock, "atom_dec_and_unlock()"); //txnmgr_force_commit_all(),\ncommit_some_atoms(),\nflush_one_atom()");
+ARC(txnmgr_lock, jnode_lock, "atom_begin_andlock()");
+ARC(txnmgr_lock, txnh_lock, "atom_begin_andlock()");
+ARC(i_sem, inode_rw_lock, "unix_file_setattr()");//,\nunix_file_write()");
+ARC(page_lock, i_sem, "reiserfs_unpack()");
+ARC(inode_rw_lock, delete_sema, "shorten()");
+//ARC(delete_sema, txncommit, "reiser4_release_reserved()");
+ARC(flush_sema, longterm_lock, "flush_scan_left()");//,\nflush_allocate_znode_update(),\nflush_scan_formatted(),\nflush_pos_to_child_and_alloc()");
+ARC(longterm_lock, page_lock, "cbk_level_lookup()");
+ARC(commit_sema, page_lock, "submit_write()");
+ARC(pfault, mm_mmap_sem, "handle_page_fault()");
+ARC(page_lock, pfault, "extent_write_flow()");
+ARC(mm_mmap_sem, kalloc, "unix_file_readpage()");
+
+//ARC(inode_rw_lock, mm_mmap_sem, "unix_file_filemap_nopage()", style=dotted, dir=back);
+//ARC(mm_mmap_sem, kalloc, "DEAD2", style="dotted");
+ARC(kalloc, jnode_lock, "emergency_flush()");
+ARC(longterm_lock, jnode_lock, "longterm_unlock_znode()");//,\nflush_allocate_znode()");
+
+ARC(kalloc, inode_guard, "eflush_add()");
+ARC(ktxnmgrd_lock, txnmgr_lock, "commit_some_atoms()");
+
+//already covered
+ARC(mapping_i_shared_sem, mapping_private_lock, "__set_page_dirty_buffers()");
+//already covered
+ARC(mapping_i_shared_sem, mapping_page_lock, "");
+ARC(mapping_i_shared_sem, mm_page_table_lock, "vma_link()");
+
+ARC(inode_lock, mapping_page_lock, "__sync_single_inode()");
+ARC(inode_lock, sb_lock, "writeback_inodes()");
+
+ARC(mm_page_table_lock, swap_device_lock, "try_to_unmap_one()");
+ARC(mm_page_table_lock, mapping_private_lock, "try_to_unmap_one()");
+//already covered
+ARC(mm_page_table_lock, mapping_page_lock, "try_to_unmap_one()");
+
+ARC(mm_mmap_sem, mapping_i_shared_sem, "do_mmap_pgoff()");
+
+ARC(swaplock, swap_device_lock, "swap_info_get()");
+ARC(swap_device_lock, mapping_page_lock, "exclusive_swap_page()");
+
+ARC(page_lock, page_chain_lock, "shrink_list()");
+ARC(mm_page_table_lock, page_chain_lock, "page_add_rmap()");//,\npage_remove_rmap()");
+ARC(mapping_page_lock, zone_lru_lock, "add_to_page_cache()");//,\nfilemap_fdatawait()");
+ARC(mm_page_table_lock, zone_lru_lock, "page_add_rmap()");//,\npage_remove_rmap()");
+ARC(zone_lru_lock, page_chain_lock, "rmap.c");
+
+ARC(cache_chain_sem, kalloc, "cpuup_callback()");
+//ARC(cache_chain_sem, pfault, "kmem_cache_create()");
+
+//obsolete ARC(dcache_lock, dparent_lock, "d_move()");
+ARC(fs_struct_lock, dcache_lock, "set_fs_pwd()");//,\nset_fs_root()");
+
+ARC(namespace_sem, i_sem, "sys_pivot_root()");
+
+ARC(sb_s_lock, txncommit, "reiser4_write_super()");
+ARC(sb_s_umount, txncommit, "reiser4_kill_super()");
+
+ARC(task_switch_lock, rq_lock, "finish_arch_switch()");
+ARC(task_proc_lock, tasklist_lock, "unhash_process()"); // de_thread()
+ARC(task_proc_lock, dcache_lock, "proc_pid_unhash()");
+
+ARC(tasklist_lock, sig_siglock, "de_thread()");//,\ndo_notify_parent(),\nsys_tkill(),\ncopy_process()"); //collect_sigign_sigcatch(),\n__exit_sighand(),\nfreeze_processes()
+ARC(dn_lock, fown_lock, "__inode_dir_notify()");
+ARC(fown_lock, tasklist_lock, "send_sigio()");//,\nsend_sigurg()");
+ARC(tasklist_lock, task_alloc_lock, "chroot_fs_refs()");
+ARC(tasklist_lock, rq_lock, "setscheduler()");
+ARC(task_capability_lock, tasklist_lock, "sys_capget()");//,\nsys_capset()");
+ARC(task_alloc_lock, files_file_lock, "match_comm()");//,\nmatch_pid()");
+
+ARC(mmlist_lock, mm_page_table_lock, "unuse_process()");
+
+ARC(tree_lock, zone_lock, "page_clear_jnode()");//,\njrelse_nolock()");
+ARC(tree_lock, zone_lru_lock, "page_clear_jnode()");//,\njrelse_nolock()");
+ARC(tree_lock, mapping_page_lock, "jdrop_in_tree()");
+ARC(tree_lock, epoch_lock, "zget()");
+ARC(tree_lock, zgen_lock, "zget()");
+
+ARC(bkl, inode_lock, "iget()");
+
+ARC(jnode_lock, mapping_page_lock, "jnode_set_dirty()");
+ARC(jnode_lock, zone_lru_lock, "jnode_set_dirty()");
+
+ARC(I_LOCK, longterm_lock, "reiser4_iget()");
+
+//one cannot wait for atom event keeping longterm lock
+ARC(atom_event, longterm_lock, "flush");
+//one cannot wait for atom event keeping page lock
+ARC(atom_event, page_lock, "jnode_extent_write()");
+ARC(zlock, stack_lock, "longterm_lock_znode()");//,\nlongterm_unlock_znode(), wake_up_all_lopri_owners()");
+
+ARC(atom_lock, stack_lock, "check_not_fused_lock_owners()");//atom_send_event()
+ARC(txnh_lock, stack_lock, "check_not_fused_lock_owners()");
+ARC(fq_lock, stack_lock, "wakeup_atom_waitfor_list()");
+ARC(atom_lock, fq_lock, "detach_fq()");
+ARC(jnode_lock, zlock, "check_not_fused_lock_owners()");
+ARC(txnh_lock, zlock, "check_not_fused_lock_owners()");
+
+ARC(suspend_pagedir_lock, zone_lock, "do_magic_suspend_2()");
+ARC(cachep_spinlock, zone_lock, "cache_flusharray()");
+
+ARC(mapping_page_lock, zone_lock, "add_to_page_cache()"); // find_lock_page
+ARC(mapping_page_lock, zone_lru_lock, "add_to_page_cache()"); // find_lock_page
+ARC(mm_page_table_lock, zone_lock, "try_to_unmap_one()"); // get_user_pages, do_wp_page, do_anonymous_page, do_no_page
+ARC(mm_page_table_lock, zone_lru_lock, "try_to_unmap_one()"); // get_user_pages, do_wp_page, do_anonymous_page, do_no_page
+ARC(jnode_lock, zone_lock, "page_clear_jnode()"); // uncapture_page, extent_write_flow
+ARC(jnode_lock, zone_lru_lock, "page_clear_jnode()"); // uncapture_page, extent_write_flow
+ARC(jnode_lock, jload_lock, "reiser4_releasepage()");
+ARC(atom_lock, super_guard, "grabbed2flush_reserved_nolock()");
+
+ARC(jnode_lock, eflush_guard, "eflush_add()");
+ARC(inode_guard, d_lock, "detach_fsdata()");
+}
diff -puN /dev/null doc/metadata-in-pagecache
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/metadata-in-pagecache	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,57 @@
+Hello,
+
+In upcoming reiser4 we are planning to use page cache to store all file system
+meta data. In some cases it is straightforward; for example, bitmaps blocks,
+placed on the disk through (almost) equal intervals ask to be bound to special
+fake inode and indexed by their disk offsets.
+
+There is one important (most important actually) case where using fake inode
+is inconvenient: blocks of internal balanced tree used by reiser4, known as
+"formatted nodes". Natural solution of using block number as offset within
+some fake inode doesn't pass, because when block size is smaller than page
+some blocks mapped to the same page may be either occupied by something other
+than formatted nodes, or just be free.
+
+This leads to the following complications:
+
+ 1. we cannot simply use block_{read|write}_full_page(), because this will
+ waste IO bandwidth: block that doesn't contain formatted node will be read
+ into memory. Moreover, this block can be later read again, for example,
+ because this is data block of some file and hashed into different place in
+ the page cache, creating alias. This will definitely confuse buffer cache;
+
+ 2. even is we keep track of what blocks have to be actually read, there still
+ will be "internal memory fragmentation", because some parts of page cache
+ pages will be unused.
+
+In brief, formatted nodes form a tree and because of this don't fit into
+<inode, offset> hashing scheme---there is no linear ordering among them.
+
+Moreover, formatted node is never looked up in the page cache by its block
+number, because for each formatted node in memory there is special data
+structure (znode) and znodes are hashed in the hash table anyway.
+
+So, all functionality that we need from the page cache is memory allocator
+with attached memory pressure hooks (I guess, this is close to what Hans
+called "sub-cache" in lkml discussions on this topic).
+
+It seems that we have two solutions:
+
+ 1. change page cache to use different indexing for formatted nodes;
+
+ 2. implement our own memory allocator sitting directly on the top of
+ alloc_pages() and installing proper ->mapping for pages that it grabs.
+
+(2) will only work if generic VM code (e.g., shrink_cache() or
+page_launder_zone() in rmap VM) don't depend on particulars of page cache
+hashing, that, fortunately, seems to be the case. This approach has following
+advantages:
+
+ . we can try to collocate related blocks on the same page, for example
+ blocks from the same transaction, of block with similar cache "hotness";
+
+ . we can use blocks larger than page size.
+
+Nikita.
+
+
diff -puN /dev/null doc/oid-locid
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/oid-locid	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,108 @@
+MIME-Version: 1.0
+Content-Type: text/plain; charset=us-ascii
+Content-Transfer-Encoding: 7bit
+Message-ID: <15392.39020.573047.826769@laputa.namesys.com>
+Date: Wed, 19 Dec 2001 16:38:52 +0300
+To: Reiserfs developers mail-list <Reiserfs-Dev@Namesys.COM>
+Subject: [RFC]: objectids and localities management
+X-Mailer: VM 6.96 under 21.4 (patch 3) "Academic Rigor" XEmacs Lucid
+FCC: ~/documents/mail/outgoing
+--text follows this line--
+Hello,
+
+there is one thing that seems awkward in current reiser{fs|4} design: in
+a key we have both locality id (locid) and object id (oid). This is
+slightly illogical because oid alone is unique, but we cannot find an
+object given oid. This was, by the way, main reason behind our NFS
+troubles. So, why is this strictly necessary? I'll try to reason from
+the "first principles". Following account doesn't pretend to be of any
+historical accuracy of course.
+
+1. In a data structure we use to store objects (tree) items
+   with close keys are packed into the same disk block. This means that
+   we cannot completely separate key allocation from block
+   allocation. That is,
+
+      - tree forces us to encode disk location preferences in a key. (A1)
+
+2. If we cannot completely separate key and block allocation let's try
+   in stead to blend them together. That is, we rely on block allocator
+   to follow tree ordering and topology: blocks containing items with
+   close keys are allocated close on disk and blocks contiguous in tree
+   order are more or less contiguous on disk. How far bitmap.c fulfill
+   or can fulfill these goals is out of the scope of this discussion,
+
+      - let's suppose that we have ideal block allocator. (A2)
+
+3. Given this, why cannot we encode disk location preferences in oid
+   alone? Because oid has to be unique and we cannot predict how many
+   objects we are going to group together in a future (how many objects
+   there will be in a directory that is). That is, suppose we create two
+   directories "a" and "b" in succession. If oid were the only thing to
+   store location preference, than we should leave after the oid of "a"
+   enough unused oids for all objects within "a", but we don't know how
+   many of them will be there.
+
+4. To solve this (locid, oid) scheme was born. It has following
+   advantages:
+
+      - it is simple to implement
+      - it allows one to encode enough location preference into the key (A3)
+
+But the more people used reiserfs and the more files they started to
+store in a single directory, the less valid (A3) became. oid became
+inadequate location preference, because while it allows to separate
+files from different directories it doesn't allow to order files within
+single directory. For example readdir of big directory is slow, because
+files are not sorted within directory. Various ad-hoc solutions have
+been proposed (oid==hash, add "band" to oid, etc), but there is obvious
+conflict between requirement that oid is unique and desire to encode
+additional information in it. In effect all such solutions amount to
+further splitting of (locid,oid) pair into (locid, someid, oid) for the
+reasons similar to those on the steps 3,4 above.
+
+The scheme proposed below tries to meet following goals:
+
+ G1. only keep unique oid in a key, thus making it possible to find file
+     given its inode number and additionally shrink key, increasing
+     fanout.
+
+ G2. allow configurable amount of fine-grained locality preference
+     information to be associated with each oid, thus allowing files
+     to be ordered in a tree according to some hierarchical "packing
+     localities", for example: first order files by oid of parent
+     directory, then by hash of name within this directory.
+
+
+Proposal:
+
+Maintain separate map (oidlocmap, implementation discussed below) from
+oid to "locpref", where locpref is additional fine-grained location
+preference data, associated with oid. For example locpref may be just
+(locid) to emulate existing behavior, or (locid, hash) or (locid,
+user-supplied-grouping-info), etc.
+
+Key only contains oid, that is, ceteris paribus, key has form
+(item-type, oid, offset). If oid is 60 bits, this is 16 bytes.
+
+Ordering of items within tree (and, given (A2), their ordering on disk)
+is completely determined by keycmp() function that compares two
+keys. Before comparing two keys, keycmp(k1, k2) consults oidlocmap and
+obtains locprefs, associated with oids of k1 and k2. locprefs then are
+"pasted" into k1 and k2, producing "expanded" keys, containing full
+location preferences information. Expanded keys are compared as usual.
+
+In simplest case oidlocmap can be implemented as normal balanced tree,
+where keys are oids (60 bits) and values locprefs. If we limit ourselves
+to fixed format of locpref (at least per file system) than, we get
+standard text-book balanced tree storing values of fixed size which is
+simple to implement.
+
+There is of course overhead of maintaining oidlocmap and, especially, of
+consulting it on each keycmp(), but it looks to me that it will be not
+that significant, because oidlocmap is compact and will be out-weighted
+by increased fanout in the main tree.
+
+Comments?
+
+Nikita.
diff -puN /dev/null doc/page-cache-for-formatted-nodes
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/page-cache-for-formatted-nodes	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,60 @@
+PROPOSAL:
+
+Keep formatted nodes in a page cache, binding them to the special fake inode
+and using block number divided by number of blocks in a page as page index.
+
+ADVANTAGES:
+
+Page cache is preferred over buffer cache. Much more optimization and
+scalability efforts are going into it. The fewer separate caches are in the
+system, the simpler and better VM can handle load.
+
+DISADVANTAGES:
+
+As formatted nodes are indexed by block number, each page will contain
+blocks with consequentive block numbers. This poses several problems:
+
+  1. When we need to read particular block from the disk (e.g., to load child
+  node during tree lookup), it is not clear that blocks with neighboring block
+  numbers are worth reading into memory at all.
+
+  2. Some of the blocks that have to go in the same page as block we need can
+  be unformatted ones.
+
+SOLUTIONS:
+
+There are several possible workarounds:
+
+  1. rely on the fact that in vast majority of cases block size is equal to
+  the page size. So, we can index formatted nodes by block number storing
+  exactly one block in the page. This will eliminate both problems at the
+  expense of the memory wasting in the setups where block size is smaller than
+  page size.
+
+  2. only load required block in the page marking other blocks mapped to this
+  page as up-to-date. It is not obvious that this will work at all, and in any
+  case, this will force us to use special API to access such pages, bypassing
+  VM interface.
+
+  3. rely on good repacker and load all blocks in the page hoping that they
+  are close to each other in tree order and will be accessed shortly.
+
+  4. allocate unformatted nodes such that they will never go into the same
+  frame as formatted. For example:
+
+    - always align extent to the page boundary on the disk (page is CPU
+    specific though);
+
+    - use some variation of border algorithm to separate formatted and
+    unformatted nodes;
+
+    - use "enriched" bitmap where formatted and unformatted nodes are
+    distinguishable.
+
+
+# Local variables:
+# mode-name: "proposal"
+# indent-tabs-mode: nil
+# tab-width: 4
+# eval: (if (fboundp 'flyspell-mode) (flyspell-mode))
+# End:
diff -puN /dev/null doc/plugin.inheritance
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/plugin.inheritance	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,119 @@
+
+				 Report about "plugin inheritance discussion"
+
+    1. Basic plugin support, psets, default plugins.
+
+    2. Plugin inheritance.
+
+    3. Meta-data inheritance, light-weight files.
+
+1. Basic plugin support, psets, default plugins.
+
+    Let's call Reiser4 file system object "active" when it is used by the
+    kernel, that is, when initialized inode exists for it. Associated with
+    each active object is its "plugin set" ("pset" for short) that is an array
+    of all plugins necessary for proper interaction with this object. Pointer
+    to pset is stored in inode. Pset is constructed when:
+
+        1. new object is created, or
+
+        2. existing object is looked up.
+
+    New object is always created as a child of some already existing
+    object. During object creation its pset is constructed on the basic of
+    parent's one---this is plugin inheritance. Details of plugin inheritance
+    are delegated to the object plugin of new object for flexibility.
+
+    File system has "default pset". In current implementation it is just pset
+    of the root directory, created by mkfs.reiser4.
+
+    When stat-data is saved to disk, pset is saved as part of stat-data. At
+    least this is what default static stat-data plugin does. More advanced
+    stat-data plugins are free to save psets separately, implement sharing,
+    etc.
+
+    As an optimization, only plugins different from default ones are stored in
+    stat-data. Correspondingly, when object is looked up, plugins found in
+    stat-data are installed into pset, and missing plugins are taken from the
+    default pset.
+
+    Plugins in pset can be divided into two types:
+
+        1. "essential"---ones that cannot be changed without some explicit
+        effort. For example, hash and fibration plugins are essential, because
+        changing them would render directory content invalid.
+
+        2. "non-essential"---plugins that can be changed implicitly. For
+        example, security plugin and formatting-policy plugin are
+        non-essential.
+
+    From previous description it is clear that essential plugins in default
+    pset cannot be modified once file system was created, because this would
+    implicitly change plugins of all objects in whose stat-data appropriate
+    plugin is missing, which is contrary to the definition of essential
+    plugin.
+
+    This poses a problem: what to do when new member is added to pset
+    (consider recent addition of fibration plugin)? And, conversely, what to
+    do when mounting a file system with unknown member in default pset?
+
+    The former is only an issue for essential plugins. When new essential
+    plugin is added to pset, backward-compatible implementation of this plugin
+    should be provided as default. That is, for example, when kernel with
+    support for fibration mounts file system without fibration plugin it the
+    root-directory stat-data, "lexicographic" fibration plugin should be
+    used. This guarantees that old file-systems can be used without corrupting
+    them. Of course, new versions of mkfs.reiser4 can set up whatever
+    fibration plugin is deemed best to be default.
+
+    "Forward-compatibility" that is, mounting a file system with
+    unknown plugin in default pset, can be simply refused.
+
+2. Plugin inheritance.
+
+    In addition to pset each active object also has a "hset"---"heir
+    set". When new child is created, it first tries to inherit plugins from
+    parent's hset, and only if plugin is missing there---from parent's
+    pset. hset is treated exactly like pset in all other respects. NOTE:
+    storing hset on disk is not yet implemented.
+
+    One question still remains to be answered: how object plugin of a child
+    being created is selected? One possible solution is to add two new members
+    PSET_CREAT, and PSET_MKDIR to the pset. They specify object plugins used
+    when child is being created through sys_creat() and sys_mkdir() system
+    calls. (Other system calls, such as sys_symlink() and sys_mknod() are too
+    specialized for such flexibility.) NOTE: this is also not yet implemented.
+
+3. Meta-data inheritance, light-weight files.
+
+    Through meta-data inheritance file system object can somehow indicate that
+    some portion of its meta-data should be taken from some place other than
+    object's stat-data. Three obvious scenarios for meta-data inheritance are:
+
+        1. meta-data are taken from file-system level default place,
+
+        2. meta-data are taken from some specially indicated place (i.e.,
+        stat-data contains a key of item(s) where meta-data have to be taken
+        from), and
+
+        3. meta-data are taken from the parent.
+
+    Note, that the last option is ambiguous, because the notion of _the_
+    parent is not well-defined in general. This can be worked around in two
+    ways:
+
+        1. only use it when there is _the_ parent, for example, disable
+        light-weight files with multiple names, or
+
+        2. don't care, for example, allow uid of light-weight file to depend
+        on path-name through which this file was reached.
+
+    In any case, meta-data inheritance can be implemented by re-using existing
+    static stat-data item plugin with simple additional plumbing in the kernel
+    code (pointer to parent inode should be passed to the stat-data
+    methods). It is not clear what to do when light-weight file is accessed
+    through NFS, and there is no parent. Simplest solution is to just disable
+    NFS access to them. This is trivial, because our ->{en,de}code_fh()
+    methods are delegated to object plugin.
+
+
diff -puN /dev/null doc/readdir-problems-and-implementations
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/readdir-problems-and-implementations	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,12 @@
+1.
+
+User level API.
+
+Standard
+
+^ Local variables:
+^ mode-name: "Design Document"
+^ indent-tabs-mode: nil
+^ tab-width: 4
+^ eval: (if (fboundp 'flyspell-mode) (flyspell-mode))
+^ End:
diff -puN /dev/null doc/reiser4_roadmap.html
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/reiser4_roadmap.html	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,1120 @@
+<p> <H1> Reiser4 (Version 4 of ReiserFS)</H1>
+
+<H2> Primary sponsor www.DARPA.mil, regular sponsors applianceware.com and
+bigstorage.com.  DARPA does not endorse this project, it merely
+sponsors it.  </H2>
+<p>Table of Contents:
+
+<p><a href="#new_ext">
+New Extensibility Infrastructure</a>
+<br>&nbsp;&nbsp;
+<a href="#file_plg">
+File Plugins</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#dir_plg">
+Directory Plugins</a>
+<br>&nbsp;&nbsp;
+<a href="#hash_plg">
+Hash Plugins</a>
+<br>&nbsp;&nbsp;
+<a href="#security_plg">
+Security Plugins</a>
+<br>&nbsp;&nbsp;
+<a href="#new_plg">
+Putting Your New Plugin To Work Will Mean Recompiling</a>
+<br>&nbsp;&nbsp;
+<a href="#item_plg">
+Item Plugins</a>
+<br>&nbsp;&nbsp;
+<a href="#key_plg">
+Key Assignment Plugins</a>
+<br>&nbsp;&nbsp;
+<a href="#search_plg">
+Node Search and Item Search Plugins</a>
+<br>&nbsp;&nbsp;
+<a href="#backup">
+Backup</a>
+<br>&nbsp;&nbsp;
+<a href="#without_plg">
+Without Plugins We Will Drown</a>
+<br>&nbsp;&nbsp;
+<a href="#steps_crt">
+Steps For Creating A Security Attribute</a>
+<br>&nbsp;&nbsp;
+<a href="#lazy">
+Plugins: FS Programming For The Lazy</a>
+<p>
+<a href="#new_funct">
+New Functionality</a>
+<br>&nbsp;&nbsp;
+<a href="#why_scrt">
+Why Linux Needs To Be Secure</a>
+<br>&nbsp;&nbsp;
+<a href="#fine_scrt">
+Fine Graining Security</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#good_scrt">
+Good Security Requires Precision In Specification Of Security</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#imprecise_scrt">
+Space Efficiency Concerns Motivate Imprecise Security</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#scrt_def">
+Security Definition Units And Data Access Patterns Sometimes Inherently Don't Align</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#etc_passwd">
+/etc/passwd As Example</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#aggr_files">
+Aggregating Files Can Improve The User Interface To Them</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#aggr_modif">
+How Do We Write Modifications To An Aggregation</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#inheritance">
+Aggregation Is Best Implemented As Inheritance</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#constr">
+Constraints</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#audit">
+Auditing</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#incr_scrt">
+Increasing the Allowed  Granularity of Security</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#files_dirs">
+Files That Are Also Directories</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#hidden_dir">
+Hidden Directory Entries</a>
+<br>&nbsp;&nbsp;
+<a href="#new_scrt">
+New Security Attributes and Set Theoretic Semantic Purity</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#min_num">
+Minimizing Number Of Primitives Is Important In Abstract Constructions</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#compose_streams">
+Can We Get By Using Just Files and Directories (Composing Streams And Attributes From Files And Directories)?</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#list_features">
+List Of Features Needed To Get Attribute And Stream Functionality From Files And Directories</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#mnt_fs">
+Mounting FS Flavors</a>
+<br>&nbsp;&nbsp;
+<a href="#api">
+API Suitable For Accessing Files That Store Security Attributes</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#flaws">
+Flaws In Traditional File API When Applied To Security Attributes</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#resolution">
+The Usual Resolution Of These Flaws Is A One-Off Solution</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#solution">
+One-Off Solutions Are A Lot of Work To Do A Lot Of</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#syscall">
+reiser4() System Call Description</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#tr_tr">
+Transactions and Transcrashes:</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#tr_necessary">
+Transactions Are Necessary Safeguard Against Certain Race Condition Exploits</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#transcr">
+Transcrashes</a>
+<br>
+<a href="#performance">
+Performance Enhancements</a>
+<br>&nbsp;&nbsp;
+<a href="#dancing">
+Dancing Trees Are Faster Than Balanced Trees</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#if_ram">
+If It Is In RAM, Dirty, and Contiguous, Then Squeeze It ALL
+Together Just Before Writing</a>
+<br>&nbsp;&nbsp;
+<a href="#repacker">
+Repacker</a>
+<br>&nbsp;&nbsp;
+<a href="#commit">
+Encryption On Commit</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#wand_lgs">
+Wandering Logs</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#more_detailed">
+(More detailed treatment soon to be available at www.namesys.com/transactions.html by Joshua MacDonald.)</a>
+<br>&nbsp;&nbsp;&nbsp;&nbsp;
+<a href="#conclusion">
+Conclusion</a>
+
+
+<p>
+<a name="new_ext"></a>
+<H1> New Extensibility Infrastructure </H1>
+<p>
+It takes more than a license to make source code open, it takes a design.
+
+<p> Reiser4 will focus on extensibility.  Plugins ala photoshop but
+for files and directories.  This is necessary if we are to enable
+vendors to DARPA (including ourselves) to cost effectively add
+substantial numbers of new security features to Reiser4.
+
+<p>
+Imagine that you were an experimental physicist who had spent his life
+using only the tools that were in his local hardware store.  Then one
+day you joined a major research lab with a machine shop, and a whole
+bunch of other physicists.  All of a sudden you are not using just
+whatever tools the large tool companies who have never heard of you
+have made for you, you are part of a cooperative of physicists all
+making your own tools, swapping tools with each other, suddenly
+empowered to have tools that are exactly what you want them to be, or
+even merely exactly what your colleagues want them to be, rather than
+what some big tool company wants them to be.  That is the transition
+you will make when you go from version 3 to version 4 of ReiserFS.
+The tools your colleagues and sysadmins (your machinists) make are
+going to be much better for what you need.
+<a name="file_plg"></a>
+<h2>File Plugins</H2>
+<p>
+Every object (file or directory) will possess a plugin id.  This
+plugin id will identify a set of methods.  The set of methods will
+embody all of the different possible interactions with the object that
+come from sources external to reiserfs.  It is a layer of indirection
+added between the external interface to reiserfs, and the rest of
+reiserfs.  Each method will have a methodid.  It will be usual to mix
+and match methods from other plugins when composing plugins.
+
+<a name="dir_plg"></a>
+<h3>Directory Plugins</h3> <p>Reiser4 will implement a plugin for
+traditional directories, and it will implement directory style access
+to file attributes as part of the plugin for regular files.  Later we
+will describe why this is useful.  Other directory plugins we will
+leave for later versions.  There is no deep reason for this
+deferra. It is simply the randomness of what features attract sponsors
+and make into a release specification, and there are no sponsors at
+the moment for additional directory plugins.  I have no doubt that
+they will appear later; new directory plugins will be too much fun to
+miss out on.:-)
+
+<p>
+<a name="hash_plg"></a>
+<H2>Hash Plugins</H2>
+
+<p>Hash plugins already exist in version 3, and if you know what they
+are this paragraph says nothing new.  To coexist with NFS we must be
+able to hand out 64 bit "cookies" that can be used to resume a
+readdir.  Cookies are implemented in most filesystems as byte offsets
+within a directory (which means they cannot shrink directories), and
+in reiserfs as hashes of filenames plus a generation counter.  We
+order directory entries in reiserfs by their cookies.  This costs us
+performance compared to ordering lexicographically (but is immensely
+faster than the linear searching employed by most other Unix
+filesystems), and depending on the hash and its match to the
+application usage pattern there may be more or less performance
+lossage.  Hash plugins will probably remain until version 5 or so,
+when directory plugins and ordering function plugins will obsolete
+them, and directory entries will be ordered by filenames like they
+should be (and possibly stem compressed as well).
+
+<a name="security_plg"></a>
+<H2>Security Plugins</H2>
+<p>
+Security plugins handle all security checks.  They are normally
+invoked by file and directory plugins.
+
+<p>
+<ul>Example of reading a file:
+<li>Access the pluginid for the file.
+<li>Invoke the read method for the plugin.
+<li>The read method determines the security plugin for the file.
+<li>That security plugin invokes its read check method for determining whether to permit the read.
+<li>The read check method for the security plugin reads file/attributes containing the permissions on the file
+<li>Since file/attributes are also files, this means invoking the plugin for reading the file/attribute.
+<li>The pluginid for this particular file/attribute for this file happens to be inherited (saving space and centralizing control of it).
+
+<li>The read method for the file/attribute is coded such that it does
+not check permissions when called by a sec plug method.  (Endless
+recursion is thereby avoided.)
+
+<li>The file/attribute plugin employs a decompression algorithm
+specially designed for efficient decompression of our encoding of
+ACLs.
+
+<li>The security plugin determines that the read should be permitted.
+<li>The read method continues and completes.
+</ul>
+
+<a name="new_plg"></a>
+<H2>Putting Your New Plugin To Work Will Mean Recompiling</H2>
+<p>If you want to add a new plugin, we think your having to ask the sysadmin to
+recompile the kernel with your new plugin added to it will be
+acceptable for version 4.0.  We will initially code plugin-id lookup
+as an in-kernel fixed length array lookup, methodids as function
+pointers, and make no provision for post-compilation loading of
+plugins.  Performance, and coding cost, motivates this.
+<a name="item_plg"></a>
+<H2>Item Plugins</H2>
+<p>
+The balancing code will be able to balance an item iff it has an item
+plugin implemented for it.  The item plugin will implement each of
+the methods the balancing code needs (methods such as splitting items,
+estimating how large the split pieces will be, overwriting, appending
+to, cutting from, or inserting into the item, etc.)
+<p>
+In addition to all of the balancing operations, item plugins will also
+implement intra-item search plugins.
+<p>
+Our current code understands the structure of the items it balances.
+This makes adding new types of items storing such new security
+attributes as other researchers develop too expensive in coding time,
+greatly inhibiting the addition of them to ReiserFS.  We anticipate
+that there will be a great proliferation in the types of security
+attributes in ReiserFS if and only if we are able to make it a matter
+requiring not a modification of the balancing code by our most
+experienced programmers, but the writing of an item handler.  This is
+necessary if we are to achieve our goal of making the adding of each
+new security attribute an order of magnitude or more easier to perform
+than it is now.
+
+<a name="key_plg"></a>
+<H2>Key Assignment Plugins</H2>
+<p>
+
+When assigning the key to an item, the key assignment plugin will be
+invoked, and it will have a key assignment method for each item type.
+A single key assignment plugin is defined for the whole FS at FS
+creation time.  We know from experience that there is no "correct" key
+assignment policy, squid has very different needs from average user
+home directories.  Yes, there could be value in varying it more
+flexibly than just at FS creation time, but we have to draw the line
+somewhere when deciding what goes into each release....
+
+<a name="search_plg"></a>
+<H2>Node Search and Item Search Plugins</H2>
+<P>
+Every node layout will have a search method for that layout, and every
+item that is searched through will have a search method for that item.
+(When doing searches, we search through a node to find an item, and
+then search within the item for those items that contain multiple
+things to find.)
+<a name="backup"></a>
+<h2>Backup</h2>
+<p>
+We need to modify tar to record plugin ids.  Some plugins may require special treatment.
+<a name="without_plg"></a>
+<H2>Without Plugins We Will Drown</H2>
+<P>
+People often ask, as ReiserFS grows in features, how will we keep the
+design from being drowned under the weight of the added complexity,
+and from reaching the point where it is difficult to work on the code?
+<p>
+The infrastructure to support security attributes implemented as files
+also enables lots of features not necessarily security related.  The
+plugins we are choosing to implement in v4.0 are all security related
+because of our funding source, but users will add other sorts of
+plugins just as they took DARPA's TCP/IP and used it for non-military
+computers.  Only requiring that all features be implemented in the
+manner that maximizes code reuse keeps ReiserFS coding complexity down
+to where we can manage it over the long term.
+
+<a name="steps_crt"></a>
+<H2>Steps For Creating A Security Attribute</H2>
+<p>
+Once this infrastructure has been created, you will be able to create a new security attribute by:
+<ul>
+<li>defining a pluginid
+<li>composing a set of methods for the plugin from ones you create or reuse from other existing plugins
+<li>defining a set of items that act as the storage containers of the object, or reusing existing items from other plugins (e.g. regular files)
+<li>implementing item handlers for all of the new items you create
+<li>creating a key assignment algorithm for all of the new items
+<li>implementing a search handler for every item you create that requires searching within it (perhaps search methods should be considered part of the item handler, we shall see while implementing it)
+</ul>
+
+<a name="lazy"></a>
+<H2>Plugins: FS Programming For The Lazy</H2>
+<p>
+The important feature here is that in practice most plugins will have
+only a very few of these features unique to them, and the rest of the
+plugin will be reused code.  This is how we will reduce adding new
+security attributes to a task requiring a few weeks work: by first
+creating the right tools for the job, and only then starting work on
+it.  Our ambition is to have two orders of magnitude more security
+features than we otherwise would in 5 years, by first making it an
+order of magnitude less work to add them to reiser4, and then
+attracting an order of magnitude more security attribute developers
+because of that.  What DARPA is paying for here, is primarily not a
+suite of security plugins from Namesys, though it is getting that, but
+an architectural (not just the license) enabling of lots of outside vendors
+to efficiently create lots of innovative security plugins that Namesys
+would never have imagined if working by itself as a supplier.
+
+<a name="new_funct"></a>
+<H1> New Functionality</H1>
+<a name="why_scrt"></a>
+<H2> Why Linux Needs To Be Secure</H2>
+<p>
+The world is sadly changing.  It used to be that there was no spam,
+because it was not socially acceptable.  Now there is spam.  It used
+to be that security attacks on civilian computers were infrequent,
+because only unbalanced teenage boys had nothing better to do.  This
+is changing in much the same way.
+<p>
+The communist government of China has attacking US information
+infrastructure as part of its military doctrine.  Linux computers are
+the bricks the US (and global) civilian information infrastructure is
+being built from.  It is in the US (and global) interest that Linux
+become SECURELY neutral, so that when large US (or elsewhere) banks
+use Linux, and the US (or anyone else) experiences an attack, the
+infrastructure does not go down.  Chinese crackers are known to have
+compromised a computer forming a part of the California power grid....
+<p>
+It used to be that most casualties in wars were to combatants.  Now
+they are mostly to civilians.  In future information infrastructure
+attacks, who will take more damage, civilian or military
+installations?  DARPA is funding us to make all Linux computers more
+resistant to attack.
+<p>
+<a name="fine_scrt"></a>
+<H2>Fine Graining Security</h2>
+<p>
+<a name="good_scrt"></a>
+<H3>Good Security Requires Precision In Specification Of Security</H3>
+<p>
+Suppose you have a large file, and this file has many components.  One
+of the themes of SE Linux is that Unix security is insufficiently fine
+grained.  This is a general principle of security, that good security
+requires precision of permissions.  When security lacks precision, it
+increases the burden of being secure, and the extent to which users
+adhere to security requirements in practice is a function of the
+burden of adhering to it.
+<p>
+<a name="imprecise_scrt"></a>
+<H3>Space Efficiency Concerns Motivate Imprecise Security</H3>
+<p>
+Many filesystems make it space usage ineffective to store small components as
+separate files for various reasons.  Not being separate
+files means that they cannot have separate permissions.  One of the
+reasons for using overly aggregated units of security is space
+efficiency.  ReiserFS currently improves this by an order of magnitude
+over most of the existing alternative art.  Space efficiency is the
+hardest of the reasons to eliminate, and its elimination makes it that
+much more enticing to attempt to eliminate the other reasons.
+
+<a name="scrt_def"></a>
+<h3>Security Definition Units And Data Access Patterns Sometimes Inherently Don't Align</h3>
+<p>
+Applications sometimes want to operate on a collection of components
+as a single aggregated stream.  (Note that commonly two different
+applications want to operate on data with different levels of
+aggregation, and the infrastructure for solving this as a security
+issue will also solve that problem as well.)
+
+<a name="etc_passwd"></a>
+<h3>/etc/passwd As Example</h3>
+<p>
+I am going to use the /etc/passwd file as an example, not because I
+think that other aspects of SE Linux won't solve its problems better,
+but because the implementation of it as a single flat file in the
+early Unixes is a wonderful illustrative example of poorly
+granularized security that the readers may share my personal
+experiences with, and then I hope they will be able to imagine that
+other data files less famous could have similar problems.
+<p>
+Have you ever tried to figure out just exactly what part of the
+/etc/passwd file changed near the time of a break-in?  Have you ever
+wished that you could have a modification time on each field in it?
+Have you ever wished the users could change part of it, such as the
+gecos field, themselves (setuid utilities have been written to allow
+this, but this is a pedagogical not a practical example), but not have
+the power to change it for other users?
+<p>
+There were good reasons why
+/etc/passwd was first implemented as a single file with one single
+permission governing the entire file.  If we can eliminate them one by
+one, the same techniques for making finer grained security effective
+will be of value to other highly secure data files.
+
+<a name="aggr_files"></a>
+<h3>Aggregating Files Can Improve The User Interface To Them</h3>
+<p>
+Consider the use of emacs on a collection of a thousand small 8-32
+byte files like you might have if you deconstructed /etc/passwd into
+small files with separable acls for every field.  It is more
+convenient in screen real estate, buffer management, and other user
+interface considerations, to operate on them as an aggregation all
+placed into a single buffer rather than as a thousand 8-32 byte
+buffers.
+
+<a name="aggr_modif"></a>
+<h3>How Do We Write Modifications To An Aggregation</h3>
+<p>
+Suppose we create a plugin that aggregates all of the files in a
+directory into a single stream.  How does one handle writes to that
+aggregation that change the length of the components of that
+aggregation?
+
+<p>Richard Stallman pointed out to me that if we separate the
+aggregated files with delimiters, then emacs need not be changed at
+all to acquire an effective interface for large numbers of small files
+accessed via an aggregation plugin.  If
+/new_syntax_access_path/big_directory_of_small_files/.glued is a
+plugin that aggregates every file in big_directory_of_small_files with
+a delimiter separating every file within the aggregation, then one can
+simply type emacs
+/new_syntax_access_path/big_directory_of_small_files/.glued, and the
+filesystem has done all the work emacs needs to be effective at this.
+Not a line of emacs needs to be changed.
+<p>
+One needs to be able to choose different delimiting syntax for
+different aggregation plugins so that one can, for say the passwd
+file, aggregate subdirectories into lines, and files within those
+subdirectories into colon separate fields within the line.  XML would
+benefit from yet other delimiter construction rules.  (We have been
+told by one XML company (need link to testimonial here) that ReiserFS is
+higher performance than any other "database" for storing XML.)
+
+<a name="inheritance"></a>
+<h3>Aggregation Is Best Implemented As Inheritance</h3>
+
+In summary, to be able to achieve precision in security we need to
+have inheritance with specifiable delimiters, and we need whole file
+inheritance to support ACLs.
+
+<a name="constr"></a>
+<h3>Constraints</h3>
+
+<p>
+Another way security may be insufficiently fine grained is in values:
+it can be useful to allow persons to change data but only within
+certain constraints.  For this project we will implement plugins, and
+one type of plugin will be write constraints.  Write-constraints are
+invoked upon write to a file, and if they return non-error then the
+write is allowed.  We will implement two trivial sample
+write-constraint plugins, one in the form of a kernel function
+loadable as a kernel module which returns non-error (thus allowing the
+write) if the file consists of the strings "secret" or "sensitive" but
+not "top-secret", and another in the form of a perl program residing
+in a file and is executed in user-space which does exactly the same.
+Use of kernel functions will have performance advantages, particularly
+for small functions, but severe disadvantages in power of scripting,
+flexibility, and ability to be installed by non-secure sources.  Both
+types of plugins will have their place.
+
+<p>Note that ACLs will also embody write constraints.
+
+<p>
+We will implement constraints that are compiled into the kernel, and
+constraints that are implemented as user space processes.
+Specifically, we will implement a plugin that executes an arbitrary
+constraint contained in an arbitary named file as a user space
+process, passes the proposed new file contents to that process as
+standard input, and iff the process exits without error allows the
+write to occur.
+
+<p>
+It can be useful to have read constraints as well as write constraints.
+<p>
+<a name="audit"></a>
+<H3>Auditing </H3>
+<p>
+We will implement a plugin that notifies administrators by email when
+access is made to files, e.g. read access.
+
+<p>With each plugin implemented, creating additional plugins becomes
+easier as the available toolkit is enriched.  Auditing constitutes a
+major additional security feature, yet it will be easy to implement
+once the infrastructure to support it exists (and it would be
+substantial work to implement it without that infrastructure).
+<p>
+The scope of this project is not the creation of plugins themselves,
+but the creation of the infrastructure that plugin authors would find
+useful.  We want to enable future contractors to the DoD (and US
+financial institutions, PGP Security developers working on SE Linux,
+etc.), to implement more secure systems on the Linux platform, not
+implement them ourselves.  By laying a proper foundation and creating
+a toolkit for them, we hope to reduce the cost of coding new security
+attributes by an order of magnitude for those who follow us.
+Employing a proper set of well orthogonalized primitives also changes
+the addition of these attributes from being a complexity burden upon
+the architecture into being an empowering extension of the
+architecture, which greatly increases their acceptability for
+ReiserFS.
+
+<a name="incr_scrt"></a>
+<H3>Increasing the Allowed  Granularity of Security</H3>
+<p>
+Inheritance of security attributes is important to providing
+flexibility in their administration.  We have spoken about making
+security more fine grained, but sometimes it needs to be larger
+grained.  Sometimes a large number of files are logically one unit in
+regards to their security, and it is desirable to have a single point
+of control over their security.  Inheritance of attributes is the
+mechanism for implementing that.  Security administrators should have
+the power to choose whatever units of security they desire, without
+having to distort them to make them correspond to semantic units.
+Inheritance of file bodies using aggregation plugins allows the units
+of security to be smaller than files, inheritance of attributes allows
+them to be larger than files.
+
+<a name="files_dirs"></a>
+<h3>Files That Are Also Directories</h3>
+<p>
+In Reiser4 (but not ReiserFS 3) an object can be both a file and a
+directory at the same time.  If you access it as a file, you obtain
+the named sequence of bytes, and if you use it as a directory you can
+obtain files within it, directory listings, etc.  There was a lengthy
+discussion on the Linux kernel about whether this was technically
+feasible to do which I won't reproduce here except to summarize that
+Linus showed that it was feasible.
+<p>
+Allowing an object to be both a file and a directory is one of the
+features necessary to to compose the functionality present in streams
+and attributes using files and directories.
+<p>
+<a name="hidden_dir"></a>
+<h3>Hidden Directory Entries</h3>
+<p>
+A file can exist, but not be visible when using readdir in the usual
+way.  WAFL does this with the .snapshots directory, and it works well
+for them without disturbing users.  This is useful for adding access
+to a variety of new features without disturbing the user and
+applications with them when they are not relevant.  An interesting
+question is whether we should have all of these hidden files have the
+same name prefix (e.g. '..' at the start of the hidden name), or not.
+I am still soliciting input on this.  Note that this feature should be
+used for special files that one does not want to be backed up.
+<p>
+<a name="new_scrt"></a>
+<H2>New Security Attributes and
+Set Theoretic Semantic Purity</H2>
+<p>
+<a name="min_num"></a>
+<h3>Minimizing Number Of Primitives Is Important In Abstract Constructions</h3>
+<p>
+To a theoretician, it is extremely important to minimize the number of
+primitives with which one achieves the desired functionality in an
+abstract construction.  It is a bit hard to explain why this is so,
+but it is well accepted that breaking an abstract model into more
+basic primitives is very important.  A not very precise explanation of
+why, is to say that if you have complex primitives, and you break them
+into more basic primitives, then by combining those basic primitives
+differently from how they were originally combined in the complex
+primitives, you can usually express new things that the complex
+primitives did not express.  Let's follow this grand tradition of
+theoreticians, and see what happens if we apply it to Linux files and
+directories.
+<a name="compose_streams"></a>
+<h3>Can We Get By Using Just Files and Directories (Composing Streams And Attributes From Files And Directories)?</h3>
+<p>
+In Linux we have files, directories, and attributes.  In NTFS they
+have streams also.  Since Samba is important to Linux, there are
+frequently requests that we add streams to ReiserFS.  There are also
+requests that we add more and more different kinds of attributes using
+more and more different APIs.  Can we do everything that can be done
+with {files, directories, attributes, streams} using just {files,
+directories}?  I say yes, if we make files and directories more powerful and flexible, and I hope that by the end of reading this you
+will agree.
+<p>Let us have two basic objects.  A file is a sequence of bytes that has a name.  A directory is a namespace mapping names to a set of objects "within" the directory.  We connect these directory namespaces such that one can use compound names whose subcomponents are separated by a delimiter '/'.
+What is missing from files and directories now that attributes and streams offer?
+<p>In ReiserFS 3, there exist file attributes.  File attributes are out-of-band data describing the sequence of bytes which is the file.  For example, the permissions defining who can access a file, or the last modification time, are file attributes.
+File attributes have their own API, and creating new file attributes creates new code complexity and compatibility issues galore.  ACLs are one example of new file attributes users want.
+<p>
+Since files can also be directories in Reiser4, then we can implement
+traditional file attributes as simply files.  To access a file
+attribute, one need merely name the file, followed by a '/', followed
+by an attribute name.  That is, a traditional file will be implemented
+to possess some of the features of a directory, it will contains files
+within the directory corresponding to file attributes which you can
+access by their names, and it will contain a file body which is what
+you access when you name the "directory" not the file.
+<p>
+Unix currently has a variety of attributes that are distinct from
+files (ACLS, permissions, timestamps, other mostly security related
+attributes....).  This is because a variety of persons needed this
+feature and that, and there was no infrastructure that would allow
+implementing the features as fully orthogonal features that could be
+applied to any file.  Reiser4 will create that infrastructure.
+<a name="list_features"></a>
+<h3>List Of Features Needed To Get Attribute And Stream Functionality From Files And Directories</h3>
+<ul>
+<li>api efficient for small files
+<li>efficient storage for small files
+<li>plugins, including plugins that can compress a file servings as an attribute into a single bit
+<li>files that also act as directories when accessed as directories
+<li>inheritance (includes file aggregation)
+<li>constraints
+<li>transactions
+<li>hidden directory entries
+</ul>
+<p>
+The reader is asked to note that each of these additional features is a feature that the filesystem would benefit by the addition of anyway.  So we add them in v4.
+<a name="mnt_fs"></a>
+<H3>Mounting FS Flavors</H3>
+<p>
+Making these attributes accessible via filenames implies a slight
+deviation from Unix tradition.  If we create a way for this deviation
+to not be visible to those who don't want it, it paradoxically gives
+us more freedom to deviate without getting paranoid about the effects
+on existing applications.
+
+<p>
+A strict POSIX filesystem API will be implemented as a restricted
+functionality namespace obtained when mounting with --POSIX-only, and
+it will be possible, and even usual, to mount the filesystem both with
+and without --rich-semantics simultaneously each at different mount
+points.  Note that Al Viro has done work in VFS to make this more
+feasible, which is nice.
+<p> "reiser4" will be a distinct filesystem type from "reiserfs" in
+the eyes of the mount command.  Upon the completion of reiser4, we
+will evaluate the relative costs of implementing a conversion script,
+or supporting mounting "reiserfs" format filesystems using "reiser4".
+Under no circumstance will we make it impossible to mount an old
+"reiserfs" formatted filesystem, though users may or may not be able
+to mount them as type "reiser4" --- this is not yet determined or
+funded.
+
+<a name="api"></a>
+<H2>API Suitable For Accessing Files That Store Security Attributes</H2>
+
+<p>A new system call reiser4() will be implemented to support
+applications that don't have to be fooled into thinking that they are
+using POSIX, and through this entry point a richer set of semantics
+will access the same files that are also accessible using POSIX calls.
+reiser4() will not implement more than hierarchical names, a full set
+theoretic naming system as described on our future vision page will
+not be implemented before reiser5() is implemented.  reiser4() will
+implement all features necessary to access ACLs as files/directories
+rather than as something neither file nor directory.  This includes
+opening and closing transactions, performing a sequence of I/Os in one
+system call, and accessing files without use of file descriptors
+(necessary for efficient small I/O).  It will do it with a syntax
+suitable for evolving into reiser5() syntax with its set theoretic
+naming.
+
+<a name="flaws"></a>
+<h3>Flaws In Traditional File API When Applied To Security Attributes</h3>
+Security related attributes tend to be small.  The traditional filesystem API for reading and writing files has these flaws in the context of accessing security attributes:
+<ul>
+<li>Creating a file descriptor is excessive overhead and not useful when accessing an 8 byte attribute.
+<li>A system call for every attribute accessed is too much overhead when accessing lots of little attributes.
+<li>Lacking constraints:  it is important to constrain what is written to the attribute, often in complex ways.
+<li>Lacking transactional semantics: Often one needs to update multiple attributes as one action that is guaranteed to either fully succeed or fully fail.
+</ul>
+<a name="resolution"></a>
+<h3>The Usual Resolution Of These Flaws Is A One-Off Solution</h3>
+<p>
+The usual response to these flaws is that persons adding security
+related and other attributes create a set of methods unique to their
+attributes, plus non-reusable code to implement those methods in which
+their particular attributes are accessed and stored not using the
+methods for files, but using their particular methods for that
+attribute.  Their particular API for that attribute typically does a
+one-off instantiation of a lightweight single system call write
+constrained atomic access with no code being reusable by those who
+want to modify file bodies.  It is very basic and crucial to system
+design to decompose desired functionality into reusable orthogonal
+separated components.  Persons designing security attributes are
+typically doing it without the filesystem that they want to add them
+to offering them a proper foundation and toolkit.  They need more help
+from us the core FS developers.  Linus said that we can have a system
+call to use as our experimental plaything in this, and with what I
+have in mind for the API, one rather flexible system call is all we
+want for creating transactional lightweight batched constrained
+accesses to files, with each of those adjectives to accesses being an
+orthogonal optional feature that may or may not be invoked in a
+particular instance of the new system call.
+
+<a name="solution"></a>
+<h3>One-Off Solutions Are A Lot of Work To Do A Lot Of</h3>
+<P>Looking at the coin from the other side, we want to make it an
+order of magnitude less work to add features to ReiserFS, so that both
+users and Namesys can add at least an order of magnitude more of them.
+To verify that it is truly more extensible you have to do some
+extending, and our DARPA funding motivates us to instantiate most of
+those extensions as new security features.
+
+<p>This system call's syntax enables attributes to be implemented as a
+particular type of file --- it avoids uglifying the semantics with two
+APIs for two supposedly but not needfully different kinds of objects.
+All of its special features that are useful for accessing particular
+attributes are all available for use on files also.  It has symmetry,
+and its features have been fully orthogonalized.  There will be
+nothing particularly interesting about this system call to a languages
+specialist (it's ideas are decades old except to filesystem
+developers) until Reiser6, when we will further evolve it into a set theoretic
+syntax that deconstructs tuple structured names into ordered set, and
+unordered set, name components.  That is described at
+www.namesys.com/future_vision.html
+<a name="syscall"></a>
+<h3>reiser4() System Call Description</h3>
+<p>The reiser4() system call will contain a sequence of commands
+separated by a separator ( comma only for now).
+
+<p>
+Assignment, and transaction, will be the commands supported in
+reiser4(), more commands will appear in reiser5.  => and <= will be
+the assignment operators.
+
+<ul>lhs
+(assignment target) values:
+
+<li> /process/buffer/first_byte/last_byte/bytes_written assigns
+(writes) to the buffer starting at address first_byte in the process
+address space, ending at last_byte, with the number of bytes actually
+written (assignment source may be smaller or larger than assignment
+target) being written to address bytes_written.  Representation of
+first_byte,last_byte, and bytes_written is left to the coder to
+determine, as it is an issue that will be of much dispute and little
+importance.  Notice how / is used to indicate that the order of the
+operands matters, see www.namesys.com/future_vision.html for details
+of why this is appropriate syntax design.  Notice the lack of a file
+descriptor
+
+<li>/filename assigns to the file named filename, wholly obliterating
+its body with what is assigned.
+
+<li>/filename/..range/first_byte/last_byte/bytes_written writes to the
+body, starting at first_byte, ending not past last_byte, recording
+number of bytes written in bytes_written
+
+<li>/filename/..offset/offset_byte writes to the body starting at offset
+
+</ul>/..process/..range/first_byte/last_byte/bytes_written writes to
+the process address space, starting at first_byte, ending not past
+last_byte, recording number of bytes actually written in bytes_written
+
+<ul>rhs (assignment source) values:
+
+<li> /process/buffer/first_byte/last_byte/bytes_read reads from the
+buffer starting at address first_byte in the process address space,
+ending at last_byte, with the number of bytes actually read
+(assignment source may be smaller or larger than assignment target)
+being written to address bytes_read.  Representation of first_byte,
+last_byte, and bytes_read is left to the coder to determine, as it is
+an issue that will be of much dispute and little importance.
+
+<li>/filename reads the entirety of the file named filename.
+
+<li>/filename/..range/first_byte/last_byte/bytes_read reads from the
+body, starting at first_byte, ending not past last_byte, recording
+number of bytes read in bytes_read
+
+<li>/filename/..offset/offset_byte/bytes_read reads from the body
+starting at offset until the end
+
+<li>/filename/..stat/owner reads from the ownership field of the stat
+data (stat data is that which is returned by the stat() system call (owner, permissions,
+etc.)
+and stored on a per file basis by the FS)
+
+<li>/filename/..nonbody returns a delimiter separated aggregation of
+all parts of the file except the body of the file (owner, permissions,
+ACLs, etc.).
+
+</ul>
+
+<a name="tr_tr"></a>
+<H3>Transactions and Transcrashes:</H3>
+<a name="tr_necessary"></a>
+<h4>Transactions Are Necessary Safeguard Against Certain Race Condition Exploits</h4>
+
+(This section to be replaced with link to Josh MacDonald paper when that is complete.)
+<p>
+Recently, a security exploit was discovered in all versions of the MIT Kerberos secure authentication system due to unsafe handling of temporary files [Bugtraq, 3/7/2001].
+http://www.linuxsecurity.net/advisories/other_advisory-1204.html
+<p>
+During the process of generating a new ticket, the attacker creates a symbolic link that redirects the ticket file being written to an arbitrary location.  This kind of vulnerability is quite common, unfortunately, due to inherent weaknesses of the traditional POSIX file system interface.  There is no primitive support for an operation that atomically tests for the existence of a symbolic link prior to opening that location, not without vulnerability to races. The solution posted in the Kerberos incident does not completely eliminate the vulnerability.  Instead, vulnerability is greatly reduced through programmer vigilance (provided a few assumptions).  The existing file system interface leaves open potential vulnerabilities such as this, by default, due to the fact that it is a stateless interface.  In general, lacking transactions the result of a file system read cannot be trusted for security decisions; the instant a value is returned it may be out of date.
+<p>
+When security is a concern and the application is sufficiently important that it can be modified to conform with more secure interfaces, there is an easy solution to these problems --- transactions.  Transactions provide the framework for strict, fine-grained locking that is used to extend the atomicity of individual operations into an atomic sequence of operations.  In the Kerberos example, the ticket-writing application would instead issue a sequence of operations to:
+<ul>
+<li>lookup the file to be written,
+<li>make security checks on that file,
+<li>open the file for writing
+<li>output data.
+</ul>
+<p>The transaction framework provides a context for ensuring that a security check remains consistent throughout the resulting operation.
+<p>
+Transactions also provide critical support for extensibility (i.e.,
+plugins), since the system is able to automatically recover from
+partial component failures, and transactions are necessary to support
+consistent operations on multiple parts of an "aggregate" file.  [For
+example: you wish to perform a complex edit over /etc/passwd that
+requires the addition of one user and the deletion of another (e.g.,
+rename user).  To perform that operation consistently you must have
+transactions to preserve the invariant.]
+<p>
+There is a close relationship between version control and transaction
+isolation, which is why the same programmer on our team (Josh
+McDonald) does both.
+
+<a name="transcr"></a>
+<H4>Transcrashes</H4>
+<p>
+There is a reason why filesystems implemented on top of databases have
+not performed well.  Traditional database transactions do more work
+than the filesystems needs them to do.  It is not that database
+transactions are done wrong (far from it, we will take great pride in
+adding database style transactions to reiser4), it is that in some
+circumstances they are doing more work than is needed by traditional
+filesystem usage requirements, and good performance requires making
+the aspects of consistency independently selectable.  In particular,
+filesystems often need to be able to guarantee that an operation will
+be atomic with respect to surviving a crash, and DON'T need to
+guarantee isolation with respect to other concurrent operations.  This
+has profound performance import, and it affects not just buffering in
+RAM, but also dramatically impacts the size of logs.
+<p>
+[J.n> Gray] models transactions as having 4 degrees of consistency.  I
+find it more appropriate to model not degrees of consistency, which
+implies that the features have ranked levels and one cannot have a
+higher level feature without also getting the lower level features
+with it, but aspects of consistency, each potentially fully orthogonal
+to the other.
+<p>
+There are three aspects of consistency we will support initially, and
+you'll note that they are decoupled and independently specifiable.
+<ul>
+<li>"Transcrashes", which guarantee that either all or none of the
+transcrash will survive a crash.
+<li>Branches, which guarantee isolation but not exclusion.
+<li>Locks, which guarantee exclusion but not isolation.
+</ul>
+<p>
+There is necessarily a performance cost to implementing an isolated
+transaction.  This cost can be reduced for transcrashes which are not
+also branched or locked.  Very frequently the application better knows
+whether it needs to branch or lock, knows that its structure of
+operation is such that it does not need the protection of branching
+and locking, and it can depend on itself to do the right thing without
+the significant unnecessary performance cost of asking the filesystem
+to protect it from itself.
+<p>
+A "limited transcrash" has the property that it can be told to finish up
+and either commit or abort within MAX_LIMITED_TRANSCRASH_DELAY time, and
+it also has the property that the filesystem doesn't have to know how to
+rollback if it chooses to abort but rather the user space process must
+track how to do rollbacks.  Most such transcrashes will be implemented
+to not ever rollback, but more simply to instead take responsibility
+for ensuring that they can commit quickly enough.  If they fail to do
+so, the commit will be imposed upon them before they have completed
+the transcrash.  This approach is particularly useful for high
+performance short running transcrashes.
+<p>
+For instance, suppose you want to do two simple updates to two files
+as an atomic transaction, and these updates will not require longer
+than MAX_TRANSCRASH_DELAY to be done, and you want to be able to do
+many of these in parallel with high performance, and the application
+process running in user space is able to handle worrying about
+enforcing isolation through selective locking.  In that case, a common
+view of the filesystem state involving many other such limited
+transcrashes can be batched together and committed as one commit.
+(This is necessarily higher performance.)  When memory pressure
+triggers commit, all new transcrashes will hang while all outstanding
+transcrashes are signalled to complete their transcrash, and given
+MAX_TRANSCRASH_DELAY time in which they can be a running process if
+they choose to be.  Carefully note that the delay allowed has to be
+measured as time during which the process has priority if it chooses
+to be runnable, not as absolute time.  (Nikita, please phrase this
+more precisely for me, you know the scheduler better than I.)
+<p>
+A particular source of concern is high concurrency of semantically
+unrelated data that has common metadata.  For instance, the super block
+and the internal nodes of the tree.  Where the application can
+track and self-ensure the isolation of itself from concurrent
+processes rather than requiring the OS to give it its own atomically
+merged and committed view, performance is very likely going to be
+higher, and perhaps order of magnitude higher.
+<p>
+Reiser4 will implement limited transcrashes first, and whether it will
+implement branching in v4.0 or 4.1 will depend on how fast
+Josh works.
+<p>
+Why are limited transcrashs the priority for us?  We need to ensure that
+the infrastructure we create is performance efficient for what
+filesystems currently do before we enable new functionality based on
+strong transactions.  In other words, we have gotten addicted to being
+the fastest FS in town, and we don't want to lose that.  Reiser4 needs
+transactional semantics for some of its internal housekeeping
+(implementing rename), and only limited transcrashs are a high enough
+performance architecture for those needs.
+<p>
+When any grouping delimiter ([] is the only one for 4.0) is preceded
+by tw/transcrash_name (e.g. tw/transcrash_33[ /home/reiser/a <=
+/home/reiser/b, /home/reiser/c <= /home/reiser/d]), then it delimits a
+transcrash.  We leave unspecified for now how to have multipart
+specifications of a transcrash (I am getting pretty shameless in
+deferring things for v4.1, yes...? ).  Transactions logically batch
+not nest, extent that the interpreter will error check the nesting to
+make sure that it has not been passed confused garbage.
+<p>
+To anyone who has worked in databases or any other aspect of language
+design, this design surely seems exceedingly simple and modest.  To
+many filesystem and OS folks, this seems like something extraordinary,
+commands that are parsed, oh no!  The complexity will be
+extraordinary, oh no!  Sigh.  Namesys, determined to bring radical new
+1960's technology from other areas of computer science into the file
+systems field no matter how crazy our competitors think we are!  Sigh.
+Reiser4 will be smaller than XFS much less VxFS....
+
+<a name="performance"></a>
+<H1>Performance Enhancements</H1>
+
+<a name="dancing"></a>
+<H2> Dancing Trees Are Faster Than Balanced Trees</H2>
+
+<p> ReiserFS V4 will also add innovations in the fundamental tree
+technology.  We will employ not balanced trees, but "dancing trees".
+Dancing trees merge insufficiently full nodes not with every
+modification to the tree, but instead:
+
+<ul>
+
+<li>in response to memory pressure
+triggering a commit.
+
+<li>when an insertion into an internal node presents a danger of
+needing to split the internal node, and the immediate children are not
+sufficiently space efficient (sufficiently being a configurable
+value), and reducing the number of children could avoid the split.
+</ul>
+<a name="if_ram"></a>
+<h3>If It Is In RAM, Dirty, and Contiguous, Then Squeeze It ALL
+Together Just Before Writing</h3>
+
+<p>Let a slum be defined as a maximal sequence of contiguous in the
+tree order, and dirty in this transaction, nodes.  A dancing tree,
+when presented with memory pressure, responds to it by committing the
+transaction, and the commit in turn triggers a repacking of all slums
+involved in the transaction which it estimates can be squeezed into
+fewer nodes than they currently occupy.
+<p>
+Balanced trees have an
+inherent tradeoff between balancing cost and space efficiency.  If
+they consider more neighboring nodes, for the purpose of merging them
+to save a node, with every change to the tree, then they can pack the
+tree more tightly at the cost of moving more data with every change to
+the tree.
+<p>
+By contrast, with a dancing tree, you simply take a large slum, shove
+everything in it as far to the left as it will go, and then free all
+the nodes in the slum that are left with nothing remaining in them, at
+the time of committing the slum's contents to disk in response to
+memory pressure.  This gives you extreme space efficiency when slums
+are large, at a cost in data movement that is lower than it would be
+with an invariant balancing criterion because it is done less often.
+By compressing at the time one flushes to disk, one compresses less
+often, and that means one can afford to do it more thoroughly.
+
+<a name="repacker"></a>
+<h2>Repacker</h2>
+<p>
+Another way of escaping from the balancing time vs. space efficiency
+tradeoff is to use a repacker.  80% of files on the disk remain
+unchanged for long periods of time.  It is efficient to pack them
+perfectly, by using a repacker that runs much less often than every
+write to disk.  This repacker goes through the entire tree ordering,
+from left to right and then from right to left, alternating each time
+it runs.  When it goes from left to right in the tree ordering, it
+shoves everything as far to the left as it will go, and when it goes
+from right to left it shoves everything as far to the right as it will
+go.  (Left means small in key or in block number:-) ).  In the absence
+of FS activity the effect of this over time is to sort by tree order
+(defragment), and to pack with perfect efficiency.
+<p>
+Reiser4.1 will modify the repacker to insert controlled "airholes", as
+it is well known that insertion efficiency is harmed by overly tight
+packing.
+<p>
+I hypothesize that it is more efficient to periodically run a repacker
+that systematically repacks using large IOs, than to perform lots of 1
+block reads of neighboring nodes of the modification points, so as to
+preserve a balancing invariant in the face of poorly localized
+modifications to the tree.
+<a name="commit"></a>
+<H2>Encryption On Commit</H2>
+<p>
+Currently, encrypted files suffer severely in their write performance
+when implemented using schemes that encrypt at every write() rather
+than at every commit to disk.  We will implement encrypt on flush,
+such that a file with an encryption plugin id is encrypted not at the
+time of write, but at the time of commit to disk.  This is both
+non-trivial to implement, and important to performance.  It requires
+implementing a memory pressure manager for ReiserFS.  That memory
+pressure manager would receive a request to either reduce memory
+consumed, reduce dirty memory (dirty memory needs special treatment
+for deadlock avoidance reasons), or verify that nothing overly old has
+been kept in memory for too long.  It would respond by selecting what
+to commit, and preparing it for writing to disk.  That preparation
+will consist of encrypting it for those files that implement the
+encryption plugin.  (It can also consist of allocating optimal block
+numbers and repacking formatted nodes and compressing data, but that
+is not of such concern here.)  I suspect you will want us to
+coordinate with the PGP developers you are also contracting with.
+
+<p>Encryption is implemented as a special form of repacking, and it
+occurs for any node which has its CONTAINS_ENCRYPTED_DATA state flag
+set on it regardless of space usage.  With the dancing tree
+infrastructure in place, it should be only a moderate amount of work
+to implement encryption as a variant on repacking on commit.
+<p>
+<a name="wand_lgs"></a>
+<h3>Wandering Logs</h3>
+<a name="more_detailed"></a>
+<h4>(More detailed treatment soon to be available at www.namesys.com/transactions.html by Joshua MacDonald.)</h4>
+<p>
+Traditional fixed location logs have a problem in that data gets
+written twice, once to the log, and once to the rest of the
+filesystem.
+<p>
+Instead of moving data out of the log, wandering logs redefine what
+blocks compose the log.  There is no fixed location for where the log
+is, though there are fixed locations for where the definition of what
+blocks compose the log is.
+<p>
+This approach has two principle disadvantages:
+<ul>
+<li>blocks which contain data that must be retained if the transcrash
+fails to complete cannot be written in the place of the block
+containing the old data, and their location may not be as optimal as
+that of the new data (it may also be more optimal though)
+
+<li>it does not support undo/redo for isolated transactions
+</ul>
+<p>
+This means that in addition to wandering block logs, we also need
+wandering logical logs.
+<p>
+Wandering logical logs log for every transaction enough information to
+either redo or undo each isolated transaction.
+<p>
+They have the disadvantage that first they write the data into the log
+(though it can go anywhere convenient to define as part of the log),
+and then they write the data again after the transaction commits.
+<p>
+They have the advantage that for small updates (when not logging a 100
+megabyte file) their log is smaller.  This is potentially useful for
+distributed filesystems which operate by transmitting the log.
+<p>
+The compelling reason for supporting them is that they are needed for
+supporting isolated transactions, and while isolated transactions are
+expected to be only a small fraction of total disk IO, they are quite
+important functionally.  (How many bytes does it take to make your
+system not secure.... )
+
+<a name="conclusion"></a>
+<h1>Conclusion</h1>
+<p>
+Reiser4 will offer a dramatically better infrastructure for creating
+new filesystem features.  Files and directories will have all of the
+features needed to make it not necessary to have file attributes be
+something different from files.  The effectiveness of this new
+infrastructure will be tested using a variety of new security
+features.  Performance will be greatly improved by the use of dancing
+trees, wandering logs, allocate on flush, a repacker, and encryption
+on commit.
diff -puN /dev/null doc/reiser4.writeback.overview
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/reiser4.writeback.overview	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,68 @@
+Hello,
+
+reiser4 has some features that make it somewhat difficult to integrate with
+existing VM mechanisms.
+
+Reiser4 maintains all meta data in the single balanced tree. This tree is
+maintained in the memory in the form different from what will be ultimately
+written to the disk. Roughly speaking, before writing tree node to the disk,
+some complex process ("flush") is to be performed. This process has following
+characteristics:
+
+ 1 it is not local, that is it operates on big number of nodes, possibly far
+   away from the starting node, both in tree and disk order.
+
+ 2 it can involve reading of the large number of nodes from the disk (for
+   example, bitmap nodes are read during extent allocation that is deferred
+   until flush).
+
+ 3 it can allocate unbounded amount of memory (during insertion of allocated
+   extents).
+
+ 4 it participates in the locking protocol which reiser4 uses to implement
+   concurrent tree modifications.
+
+ 5 it is CPU consuming and long
+
+As a result, flush reorganizes some part of reiser4 tree and produces large
+queue of nodes ready to be submitted for io (as a matter of fact, flush write
+clustering is so good that it used to hit BIO_MAX_PAGES all the time, until
+checks were added for this).
+
+Items (3) and (4) alone make flush unsuitable for being called directly from
+reiser4 ->vm_writeback() callback, because of OOM and deadlocks against
+threads waiting for memory.
+
+So, it was decided that flush has to be performed from the separate
+thread. Reiser4 has thread used to periodically commit old transactions and
+this thread can be used for the flushing. That is, flushing thread does flush
+and accumulates nodes prepared for the IO on the special
+queue. reiser4_vm_writeback() submits nodes from this queue, if queue is
+empty, it only wakes up flushing thread and immediately returns.
+
+Still there are some problems with integrating this stuff into VM scanning:
+
+ 1 As ->vm_writeback() returns immediately without actually submitting pages
+   for IO, throttling on PG_writeback in shrink_list() will not work. This
+   opens a possibility (on a fast CPU), of try_to_free_pages() completing
+   scanning and calling out_of_memory() before flushing thread managed to add
+   anything to the queue.
+
+ 2 It is possible, however unlikely, that flushing thread will be unable to flush
+   anything, because there is not enough memory. In this case reiser4 resorts
+   to the "emergency flush": some dumb algorithm that writes tree nodes to the
+   disk without taking locks and without optimizing tree layout.
+
+ 3 Nodes prepared for IO can be from the active list, this means that they
+   will not be met/freed by shrink_list() after IO completion. New
+   blk_congestion_wait() should help here though.
+
+It looks like we need following changes to make this stuff working:
+
+ 1 Adding ->priority field into struct writeback_control, so that file system
+   can vary its behavior depending on how desperate memory pressure is.
+
+ 2 Different mechanism for scan throttling.
+
+Actually latter can be implemented completely within reiser4 but with some
+awkwardness.
diff -puN /dev/null doc/set-theoretic-stuff.tex
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/set-theoretic-stuff.tex	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,82 @@
+\documentclass[a4paper, oneside, fleqn]{article}
+
+\usepackage{latexsym}
+\usepackage{url}
+\usepackage[T2A]{fontenc}
+
+\pagestyle{empty}
+\listfiles
+\setcounter{errorcontextlines}{100}
+\makeindex
+\pagestyle{headings}
+\frenchspacing
+\tolerance=1000
+\parindent=0pt
+\raggedbottom
+\setlength\parskip{6pt}
+
+\DeclareMathAlphabet{\mathbsf}{T2A}{cmss}{b}{n}
+\SetMathAlphabet{\mathbsf}{normal}{T2A}{cmss}{b}{n}
+
+\def\qopname@#1{\mathop{\fam 0#1}\nolimits}
+\newcommand{\mathsign}[1]
+	{\index{#1@$\mathbsf{#1}$}\qopname@{\mathbsf{#1}}}
+
+\def\As{\mathsign{Assoc}}
+\newcommand{\svi}[2]
+    {\texttt{[} #1 \ V \texttt{]}}
+
+\begin{document}
+
+\thispagestyle{empty}
+
+%\section{Definitions}
+
+We have a set $X$ of objects, and ``associated-with'' relation. We shall write
+
+$$a\As b, \quad a\in X, \ b\in X$$
+
+to denote that $a$ is associated with $b$.
+
+One can imagine $\As$ relation as graph where elements of $X$ are nodes and
+where there is arc (arrow) from $a$ to $b$ iff $a$ is associated with
+$b$. Note that no further restrictions are placed on $\As$. In particular, it
+is not supposed that $\As$ is reflexive (object is not necessary associated
+with itself), symmetric, or transitive.
+
+$\beta(X)$ is set of all subsets of $X$, that is $$\beta(X) = \{ U \subseteq X
+\}$$
+
+Let's define function $A:X\to^{}\beta(X)$ as follows:
+
+$$A(x)=\{y\in X\ |\ y\As x\}, \quad x\in X.$$
+
+that is $A(x)$ is a set of all objects in $X$ associated with $x$.
+Then, define \mbox{$A^*:\beta(X)\to^{}\beta(X)$} as follows:
+
+$$A^*(U)=\bigcup\limits_{x\in U} A(x), \quad U\subseteq X.$$
+
+that is, $A(U)$ is set of all objects associated with any element of $U$. Now
+we can define $\svi{U}{V}$, where $U, V\subseteq X$---``set vicinity
+intersection'' operation as:
+
+%\begin{displaymath}
+%A^+(U) = \left\{
+%    \begin{array}{rl}
+%    U = \{x\}      & \Rightarrow A(x),\\
+%    \textrm{else}  & \Rightarrow A^*(U)
+%    \end{array} \right.
+%\end{displaymath}
+
+$$\svi{U}{V} = A^*(U) \cap A^*(V).$$
+
+In other words, $\svi{U}{V}$ is a set of all objects associated with some
+element of $U$ \emph{and} some element of $V$.
+
+\end{document}
+
+% Local variables:
+% indent-tabs-mode: nil
+% tab-width: 4
+% eval: (progn (if (fboundp 'flyspell-mode) (flyspell-mode)) (set (make-local-variable 'compile-command) "latex set-theoretic-stuff.tex ; dvips -o set-theoretic-stuff.ps set-theoretic-stuff.dvi"))
+% End:
diff -puN /dev/null doc/syntax.alg
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/syntax.alg	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,152 @@
+<TITLE>Reiser4() Syntax In All Its Obscurities</TITLE>
+
+<H1>Introduction</H1>
+
+<p> We define a file operations API, that allows accessing files and
+performing operations on them.  These same files are also accessible
+by the usual Linux conventional VFS API.
+
+<p>The existing VFS API is appropriate for accessing streams of data
+that are larger than the buffers used to hold them, by using simple
+hierarchical names.
+
+<p>
+There exist other needs.
+
+<p> The new API provides a very few of them, but more significantly,
+makes it easy to add more of them later.  Much of what we do in v4 to
+expand the existing semantics can be done by accessing special
+pseudo-files, and so we implement that.  Some of it, particularly
+efficiently accessing multiple small files (or "attributes" which
+should be implemented as files) with transactions in a single system
+call, cannot be done via existing system calls, and requires a new
+API.
+
+
+<H2>Why Not Change The VFS All Filesystems Use?</H2>
+
+<p> It is usual to ask, why don't we implement all of the new
+functionality in VFS, changing all of the other filesystems, and
+getting all of the authors of all of the other filesystems to agree
+with the changes and participate in making them.
+
+<p>The programming community has a different customary process, for
+several reasons.  Too many cooks spoil the soup, regardless of how
+good they are.  Only after the soup is made, can others know whether
+our recipe is desirable or to be avoided.  Then, using the GPL license
+with its restrictions, or obtaining another license from us if
+proprietary, they can take what was shown to work well from our code,
+and improve it from there.  Also, stability is very important to VFS,
+and by making our experimental changes to separate code accessed by a
+separate system call, we make change less disruptive.  Standards are
+for when consensus has emerged, not for the tumult of active research.
+It is not realistic to think that such a consensus will be quickly
+reached, and a working implementation will propell such a consensus
+faster than any other form of persuasion.
+
+
+<h2>Library vs. Kernel</h2>
+
+<p> We have no deep reason for not adopting an exo-kernel style
+approach.  We developed for Linux, and Linux is not an exo-kernel.  It
+is not appropriate for us to differ from the rest of Linux in this
+aspect.  I am far from religious about the micro/exo/macro kernel
+debates.  Micro kernels (e.g. HURD) seem to have substantially lower
+performance while being easier to debug.  It won't surprise me if
+somebody cures the lowered performance someday by being clever.  Many
+of the developers on our team think we should put as much of our
+functionality into the libraries as possible.  The danger in doing
+that blindly is the danger of experiencing micro-kernel performance
+problems.  Putting the functionality either all in the kernel
+(monolithic kernel (Linux)), or all out of the kernel (exo-kernel)
+seems likely to result in the best performance.  Selecting certain
+functionality which lends itself naturally to being layered above our
+interface, and putting it into libraries, is also reasonable, though
+there might not be much of it frankly. Functionality that initially
+seems likely to someday evolve to access functions not exposed outside
+the kernel should be inside the kernel for optimal efficiency, and for
+simplicity of kernel interface. If the applications don't see whether
+it is in the kernel or in the library, then one can change the
+location later.  For now our first pass at the problem is to put the
+functionality into the kernel part of Reiser4.  Perhaps during the
+debugging phase we will even pull certain pieces out of the kernel....
+
+<h2>Creating Objects</h2>
+
+<p> Every object must have at least one name, though that name might
+be just its key.  Every object has a key.
+
+<h3>Objects With Only Keys For Names</h3>
+
+Objects with only keys for names can be accessed by the name
+"..key/KEY" where KEY is of type key.  "..key" is not implemented as a
+tradition directory: it has no directory entries, and performs lookups
+by looking in the tree for them.  Objects that may have only keys for
+names must have a flag so indicating in their stat data, or else fsck
+will assume they are lost files and put them in lost+found.
+Permission to access by key must be explicitly granted, and by default
+is not granted to any user even root.
+
+<H3>Object Plugin Determined At Object Creation Time</H3>
+
+<p> There are various non-symmetries of object creation.  Plugins can
+only be specified at object creation time (this might change in the
+future for some plugins, but it is universally true in v4.0), and
+changing plugins requires creating a new file and copying the old file
+to the new file.
+
+<p> The implication of these non-symmetries is that the syntax for
+object creation necessarily must allow for multi-value assignment.
+Each plugin must specify a set of assignments to look for, and provide
+defaults for the event that they are ommitted.  There is even a
+default packing locality for objects created without specified names
+or packing localities.
+
+<H3>The object creation method is determined by the name.</H3>
+
+<H3>Packing Locality Is Determined At Object Creation Time</H3>
+
+<p> Keys determine what an object is to be packed near. If the packing
+locality for an object is specified at creation time, then we use the
+specified packing locality.  If not, then if a name for the object is
+specified at object creation time, then we let the parent directory
+present in the name determine its packing locality, which by default
+means to set it equal to the packing locality of its parent directory..
+<p>
+The implication of this is that specifying a name for an object at
+creation time has an effect in addition to that of specifying a name
+at some later time if the packing locality will be inherited from the
+parent directory in the name.  Also, objects whose packing localities
+are equal to the parent directory for their name can have their keys
+better compressed.
+
+<p> If an object is created without name and without specified packing
+locality, then it is assigned to the default packing locality.  Since
+the next field after packing locality within a key is the objectid,
+and object creation time proximity correlates strongly with objectid
+proximity due to the algorithms used, this has the effect of causing
+objects with creation time proximity to be created near each other in
+tree order and thus near each other in disk geometry.  This is an
+intended effect.  Interleaved deletes may complicate this, but some
+correlation will remain.  There is to be a special directory "/..keys"
+which allows listing of all objects in the FS by key.
+
+<h3>We Offer An Object, Not Block, Storage Interface</h3>
+
+<p> Allowing applications to reserve and control specific blocks ala
+Franz's exo-kernel is a feature not yet supported, though it would
+have advantages for boot loaders and other applications.  Our current
+mechanism of allowing tails to be turned off, and then allowing
+querying of what blocks a file occupies, can be thought of as a poorly
+abstracted version of this (and the linux boot loaders currently
+support this poor abstraction we offer.)
+
+<p>
+ascii_command =
+<p>                '/home/teletubbies/(..new/(..name<-glove_location,..object_t<-(audit|encrypted), ..perm_t<-acl );
+<p>                 glove_location/..acl/(uid=357, access<-denied));
+<p>                /home/teletubbies/glove_location/..audit/..new/(mailto<-"(teletubbies@pbs.org));
+<p>                /home/teletubbies/glove_location<-"(we stole it quite some number of years ago,and put it in the very first loot pile (in the hole near the purple flower).);'
+
+
+
diff -puN /dev/null doc/sys-reiser4-implemenation-overview
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/sys-reiser4-implemenation-overview	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,222 @@
+SYS_REISER4 IMPLEMENTATION OVERVIEW
+
+
+A. Basics
+*****************************************************************
+
+sys_reiser4() system call executing a sequence of actions upon the
+file-system(s). Actions are specified by the user in the form of a command
+string. For the purposes of present discussion, said command string can be
+thought of as a program in a special purpose programming language, which will
+be further referred to as reiser4_lang.
+
+Canonical example of reiser4_lang program is
+
+/dir1/dir2/dir3/file1 <- /dir4/dir5/dir6/file2
+
+It semantics is following:
+
+1. resolve "/dir1/dir2/dir3/file1" into file-system object (lookup operation)
+2. resolve "/dir4/dir5/dir6/file2" into file-system object (lookup operation)
+3. assign latter to the former.
+
+This is "assignment" operator. Assignment involves two "file-system objects"
+and semantics of both lookup stage and assignment proper depends upon the type
+of the file-system object.
+
+Following types of file-system objects are recognized:
+
+1. foreign objects: objects of different file-systems. Foreign object cannot
+be target or source of an assignment. Rather, foreign objects can only appear
+during path name lookup, while traversing non-reiser4 part of the file-system
+name-space. Probably one should distinguish between objects belonging to
+different file-system types (etx2, NFS) and objects belonging to different
+reiser4 mounts. After sys_reiser4() is stable, foreign objects will be more
+fully supported.
+
+2. reiser4 objects.
+
+3. pseudo-objects: these are entities injected into reiser4 name-space to
+provide uniform access to various file-system meta-data. Pseudo-objects are
+(usually) attached to some particular "host" object. [In the initial version,]
+host objects are reiser4 objects. [Later it is possible to implement some
+pseudo-objects for foreign objects.] Convention (but not enforced rule) is
+that pseudo-objects are accessible through names starting with some well-known
+prefix (".." is current favorite). Examples: ..owner, ..acl, etc. See comment
+at the top of fs/reiser4/plugin/pseudo/pseudo.c for more details.
+
+B. lnodes
+*****************************************************************
+
+lnodes are handles for file-system objects described above. They serve dual
+purpose:
+
+1. uniform interface to the various types of objects. This allows the
+reiser4_lang implementation to treat various types of objects in the same
+manner. When new type of object has to be added, all changes will be grouped
+in one place, rather than scattered across various files. This uniformity also
+allows code sharing between reiser4_lang and VFS access paths. For example,
+the same ->write method can be used by both. That is, ->read(), and ->write()
+plugin methods used in VFS access paths will take lnode(s) as arguments and
+can share code with sys_reiser4() implementation. For example, assignment is
+particular case of write (or visa versa, depending on point of view).
+
+
+2. synchronization. reiser4_lang doesn't use inodes and this poses a problem of
+synchronization with VFS. Each lnode serves as a lock. See lnode.c for more
+details.
+
+C. lookup
+*****************************************************************
+
+reiser4_lang still supports only two traditional UNIX kinds of ordered names
+(pathnames): absolute and relative to the current working directory. In both
+cases, lookup starts from some file-system object represented by lnode. Then
+lookup proceeds component-by-component as follows:
+
+   lnode *parent;
+   lnode  child;
+
+   ret_code = lnode_get_dir_plugin( parent ) -> lnode_by_name( parent,
+                                                               path_component,
+                                                               &child );
+
+1. Abovementioned locking issues require that parent lnode has to be kept
+until operation on child finishes. In effect we get lock-coupling much like in
+internal tree traversal. Also, possibility to use lock on node with directory
+entry in stead of object lock was discussed. We have to think more on this.
+
+
+2. Mount points crossing. It is possible, because dentries and therefore
+inodes of all mount points are pinned in memory and lookup code can check at
+each step whether mount point is crossed. Details are not very nice, because
+for each inode in a path we have to scan list of all its dentries and check
+whether correct one (corresponding to our path) is mount point.
+
+3. It is also possible to pass ->lnode_by_name the whole of the remaining
+name, and let it decide how much of it it should handle. This will complicate
+locking somewhat. But this is doable, though requires changes to the parser.
+
+
+D. assignment
+*****************************************************************
+
+Assignment A<-B basically means duplicating content of B into A. No
+copy-on-write optimizations will be in version 4.0.
+
+Assignment implementation is based on the notion of flow (flow_t). Flow is a
+source from which data can be obtained. Flow can be "backed up" by one of the
+following:
+
+1. memory area in user space. (char *area, size_t length)
+2. memory area in kernel space. (caddr_t *area, size_t length)
+3. file-system object (lnode *obj, loff_t offset, size_t length)
+
+Main function to manipulate flows is:
+
+int flow_place( flow_t *flow, char *area, size_t length );
+
+it copies @length bytes of @flow into @area and updated @flow correspondingly.
+Behavior of flow_place() depends on the type of entity backing up @flow. If
+@flow is based on the kernel-space area, memmove() is used to copy data. If
+@flow is based on the user-space area, copy_from_user() is used. If @flow is
+based on file-system object, flow_place() loads object's data into page cache
+and copies them into @area.
+
+Thus, assignment code looks like following:
+
+typedef int ( *connect_t )( sink_t *target, flow_t *source );
+
+int reiser4_assign( lnode *dst, lnode *src )
+{
+    flow_t        source;
+    sink_t        target;
+    int           ret_code;
+    file_plugin  *src_fplug;
+    file_plugin  *dst_fplug;
+    connect_t     connection;
+
+    /* get plugins */
+
+    src_fplug = lnode_get_file_plugin( src );
+    dst_fplug = lnode_get_file_plugin( dst );
+
+    /* build source flow */
+    ret_code = src_fplug -> build_flow( src, &source, 0 /* offset */ );
+
+    /* build target sink */
+    ret_code = dst_fplug -> build_sink( dst, &target, 0 /* offset */ );
+
+    /*
+     * select how to transfer data from @src to @dst.
+     *
+     * Default implementation of this is common_transfer() (see below).
+     *
+     * Smart file plugin can choose connection based on type of @dst.
+     *
+     */
+    connection = src_fplug -> select_connection( src, dst );
+
+    /* do transfer */
+    return connection( &target, &source );
+}
+
+
+/* look to chain conversion of (lnode * dst) -> (sink_t target) -> (lnode * dst)
+ I think, functions build_sink(...) and  sink_object(...) - superfluous */
+
+int common_transfer( sink_t *target, flow_t *source )
+{
+    lnode  *dst;
+
+    dst = sink_object( target );
+    while( flow_not_empty( source ) ) {
+        char   *area;
+        size_t  length;
+
+        /*
+         * append some space to @target. Reasonable implementation will
+         * allocate several pagesful here
+         */
+        ret_code = lnode_get_body_plugin( dst ) -> prepare_append( dst,
+                                                                   &area,
+                                                                   &length );
+                                            /* why @length not depended from source? */
+        /*
+         * put data from flow into newly alloted space. This also updates
+         * @flow.
+         */
+        flow_place( source, area, length );
+        /*
+         * perform necessary post-write activity required by @dst plugin, like
+         * encryption, compression, etc. Release pages.
+         */
+        ret_code = lnode_get_body_plugin( dst ) -> commit_append( dst,
+                                                                  area, length );
+    }
+}
+
+
+E. parsing
+*****************************************************************
+
+It is not clear what parts of reiser4_lang processing should go into
+kernel. In any case, providing direct system call as main (or, worse, the
+only) way to access reiser4_lang functionality bounds as to maintain binary
+compatibility in a future. To avoid this, reiser4 should be shipped with
+user-level library, containing
+
+int reiser4( const char *cmd, size_t length );
+
+function. For now, this function will directly despatch @cmd to the
+sys_reiser4() in a future, it may do parsing itself and pass parse tree to the
+kernel interpreter.
+
+*****************************************************************
+
+# Local variables:
+# mode-name: "proposal"
+# indent-tabs-mode: nil
+# tab-width: 4
+# eval: (if (fboundp 'flyspell-mode) (flyspell-mode))
+# End:
diff -puN /dev/null doc/wander.txt
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/doc/wander.txt	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,184 @@
+
+Before discussing the format of the commit record occupying the
+journal area, we must revisit the topic of free space bitmap
+management.  At the time an atom is closing and formatting its commit
+record, the question is how to deallocate the blocks deleted by the
+atom.  Those blocks become free once the atom commits, but they cannot
+be re-allocated before that point in time.
+
+Modified bitmaps are always part of the overwrite set, meaning copies
+are written to wandered positions (i.e., part of the log) before later
+being overwritten.
+
+We have defined these terms:
+
+WORKING BITMAPS: the "current" in-memory bitmaps
+
+COMMIT BITMAPS: bitmap copies written to wandered, overwrite positions
+
+DELETE SET: the set of deleted blocks plus the set of former positions
+of relocated blocks.  These block positions are deallocated when the
+atom commits.
+
+WANDERED SET: the set of temporary locations used to store overwrite
+blocks before they are actually overwritten.  These block positions
+are deallocated some time after the atom commits, when it is ensured
+that the atom will no longer replay during crash recovery.
+
+Both the delete set and the wandered set are blocks to be deleted, but
+the details of handling these deletions are necessarily different.
+
+---- Consider first the handling of the DELETE SET.
+
+There are two ways to handle the delete set.  Before reading their
+descriptions, let me offer my opinion.  The first is MORE complicated
+but requires LESS data to be logged in the commit record.  The second
+is LESS complicated but requires MORE data to be logged in the commit
+record.
+
+Strategy #1: MORE COMPLICATED, LESS LOGGED DATA
+
+  At the time an atom closes, it creates a snapshot of all the
+  modified bitmaps.  In other words, it creates commit bitmaps which
+  are copies of the working bitmaps.  The delete set are immediately
+  deallocated in the commit bitmaps, which are written to their
+  wandered positions and later overwritten in their actual positions.
+
+  This way, the commit record does not contain any record of the
+  delete set.
+
+  But there are problems with this approach, too.  First, there is
+  extra memory pressure associated with maintaining extra copies of
+  modified bitmaps.  Second, it is less straight forward than it may
+  appear at first.  Suppose there are two atoms that commit in
+  sequence, such that the first does not complete its commit (i.e.,
+  finish all the required writes) before the second prepares to
+  commit.  Which bitmaps does the second committing atom copy as its
+  commit bitmaps?  It does not just copy the working bitmaps, since
+  those do not yet represent the first atom deallocations.
+
+  Instead, it looks like we would end up maintaining multiple copies
+  of every bitmap.  Each atom's commit bitmaps are the commit bitmaps
+  of the previous atom plus whatever modifications were made by the
+  atom itself.  This means in addition to maintaining the working
+  bitmaps, we end up maintaining separate commit bitmaps.  It is not
+  just as simple as copying the working bitmaps at the time of commit.
+
+  This solution looks far too complicated to me.  I admit that I have
+  not fully tried to understand the complexity, but I do not think the
+  advantages (smaller commit records) will outweigh the additional
+  complexity, not to mention the additional memory pressure.
+
+Strategy #2: LESS COMPLICATED, MORE LOGGED DATA
+
+  In this solution, the commit bitmaps are the same as the working
+  bitmaps--no copies are made.  We commit the working bitmaps without
+  deallocating the delete set and we include the delete set in the
+  commit record instead.
+
+  Before I describe exactly how deallocation works in this case, let
+  me add that there is another reason why this method is preferred.
+  The wandered set has to be deleted after the atom commits, since it
+  does not become available until the atom will no longer be
+  replayed.  With this approach to freeing the delete set, both kinds
+  of deletion can be handled in the same manner, since they both take
+  place after the atom commits.
+
+  In other words, since we have to address deallocating the wandered
+  set after commit anyway, we might as well use the same mechanism for
+  deallocating the delete set.  It means that additional data is
+  logged, but it reduces complexity in my opinion.
+
+  Here's how it works.  The atom stores a record of its delete set in
+  memory.  When a block is deallocated or relocated, the bit is of
+  course not immediately deallocated in the working bitmaps.
+
+  The delete set is included in the commit record, which is written to
+  the journal area.  The delete set is just a set of block numbers, so
+  there are several possible representations.  The implementation
+  could actually dynamically chose the representation to achieve the
+  best compression: (a) list of blocks, (b) bitmap, and (c) extent
+  compression.  The second two options are likely to achieve
+  significant compression of the delete set unless fragmentation
+  becomes a problem.
+
+  The atom maintains its in-memory copy of the delete set until the
+  commit record is flushed to the disk.  At this point, those blocks
+  become available for new atoms to re-allocate.  The atom releases
+  these blocks back into the working bitmaps through the process of
+  "reposession".  The reposession process makes a younger atom
+  responsible for committing a deallocation from a previous atom.
+
+  For each block in the committed atom's delete set, a younger atom is
+  selected (or created) to handle the deallocation of that block.  The
+  working bitmap corresponding to the block being deleted is or was
+  already captured by the younger (reposessing) atom.  The block is
+  simply marked as deallocated in the working bitmap block captured.
+
+  The reposessing atom may immediately use this block or not, but in
+  either case the deallocation is committed once the reposessing atom
+  commits.  For recovery purposes (not discussed here), each atom also
+  includes a list of atoms for which it resposesses.
+
+---- The commit record
+
+The commit record includes three lists:
+
+  DELETE SET: The set of blocks deallocated by this atom, represented
+  as either a list, bitmap, or using extents.
+
+  WANDER SET: A list of block-pairs giving the original location and
+  the temporary wandered location.  During replay the temporary
+  location is copied to the original location.  After replay is no
+  longer needed, the temporary locations are deallocated using
+  reposession as previously described.
+
+  REPOSESSES FOR SET: A list of the previous atoms for which this atom
+  reposesses deallocated blocks.  This is used to know which atoms
+  deallocations must be replayed during crash recovery.
+
+I propose that all of this information is included in the commit
+record, which is written to the journal area.  There may be multiple
+journal areas (a significant complication) or there may not, but the
+key point is that all of this data is written into a reserved,
+cyclical journal area.  Because the journal area is reserved and
+written in a simple cyclical manner, there are no allocation decisions
+needed to find space for these commit records.
+
+---- The example
+
+Consider a roughly 50G file being modified in a 100G file system.
+Realize that due to maintaining the preserve set, it is not possible
+to transactionally write a file larger than 50G on a 100G file system.
+In the absolute worst case, no extent compression is possible and the
+best representation of the delete set requires a bitmap covering the
+entire file system.
+
+A 100G file system with 4K blocks has 3.27MB of bitmaps, and this is
+the same as the worst-case representation of the delete set, assuming
+just about every other block is deleted.  In reality, we expect the
+delete set to be much smaller because extent-compression would achieve
+significant savings.
+
+The wander set could possibly be compressed, but that is a more
+difficult task.  Suppose we attempt to overwrite the entire 50GB file
+instead of relocating it.  A 50G file has 13 million blocks, therefore
+the wander set requires storing 26 million block address pairs.  With
+8-byte block addresses that requires writing 210MB of wander set
+data.  Ouch!
+
+We should hope that the size of the wander set does not grow so large.
+After all, its parent the extent record must be modified in this case,
+so these blocks are all candidates for relocation.  It would take a
+dumb allocate/flush plugin to try to overwrite a 50G file instead of
+relocating it.
+
+---- The conclusion
+
+I maintain that it is much simpler to write all of this data inside
+reserved log areas.  It is possible that we could write this data
+outside the log, but then it will complicate the allocation and
+deallocation proceedure, since space for the log itself must then be
+allocated using ordinary methods.
+
+Comments?
diff -puN emergency_flush.c~profile-stat-trace-repacker emergency_flush.c
--- reiser4/emergency_flush.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/emergency_flush.c	2005-02-01 11:51:11.000000000 +0300
@@ -291,6 +291,7 @@ emergency_flush(struct page *page)
 	assert("vs-1452", node != NULL);
 
 	jref(node);
+	INC_STAT(node, vm.eflush.called);
 
 	result = 0;
 	LOCK_JNODE(node);
@@ -318,6 +319,7 @@ emergency_flush(struct page *page)
 
 			blocknr_hint_init(&hint);
 
+			INC_STAT(node, vm.eflush.needs_block);
 			result = ef_prepare(node, &blk, &efnode, &hint);
 			if (flushable(node, page, 0) && result == 0) {
 				assert("nikita-2759", efnode != NULL);
@@ -325,6 +327,7 @@ emergency_flush(struct page *page)
 
 				result = page_io(page, node, WRITE,
 						 GFP_NOFS | __GFP_HIGH);
+				INC_STAT(node, vm.eflush.ok);
 			} else {
 				JF_CLR(node, JNODE_EFLUSH);
 				UNLOCK_JLOAD(node);
@@ -334,15 +337,19 @@ emergency_flush(struct page *page)
 						      hint.block_stage, efnode);
 					kmem_cache_free(eflush_slab, efnode);
 				}
+				ON_TRACE(TRACE_EFLUSH, "failure-2\n");
 				result = 1;
+				INC_STAT(node, vm.eflush.nolonger);
 			}
 
 			blocknr_hint_done(&hint);
 		} else {
-			/* eflush without allocation temporary location for a node */
 			txn_atom *atom;
 			flush_queue_t *fq;
 
+			/* eflush without allocation temporary location for a node */
+			ON_TRACE(TRACE_EFLUSH, "flushing to relocate place: %llu..", *jnode_get_block(node));
+
 			/* get flush queue for this node */
 			result = fq_by_jnode_gfp(node, &fq, GFP_ATOMIC);
 
@@ -352,6 +359,7 @@ emergency_flush(struct page *page)
 			atom = node->atom;
 
 			if (!flushable(node, page, 1) || needs_allocation(node) || !jnode_is_dirty(node)) {
+				ON_TRACE(TRACE_EFLUSH, "failure-3\n");
 				UNLOCK_JLOAD(node);
 				UNLOCK_JNODE(node);
 				UNLOCK_ATOM(atom);
@@ -372,6 +380,7 @@ emergency_flush(struct page *page)
 			if (result != 0)
 				lock_page(page);
 
+			ON_TRACE(TRACE_EFLUSH, "flushed %d blocks\n", result);
 			/* Even if we wrote nothing, We unlocked the page, so let know to the caller that page should
 			   not be unlocked again */
 			fq_put(fq);
@@ -380,6 +389,7 @@ emergency_flush(struct page *page)
 	} else {
 		UNLOCK_JLOAD(node);
 		UNLOCK_JNODE(node);
+		ON_TRACE(TRACE_EFLUSH, "failure-1\n");
 		result = 1;
 	}
 
@@ -395,32 +405,41 @@ flushable(const jnode * node, struct pag
 	assert("nikita-3388", spin_jload_is_locked(node));
 
 	if (jnode_is_loaded(node)) {             /* loaded */
+		INC_STAT(node, vm.eflush.loaded);
 		return 0;
 	}
 	if (JF_ISSET(node, JNODE_FLUSH_QUEUED)) { /* already pending io */
+		INC_STAT(node, vm.eflush.queued);
 		return 0;
 	}
 	if (JF_ISSET(node, JNODE_EPROTECTED)) {  /* protected from e-flush */
+		INC_STAT(node, vm.eflush.protected);
 		return 0;
 	}
 	if (JF_ISSET(node, JNODE_HEARD_BANSHEE)) {
+		INC_STAT(node, vm.eflush.heard_banshee);
 		return 0;
 	}
 	if (page == NULL) {           		/* nothing to flush */
+		INC_STAT(node, vm.eflush.nopage);
 		return 0;
 	}
 	if (PageWriteback(page)) {               /* already under io */
+		INC_STAT(node, vm.eflush.writeback);
 		return 0;
 	}
 	/* don't flush bitmaps or journal records */
 	if (!jnode_is_znode(node) && !jnode_is_unformatted(node)) {
+		INC_STAT(node, vm.eflush.bitmap);
 		return 0;
 	}
 	/* don't flush cluster pages */
 	if (jnode_is_cluster_page(node)) {
+		INC_STAT(node, vm.eflush.clustered);
 		return 0;
 	}
 	if (check_eflush && JF_ISSET(node, JNODE_EFLUSH)) {      /* already flushed */
+		INC_STAT(node, vm.eflush.eflushed);
 		return 0;
 	}
 	return 1;
@@ -498,7 +517,8 @@ reiser4_internal int
 eflush_init_at(struct super_block *super)
 {
 	return ef_hash_init(&get_super_private(super)->efhash_table,
-			    8192);
+			    8192,
+			    reiser4_stat(super, hashes.eflush));
 }
 
 reiser4_internal void
diff -puN entd.c~profile-stat-trace-repacker entd.c
--- reiser4/entd.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/entd.c	2005-02-01 11:51:11.000000000 +0300
@@ -54,7 +54,7 @@ init_entd_context(struct super_block *su
 
 	ctx = get_entd_context(super);
 
-	memset(ctx, 0, sizeof *ctx);
+	xmemset(ctx, 0, sizeof *ctx);
 	kcond_init(&ctx->startup);
 	kcond_init(&ctx->wait);
 	init_completion(&ctx->finish);
diff -puN eottl.c~profile-stat-trace-repacker eottl.c
--- reiser4/eottl.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/eottl.c	2005-02-01 11:51:11.000000000 +0300
@@ -181,6 +181,7 @@ add_empty_leaf(coord_t * insert_coord, l
 	if (IS_ERR(pool))
 		return PTR_ERR(pool);
 	init_carry_level(&todo, pool);
+	ON_STATS(todo.level_no = TWIG_LEVEL);
 	assert("vs-49827", znode_contains_key_lock(insert_coord->node, key));
 
 	tree = znode_get_tree(insert_coord->node);
@@ -298,6 +299,7 @@ handle_eottl(cbk_handle * h /* cbk handl
 	if (*outcome == NS_FOUND) {
 		/* we have found desired key on twig level in extent item */
 		h->result = CBK_COORD_FOUND;
+		reiser4_stat_inc(tree.cbk_found);
 		*outcome = LOOKUP_DONE;
 		return 1;
 	}
diff -puN estimate.c~profile-stat-trace-repacker estimate.c
--- reiser4/estimate.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/estimate.c	2005-02-01 11:51:11.000000000 +0300
@@ -41,6 +41,12 @@ calc_estimate_one_insert(tree_level heig
 }
 
 reiser4_internal reiser4_block_nr
+estimate_internal_amount(reiser4_block_nr children, tree_level tree_height)
+{
+	return max_balance_overhead(children, tree_height);
+}
+
+reiser4_internal reiser4_block_nr
 estimate_one_insert_item(reiser4_tree *tree)
 {
 	return tree->estimate_one_insert;
diff -puN file_ops.c~profile-stat-trace-repacker file_ops.c
--- reiser4/file_ops.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/file_ops.c	2005-02-01 11:51:11.000000000 +0300
@@ -26,12 +26,14 @@
 #include "znode.h"
 #include "block_alloc.h"
 #include "tree.h"
+#include "log.h"
 #include "vfs_ops.h"
 #include "inode.h"
 #include "page_cache.h"
 #include "ktxnmgrd.h"
 #include "super.h"
 #include "reiser4.h"
+#include "kattr.h"
 #include "entd.h"
 #include "emergency_flush.h"
 
@@ -94,6 +96,10 @@ reiser4_llseek(struct file *file, loff_t
 	reiser4_context ctx;
 
 	init_context(&ctx, inode->i_sb);
+	reiser4_stat_inc(vfs_calls.llseek);
+
+	ON_TRACE(TRACE_VFS_OPS,
+		 "llseek: (i_ino %li, size %lld): off %lli, origin %d\n", inode->i_ino, inode->i_size, off, origin);
 
 	fplug = inode_file_plugin(inode);
 	assert("nikita-2291", fplug != NULL);
@@ -133,6 +139,8 @@ reiser4_readdir(struct file *f /* direct
 
 	inode = f->f_dentry->d_inode;
 	init_context(&ctx, inode->i_sb);
+	write_syscall_log("%s", f->f_dentry->d_name.name);
+	reiser4_stat_inc(vfs_calls.readdir);
 
 	dplug = inode_dir_plugin(inode);
 	if ((dplug != NULL) && (dplug->readdir != NULL))
@@ -143,6 +151,7 @@ reiser4_readdir(struct file *f /* direct
 	/*
 	 * directory st_atime is updated by callers (if necessary).
 	 */
+	write_syscall_log("ex");
 	context_set_commit_async(&ctx);
 	reiser4_exit_context(&ctx);
 	return result;
@@ -158,12 +167,15 @@ reiser4_ioctl(struct inode *inode, struc
 	reiser4_context ctx;
 
 	init_context(&ctx, inode->i_sb);
+	write_syscall_log("%s", filp->f_dentry->d_name.name);
+	reiser4_stat_inc(vfs_calls.ioctl);
 
 	if (inode_file_plugin(inode)->ioctl == NULL)
 		result = -ENOSYS;
 	else
 		result = inode_file_plugin(inode)->ioctl(inode, filp, cmd, arg);
 
+	write_syscall_log("ex");
 	reiser4_exit_context(&ctx);
 	return result;
 }
@@ -177,10 +189,17 @@ reiser4_mmap(struct file *file, struct v
 	reiser4_context ctx;
 
 	init_context(&ctx, file->f_dentry->d_inode->i_sb);
+	write_syscall_log("%s", file->f_dentry->d_name.name);
+	reiser4_stat_inc(vfs_calls.mmap);
+
+	ON_TRACE(TRACE_VFS_OPS, "MMAP: (i_ino %lli, size %lld)\n",
+		 get_inode_oid(file->f_dentry->d_inode),
+		 file->f_dentry->d_inode->i_size);
 
 	inode = file->f_dentry->d_inode;
 	assert("nikita-2936", inode_file_plugin(inode)->mmap != NULL);
 	result = inode_file_plugin(inode)->mmap(file, vma);
+	write_syscall_log("ex");
 	reiser4_exit_context(&ctx);
 	return result;
 }
@@ -209,6 +228,12 @@ reiser4_read(struct file *file /* file t
 
 	inode = file->f_dentry->d_inode;
 	init_context(&ctx, inode->i_sb);
+	write_syscall_log("%s", file->f_dentry->d_name.name);
+	reiser4_stat_inc(vfs_calls.read);
+
+	ON_TRACE(TRACE_VFS_OPS,
+		 "READ: (i_ino %li, size %lld): %u bytes from pos %lli\n",
+		 inode->i_ino, inode->i_size, (unsigned int)count, *off);
 
 	result = perm_chk(inode, read, file, buf, count, off);
 	if (likely(result == 0)) {
@@ -221,6 +246,7 @@ reiser4_read(struct file *file /* file t
 		/* unix_file_read is one method that might be invoked below */
 		result = fplug->read(file, buf, count, off);
 	}
+	write_syscall_log("ex");
 	reiser4_exit_context(&ctx);
 	return result;
 }
@@ -244,6 +270,12 @@ reiser4_write(struct file *file /* file 
 
 	inode = file->f_dentry->d_inode;
 	init_context(&ctx, inode->i_sb);
+	write_syscall_log("%s", file->f_dentry->d_name.name);
+	reiser4_stat_inc(vfs_calls.write);
+
+	ON_TRACE(TRACE_VFS_OPS,
+		 "WRITE: (i_ino %li, size %lld): %u bytes to pos %lli\n",
+		 inode->i_ino, inode->i_size, (unsigned int)size, *off);
 
 	result = perm_chk(inode, write, file, buf, size, off);
 	if (likely(result == 0)) {
@@ -254,6 +286,7 @@ reiser4_write(struct file *file /* file 
 
 		result = fplug->write(file, buf, size, off);
 	}
+	write_syscall_log("ex");
 	context_set_commit_async(&ctx);
 	reiser4_exit_context(&ctx);
 	return result;
@@ -276,6 +309,8 @@ reiser4_release(struct inode *i /* inode
 	fplug = inode_file_plugin(i);
 	assert("umka-082", fplug != NULL);
 
+	ON_TRACE(TRACE_VFS_OPS,
+		 "RELEASE: (i_ino %li, size %lld)\n", i->i_ino, i->i_size);
 
 	if (fplug->release != NULL && get_current_context() == &ctx)
 		result = fplug->release(i, f);
@@ -330,6 +365,7 @@ reiser4_open(struct inode * inode, struc
 	file_plugin *fplug;
 
 	init_context(&ctx, inode->i_sb);
+	reiser4_stat_inc(vfs_calls.open);
 	fplug = inode_file_plugin(inode);
 
 	if (fplug->open != NULL)
diff -puN flush.c~profile-stat-trace-repacker flush.c
--- reiser4/flush.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/flush.c	2005-02-01 11:51:11.000000000 +0300
@@ -23,8 +23,10 @@
 #include "page_cache.h"
 #include "wander.h"
 #include "super.h"
+#include "log.h"
 #include "entd.h"
 #include "reiser4.h"
+#include "prof.h"
 #include "flush.h"
 #include "writeout.h"
 
@@ -433,6 +435,11 @@ assert("nikita-3435",							\
 	    extent_is_unallocated(&scan->parent_coord),			\
 	    extent_unit_index(&scan->parent_coord) == index_jnode(scan->node)))
 
+/* Flush debug functions */
+#if REISER4_DEBUG_OUTPUT
+#else
+#endif
+
 const char *pos_tostring(flush_pos_t * pos);
 
 /* This flush_cnt variable is used to track the number of concurrent flush operations,
@@ -472,6 +479,9 @@ static int write_prepped_nodes (flush_po
 		return 0;
 #endif /* FLUSH_CHECKS_CONGESTION */
 
+	/* trace_mark(flush); */
+	write_current_logf(WRITE_IO_LOG, "mark=flush\n");
+
 	ret = write_fq(pos->fq, pos->nr_written,
 		       WRITEOUT_SINGLE_STREAM | WRITEOUT_FOR_PAGE_RECLAIM);
 	return ret;
@@ -560,10 +570,23 @@ static int prepare_flush_pos(flush_pos_t
 }
 
 #if REISER4_DEBUG
+void check_pos(flush_pos_t *pos)
+{
+	znode *node;
+
+	node = pos->lock.node;
+	if (node != NULL && znode_is_any_locked(node))
+		assert("nikita-3562", znode_at_read(node));
+}
+#endif
+
+#if REISER4_TRACE
 
 const char *coord_tween_tostring(between_enum n);
 
-static void
+
+
+reiser4_internal void
 jnode_tostring_internal(jnode * node, char *buf)
 {
 	const char *state;
@@ -626,6 +649,22 @@ jnode_tostring(jnode * node)
 	return fmtbuf;
 }
 
+static const char *
+flags_tostring(int flags)
+{
+	switch (flags) {
+	case JNODE_FLUSH_WRITE_BLOCKS:
+		return "(write blocks)";
+	case JNODE_FLUSH_COMMIT:
+		return "(commit)";
+	case JNODE_FLUSH_MEMORY_FORMATTED:
+		return "(memory-z)";
+	case JNODE_FLUSH_MEMORY_UNFORMATTED:
+		return "(memory-j)";
+	default:
+		return "(unknown)";
+	}
+}
 reiser4_internal const char *
 znode_tostring(znode * node)
 {
@@ -784,16 +823,29 @@ static int jnode_flush(jnode * node, lon
 	sb = reiser4_get_current_sb();
 	sbinfo = get_super_private(sb);
 	if (!reiser4_is_set(sb, REISER4_MTFLUSH)) {
+#if REISER4_STATS
+		unsigned long sleep_start = jiffies;
+#endif
 		down(&sbinfo->flush_sema);
+#if REISER4_STATS
+		reiser4_stat_add(flush.slept_in_mtflush_sem , jiffies - sleep_start);
+#endif
 	}
 
 	/* Flush-concurrency debug code */
 #if REISER4_DEBUG
 	atomic_inc(&flush_cnt);
+	ON_TRACE(TRACE_FLUSH,
+		 "flush enter: pid %ul %u concurrent procs\n",
+		 current->pid, atomic_read(&flush_cnt));
+	IF_TRACE(TRACE_FLUSH,
+		 if (atomic_read(&flush_cnt) > 1) printk("flush concurrency\n"););
 #endif
 
 	enter_flush(sb);
 
+	ON_TRACE(TRACE_FLUSH, "flush squalloc %s %s\n", jnode_tostring(node), flags_tostring(flags));
+
 	/* Initialize a flush position. */
 	pos_init(&flush_pos);
 
@@ -840,6 +892,7 @@ static int jnode_flush(jnode * node, lon
 	   leftward scan.  If we do scan right, we only care to go far enough to establish
 	   that at least FLUSH_RELOCATE_THRESHOLD number of nodes are being flushed.  The
 	   scan limit is the difference between left_scan.count and the threshold. */
+	reiser4_stat_add(flush.left, left_scan.count);
 
 	todo = sbinfo->flush.relocate_threshold - left_scan.count;
 	/* scan right is inherently deadlock prone, because we are
@@ -854,11 +907,18 @@ static int jnode_flush(jnode * node, lon
 	/* Only the right-scan count is needed, release any rightward locks right away. */
 	scan_done(&right_scan);
 
+	ON_TRACE(TRACE_FLUSH, "flush: left: %i, right: %i\n",
+		 left_scan.count, right_scan.count);
+
+	reiser4_stat_add(flush.right, right_scan.count);
+
 	/* ... and the answer is: we should relocate leaf nodes if at least
 	   FLUSH_RELOCATE_THRESHOLD nodes were found. */
 	flush_pos.leaf_relocate = JF_ISSET(node, JNODE_REPACK) ||
 		(left_scan.count + right_scan.count >= sbinfo->flush.relocate_threshold);
 
+	/*assert ("jmacd-6218", jnode_check_dirty (left_scan.node)); */
+
 	/* Funny business here.  We set the 'point' in the flush_position at prior to
 	   starting squalloc regardless of whether the first point is
 	   formatted or unformatted.  Without this there would be an invariant, in the
@@ -884,6 +944,7 @@ static int jnode_flush(jnode * node, lon
 	   node or its parent (in case of unformatted) helps us in case of
 	   concurrent flushing. */
 	if (jnode_check_flushprepped(leftmost_in_slum) && !jnode_convertible(leftmost_in_slum)) {
+		ON_TRACE(TRACE_FLUSH_VERB, "flush concurrency: %s already allocated\n", pos_tostring(&flush_pos));
 		ret = 0;
 		goto failed;
 	}
@@ -903,6 +964,7 @@ static int jnode_flush(jnode * node, lon
 	}
 
 	if (jnode_check_flushprepped(leftmost_in_slum) && !jnode_convertible(leftmost_in_slum)) {
+		ON_TRACE(TRACE_FLUSH_VERB, "flush concurrency: %s already allocated\n", pos_tostring(&flush_pos));
 		ret = 0;
 		goto failed;
 	}
@@ -913,7 +975,9 @@ static int jnode_flush(jnode * node, lon
 		goto failed;
 
 	/* Do the main rightward-bottom-up squeeze and allocate loop. */
+	check_pos(&flush_pos);
 	ret = squalloc(&flush_pos);
+	check_pos(&flush_pos);
 	pos_stop(&flush_pos);
 	if (ret)
 		goto failed;
@@ -970,6 +1034,7 @@ failed:
 
 	if (nr_to_flush != NULL) {
 		if (ret >= 0) {
+			ON_TRACE(TRACE_FLUSH, "flush_jnode wrote %u blocks\n", flush_pos.prep_or_free_cnt);
 			(*nr_to_flush) = flush_pos.prep_or_free_cnt;
 		} else {
 			(*nr_to_flush) = 0;
@@ -985,6 +1050,7 @@ failed:
 		/* FIXME(C): Except for E_DEADLOCK, these should probably be handled properly
 		   in each case.  They already are handled in many cases. */
 		/* Something bad happened, but difficult to avoid...  Try again! */
+		ON_TRACE(TRACE_FLUSH, "flush restartable failure: %ld\n", ret);
 		ret = 0;
 	}
 
@@ -997,6 +1063,8 @@ failed:
 
 	ON_DEBUG(atomic_dec(&flush_cnt));
 
+	write_syscall_log("ex");
+
 	leave_flush(sb);
 
 	if (!reiser4_is_set(sb, REISER4_MTFLUSH))
@@ -1072,6 +1140,12 @@ flush_current_atom (int flags, long *nr_
 	/* count ourself as a flusher */
 	(*atom)->nr_flushers++;
 
+	if (REISER4_LOG) {
+		UNLOCK_ATOM(*atom);
+		write_syscall_log("in");
+		*atom = get_current_atom_locked();
+	}
+	reiser4_stat_inc(flush.flush);
 	writeout_mode_enable();
 
 	nr_queued = 0;
@@ -1128,6 +1202,9 @@ flush_current_atom (int flags, long *nr_
 		jput(node);
 	}
 
+	/* trace_mark(flush); */
+	write_current_logf(WRITE_IO_LOG, "mark=flush\n");
+
 	ret = write_fq(fq, nr_submitted, WRITEOUT_SINGLE_STREAM | WRITEOUT_FOR_PAGE_RECLAIM);
 
 	*atom = get_current_atom_locked();
@@ -1137,6 +1214,7 @@ flush_current_atom (int flags, long *nr_
 	UNLOCK_ATOM(*atom);
 
 	writeout_mode_disable();
+	write_syscall_log("ex");
 
 	if (ret == 0)
 		ret = -E_REPEAT;
@@ -1298,6 +1376,8 @@ static int alloc_pos_and_ancestors(flush
 	if (znode_check_flushprepped(pos->lock.node))
 		return 0;
 
+	ON_TRACE(TRACE_FLUSH_VERB, "flush alloc ancestors: %s\n", pos_tostring(pos));
+
 	coord_init_invalid(&pcoord, NULL);
 	init_lh(&plock);
 	init_load_count(&pload);
@@ -1556,6 +1636,11 @@ static int squeeze_right_twig(znode * le
 	assert("jmacd-2008", !node_is_empty(right));
 	coord_init_first_unit(&coord, right);
 
+	DISABLE_NODE_CHECK;
+
+	ON_TRACE(TRACE_FLUSH_VERB, "sq_twig before copy extents: left %s\n", znode_tostring(left));
+	ON_TRACE(TRACE_FLUSH_VERB, "sq_twig before copy extents: right %s\n", znode_tostring(right));
+
 	/* FIXME: can be optimized to cut once */
 	while (!node_is_empty(coord.node) && item_is_extent(&coord)) {
 		ON_DEBUG(void *vp);
@@ -1582,12 +1667,17 @@ static int squeeze_right_twig(znode * le
 	if (node_is_empty(coord.node))
 		ret = SQUEEZE_SOURCE_EMPTY;
 
+	ENABLE_NODE_CHECK;
+	node_check(left, REISER4_NODE_DKEYS);
+	node_check(right, REISER4_NODE_DKEYS);
+
 	if (ret == SQUEEZE_TARGET_FULL) {
 		goto out;
 	}
 
 	if (node_is_empty(right)) {
 		/* The whole right node was copied into @left. */
+		ON_TRACE(TRACE_FLUSH_VERB, "sq_twig right node empty: %s\n", znode_tostring(right));
 		assert("vs-464", ret == SQUEEZE_SOURCE_EMPTY);
 		goto out;
 	}
@@ -1625,7 +1715,7 @@ out:
 }
 
 #if REISER4_DEBUG
-static void
+reiser4_internal void
 item_convert_invariant(flush_pos_t * pos)
 {
 	if (convert_data(pos) && item_convert_data(pos)) {
@@ -1636,10 +1726,6 @@ item_convert_invariant(flush_pos_t * pos
 		assert("edward-1001", iplug->f.convert != NULL);
 	}
 }
-#else
-
-#define item_convert_invariant(pos) noop
-
 #endif
 
 /* Scan node items starting from the first one and apply for each
@@ -1751,6 +1837,9 @@ static int squeeze_right_neighbor(flush_
 	assert("jmacd-9322", !node_is_empty(right));
 	assert("jmacd-9323", znode_get_level(left) == znode_get_level(right));
 
+	ON_TRACE(TRACE_FLUSH_VERB, "sq_rn[%u] left  %s\n", znode_get_level(left), znode_tostring(left));
+	ON_TRACE(TRACE_FLUSH_VERB, "sq_rn[%u] right %s\n", znode_get_level(left), znode_tostring(right));
+
 	switch (znode_get_level(left)) {
 	case TWIG_LEVEL:
 		/* Shift with extent allocating until either an internal item
@@ -1768,6 +1857,16 @@ static int squeeze_right_neighbor(flush_
 
 	assert("jmacd-2011", (ret < 0 ||
 			      ret == SQUEEZE_SOURCE_EMPTY || ret == SQUEEZE_TARGET_FULL || ret == SUBTREE_MOVED));
+
+	if (ret == SQUEEZE_SOURCE_EMPTY) {
+		reiser4_stat_inc(flush.squeezed_completely);
+	}
+
+	ON_TRACE(TRACE_FLUSH_VERB, "sq_rn[%u] returns %s: left %s\n",
+		 znode_get_level(left),
+		 (ret == SQUEEZE_SOURCE_EMPTY) ? "src empty" :
+		 ((ret == SQUEEZE_TARGET_FULL) ? "tgt full" :
+		  ((ret == SUBTREE_MOVED) ? "tree moved" : "error")), znode_tostring(left));
 	return ret;
 }
 
@@ -1978,13 +2077,16 @@ static int handle_pos_on_formatted (flus
 	init_lh(&right_lock);
 	init_load_count(&right_load);
 
+	check_pos(pos);
 	if (should_convert_node(pos, pos->lock.node)) {
 		ret = convert_node(pos, pos->lock.node);
+		check_pos(pos);
 		if (ret)
 			return ret;
 	}
 
 	while (1) {
+		check_pos(pos);
 		ret = neighbor_in_slum(pos->lock.node, &right_lock, RIGHT_SIDE, ZNODE_WRITE_LOCK);
 		if (ret)
 			break;
@@ -2005,6 +2107,7 @@ static int handle_pos_on_formatted (flus
 
 		if (should_convert_node(pos, right_lock.node)) {
 			ret = convert_node(pos, right_lock.node);
+			check_pos(pos);
 			if (ret)
 				break;
 			if (node_is_empty(right_lock.node)) {
@@ -2017,6 +2120,7 @@ static int handle_pos_on_formatted (flus
 
                 /* squeeze _before_ going upward. */
 		ret = squeeze_right_neighbor(pos, pos->lock.node, right_lock.node);
+		check_pos(pos);
 		if (ret < 0)
 			break;
 
@@ -2041,10 +2145,12 @@ static int handle_pos_on_formatted (flus
 		/* parent(right_lock.node) has to be processed before
 		 * (right_lock.node) due to "parent-first" allocation order. */
 		ret = check_parents_and_squalloc_upper_levels(pos, pos->lock.node, right_lock.node);
+		check_pos(pos);
 		if (ret)
 			break;
 		/* (re)allocate _after_ going upward */
 		ret = lock_parent_and_allocate_znode(right_lock.node, pos);
+		check_pos(pos);
 		if (ret)
 			break;
 
@@ -2057,9 +2163,11 @@ static int handle_pos_on_formatted (flus
 		move_flush_pos(pos, &right_lock, &right_load, NULL);
 
 		ret = rapid_flush(pos);
+		check_pos(pos);
 		if (ret)
 			break;
 	}
+	check_pos(pos);
 
 	assert("edward-1006", !convert_data(pos) || !item_convert_data(pos));
 
@@ -2141,6 +2249,7 @@ static int handle_pos_on_twig (flush_pos
 	assert ("zam-844", pos->state == POS_ON_EPOINT);
 	assert ("zam-843", item_is_extent(&pos->coord));
 
+	check_pos(pos);
 	/* We decide should we continue slum processing with current extent
 	   unit: if leftmost child of current extent unit is flushprepped
 	   (i.e. clean or already processed by flush) we stop squalloc().  There
@@ -2155,7 +2264,9 @@ static int handle_pos_on_twig (flush_pos
 	}
 
 	while (pos_valid(pos) && coord_is_existing_unit(&pos->coord) && item_is_extent(&pos->coord)) {
+		check_pos(pos);
 		ret = alloc_extent(pos);
+		check_pos(pos);
 		if (ret) {
 			break;
 		}
@@ -2173,6 +2284,7 @@ static int handle_pos_on_twig (flush_pos
 
 	assert ("zam-860", item_is_extent(&pos->coord));
 
+	check_pos(pos);
 	/* "slum" is over */
 	pos->state = POS_INVALID;
 	return 0;
@@ -2196,6 +2308,7 @@ static int handle_pos_end_of_twig (flush
 	init_lh(&right_lock);
 	init_load_count(&right_load);
 
+	check_pos(pos);
 	/* We get a lock on the right twig node even it is not dirty because
 	 * slum continues or discontinues on leaf level not on next twig. This
 	 * lock on the right twig is needed for getting its leftmost child. */
@@ -2212,7 +2325,9 @@ static int handle_pos_end_of_twig (flush
 		/* If right twig node is dirty we always attempt to squeeze it
 		 * content to the left... */
 became_dirty:
+		check_pos(pos);
 		ret = squeeze_right_twig_and_advance_coord(pos, right_lock.node);
+		check_pos(pos);
 		if (ret <=0) {
 			/* pos->coord is on internal item, go to leaf level, or
 			 * we have an error which will be caught in squalloc() */
@@ -2230,11 +2345,13 @@ became_dirty:
 		if (!znode_check_flushprepped(right_lock.node)) {
 			/* As usual, process parent before ...*/
 			ret = check_parents_and_squalloc_upper_levels(pos, pos->lock.node, right_lock.node);
+			check_pos(pos);
 			if (ret)
 				goto out;
 
 			/* ... processing the child */
 			ret = lock_parent_and_allocate_znode(right_lock.node, pos);
+			check_pos(pos);
 			if (ret)
 				goto out;
 		}
@@ -2250,7 +2367,9 @@ became_dirty:
 
 		/* check clean twig for possible relocation */
 		if (!znode_check_flushprepped(right_lock.node)) {
+			check_pos(pos);
 			ret = reverse_relocate_check_dirty_parent(child, &at_right, pos);
+			check_pos(pos);
 			if (ret)
 				goto out;
 			if (znode_check_dirty(right_lock.node))
@@ -2273,6 +2392,7 @@ became_dirty:
 	move_flush_pos(pos, &right_lock, &right_load, &at_right);
 
  out:
+	check_pos(pos);
 	done_load_count(&right_load);
 	done_lh(&right_lock);
 
@@ -2297,6 +2417,7 @@ static int handle_pos_to_leaf (flush_pos
 	init_lh(&child_lock);
 	init_load_count(&child_load);
 
+	check_pos(pos);
 	ret = get_leftmost_child_of_unit(&pos->coord, &child);
 	if (ret)
 		return ret;
@@ -2319,6 +2440,7 @@ static int handle_pos_to_leaf (flush_pos
 		goto out;
 
 	ret = allocate_znode(JZNODE(child), &pos->coord, pos);
+	check_pos(pos);
 	if (ret)
 		goto out;
 
@@ -2328,9 +2450,11 @@ static int handle_pos_to_leaf (flush_pos
 
 	if (node_is_empty(JZNODE(child))) {
 		ret = delete_empty_node(JZNODE(child));
+		check_pos(pos);
 		pos->state = POS_INVALID;
 	}
  out:
+	check_pos(pos);
 	done_load_count(&child_load);
 	done_lh(&child_lock);
 	jput(child);
@@ -2352,6 +2476,7 @@ static int handle_pos_to_twig (flush_pos
 	init_lh(&parent_lock);
 	init_load_count(&parent_load);
 
+	check_pos(pos);
 	ret = reiser4_get_parent(&parent_lock, pos->lock.node, ZNODE_WRITE_LOCK, 0);
 	if (ret)
 		goto out;
@@ -2382,6 +2507,7 @@ static int handle_pos_to_twig (flush_pos
 	move_flush_pos(pos, &parent_lock, &parent_load, &pcoord);
 
  out:
+	check_pos(pos);
 	done_load_count(&parent_load);
 	done_lh(&parent_lock);
 
@@ -2416,11 +2542,14 @@ static int squalloc (flush_pos_t * pos)
 	/* maybe needs to be made a case statement with handle_pos_on_leaf as first case, for
 	 * greater CPU efficiency? Measure and see.... -Hans */
 	while (pos_valid(pos)) {
+		check_pos(pos);
 		ret = flush_pos_handlers[pos->state](pos);
+		check_pos(pos);
 		if (ret < 0)
 			break;
 
 		ret = rapid_flush(pos);
+		check_pos(pos);
 		if (ret)
 			break;
 	}
@@ -2473,6 +2602,8 @@ shift_everything_left(znode * right, zno
 
 	coord_init_after_last_item(&from, right);
 
+	IF_TRACE(TRACE_COORDS, print_coord("shift_everything_left:", &from, 0));
+
 	nplug = node_plugin_by_node(right);
 	info.doing = NULL;
 	info.todo = todo;
@@ -2491,6 +2622,7 @@ squeeze_right_non_twig(znode * left, zno
 	int ret;
 	carry_pool *pool;
 	carry_level todo;
+	ON_STATS(int old_items; int old_free_space);
 
 	assert("nikita-2246", znode_get_level(left) == znode_get_level(right));
 
@@ -2502,6 +2634,8 @@ squeeze_right_non_twig(znode * left, zno
 		return PTR_ERR(pool);
 	init_carry_level(&todo, pool);
 
+	ON_STATS(old_items = node_num_items(left); old_free_space = znode_free_space(left));
+
 	ret = shift_everything_left(right, left, &todo);
 	if (ret > 0) {
 		/* something was shifted */
@@ -2523,6 +2657,9 @@ squeeze_right_non_twig(znode * left, zno
 		grabbed = get_current_context()->grabbed_blocks;
 		ret = reiser4_grab_space_force(tree->height, BA_RESERVED);
 		assert("nikita-3003", ret == 0); /* reserved space is exhausted. Ask Hans. */
+
+		ON_STATS(todo.level_no = znode_get_level(left) + 1);
+
 		ret = carry(&todo, NULL /* previous level */ );
 		grabbed2free_mark(grabbed);
 	} else {
@@ -2532,6 +2669,14 @@ squeeze_right_non_twig(znode * left, zno
 
 	done_carry_pool(pool);
 
+#if REISER4_STATS
+	if (znode_get_level(left) == LEAF_LEVEL) {
+		reiser4_stat_inc(flush.squeezed_leaves);
+		reiser4_stat_add(flush.squeezed_leaf_items, node_num_items(left) - old_items);
+		reiser4_stat_add(flush.squeezed_leaf_bytes, old_free_space - znode_free_space(left));
+	}
+#endif
+
 	return ret;
 }
 
@@ -2603,10 +2748,16 @@ shift_one_internal_unit(znode * left, zn
 		ret = reiser4_grab_space_force(tree->height, BA_RESERVED);
 		assert("nikita-3003", ret == 0); /* reserved space is exhausted. Ask Hans. */
 
+		ON_STATS(todo.level_no = znode_get_level(left) + 1);
+
 		ret = carry(&todo, NULL /* previous level */ );
 		grabbed2free_mark(grabbed);
 	}
 
+	ON_TRACE(TRACE_FLUSH_VERB,
+		 "shift_one %s an item: left has %u items, right has %u items\n",
+		 moved > 0 ? "moved" : "did not move", node_num_items(left), node_num_items(right));
+
 	done_carry_pool(pool);
 
 	if (ret != 0) {
@@ -2658,6 +2809,7 @@ allocate_znode_loaded(znode * node,
 			   using of default value for search start is better than search
 			   from block #0. */
 			get_blocknr_hint_default(&pos->preceder.blk);
+			reiser4_stat_inc(block_alloc.nohint);
 			check_preceder(pos->preceder.blk);
 		}
 
@@ -3095,6 +3247,12 @@ scan_goto(flush_scan * scan, jnode * ton
 
 	if (!go) {
 		scan->stop = 1;
+		ON_TRACE(TRACE_FLUSH_VERB,
+			 "flush %s scan stop: stop at node %s\n",
+			 scanning_left(scan) ? "left" : "right", jnode_tostring(scan->node));
+		ON_TRACE(TRACE_FLUSH_VERB,
+			 "flush %s scan stop: do not cont at %s\n",
+			 scanning_left(scan) ? "left" : "right", jnode_tostring(tonode));
 		jput(tonode);
 	}
 
@@ -3335,12 +3493,16 @@ scan_unformatted(flush_scan * scan, flus
 
 		if (ret == CBK_COORD_NOTFOUND) {
 			/* FIXME(C): check EINVAL, E_DEADLOCK */
+			ON_TRACE(TRACE_FLUSH,
+				 "flush_scan_common: jnode_lock_parent_coord returned %d\n", ret);
 			if (!scan_should_link_node(scan))
-				return ret;
+			return ret;
 		}
 		else {
 			/* parent was found */
 			set_flush_scan_nstat(scan, LINKED);
+			ON_TRACE(TRACE_FLUSH,
+				 "flush_scan_common: jnode_lock_parent_coord returned 0\n");
 			assert("jmacd-8661", other != NULL);
 		}
 
@@ -3399,6 +3561,9 @@ scan_formatted(flush_scan * scan)
 			break;
 		}
 
+		ON_TRACE(TRACE_FLUSH_VERB, "format scan %s %s\n",
+			 scanning_left(scan) ? "left" : "right", znode_tostring(neighbor));
+
 		/* Check the condition for going left, break if it is not met.  This also
 		   releases (jputs) the neighbor if false. */
 		if (!scan_goto(scan, ZJNODE(neighbor))) {
@@ -3581,7 +3746,7 @@ scan_by_coord(flush_scan * scan)
 static void
 pos_init(flush_pos_t * pos)
 {
-	memset(pos, 0, sizeof *pos);
+	xmemset(pos, 0, sizeof *pos);
 
 	pos->state = POS_INVALID;
 	coord_init_invalid(&pos->coord, NULL);
@@ -3644,6 +3809,14 @@ pos_hint(flush_pos_t * pos)
 	return &pos->preceder;
 }
 
+/* Return true if we have decided to unconditionally relocate leaf nodes, thus write
+   optimizing. */
+reiser4_internal int
+pos_leaf_relocate(flush_pos_t * pos)
+{
+	return pos->leaf_relocate;
+}
+
 reiser4_internal flush_queue_t * pos_fq(flush_pos_t * pos)
 {
 	return pos->fq;
diff -puN flush.h~profile-stat-trace-repacker flush.h
--- reiser4/flush.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/flush.h	2005-02-01 11:51:11.000000000 +0300
@@ -277,17 +277,21 @@ txn_atom *atom_locked_by_fq(flush_queue_
 int init_fqs(void);
 void done_fqs(void);
 
-#if REISER4_DEBUG
+#if REISER4_TRACE
 const char *jnode_tostring(jnode * node);
+#else
+#define jnode_tostring(n) ""
 #endif
 
 #if REISER4_DEBUG
 #define check_preceder(blk) \
 assert("nikita-2588", blk < reiser4_block_count(reiser4_get_current_sb()));
+extern void item_convert_invariant(flush_pos_t * pos);
 extern void check_pos(flush_pos_t *pos);
 #else
 #define check_preceder(b) noop
 #define check_pos(pos) noop
+#define item_convert_invariant(pos) noop
 #endif
 
 /* __REISER4_FLUSH_H__ */
diff -puN flush_queue.c~profile-stat-trace-repacker flush_queue.c
--- reiser4/flush_queue.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/flush_queue.c	2005-02-01 11:51:11.000000000 +0300
@@ -58,7 +58,7 @@ SPIN_LOCK_FUNCTIONS(fq, flush_queue_t, g
 #define mark_fq_ready(fq)      do { (fq)->state &= ~FQ_IN_USE;   } while (0)
 
 /* get lock on atom from locked flush queue object */
-static txn_atom *
+reiser4_internal txn_atom *
 atom_get_locked_by_fq(flush_queue_t * fq)
 {
 	/* This code is similar to jnode_get_atom(), look at it for the
@@ -102,7 +102,7 @@ atom_locked_by_fq(flush_queue_t * fq)
 static void
 init_fq(flush_queue_t * fq)
 {
-	memset(fq, 0, sizeof *fq);
+	xmemset(fq, 0, sizeof *fq);
 
 	atomic_set(&fq->nr_submitted, 0);
 
@@ -541,7 +541,7 @@ write_fq(flush_queue_t * fq, long * nr_s
    atom lock is obtained by different ways in different parts of reiser4,
    usually it is current atom, but we need a possibility for getting fq for the
    atom of given jnode. */
-static int
+reiser4_internal int
 fq_by_atom_gfp(txn_atom * atom, flush_queue_t ** new_fq, int gfp)
 {
 	flush_queue_t *fq;
diff -puN init_super.c~profile-stat-trace-repacker init_super.c
--- reiser4/init_super.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/init_super.c	2005-02-01 11:51:11.000000000 +0300
@@ -13,8 +13,11 @@
 #include "ktxnmgrd.h"
 #include "super.h"
 #include "reiser4.h"
+#include "kattr.h"
 #include "entd.h"
 #include "emergency_flush.h"
+#include "prof.h"
+#include "repacker.h"
 #include "safe_link.h"
 #include "plugin/dir/dir.h"
 
@@ -55,7 +58,7 @@ _INIT_(sinfo)
 
 	s->s_fs_info = sbinfo;
 	s->s_op = NULL;
-	memset(sbinfo, 0, sizeof (*sbinfo));
+	xmemset(sbinfo, 0, sizeof (*sbinfo));
 
 	ON_DEBUG(INIT_LIST_HEAD(&sbinfo->all_jnodes));
 	ON_DEBUG(spin_lock_init(&sbinfo->all_guard));
@@ -76,6 +79,16 @@ _DONE_(sinfo)
 	s->s_fs_info = NULL;
 }
 
+_INIT_(stat)
+{
+	return reiser4_stat_init(&get_super_private(s)->stats);
+}
+
+_DONE_(stat)
+{
+	reiser4_stat_done(&get_super_private(s)->stats);
+}
+
 _INIT_(context)
 {
 	return init_context(ctx, s);
@@ -87,6 +100,11 @@ _DONE_(context)
 
 	sbinfo = get_super_private(s);
 
+	close_log_file(&sbinfo->log_file);
+
+	if (reiser4_is_debugged(s, REISER4_STATS_ON_UMOUNT))
+		reiser4_print_stats();
+
 	/* we don't want ->write_super to be called any more. */
 	if (s->s_op)
 		s->s_op->write_super = NULL;
@@ -102,9 +120,9 @@ _DONE_(context)
 			info_jnode("\nafter umount", busy);
 		}
 	}
-	if (sbinfo->kmallocs > 0)
+	if (sbinfo->kmalloc_allocated > 0)
 		warning("nikita-2622",
-			"%i areas still allocated", sbinfo->kmallocs);
+			"%i bytes still allocated", sbinfo->kmalloc_allocated);
 #endif
 
 	get_current_context()->trans = NULL;
@@ -118,7 +136,7 @@ _INIT_(parse_options)
 
 _DONE_(parse_options)
 {
-	return;
+	close_log_file(&get_super_private(s)->log_file);
 }
 
 _INIT_(object_ops)
@@ -424,6 +442,28 @@ _DONE_(fs_root)
 	
 }
 
+_INIT_(sysfs)
+{
+	return reiser4_sysfs_init(s);
+}
+
+_DONE_(sysfs)
+{
+	reiser4_sysfs_done(s);
+}
+
+#if defined(REISER4_REPACKER)
+_INIT_(repacker)
+{
+	return init_reiser4_repacker(s);
+}
+
+_DONE_(repacker)
+{
+	done_reiser4_repacker(s);
+}
+#endif /*REISER4_REPACKER*/
+
 _INIT_(safelink)
 {
 	process_safelinks(s);
@@ -453,6 +493,7 @@ struct reiser4_subsys {
 static struct reiser4_subsys subsys_array[] = {
 	_SUBSYS(mount_flags_check),
 	_SUBSYS(sinfo),
+	_SUBSYS(stat),
 	_SUBSYS(context),
 	_SUBSYS(parse_options),
 	_SUBSYS(object_ops),
@@ -467,6 +508,10 @@ static struct reiser4_subsys subsys_arra
 	_SUBSYS(sb_counters),
 	_SUBSYS(d_cursor),
 	_SUBSYS(fs_root),
+	_SUBSYS(sysfs),
+#if defined(REISER4_REPACKER)
+	_SUBSYS(repacker),
+#endif /*REISER4_REPACKER*/
 	_SUBSYS(safelink),
 	_SUBSYS(exit_context)
 };
diff -puN inode.c~profile-stat-trace-repacker inode.c
--- reiser4/inode.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/inode.c	2005-02-01 11:51:11.000000000 +0300
@@ -331,7 +331,7 @@ init_locked_inode(struct inode *inode /*
    (objectids) are distinguished by their packing locality.
 
 */
-static int
+reiser4_internal int
 reiser4_inode_find_actor(struct inode *inode	/* inode from hash table to
 						 * check */ ,
 			 void *opaque	/* "cookie" passed to
@@ -476,6 +476,7 @@ reiser4_iget(struct super_block *super /
 		if (inode_file_plugin(inode)->not_linked(inode)) {
 			warning("nikita-3559", "Unlinked inode found: %llu\n",
 				(unsigned long long)get_inode_oid(inode));
+			print_inode("inode", inode);
 		}
 	}
 	return inode;
@@ -678,6 +679,17 @@ inode_set_vroot(struct inode *inode, zno
 	UNLOCK_INODE(info);
 }
 
+reiser4_internal void
+inode_clean_vroot(struct inode *inode)
+{
+	reiser4_inode *info;
+
+	info = reiser4_inode_data(inode);
+	LOCK_INODE(info);
+	info->vroot = UBER_TREE_ADDR;
+	UNLOCK_INODE(info);
+}
+
 reiser4_internal int
 get_reiser4_inode_by_key (struct inode ** result, const reiser4_key * key)
 {
diff -puN inode.h~profile-stat-trace-repacker inode.h
--- reiser4/inode.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/inode.h	2005-02-01 11:51:11.000000000 +0300
@@ -315,6 +315,7 @@ extern int inode_has_no_jnodes(reiser4_i
 
 extern znode *inode_get_vroot(struct inode *inode);
 extern void   inode_set_vroot(struct inode *inode, znode *vroot);
+extern void   inode_clean_vroot(struct inode *inode);
 
 extern int reiser4_max_filename_len(const struct inode *inode);
 extern int max_hash_collisions(const struct inode *dir);
@@ -323,6 +324,7 @@ extern int is_reiser4_inode(const struct
 extern int setup_inode_ops(struct inode *inode, reiser4_object_create_data *);
 extern struct inode *reiser4_iget(struct super_block *super, const reiser4_key * key, int silent);
 extern void reiser4_iget_complete (struct inode * inode);
+extern int reiser4_inode_find_actor(struct inode *inode, void *opaque);
 extern int get_reiser4_inode_by_key (struct inode **, const reiser4_key *);
 
 
@@ -411,8 +413,10 @@ jnode_tree_by_reiser4_inode(reiser4_inod
 	return &r4_inode->jnodes_tree;
 }
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 extern void print_inode(const char *prefix, const struct inode *i);
+#else
+#define print_inode(p, i) noop
 #endif
 
 /* __REISER4_INODE_H__ */
diff -puN inode_ops.c~profile-stat-trace-repacker inode_ops.c
--- reiser4/inode_ops.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/inode_ops.c	2005-02-01 11:51:11.000000000 +0300
@@ -19,12 +19,14 @@
 #include "znode.h"
 #include "block_alloc.h"
 #include "tree.h"
+#include "log.h"
 #include "vfs_ops.h"
 #include "inode.h"
 #include "page_cache.h"
 #include "ktxnmgrd.h"
 #include "super.h"
 #include "reiser4.h"
+#include "kattr.h"
 #include "entd.h"
 #include "emergency_flush.h"
 
@@ -87,10 +89,31 @@ reiser4_create(struct inode *parent	/* i
 	       struct nameidata *nameidata)
 {
 	reiser4_object_create_data data;
+#if TEST_CRC
+	compression_data_t co;
+	cluster_data_t cl;
+	static atomic_t cnt = ATOMIC_INIT(0);
+#endif
+
+	xmemset(&data, 0, sizeof data);
+
+	reiser4_stat_inc_at(parent->i_sb, vfs_calls.create);
 
-	memset(&data, 0, sizeof data);
 	data.mode = S_IFREG | mode;
-	data.id = UNIX_FILE_PLUGIN_ID;
+
+#if TEST_CRC
+	atomic_inc(&cnt);
+	if ((atomic_read(&cnt) % 2) == 0) {
+		data.id = CRC_FILE_PLUGIN_ID;
+
+		cl = 4;
+		data.cluster = &cl;
+
+		co.coa = LZO1_COMPRESSION_ID;
+		data.compression = &co;
+	} else
+#endif		
+		data.id = UNIX_FILE_PLUGIN_ID;
 	return invoke_create_method(parent, dentry, &data);
 }
 
@@ -104,6 +127,8 @@ reiser4_mkdir(struct inode *parent	/* in
 {
 	reiser4_object_create_data data;
 
+	reiser4_stat_inc_at(parent->i_sb, vfs_calls.mkdir);
+
 	data.mode = S_IFDIR | mode;
 	data.id = DIRECTORY_FILE_PLUGIN_ID;
 	return invoke_create_method(parent, dentry, &data);
@@ -120,6 +145,8 @@ reiser4_symlink(struct inode *parent	/* 
 {
 	reiser4_object_create_data data;
 
+	reiser4_stat_inc_at(parent->i_sb, vfs_calls.symlink);
+
 	data.name = linkname;
 	data.id = SYMLINK_FILE_PLUGIN_ID;
 	data.mode = S_IFLNK | S_IRWXUGO;
@@ -136,6 +163,8 @@ reiser4_mknod(struct inode *parent /* in
 {
 	reiser4_object_create_data data;
 
+	reiser4_stat_inc_at(parent->i_sb, vfs_calls.mknod);
+
 	data.mode = mode;
 	data.rdev = rdev;
 	data.id = SPECIAL_FILE_PLUGIN_ID;
@@ -155,6 +184,7 @@ reiser4_rename(struct inode *old_dir, st
 	assert("nikita-2317", new != NULL);
 
 	init_context(&ctx, old_dir->i_sb);
+	reiser4_stat_inc(vfs_calls.rename);
 
 	result = perm_chk(old_dir, rename, old_dir, old, new_dir, new);
 	if (result == 0) {
@@ -201,6 +231,7 @@ reiser4_lookup(struct inode *parent,	/* 
 	assert("nikita-404", dentry != NULL);
 
 	init_context(&ctx, parent->i_sb);
+	reiser4_stat_inc(vfs_calls.lookup);
 
 	/* find @parent directory plugin and make sure that it has lookup
 	   method */
@@ -265,6 +296,7 @@ static int
 reiser4_readlink(struct dentry *dentry, char *buf, int buflen)
 {
 	assert("vs-852", S_ISLNK(dentry->d_inode->i_mode));
+	reiser4_stat_inc_at(dentry->d_inode->i_sb, vfs_calls.readlink);
 	if (!dentry->d_inode->u.generic_ip || !inode_get_flag(dentry->d_inode, REISER4_GENERIC_PTR_USED))
 		return RETERR(-EINVAL);
 	return vfs_readlink(dentry, buf, buflen, dentry->d_inode->u.generic_ip);
@@ -276,6 +308,7 @@ reiser4_follow_link(struct dentry *dentr
 {
 	assert("vs-851", S_ISLNK(dentry->d_inode->i_mode));
 
+	reiser4_stat_inc_at(dentry->d_inode->i_sb, vfs_calls.follow_link);
 	if (!dentry->d_inode->u.generic_ip || !inode_get_flag(dentry->d_inode, REISER4_GENERIC_PTR_USED))
 		return RETERR(-EINVAL);
 	return vfs_follow_link(data, dentry->d_inode->u.generic_ip);
@@ -296,6 +329,7 @@ reiser4_setattr(struct dentry *dentry, s
 	inode = dentry->d_inode;
 	assert("vs-1108", inode != NULL);
 	init_context(&ctx, inode->i_sb);
+	reiser4_stat_inc(vfs_calls.setattr);
 	result = perm_chk(inode, setattr, dentry, attr);
 	if (result == 0) {
 		if (!inode_get_flag(inode, REISER4_IMMUTABLE)) {
@@ -323,6 +357,7 @@ reiser4_getattr(struct vfsmount *mnt UNU
 
 	inode = dentry->d_inode;
 	init_context(&ctx, inode->i_sb);
+	reiser4_stat_inc(vfs_calls.getattr);
 	result = perm_chk(inode, getattr, mnt, dentry, stat);
 	if (result == 0) {
 		file_plugin *fplug;
@@ -348,6 +383,8 @@ truncate_object(struct inode *inode /* o
 	assert("nikita-1027", is_reiser4_inode(inode));
 	assert("nikita-1028", inode->i_sb != NULL);
 
+	write_syscall_log("%llu %lli", get_inode_oid(inode), size);
+
 	fplug = inode_file_plugin(inode);
 	assert("vs-142", fplug != NULL);
 
@@ -357,6 +394,7 @@ truncate_object(struct inode *inode /* o
 		warning("nikita-1602", "Truncate error: %i for %lli", result,
 			(unsigned long long)get_inode_oid(inode));
 
+	write_syscall_log("ex");
 	return result;
 }
 
@@ -369,6 +407,8 @@ reiser4_truncate(struct inode *inode /* 
 	assert("umka-075", inode != NULL);
 
 	init_context(&ctx, inode->i_sb);
+	reiser4_stat_inc(vfs_calls.truncate);
+	ON_TRACE(TRACE_VFS_OPS, "TRUNCATE: i_ino %li to size %lli\n", inode->i_ino, inode->i_size);
 
 	truncate_object(inode, inode->i_size);
 
@@ -404,16 +444,21 @@ unlink_file(struct inode *parent /* pare
 	reiser4_context ctx;
 
 	init_context(&ctx, parent->i_sb);
+	write_syscall_log("%s", victim->d_name.name);
 
 	assert("nikita-1435", parent != NULL);
 	assert("nikita-1436", victim != NULL);
 
+	ON_TRACE(TRACE_DIR | TRACE_VFS_OPS, "unlink: %lli/%s\n",
+		 get_inode_oid(parent), victim->d_name.name);
+
 	dplug = inode_dir_plugin(parent);
 	assert("nikita-1429", dplug != NULL);
 	if (dplug->unlink != NULL)
 		result = dplug->unlink(parent, victim);
 	else
 		result = RETERR(-EPERM);
+	write_syscall_log("ex");
 	/* @victim can be already removed from the disk by this time. Inode is
 	   then marked so that iput() wouldn't try to remove stat data. But
 	   inode itself is still there.
@@ -442,6 +487,7 @@ reiser4_unlink(struct inode *parent /* p
 	assert("nikita-2011", parent != NULL);
 	assert("nikita-2012", victim != NULL);
 	assert("nikita-2013", victim->d_inode != NULL);
+	reiser4_stat_inc_at(parent->i_sb,vfs_calls.unlink);
 	if (inode_dir_plugin(victim->d_inode) == NULL)
 		return unlink_file(parent, victim);
 	else
@@ -463,6 +509,7 @@ reiser4_rmdir(struct inode *parent /* pa
 	assert("nikita-2015", victim != NULL);
 	assert("nikita-2016", victim->d_inode != NULL);
 
+	reiser4_stat_inc_at(parent->i_sb, vfs_calls.rmdir);
 	if (inode_dir_plugin(victim->d_inode) != NULL)
 		/* there is no difference between unlink and rmdir for
 		   reiser4 */
@@ -494,6 +541,7 @@ reiser4_link(struct dentry *existing	/* 
 
 	init_context(&ctx, parent->i_sb);
 	context_set_commit_async(&ctx);
+	reiser4_stat_inc(vfs_calls.link);
 
 	dplug = inode_dir_plugin(parent);
 	assert("nikita-1430", dplug != NULL);
@@ -529,6 +577,7 @@ invoke_create_method(struct inode *paren
 
 	init_context(&ctx, parent->i_sb);
 	context_set_commit_async(&ctx);
+	write_syscall_log("%s %o", dentry->d_name.name, data->mode);
 
 	assert("nikita-426", parent != NULL);
 	assert("nikita-427", dentry != NULL);
@@ -563,10 +612,15 @@ invoke_create_method(struct inode *paren
 			}
 		} else {
 			d_instantiate(dentry, child);
+			ON_TRACE(TRACE_VFS_OPS, "create: %s (%o) %llu\n",
+				 dentry->d_name.name,
+				 data->mode, get_inode_oid(child));
 		}
 	} else
 		result = RETERR(-EPERM);
 
+	write_syscall_log("ex");
+
 	reiser4_exit_context(&ctx);
 	return result;
 }
diff -puN jnode.c~profile-stat-trace-repacker jnode.c
--- reiser4/jnode.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/jnode.c	2005-02-01 11:51:11.000000000 +0300
@@ -113,6 +113,7 @@
 #include "super.h"
 #include "inode.h"
 #include "page_cache.h"
+#include "prof.h"
 
 #include <asm/uaccess.h>        /* UML needs this for PAGE_OFFSET */
 #include <linux/types.h>
@@ -126,8 +127,7 @@
 static kmem_cache_t *_jnode_slab = NULL;
 
 static void jnode_set_type(jnode * node, jnode_type type);
-static int jdelete(jnode * node);
-static int jnode_try_drop(jnode * node);
+
 
 /* true if valid page is attached to jnode */
 static inline int jnode_is_parsed (jnode * node)
@@ -170,7 +170,8 @@ reiser4_internal int
 jnodes_tree_init(reiser4_tree * tree /* tree to initialise jnodes for */ )
 {
 	assert("nikita-2359", tree != NULL);
-	return j_hash_init(&tree->jhash_table, 16384);
+	return j_hash_init(&tree->jhash_table, 16384,
+			   reiser4_stat(tree->super, hashes.jnode));
 }
 
 /* call this to destroy jnode hash table. This is called during umount. */
@@ -186,8 +187,14 @@ jnodes_tree_done(reiser4_tree * tree /* 
 	/*
 	 * Scan hash table and free all jnodes.
 	 */
+
+	IF_TRACE(TRACE_ZWEB, UNDER_RW_VOID(tree, tree, read,
+					   print_jnodes("umount", tree)));
+
 	jtable = &tree->jhash_table;
 	for_all_in_htable(jtable, j, node, next) {
+		if (atomic_read(&node->x_count))
+			info_jnode("x_count != 0", node);
 		assert("nikita-2361", !atomic_read(&node->x_count));
 		jdrop(node);
 	}
@@ -239,7 +246,7 @@ jnode_init(jnode * node, reiser4_tree * 
 {
 	assert("umka-175", node != NULL);
 
-	memset(node, 0, sizeof (jnode));
+	xmemset(node, 0, sizeof (jnode));
 	ON_DEBUG(node->magic = JMAGIC);
 	jnode_set_type(node, type);
 	atomic_set(&node->d_count, 0);
@@ -319,7 +326,7 @@ jfree(jnode * node)
 	/* not yet phash_jnode_destroy(node); */
 
 	/* poison memory. */
-	ON_DEBUG(memset(node, 0xad, sizeof *node));
+	ON_DEBUG(xmemset(node, 0xad, sizeof *node));
 	kmem_cache_free(_jnode_slab, node);
 }
 
@@ -704,6 +711,8 @@ page_clear_jnode(struct page *page, jnod
 	ClearPagePrivate(page);
 	node->pg = NULL;
 	page_cache_release(page);
+	if (REISER4_DEBUG_MODIFY && jnode_is_znode(node))
+		ON_DEBUG_MODIFY(JZNODE(node)->cksum = 0);
 }
 
 /* it is only used in one place to handle error */
@@ -730,7 +739,7 @@ page_detach_jnode(struct page *page, str
    the opposite direction. This is done through standard trylock-and-release
    loop.
 */
-static struct page *
+reiser4_internal struct page *
 jnode_lock_page(jnode * node)
 {
 	struct page *page;
@@ -884,6 +893,7 @@ jload_gfp (jnode * node /* node to load 
 	int parsed;
 
 	assert("nikita-3010", schedulable());
+	write_node_log(node);
 
 	prefetchw(&node->pg);
 
@@ -901,6 +911,8 @@ jload_gfp (jnode * node /* node to load 
 	UNLOCK_JLOAD(node);
 
 	if (unlikely(!parsed)) {
+		ON_TRACE(TRACE_PCACHE, "read node: %p\n", node);
+
 		page = jnode_get_page_locked(node, gfp_flags);
 		if (unlikely(IS_ERR(page))) {
 			result = PTR_ERR(page);
@@ -932,6 +944,8 @@ jload_gfp (jnode * node /* node to load 
 		check_jload(node, page);
 		if (do_kmap)
 			node->data = kmap(page);
+		reiser4_stat_inc_at_level(jnode_get_level(node),
+					  jnode.jload_already);
 	}
 
 	if (unlikely(JF_ISSET(node, JNODE_EFLUSH)))
@@ -1027,6 +1041,8 @@ jrelse(jnode * node /* jnode to release 
 	assert("nikita-487", node != NULL);
 	assert("nikita-1906", spin_jnode_is_not_locked(node));
 
+	ON_TRACE(TRACE_PCACHE, "release node: %p\n", node);
+
 	page = jnode_page(node);
 	if (likely(page != NULL)) {
 		/*
@@ -1376,7 +1392,7 @@ znode *zalloc(int gfp_flag);
 void zinit(znode *, const znode * parent, reiser4_tree *);
 
 /* ->clone() method for formatted nodes */
-static jnode *
+reiser4_internal jnode *
 clone_formatted(jnode *node)
 {
 	znode *clone;
@@ -1394,7 +1410,7 @@ clone_formatted(jnode *node)
 }
 
 /* jplug->clone for unformatted nodes */
-static jnode *
+reiser4_internal jnode *
 clone_unformatted(jnode *node)
 {
 	jnode *clone;
@@ -1610,16 +1626,19 @@ void jnode_list_remove(jnode * node)
  * this is called by jput_final() to remove jnode when last reference to it is
  * released.
  */
-static int
+reiser4_internal int
 jnode_try_drop(jnode * node)
 {
 	int result;
 	reiser4_tree *tree;
 	jnode_type    jtype;
 
+	trace_stamp(TRACE_ZNODES);
 	assert("nikita-2491", node != NULL);
 	assert("nikita-2583", JF_ISSET(node, JNODE_RIP));
 
+	ON_TRACE(TRACE_PCACHE, "trying to drop node: %p\n", node);
+
 	tree = jnode_get_tree(node);
 	jtype = jnode_get_type(node);
 
@@ -1659,7 +1678,7 @@ jnode_try_drop(jnode * node)
 }
 
 /* jdelete() -- Delete jnode from the tree and file system */
-static int
+reiser4_internal int
 jdelete(jnode * node /* jnode to finish with */)
 {
 	struct page *page;
@@ -1667,12 +1686,15 @@ jdelete(jnode * node /* jnode to finish 
 	reiser4_tree *tree;
 	jnode_type    jtype;
 
+	trace_stamp(TRACE_ZNODES);
 	assert("nikita-467", node != NULL);
 	assert("nikita-2531", JF_ISSET(node, JNODE_RIP));
 	/* jnode cannot be eflushed at this point, because emegrency flush
 	 * acquired additional reference counter. */
 	assert("nikita-2917", !JF_ISSET(node, JNODE_EFLUSH));
 
+	ON_TRACE(TRACE_PCACHE, "delete node: %p\n", node);
+
 	jtype = jnode_get_type(node);
 
 	page = jnode_lock_page(node);
@@ -1735,6 +1757,7 @@ jdrop_in_tree(jnode * node, reiser4_tree
 	assert("nikita-2403", !JF_ISSET(node, JNODE_HEARD_BANSHEE));
 	// assert( "nikita-2532", JF_ISSET( node, JNODE_RIP ) );
 
+	ON_TRACE(TRACE_PCACHE, "drop node: %p\n", node);
 
 	jtype = jnode_get_type(node);
 
@@ -1833,7 +1856,7 @@ jnode_get_mapping(const jnode * node)
 	return jnode_ops(node)->mapping(node);
 }
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_NODE_INVARIANT
 /* debugging aid: jnode invariant */
 reiser4_internal int
 jnode_invariant_f(const jnode * node,
@@ -1915,7 +1938,25 @@ jnode_invariant(const jnode * node, int 
 	return result;
 }
 
-static const char *
+/* REISER4_DEBUG_NODE_INVARIANT */
+#endif
+
+#if REISER4_STATS
+void reiser4_stat_inc_at_level_jput(const jnode * node)
+{
+	reiser4_stat_inc_at_level(jnode_get_level(node), jnode.jput);
+}
+
+void reiser4_stat_inc_at_level_jputlast(const jnode * node)
+{
+	reiser4_stat_inc_at_level(jnode_get_level(node), jnode.jputlast);
+}
+/* REISER4_STATS */
+#endif
+
+#if REISER4_DEBUG_OUTPUT
+
+reiser4_internal const char *
 jnode_type_name(jnode_type type)
 {
 	switch (type) {
@@ -1982,7 +2023,11 @@ info_jnode(const char *prefix /* prefix 
 	       jnode_get_level(node), sprint_address(jnode_get_block(node)),
 	       atomic_read(&node->d_count), atomic_read(&node->x_count),
 	       jnode_page(node), node->atom,
+#if REISER4_LOCKPROF && REISER4_LOCKPROF_OBJECTS
+	       node->guard.held, node->guard.trying,
+#else
 	       0, 0,
+#endif
 	       jnode_type_name(jnode_get_type(node)));
 	if (jnode_is_unformatted(node)) {
 		printk("inode: %llu, index: %lu, ",
@@ -2001,7 +2046,35 @@ print_jnode(const char *prefix /* prefix
 		info_jnode(prefix, node);
 }
 
-#endif /* REISER4_DEBUG */
+/* this is cut-n-paste replica of print_znodes() */
+reiser4_internal void
+print_jnodes(const char *prefix, reiser4_tree * tree)
+{
+	jnode *node;
+	jnode *next;
+	j_hash_table *htable;
+	int tree_lock_taken;
+
+	if (tree == NULL)
+		tree = current_tree;
+
+	/* this is a debugging function. It can be called by reiser4_panic()
+	   with tree spin-lock already held. Trylock is not exactly what we
+	   want here, but it is passable.
+	*/
+	tree_lock_taken = write_trylock_tree(tree);
+	htable = &tree->jhash_table;
+
+	for_all_in_htable(htable, j, node, next) {
+		info_jnode(prefix, node);
+		printk("\n");
+	}
+	if (tree_lock_taken)
+		WUNLOCK_TREE(tree);
+}
+
+/* REISER4_DEBUG_OUTPUT */
+#endif
 
 /* this is only used to created jnode during capture copy */
 reiser4_internal jnode *jclone(jnode *node)
diff -puN jnode.h~profile-stat-trace-repacker jnode.h
--- reiser4/jnode.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/jnode.h	2005-02-01 12:01:17.000000000 +0300
@@ -396,7 +396,7 @@ extern void unformatted_make_reloc(jnode
 
 extern void jnode_set_block(jnode * node,
 			    const reiser4_block_nr * blocknr) NONNULL;
-/*extern struct page *jnode_lock_page(jnode *) NONNULL;*/
+extern struct page *jnode_lock_page(jnode *) NONNULL;
 extern struct address_space *jnode_get_mapping(const jnode * node) NONNULL;
 
 /* block number of node */
@@ -425,6 +425,7 @@ jnode_get_io_block(const jnode * node)
 
 /* Jnode flush interface. */
 extern reiser4_blocknr_hint *pos_hint(flush_pos_t * pos);
+extern int pos_leaf_relocate(flush_pos_t * pos);
 extern flush_queue_t * pos_fq(flush_pos_t * pos);
 
 /* FIXME-VS: these are used in plugin/item/extent.c */
@@ -459,17 +460,23 @@ extern int jnodes_tree_done(reiser4_tree
 #if REISER4_DEBUG
 extern int znode_is_any_locked(const znode * node);
 extern void jnode_list_remove(jnode * node);
-extern int jnode_invariant(const jnode * node, int tlocked, int jlocked);
 #else
 #define jnode_list_remove(node) noop
+#endif
+
+#if REISER4_DEBUG_NODE_INVARIANT
+extern int jnode_invariant(const jnode * node, int tlocked, int jlocked);
+#else
 #define jnode_invariant(n, t, j) (1)
 #endif
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 extern void info_jnode(const char *prefix, const jnode * node);
 extern void print_jnode(const char *prefix, const jnode * node);
+extern void print_jnodes(const char *prefix, reiser4_tree * tree);
 #else
 #define info_jnode(p, n) noop
+#define print_jnodes(p, t) noop
 #define print_jnode(p, n) noop
 #endif
 
@@ -505,6 +512,8 @@ jref(jnode * node)
 	return node;
 }
 
+extern int jdelete(jnode * node) NONNULL;
+
 /* get the page of jnode */
 static inline struct page *
 jnode_page(const jnode * node)
@@ -713,9 +722,18 @@ jnode_is_root(const jnode * node)
 extern struct address_space * mapping_jnode(const jnode * node);
 extern unsigned long index_jnode(const jnode * node);
 
+extern int jnode_try_drop(jnode * node);
+
 static inline void jput(jnode * node);
 extern void jput_final(jnode * node);
 
+#if REISER4_STATS
+extern void reiser4_stat_inc_at_level_jput(const jnode * node);
+extern void reiser4_stat_inc_at_level_jputlast(const jnode * node);
+#else
+#define reiser4_stat_inc_at_level_jput(node) noop
+#define reiser4_stat_inc_at_level_jputlast(node) noop
+#endif
 
 /* jput() - decrement x_count reference counter on znode.
 
@@ -727,17 +745,21 @@ extern void jput_final(jnode * node);
 static inline void
 jput(jnode * node)
 {
+	trace_stamp(TRACE_ZNODES);
+
 	assert("jmacd-509", node != NULL);
 	assert("jmacd-510", atomic_read(&node->x_count) > 0);
 	assert("nikita-3065", spin_jnode_is_not_locked(node));
 	assert("zam-926", schedulable());
 	LOCK_CNT_DEC(x_refs);
 
+	reiser4_stat_inc_at_level_jput(node);
 	rcu_read_lock();
 	/*
 	 * we don't need any kind of lock here--jput_final() uses RCU.
 	 */
 	if (unlikely(atomic_dec_and_test(&node->x_count))) {
+		reiser4_stat_inc_at_level_jputlast(node);
 		jput_final(node);
 	} else
 		rcu_read_unlock();
diff -puN kassign.c~profile-stat-trace-repacker kassign.c
--- reiser4/kassign.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/kassign.c	2005-02-01 11:51:11.000000000 +0300
@@ -272,7 +272,7 @@ pack_string(const char *name /* string t
 	return str;
 }
 
-#if !REISER4_DEBUG
+#if !REISER4_DEBUG_OUTPUT
 static
 #endif
 /* opposite to pack_string(). Takes value produced by pack_string(), restores
@@ -529,7 +529,7 @@ build_obj_key_id(const reiser4_key * key
 	assert("nikita-1151", key != NULL);
 	assert("nikita-1152", id != NULL);
 
-	memcpy(id, key, sizeof *id);
+	xmemcpy(id, key, sizeof *id);
 	return 0;
 }
 
@@ -564,7 +564,7 @@ extract_key_from_id(const obj_key_id * i
 	assert("nikita-1154", key != NULL);
 
 	reiser4_key_init(key);
-	memcpy(key, id, sizeof *id);
+	xmemcpy(key, id, sizeof *id);
 	return 0;
 }
 
@@ -618,7 +618,7 @@ build_de_id_by_key(const reiser4_key * e
 							 * entry */ ,
 		   de_id * id /* short key of directory entry */ )
 {
-	memcpy(id, ((__u64 *) entry_key) + 1, sizeof *id);
+	xmemcpy(id, ((__u64 *) entry_key) + 1, sizeof *id);
 	return 0;
 }
 
@@ -635,12 +635,36 @@ extract_key_from_de_id(const oid_t local
 		       reiser4_key * key /* result */ )
 {
 	/* no need to initialise key here: all fields are overwritten */
-	memcpy(((__u64 *) key) + 1, id, sizeof *id);
+	xmemcpy(((__u64 *) key) + 1, id, sizeof *id);
 	set_key_locality(key, locality);
 	set_key_type(key, KEY_FILE_NAME_MINOR);
 	return 0;
 }
 
+/* compare two &obj_key_id */
+reiser4_internal cmp_t
+key_id_cmp(const obj_key_id * i1 /* first object key id to compare */ ,
+	   const obj_key_id * i2 /* second object key id to compare */ )
+{
+	reiser4_key k1;
+	reiser4_key k2;
+
+	extract_key_from_id(i1, &k1);
+	extract_key_from_id(i2, &k2);
+	return keycmp(&k1, &k2);
+}
+
+/* compare &obj_key_id with full key */
+reiser4_internal cmp_t
+key_id_key_cmp(const obj_key_id * id /* object key id to compare */ ,
+	       const reiser4_key * key /* key to compare */ )
+{
+	reiser4_key k1;
+
+	extract_key_from_id(id, &k1);
+	return keycmp(&k1, key);
+}
+
 /* compare two &de_id's */
 reiser4_internal cmp_t
 de_id_cmp(const de_id * id1 /* first &de_id to compare */ ,
@@ -674,6 +698,19 @@ de_id_key_cmp(const de_id * id /* direct
 	return result;
 }
 
+/* true if key of root directory sd */
+reiser4_internal int
+is_root_dir_key(const struct super_block *super /* super block to check */ ,
+		const reiser4_key * key /* key to check */ )
+{
+	assert("nikita-1819", super != NULL);
+	assert("nikita-1820", key != NULL);
+	/* call disk plugin's root_dir_key method if it exists */
+	if (get_super_private(super)->df_plug && get_super_private(super)->df_plug->root_dir_key)
+		return keyeq(key, get_super_private(super)->df_plug->root_dir_key(super));
+	return 0;
+}
+
 /*
  * return number of bytes necessary to encode @inode identity.
  */
diff -puN kassign.h~profile-stat-trace-repacker kassign.h
--- reiser4/kassign.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/kassign.h	2005-02-01 11:51:11.000000000 +0300
@@ -70,6 +70,8 @@ extern oid_t extract_dir_id_from_key(con
 extern int build_de_id(const struct inode *dir, const struct qstr *name, de_id * id);
 extern int build_de_id_by_key(const reiser4_key * entry_key, de_id * id);
 extern int extract_key_from_de_id(const oid_t locality, const de_id * id, reiser4_key * key);
+extern cmp_t key_id_cmp(const obj_key_id * i1, const obj_key_id * i2);
+extern cmp_t key_id_key_cmp(const obj_key_id * id, const reiser4_key * key);
 extern cmp_t de_id_cmp(const de_id * id1, const de_id * id2);
 extern cmp_t de_id_key_cmp(const de_id * id, const reiser4_key * key);
 
@@ -78,6 +80,7 @@ extern void build_entry_key_common(const
 extern void build_entry_key_stable_entry(const struct inode *dir, const struct qstr *name, reiser4_key * result);
 extern int is_dot_key(const reiser4_key * key);
 extern reiser4_key *build_sd_key(const struct inode *target, reiser4_key * result);
+extern int is_root_dir_key(const struct super_block *super, const reiser4_key * key);
 
 extern int is_longname_key(const reiser4_key *key);
 extern int is_longname(const char *name, int len);
diff -puN /dev/null kattr.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/kattr.c	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,641 @@
+/* Copyright 2001, 2002, 2003 by Hans Reiser, licensing governed by
+ * reiser4/README */
+
+/* Interface to sysfs' attributes */
+
+/*
+ * Reiser4 exports some of its internal data through sysfs.
+ *
+ * For details on sysfs see fs/sysfs, include/linux/sysfs.h,
+ * include/linux/kobject.h. Roughly speaking, one embeds struct kobject into
+ * some kernel data type. Objects of this type will be represented as
+ * _directories_ somewhere below /sys. Attributes can be registered for
+ * kobject and they will be visible as files within corresponding
+ * directory. Each attribute is represented by struct kattr. How given
+ * attribute reacts to read and write is determined by ->show and ->store
+ * operations that are properties of its parent kobject.
+ *
+ * Reiser4 exports following stuff through sysfs:
+ *
+ *    path                                              kobject or attribute
+ *
+ * /sys/fs/reiser4/
+ *                 <dev>/                               sbinfo->kobj
+ *                       sb-fields                      def_attrs[]
+ *                       stats/                         sbinfo->stats_kobj
+ *                             stat-cnts                reiser4_stat_defs[]
+ *                             level-NN/                sbinfo->level[].kobj
+ *                                      stat-cnts       reiser4_stat_level_defs[]
+ *
+ * (For some reasons we also add /sys/fs and /sys/fs/reiser4 manually, but
+ * this is supposed to be done by core.)
+ *
+ * Our kattr.[ch] code depends on some additional functionality missing in the
+ * core kernel. This functionality is added in kobject-umount-race.patch from
+ * our core-patches repository. As it's obvious from its name this patch adds
+ * protection against /sys/fs/reiser4/<dev>/ * accesses and concurrent umount
+ * of <dev>. See commentary in this patch for more details.
+ *
+ * Shouldn't struct kobject be renamed to struct knobject?
+ *
+ */
+
+#include "debug.h"
+#include "super.h"
+#include "kattr.h"
+#include "prof.h"
+
+#include <linux/kobject.h>     /* struct kobject */
+#include <linux/fs.h>          /* struct super_block */
+
+#if REISER4_USE_SYSFS
+
+/*
+ * Super-block fields exporting.
+ *
+ * Many fields of reiser4-private part of super-block
+ * (fs/reiser4/super.h:reiser4_super_info_data) are exported through
+ * sysfs. Code below tries to minimize code duplication for this common case.
+ *
+ * Specifically, all fields that are "scalars" (i.e., basically integers) of
+ * 32 or 64 bits are handled by the same ->show() and ->store()
+ * functions. Each such field is represented by two pieces of data:
+ *
+ *     1. super_field_cookie, and
+ *
+ *     2. reiser4_kattr.
+ *
+ * super_field_cookie contains "field description":
+ *
+ *     1. field offset in bytes from the beginning of reiser4-specific portion
+ *     of super block, and
+ *
+ *     2. printf(3) format to show field content in ->show() function.
+ *
+ * reiser4_kattr is standard object we are using to embed struct fs_attribute
+ * in. It stores pointer to the corresponding super_field_cookie. Also
+ * reiser4_kattr contains ->store and ->show function pointers that are set
+ * according to field width and desired access rights to
+ * {show,store}_{ro,rw}_{32,64}().
+ *
+ * These functions use super_field_cookie (stored in ->cookie field of
+ * reiser4_kattr) to obtain/store value of field involved and format it
+ * properly.
+ *
+ */
+
+/* convert @attr to reiser4_kattr object it is embedded in */
+typedef struct {
+	/* offset in bytes to the super-block field from the beginning of
+	 * reiser4_super_info_data */
+	ptrdiff_t   offset;
+	/* desired printf(3) format for ->show() method. */
+	const char *format;
+} super_field_cookie;
+
+/*
+ * This macro defines super_field_cookie and reiser4_kattr for given
+ * super-block field.
+ */
+#define DEFINE_SUPER_F(aname /* unique identifier used to generate variable \
+			      * names */,				\
+	  afield /* name of super-block field */,			\
+	  aformat /* desired ->show() format */,			\
+	  asize /* field size (as returned by sizeof()) */,		\
+	  ashow /* show method */,					\
+	  astore /* store method */,					\
+	  amode /* access method */)					\
+static super_field_cookie __cookie_ ## aname = {			\
+	.offset = offsetof(reiser4_super_info_data, afield),		\
+	.format = aformat "\n"						\
+};									\
+									\
+static reiser4_kattr kattr_super_ ## aname = {				\
+	.attr = {							\
+		.kattr = {						\
+			.name = (char *) #afield,			\
+			.mode = amode					\
+		},							\
+		.show = ashow,						\
+		.store = astore						\
+	},								\
+	.cookie = &__cookie_ ## aname					\
+}
+
+/*
+ * Specialized version of DEFINE_SUPER_F() used to generate description of
+ * read-only fields
+ */
+#define DEFINE_SUPER_RO(aname, afield, aformat, asize)			\
+	DEFINE_SUPER_F(aname,						\
+		       afield, aformat, asize, show_ro_ ## asize, NULL, 0440)
+
+/*
+ * Specialized version of DEFINE_SUPER_F() used to generate description of
+ * read-write fields
+ */
+#define DEFINE_SUPER_RW(aname, afield, aformat, asize)			\
+	DEFINE_SUPER_F(aname,						\
+		       afield, aformat, asize, show_ro_ ## asize,	\
+		       store_rw_ ## asize, 0660)
+
+/* helper macro: return field of type @type stored at the offset of @offset
+ * bytes from the @ptr. */
+#define getat(ptr, offset, type) *(type *)(((char *)(ptr)) + (offset))
+
+/* helper macro: modify value of field to @value. See getat() above for the
+ * meaning of other arguments */
+#define setat(ptr, offset, type, val)			\
+	({ *(type *)(((char *)(ptr)) + (offset)) = (val); })
+
+/* return cookie contained in reiser4_kattr that @attr is embedded into */
+static inline void *
+getcookie(struct fs_kattr *attr)
+{
+	return container_of(attr, reiser4_kattr, attr)->cookie;
+}
+
+/*
+ * ->show method for read-only 32bit scalar super block fields.
+ */
+static ssize_t
+show_ro_32(struct super_block * s /* super-block field belongs to */,
+	   struct fs_kobject *o /* object attribute of which @kattr is. */,
+	   struct fs_kattr * kattr /* file-system attribute that is
+				    * exported */,
+	   char * buf /* buffer to store field representation into */)
+{
+	char *p;
+	super_field_cookie *cookie;
+	__u32 val;
+
+	cookie = getcookie(kattr);
+	/* obtain field value from super-block, ... */
+	val = getat(get_super_private(s), cookie->offset, __u32);
+	p = buf;
+	/* and print it according to the format string specified in the
+	 * cookie */
+	KATTR_PRINT(p, buf, cookie->format, (unsigned long long)val);
+	return (p - buf);
+}
+
+/*
+ * ->store method for read-write 32bit scalar super-block fields.
+ */
+static ssize_t
+store_rw_32(struct super_block * s /* super-block field belongs to */,
+	    struct fs_kobject *o /* object attribute of which @kattr is. */,
+	    struct fs_kattr * kattr /* file-system attribute that is
+				    * exported */,
+	    const char * buf /* buffer to read field value from */,
+	    size_t size /* buffer size */)
+{
+	super_field_cookie *cookie;
+	__u32 val;
+
+	cookie = getcookie(kattr);
+	/* read value from the buffer */
+	if (sscanf(buf, "%i", &val) == 1)
+		/* if buffer contains well-formed value, update super-block
+		 * field. */
+		setat(get_super_private(s), cookie->offset, __u32, val);
+	else
+		size = RETERR(-EINVAL);
+	return size;
+}
+
+/*
+ * ->show method for read-only 64bit scalar super block fields.
+ *
+ * It's exactly like show_ro_32, mutatis mutandis.
+ */
+static ssize_t show_ro_64(struct super_block * s, struct fs_kobject *o,
+			  struct fs_kattr * kattr, char * buf)
+{
+	char *p;
+	super_field_cookie *cookie;
+	__u64 val;
+
+	cookie = getcookie(kattr);
+	val = getat(get_super_private(s), cookie->offset, __u64);
+	p = buf;
+	KATTR_PRINT(p, buf, cookie->format, (unsigned long long)val);
+	return (p - buf);
+}
+
+#if 0
+/* We don't have writable 64bit attributes yet. */
+static ssize_t
+store_rw_64(struct super_block * s,
+	    struct fs_kobject *o, struct fs_kattr * kattr,
+	    char * buf, size_t size)
+{
+	super_field_cookie *cookie;
+	__u64 val;
+
+	cookie = getcookie(kattr);
+	if (sscanf(buf, "%lli", &val) == 1)
+		setat(get_super_private(s), cookie->offset, __u64, val);
+	else
+		size = RETERR(-EINVAL);
+	return size;
+}
+#endif
+
+#undef getat
+#undef setat
+
+/*
+ * Exporting reiser4 compilation options.
+ *
+ * reiser4 compilation options are exported through
+ * /sys/fs/<dev>/options. Read-only for now. :)
+ *
+ */
+
+#define SHOW_OPTION(p, buf, option)			\
+	if (option)					\
+		KATTR_PRINT((p), (buf), #option "\n")
+
+static ssize_t
+show_options(struct super_block * s,
+	     struct fs_kobject *o, struct fs_kattr * kattr, char * buf)
+{
+	char *p;
+
+	p = buf;
+
+	/*
+	 * PLEASE update this when adding new compilation option
+	 */
+
+	SHOW_OPTION(p, buf, REISER4_DEBUG);
+	SHOW_OPTION(p, buf, REISER4_DEBUG_MODIFY);
+	SHOW_OPTION(p, buf, REISER4_DEBUG_MEMCPY);
+	SHOW_OPTION(p, buf, REISER4_DEBUG_NODE);
+	SHOW_OPTION(p, buf, REISER4_ZERO_NEW_NODE);
+	SHOW_OPTION(p, buf, REISER4_TRACE);
+	SHOW_OPTION(p, buf, REISER4_LOG);
+	SHOW_OPTION(p, buf, REISER4_STATS);
+	SHOW_OPTION(p, buf, REISER4_DEBUG_OUTPUT);
+	SHOW_OPTION(p, buf, REISER4_LOCKPROF);
+	SHOW_OPTION(p, buf, REISER4_LARGE_KEY);
+	SHOW_OPTION(p, buf, REISER4_PROF);
+	SHOW_OPTION(p, buf, REISER4_COPY_ON_CAPTURE);
+	SHOW_OPTION(p, buf, REISER4_ALL_IN_ONE);
+	SHOW_OPTION(p, buf, REISER4_DEBUG_NODE_INVARIANT);
+	SHOW_OPTION(p, buf, REISER4_DEBUG_SPIN_LOCKS);
+	SHOW_OPTION(p, buf, REISER4_DEBUG_CONTEXTS);
+	SHOW_OPTION(p, buf, REISER4_DEBUG_SIBLING_LIST);
+
+	return (p - buf);
+}
+
+static reiser4_kattr compile_options = {
+	.attr = {
+		.kattr = {
+			 .name = (char *) "options",
+			 .mode = 0444   /* r--r--r-- */
+		 },
+		.show = show_options,
+	},
+	.cookie = NULL
+};
+
+/*
+ * show a name of device on top of which reiser4 file system exists in
+ * /sys/fs/reiser4/<dev>/device.
+ */
+
+static ssize_t
+show_device(struct super_block * s,
+	    struct fs_kobject *o, struct fs_kattr * kattr, char * buf)
+{
+	char *p;
+
+	p = buf;
+	KATTR_PRINT(p, buf, "%d:%d\n", MAJOR(s->s_dev), MINOR(s->s_dev));
+	return (p - buf);
+}
+
+static reiser4_kattr device = {
+	.attr = {
+		.kattr = {
+			 .name = (char *) "device",
+			 .mode = 0444   /* r--r--r-- */
+		 },
+		.show = show_device,
+	},
+	.cookie = NULL
+};
+
+#if REISER4_DEBUG
+
+/*
+ * debugging code: break into debugger on each write into this file. Useful
+ * when event of importance can be detected in the user space, but not in the
+ * kernel.
+ */
+
+ssize_t store_bugme(struct super_block * s, struct fs_kobject *o,
+		    struct fs_kattr *ka, const char *buf, size_t size)
+{
+	DEBUGON(1);
+	return size;
+}
+
+static reiser4_kattr bugme = {
+	.attr = {
+		.kattr = {
+			 .name = (char *) "bugme",
+			 .mode = 0222   /* -w--w--w- */
+		 },
+		.store = store_bugme,
+	},
+	.cookie = NULL
+};
+
+/* REISER4_DEBUG */
+#endif
+
+/*
+ * Declare all super-block fields we want to export
+ */
+
+DEFINE_SUPER_RO(01, mkfs_id, "%#llx", 32);
+DEFINE_SUPER_RO(02, block_count, "%llu", 64);
+DEFINE_SUPER_RO(03, blocks_used, "%llu", 64);
+DEFINE_SUPER_RO(04, blocks_free_committed, "%llu", 64);
+DEFINE_SUPER_RO(05, blocks_grabbed, "%llu", 64);
+DEFINE_SUPER_RO(06, blocks_fake_allocated_unformatted, "%llu", 64);
+DEFINE_SUPER_RO(07, blocks_fake_allocated, "%llu", 64);
+DEFINE_SUPER_RO(08, blocks_flush_reserved, "%llu", 64);
+DEFINE_SUPER_RO(09, fsuid, "%#llx", 32);
+#if REISER4_DEBUG
+DEFINE_SUPER_RO(10, eflushed, "%llu", 32);
+#endif
+DEFINE_SUPER_RO(11, blocknr_hint_default, "%lli", 64);
+DEFINE_SUPER_RO(12, nr_files_committed, "%llu", 64);
+DEFINE_SUPER_RO(13, tmgr.atom_count, "%llu", 32);
+DEFINE_SUPER_RO(14, tmgr.id_count, "%llu", 32);
+DEFINE_SUPER_RO(15, tmgr.atom_max_size, "%llu", 32);
+DEFINE_SUPER_RO(16, tmgr.atom_max_age, "%llu", 32);
+
+/* tree fields */
+DEFINE_SUPER_RO(17, tree.root_block, "%llu", 64);
+DEFINE_SUPER_RO(18, tree.height, "%llu", 32);
+DEFINE_SUPER_RO(19, tree.znode_epoch, "%llu", 64);
+DEFINE_SUPER_RO(20, tree.carry.new_node_flags, "%#llx", 32);
+DEFINE_SUPER_RO(21, tree.carry.new_extent_flags, "%#llx", 32);
+DEFINE_SUPER_RO(22, tree.carry.paste_flags, "%#llx", 32);
+DEFINE_SUPER_RO(23, tree.carry.insert_flags, "%#llx", 32);
+
+/* not very good. Should be done by the plugin in stead */
+DEFINE_SUPER_RO(24, next_to_use, "%llu", 64);
+DEFINE_SUPER_RO(25, oids_in_use, "%llu", 64);
+
+DEFINE_SUPER_RO(26, entd.flushers, "%llu", 32);
+
+DEFINE_SUPER_RW(27, trace_flags, "%#llx", 32);
+DEFINE_SUPER_RW(28, log_flags, "%#llx", 32);
+
+#define ATTR_NO(n) &kattr_super_ ## n .attr.kattr
+
+static struct attribute * kattr_def_attrs[] = {
+	ATTR_NO(01),
+	ATTR_NO(02),
+	ATTR_NO(03),
+	ATTR_NO(04),
+	ATTR_NO(05),
+	ATTR_NO(06),
+	ATTR_NO(07),
+	ATTR_NO(08),
+	ATTR_NO(09),
+#if REISER4_DEBUG
+	ATTR_NO(10),
+#endif
+	ATTR_NO(11),
+	ATTR_NO(12),
+	ATTR_NO(13),
+	ATTR_NO(14),
+	ATTR_NO(15),
+	ATTR_NO(16),
+	ATTR_NO(17),
+	ATTR_NO(18),
+	ATTR_NO(19),
+	ATTR_NO(20),
+	ATTR_NO(21),
+	ATTR_NO(22),
+	ATTR_NO(23),
+	ATTR_NO(24),
+	ATTR_NO(25),
+	ATTR_NO(26),
+	ATTR_NO(27),
+	ATTR_NO(28),
+/*
+	ATTR_NO(29),
+	ATTR_NO(30),
+*/
+	&compile_options.attr.kattr,
+	&device.attr.kattr,
+#if REISER4_DEBUG
+	&bugme.attr.kattr,
+#endif
+	NULL
+};
+
+struct kobj_type ktype_reiser4 = {
+	.sysfs_ops	= &fs_attr_ops,
+	.default_attrs	= kattr_def_attrs,
+	.release	= NULL
+};
+
+#if REISER4_STATS
+
+/*
+ * Statistical counters exporting.
+ *
+ * When REISER4_STATS mode is on, reiser4 collects a lot of statistics. See
+ * stat.[ch] for more details. All these stat-counters are exported through
+ * sysfs in /sys/fs/reiser4/<dev>/stats/ directory. This directory contains
+ * "global" stat-counters and also level-* sub-directories for per-level
+ * counters (that is counters collected for specific levels of reiser4
+ * internal tree).
+ *
+ */
+
+static struct kobj_type ktype_noattr = {
+	.sysfs_ops	= &fs_attr_ops,
+	.default_attrs	= NULL,
+	.release        = NULL
+};
+
+/*
+ * register stat-counters for the level @i with sysfs. This is called during
+ * mount.
+ */
+static int register_level_attrs(reiser4_super_info_data *sbinfo, int i)
+{
+	struct fs_kobject *level   /* file system kobject representing @i-th
+				    * level*/;
+	struct fs_kobject *parent; /* it's parent in sysfs tree */
+	int result;
+
+	/* first, setup @level */
+	parent = &sbinfo->stats_kobj;
+	sbinfo->level[i].level = i;
+	level = &sbinfo->level[i].kobj;
+	level->kobj.parent = kobject_get(&parent->kobj);
+	if (level->kobj.parent != NULL) {
+		snprintf(level->kobj.name, KOBJ_NAME_LEN, "level-%2.2i", i);
+		level->kobj.ktype = &ktype_noattr;
+		/* register @level with sysfs */
+		result = fs_kobject_register(sbinfo->tree.super, level);
+		if (result == 0)
+			/* and ultimately populate it with attributes, that
+			 * is, stat-counters */
+			result = reiser4_populate_kattr_level_dir(&level->kobj);
+	} else
+		result = RETERR(-EBUSY);
+	return result;
+}
+#endif
+
+static decl_subsys(fs, NULL, NULL);
+decl_subsys(reiser4, &ktype_reiser4, NULL);
+
+/*
+ * initialization function called once during kernel boot-up, or reiser4
+ * module loading.
+ */
+reiser4_internal int
+reiser4_sysfs_init_once(void)
+{
+	int result;
+
+	/* add /sys/fs */
+	result = subsystem_register(&fs_subsys);
+	if (result == 0) {
+		kset_set_kset_s(&reiser4_subsys, fs_subsys);
+		/* add /sys/fs/reiser4 */
+		result = subsystem_register(&reiser4_subsys);
+		if (result == 0)
+			result = init_prof_kobject();
+	}
+	return result;
+}
+
+/*
+ * shutdown function dual to reiser4_sysfs_init_once(). Called during module
+ * unload
+ */
+reiser4_internal void
+reiser4_sysfs_done_once(void)
+{
+	subsystem_unregister(&reiser4_subsys);
+	subsystem_unregister(&fs_subsys);
+	done_prof_kobject();
+}
+
+/*
+ * initialization function called during mount of @super
+ */
+reiser4_internal int
+reiser4_sysfs_init(struct super_block *super)
+{
+	reiser4_super_info_data *sbinfo;
+	struct fs_kobject *kobj;
+	int result;
+	ON_STATS(struct fs_kobject *stats_kobj);
+
+	sbinfo = get_super_private(super);
+
+	kobj = &sbinfo->kobj;
+
+	/*
+	 * setup and register /sys/fs/reiser4/<dev> object
+	 */
+	snprintf(kobj->kobj.name, KOBJ_NAME_LEN, "%s", super->s_id);
+	kobj_set_kset_s(&sbinfo->kobj, reiser4_subsys);
+	result = fs_kobject_register(super, kobj);
+	if (result != 0)
+		return result;
+#if REISER4_STATS
+	/* add attributes representing statistical counters */
+	stats_kobj = &sbinfo->stats_kobj;
+	stats_kobj->kobj.parent = kobject_get(&kobj->kobj);
+	snprintf(stats_kobj->kobj.name, KOBJ_NAME_LEN, "stats");
+	stats_kobj->kobj.ktype = &ktype_noattr;
+	result = fs_kobject_register(super, stats_kobj);
+	if (result != 0)
+		return result;
+	result = reiser4_populate_kattr_dir(&stats_kobj->kobj);
+	if (result == 0) {
+		int i;
+
+		for (i = 0; i < sizeof_array(sbinfo->level); ++i) {
+			result = register_level_attrs(sbinfo, i);
+			if (result != 0)
+				break;
+		}
+	}
+#else
+	result = reiser4_populate_kattr_dir(&kobj->kobj);
+#endif
+
+	return result;
+}
+
+reiser4_internal void
+reiser4_sysfs_done(struct super_block *super)
+{
+	reiser4_super_info_data *sbinfo;
+	ON_STATS(int i);
+
+	sbinfo = get_super_private(super);
+#if REISER4_STATS
+	for (i = 0; i < sizeof_array(sbinfo->level); ++i)
+		fs_kobject_unregister(&sbinfo->level[i].kobj);
+	fs_kobject_unregister(&sbinfo->stats_kobj);
+#endif
+	fs_kobject_unregister(&sbinfo->kobj);
+}
+
+/* REISER4_USE_SYSFS */
+#else
+
+/*
+ * Below are stubs for !REISER4_USE_SYSFS case. Do nothing.
+ */
+
+reiser4_internal int
+reiser4_sysfs_init(struct super_block *super)
+{
+	return 0;
+}
+
+reiser4_internal void
+reiser4_sysfs_done(struct super_block *super)
+{}
+
+reiser4_internal int
+reiser4_sysfs_init_once(void)
+{
+	return 0;
+}
+
+reiser4_internal void
+reiser4_sysfs_done_once(void)
+{}
+
+#endif
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   End:
+*/
diff -puN /dev/null kattr.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/kattr.h	2005-02-01 12:10:24.000000000 +0300
@@ -0,0 +1,70 @@
+/* Copyright 2001, 2002, 2003 by Hans Reiser, licensing governed by
+ * reiser4/README */
+
+/* Interface to sysfs' attributes. See kattr.c for comments */
+
+#if !defined( __REISER4_KATTR_H__ )
+#define __REISER4_KATTR_H__
+
+#include <linux/types.h>
+#include <linux/list.h>
+#include <linux/sysfs.h>
+#include <linux/fs.h>
+
+/* fixme: access to sysfs files may cause deadlock. Do not turn for now.
+   this requires reiser4-kobject-umount-race.patch */
+#define REISER4_USE_SYSFS (1)
+
+#if REISER4_USE_SYSFS
+
+/* helper macros used by kattr code to output information into buffer without
+ * caring about overflow checking. */
+#define KATTR_LEFT(p, buf) (PAGE_SIZE - (p - buf) - 1)
+#define KATTR_PRINT(p, buf, ...)				\
+({ 								\
+	p += snprintf(p, KATTR_LEFT(p, buf) , ## __VA_ARGS__); 	\
+})
+
+struct super_block;
+struct reiser4_kattr;
+typedef struct reiser4_kattr reiser4_kattr;
+
+/*
+ * reiser4_kattr represents a sysfs-exported attribute of reiser4 file system.
+ */
+struct reiser4_kattr {
+	struct fs_kattr attr; /* file-system attribute used to interact with
+			       * sysfs */
+	void  *cookie;        /* parameter used to avoid code duplication. See
+			       * kattr.c for explanation. */
+};
+
+extern struct kobj_type ktype_reiser4;
+
+#else
+
+struct reiser4_kattr {
+};
+
+typedef struct reiser4_kattr reiser4_kattr;
+#endif /* REISER4_USE_SYSFS */
+
+extern int reiser4_sysfs_init_once(void);
+extern void reiser4_sysfs_done_once(void);
+
+extern int  reiser4_sysfs_init(struct super_block *super);
+extern void reiser4_sysfs_done(struct super_block *super);
+
+/* __REISER4_KATTR_H__ */
+#endif
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   scroll-step: 1
+   End:
+*/
diff -puN kcond.c~profile-stat-trace-repacker kcond.c
--- reiser4/kcond.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/kcond.c	2005-02-01 11:51:11.000000000 +0300
@@ -55,12 +55,19 @@ kcond_init(kcond_t * cvar /* cvar to ini
 {
 	assert("nikita-1868", cvar != NULL);
 
-	memset(cvar, 0, sizeof *cvar);
+	xmemset(cvar, 0, sizeof *cvar);
 	spin_lock_init(&cvar->lock);
 	cvar->queue = NULL;
 	return cvar;
 }
 
+/* destroy condition variable. */
+reiser4_internal int
+kcond_destroy(kcond_t * cvar /* cvar to destroy */ )
+{
+	return kcond_are_waiters(cvar) ? -EBUSY : 0;
+}
+
 /* Wait until condition variable is signalled. Call this with @lock locked.
    If @signl is true, then sleep on condition variable will be interruptible
    by signals. -EINTR is returned if sleep were interrupted by signal and 0
@@ -238,6 +245,14 @@ kcond_broadcast(kcond_t * cvar /* cvar t
 	return 1;
 }
 
+/* true if there are threads sleeping on @cvar */
+reiser4_internal int
+kcond_are_waiters(kcond_t * cvar /* cvar to query */ )
+{
+	assert("nikita-1877", cvar != NULL);
+	return cvar->queue != NULL;
+}
+
 /* timer expiration function used by kcond_timedwait */
 static void
 kcond_timeout(unsigned long datum)
diff -puN kcond.h~profile-stat-trace-repacker kcond.h
--- reiser4/kcond.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/kcond.h	2005-02-01 11:51:11.000000000 +0300
@@ -28,12 +28,15 @@ struct kcond_queue_link_s {
 };
 
 extern kcond_t *kcond_init(kcond_t * cvar);
+extern int kcond_destroy(kcond_t * cvar);
 
 extern int kcond_wait(kcond_t * cvar, spinlock_t * lock, int signl);
 extern int kcond_timedwait(kcond_t * cvar, spinlock_t * lock, signed long timeout, int signl);
 extern int kcond_signal(kcond_t * cvar);
 extern int kcond_broadcast(kcond_t * cvar);
 
+extern int kcond_are_waiters(kcond_t * cvar);
+
 extern void kcond_print(kcond_t * cvar);
 
 #define KCOND_STATIC_INIT			\
diff -puN Kconfig~profile-stat-trace-repacker Kconfig
--- reiser4/Kconfig~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/Kconfig	2005-02-01 11:51:11.000000000 +0300
@@ -1,7 +1,7 @@
 config REISER4_FS
 	tristate "Reiser4 (EXPERIMENTAL very fast general purpose filesystem)"
 	depends on EXPERIMENTAL && !4KSTACKS
-	help
+	---help---
 	  Reiser4 is more than twice as fast for both reads and writes as
 	  ReiserFS V3, and is the fastest Linux filesystem, by a lot,
 	  for typical IO intensive workloads.  [It is slow at fsync
@@ -72,10 +72,10 @@ config REISER4_FS
 
 	  To learn more about reiser4, go to http://www.namesys.com
 
-config REISER4_DEBUG
-	bool "Enable reiser4 debug mode"
+config REISER4_CHECK
+	bool "Enable reiser4 debug options"
 	depends on REISER4_FS
-	help
+	---help---
 	  Don't use this unless you are a developer debugging reiser4.  If
 	  using a kernel made by a distro that thinks they are our competitor
 	  (sigh) rather than made by Linus, always check each release to make
@@ -88,3 +88,61 @@ config REISER4_DEBUG
 	  again.  Include a description of what you did to test it.  All
 	  reiser4 code must be tested, reviewed, and signed off on by two
 	  persons before it will be accepted into a stable kernel by Hans.
+
+config REISER4_DEBUG
+	bool "Assertions"
+	depends on REISER4_CHECK && REISER4_FS!=m
+	help
+	  Turns on assertions checks. Eats a lot of CPU.
+
+config REISER4_DEBUG_MODIFY
+	bool "Dirtying"
+	depends on REISER4_CHECK
+	help
+	  Check that node is marked dirty each time it's modified. This is done
+	  through maintaining checksum of node content. CPU hog.
+
+config REISER4_DEBUG_MEMCPY
+	bool "Memory copying"
+	depends on REISER4_CHECK
+	help
+	  Use special non-inlined versions on memcpy, memset, and memmove in
+	  reiser4 to estimate amount of CPU time spent in data copying.
+
+config REISER4_DEBUG_NODE
+	bool "Node consistency"
+	depends on REISER4_CHECK
+	help
+	  Run consistency checks on nodes in balanced tree. CPU hog.
+
+config REISER4_ZERO_NEW_NODE
+	bool "Node zeroing"
+	depends on REISER4_CHECK
+	help
+	  Zero new node before use.
+
+config REISER4_TRACE
+	bool "Tracing"
+	depends on REISER4_CHECK
+	help
+	  Turn on tracing facility. This enables trace_flags mount option.
+
+config REISER4_EVENT_LOG
+	bool "Log events"
+	depends on REISER4_CHECK
+	help
+	  Log events into user supplied file. This enables trace_file mount option.
+
+config REISER4_STATS
+	bool "Statistics"
+	depends on REISER4_CHECK
+	help
+	  Turn on statistics collection. This increases size of in-memory super
+	  block considerably.
+
+config REISER4_DEBUG_OUTPUT
+	bool "Printing"
+	depends on REISER4_CHECK
+	help
+	  Enable compilation of functions that print internal kernel data
+	  structures in human readable form. Useful for debugging.
diff -puN key.c~profile-stat-trace-repacker key.c
--- reiser4/key.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/key.c	2005-02-01 11:51:11.000000000 +0300
@@ -36,7 +36,7 @@ reiser4_internal void
 reiser4_key_init(reiser4_key * key /* key to init */ )
 {
 	assert("nikita-1169", key != NULL);
-	memset(key, 0, sizeof *key);
+	xmemset(key, 0, sizeof *key);
 }
 
 /* minimal possible key in the tree. Return pointer to the static storage. */
@@ -53,7 +53,7 @@ max_key(void)
 	return &MAXIMAL_KEY;
 }
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 /* debugging aid: print symbolic name of key type */
 static const char *
 type_name(unsigned int key_type /* key type */ )
diff -puN key.h~profile-stat-trace-repacker key.h
--- reiser4/key.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/key.h	2005-02-01 11:51:11.000000000 +0300
@@ -369,7 +369,7 @@ prefetchkey(reiser4_key *key)
 #define KEY_BUF_LEN (80)
 
 extern int sprintf_key(char *buffer, const reiser4_key * key);
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 extern void print_key(const char *prefix, const reiser4_key * key);
 #else
 #define print_key(p,k) noop
diff -puN ktxnmgrd.c~profile-stat-trace-repacker ktxnmgrd.c
--- reiser4/ktxnmgrd.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/ktxnmgrd.c	2005-02-01 11:51:11.000000000 +0300
@@ -51,7 +51,7 @@ init_ktxnmgrd_context(txn_mgr * mgr)
 
 	assert("nikita-2442", ctx != NULL);
 
-	memset(ctx, 0, sizeof *ctx);
+	xmemset(ctx, 0, sizeof *ctx);
 	init_completion(&ctx->finish);
 	kcond_init(&ctx->startup);
 	kcond_init(&ctx->wait);
diff -puN /dev/null lnode.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/lnode.c	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,431 @@
+/* Copyright 2001, 2002, 2003 by Hans Reiser, licensing governed by reiser4/README */
+
+/* Lnode manipulation functions. */
+/* Lnode is light-weight node used as common data-structure by both VFS access
+   paths and reiser4() system call processing.
+
+   One of the main targets of reiser4() system call is to allow manipulation
+   on potentially huge number of objects. This makes use of inode in reiser4()
+   impossible. On the other hand there is a need to synchronize reiser4() and
+   VFS access.
+
+   To do this small object (lnode) is allocated (on the stack if possible) for
+   each object involved into reiser4() system call. Such lnode only contains
+   lock, information necessary to link it into global hash table, and
+   condition variable to wake up waiters (see below).
+
+   In other words, lnode is handle that reiser4 keeps for a file system object
+   while object is being actively used. For example, when read is performed by
+   reiser4_read(), lnode exists for inode being read. When reiser4_read()
+   exits lnode is deleted, but inode is still there in the inode cache.
+
+   As lnode only exists while object is being actively manipulated by some
+   threads, it follows that lnodes can always live on the stack of such
+   threads.
+
+   Case-by-case:
+
+     A. access through VFS (reiser4_{read|write|truncate|*}()):
+
+       1. operation starts with inode supplied by VFS.
+
+       2. lget( &local_lnode, LNODE_INODE, inode -> i_ino ) is called. This,
+       if necessary, will wait until sys_reiser4() access to this file is
+       finished, and
+
+       3. add lnode to the per super block hash table.
+
+     B. creation of new inode in reiser4_iget():
+
+       1. create new empty inode (iget(), or icreate())
+
+       2. step A.3. A.2 is not necessary, because we are creating new object
+       and parent is in VFS access (hence sys_reiser4() cannot add/delete
+       objects in parent).
+
+       3. read stat data from disk and initialise inode
+
+     C. sys_reiser4() access:
+
+       1. check for existing inode in a hash-table.
+
+          Rationale: if inode is already here it is advantageous to use it,
+          because it already has information from stat data.
+
+          If inode is found proceed as in case A.
+
+       2. otherwise, lget( &local_lnode, LNODE_LW, oid ) is called.
+
+
+   NOT FINISHED.
+
+
+
+
+
+
+
+   INTERNAL NOTES:
+
+   1. fs/inode.c:inode_lock is not static: we can use it. Good.
+
+   2. but fs/inode.c:find_inode() is. Either write own version, or remove
+   static and EXPORT_SYMBOL-ize it.
+
+
+
+*/
+
+#include "debug.h"
+#include "kcond.h"
+#include "key.h"
+#include "kassign.h"
+#include "plugin/plugin_header.h"
+#include "plugin/plugin_set.h"
+#include "lnode.h"
+#include "super.h"
+#include "reiser4.h"
+
+#include <linux/fs.h>		/* for struct super_block  */
+#include <linux/spinlock.h>
+
+static reiser4_key *lnode_dentry_key(const lnode * node, reiser4_key * result);
+static reiser4_key *lnode_inode_key(const lnode * node, reiser4_key * result);
+static reiser4_key *lnode_lw_key(const lnode * node, reiser4_key * result);
+static int lnode_inode_eq(const lnode * node1, const lnode * node2);
+static int lnode_lw_eq(const lnode * node1, const lnode * node2);
+
+#if REISER4_DEBUG
+static int lnode_valid_type(lnode_type type);
+#endif
+
+/* Common operations for various types of lnodes.
+
+   NOTE-NIKITA consider making this plugin. */
+static struct {
+	/* get a key of the corresponding file system object */
+	reiser4_key *(*key) (const lnode * node, reiser4_key * result);
+	/* get a plugin suitable for the corresponding file system object */
+	int (*get_plugins) (const lnode * node, plugin_set * area);
+	/* set a plugin suitable for the corresponding file system object */
+	int (*set_plugins) (lnode * node, const plugin_set * area);
+	/* true if @node1 and @node2 refer to the same object */
+	int (*eq) (const lnode * node1, const lnode * node2);
+} lnode_ops[LNODE_NR_TYPES] = {
+	[LNODE_DENTRY] = {
+		.key = lnode_dentry_key,
+		.get_plugins = NULL,
+		.set_plugins = NULL,
+		.eq = NULL
+	},
+	[LNODE_INODE] = {
+		.key = lnode_inode_key,
+		.get_plugins = NULL,
+		.set_plugins = NULL,
+		.eq = lnode_inode_eq
+	},
+	/*
+	[LNODE_PSEUDO] = {
+		.key = NULL,
+		.get_plugins = NULL,
+		.set_plugins = NULL,
+		.eq = NULL
+	},
+	*/
+	[LNODE_LW] = {
+		.key = lnode_lw_key,
+		.get_plugins = NULL,
+		.set_plugins = NULL,
+		.eq = lnode_lw_eq
+	}
+};
+
+/* hash table support */
+
+/* compare two block numbers for equality. Used by hash-table macros */
+/* Audited by: green(2002.06.15) */
+static inline int
+oid_eq(const oid_t * o1 /* first oid to compare */ ,
+       const oid_t * o2 /* second oid to compare */ )
+{
+	return *o1 == *o2;
+}
+
+/* Hash znode by block number. Used by hash-table macros */
+/* Audited by: green(2002.06.15) */
+static inline __u32
+oid_hash(ln_hash_table *table, const oid_t * o /* oid to hash */ )
+{
+	return *o & (LNODE_HTABLE_BUCKETS - 1);
+}
+
+/* The hash table definition */
+#define KMALLOC(size) kmalloc((size), GFP_KERNEL)
+#define KFREE(ptr, size) kfree(ptr)
+TYPE_SAFE_HASH_DEFINE(ln, lnode, oid_t, h.oid, h.link, oid_hash, oid_eq);
+#undef KFREE
+#undef KMALLOC
+
+ln_hash_table lnode_htable;
+spinlock_t    lnode_guard = SPIN_LOCK_UNLOCKED;
+
+
+/* true if @required lnode type is @compatible with @set lnode type. If lnode
+   types are incompatible, then thread trying to obtain @required type of
+   access will wait until all references (lnodes) of the @set type to the file
+   system object are released.
+
+   For example, thread trying to manipulate object through VFS (@required type
+   is LNODE_INODE) will wait if object is currently manipulated through
+   reiser4() call (that is, there are lnodes with type LNODE_LW).
+
+*/
+/* Audited by: green(2002.06.15) */
+reiser4_internal int
+lnode_compatible_type(lnode_type required /* required lnode type */ ,
+		      lnode_type set /* lnode type already set */ )
+{
+	return !((set == LNODE_LW) && (required != LNODE_INODE));
+}
+
+/* initialise lnode module for @super. */
+/* Audited by: green(2002.06.15) */
+reiser4_internal int
+lnodes_init(void)
+{
+	ln_hash_init(&lnode_htable, LNODE_HTABLE_BUCKETS, NULL);
+	return 0;
+}
+
+/* free lnode resources associated with @super. */
+/* Audited by: green(2002.06.15) */
+reiser4_internal int
+lnodes_done(void)
+{
+	ln_hash_done(&lnode_htable);
+	return 0;
+}
+
+/* Acquire handle to file system object.
+
+   First check whether there is already lnode for this oid in a hash table.
+   If no---initialise @node and add it into the hash table. If hash table
+   already contains lnode with such oid, and incompatible type, wait until
+   said lnode is deleted. If compatible lnode is found in the hash table,
+   increase its reference counter and return.
+
+
+
+
+*/
+/* Audited by: green(2002.06.15) */
+reiser4_internal lnode *
+lget(                 /*lnode * node ,  lnode to add to the hash table */
+     lnode_type type /* lnode type */ , oid_t oid /* objectid */ )
+{
+	lnode *result;
+
+	//	assert("nikita-1862", node != NULL);
+	assert("nikita-1866", lnode_valid_type(type));
+
+	spin_lock(&lnode_guard);
+	/* check hash table */
+	while ((result = ln_hash_find(&lnode_htable, &oid)) != 0) {
+		if (!lnode_compatible_type(type, result->h.type)) {
+			int ret;
+
+			/* if lnode is of incompatible type, wait until all
+			   incompatible users go away. For example, if we are
+			   requesting lnode for VFS access (and our @type is
+			   LNODE_INODE), wait until all reiser4() system call
+			   manipulations with this object finish.
+			*/
+			ret = kcond_wait(&result->h.cvar, &lnode_guard, 1);
+			if (ret != 0) {
+				result = ERR_PTR(ret);
+				break;
+			}
+		} else {
+			/* compatible lnode found in the hash table. Just
+			   return it. */
+			++result->h.ref;
+			break;
+		}
+	}
+	if (result == NULL) {
+		/* lnode wasn't found in the hash table, initialise @node and
+		   add it into hash table. */
+		result = ( lnode * ) kmalloc( sizeof( lnode ), GFP_KERNEL);
+		xmemset(result, 0, sizeof( lnode ));
+		result->h.type = type;
+		result->h.oid = oid;
+		kcond_init(&result->h.cvar);
+		result->h.ref = 1;
+		ln_hash_insert(&lnode_htable, result);
+	}
+	spin_unlock(&lnode_guard);
+	return result;
+}
+
+/* release reference to file system object */
+/* Audited by: green(2002.06.15) */
+reiser4_internal void
+lput(lnode * node /* lnode to release */ )
+{
+	assert("nikita-1864", node != NULL);
+	assert("nikita-1961", lnode_valid_type(node->h.type));	/* man in
+								 * a
+								 * space */
+	spin_lock(&lnode_guard);
+	assert("nikita-1878", ln_hash_find(&lnode_htable, &node->h.oid) == node);
+	if (--node->h.ref == 0) {
+		ln_hash_remove(&lnode_htable, node);
+		kcond_broadcast(&node->h.cvar);
+		kfree(node);
+	}
+	spin_unlock(&lnode_guard);
+}
+
+reiser4_internal lnode *
+lref(lnode * node)
+{
+	assert("nikita-3241", node != NULL);
+	assert("nikita-3242", lnode_valid_type(node->h.type));
+
+	spin_lock(&lnode_guard);
+	++ node->h.ref;
+	spin_unlock(&lnode_guard);
+	return node;
+}
+
+/* true if @node1 and @node2 refer to the same object */
+/* Audited by: green(2002.06.15) */
+reiser4_internal int
+lnode_eq(const lnode * node1 /* first node to compare */ ,
+	 const lnode * node2 /* second node to compare */ )
+{
+	assert("nikita-1921", node1 != NULL);
+	assert("nikita-1922", node2 != NULL);	/* Finnegans Wake started */
+
+	if (node1->h.oid != node2->h.oid)
+		return 0;
+	else if (node1->h.type != node2->h.type)
+		return 0;
+	else
+		return lnode_ops[node1->h.type].eq(node1, node2);
+}
+
+/* return key of object behind @node */
+/* Audited by: green(2002.06.15) */
+reiser4_internal reiser4_key *
+lnode_key(const lnode * node /* lnode to query */ ,
+	  reiser4_key * result /* result */ )
+{
+	assert("nikita-1849", node != NULL);
+	assert("nikita-1855", lnode_valid_type(node->h.type));
+	return lnode_ops[node->h.type].key(node, result);
+}
+
+/* return plugins of object behind @node */
+/* Audited by: green(2002.06.15) */
+reiser4_internal int
+get_lnode_plugins(const lnode * node /* lnode to query */ ,
+		  plugin_set * area /* result */ )
+{
+	assert("nikita-1853", node != NULL);
+	assert("nikita-1858", lnode_valid_type(node->h.type));
+	return lnode_ops[node->h.type].get_plugins(node, area);
+}
+
+/* set plugins of object behind @node */
+/* Audited by: green(2002.06.15) */
+reiser4_internal int
+set_lnode_plugins(lnode * node /* lnode to modify */ ,
+		  const plugin_set * area /* plugins to install */ )
+{
+	assert("nikita-1859", node != NULL);
+	assert("nikita-1860", lnode_valid_type(node->h.type));
+	return lnode_ops[node->h.type].set_plugins(node, area);
+}
+
+#if REISER4_DEBUG
+/* true if @type is valid lnode type */
+/* Audited by: green(2002.06.15) */
+static int
+lnode_valid_type(lnode_type type /* would-be lnode type */ )
+{
+	return type < LNODE_NR_TYPES;
+}
+#endif
+
+/* return key of object behind dentry-based @node */
+reiser4_internal reiser4_key *
+lnode_dentry_key(const lnode * node /* lnode to query */ ,
+		reiser4_key * result /* result */ )
+{
+	return build_sd_key(node->l_dentry.dentry->d_inode, result);
+}
+
+
+
+/* return key of object behind inode-based @node */
+/* Audited by: green(2002.06.15) */
+static reiser4_key *
+lnode_inode_key(const lnode * node /* lnode to query */ ,
+		reiser4_key * result /* result */ )
+{
+	return build_sd_key(node->l_inode.inode, result);
+}
+
+/* return key of object behind lighweight @node */
+/* Audited by: green(2002.06.15) */
+static reiser4_key *
+lnode_lw_key(const lnode * node /* lnode to query */ ,
+	     reiser4_key * result /* result */ )
+{
+	*result = node->l_lw.key;
+	return result;
+}
+
+/* compare two inodes */
+/* Audited by: green(2002.06.15) */
+static int
+lnode_inode_eq(const lnode * node1 /* first node to compare */ ,
+	       const lnode * node2 /* second node to compare */ )
+{
+	assert("nikita-1923", node1 != NULL);
+	assert("nikita-1924", node2 != NULL);
+
+	assert("nikita-1927", node1->l_inode.inode != NULL);
+	assert("nikita-1928", node2->l_inode.inode != NULL);
+
+	return (node1->l_inode.inode == node2->l_inode.inode);
+
+}
+
+/* compare two lw objects */
+/* Audited by: green(2002.06.15) */
+static int
+lnode_lw_eq(const lnode * node1 UNUSED_ARG	/* first node to
+						 * compare */ ,
+	    const lnode * node2 UNUSED_ARG	/* second node to
+						 * compare */ )
+{
+	assert("nikita-1925", node1 != NULL);
+	assert("nikita-1926", node2 != NULL);
+
+	/* we only get there if oids are equal */
+	assert("nikita-1929", node1->h.oid == node2->h.oid);
+	assert("nikita-1930", keyeq(&node1->l_lw.key, &node2->l_lw.key));
+	return 1;
+}
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   End:
+*/
diff -puN /dev/null lnode.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/lnode.h	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,122 @@
+/* Copyright 2002, 2003 by Hans Reiser, licensing governed by reiser4/README */
+
+/* Declaration of lnode (light-weight node). */
+
+#ifndef __LNODE_H__
+#define __LNODE_H__
+
+#include "forward.h"
+#include "dformat.h"
+#include "kcond.h"
+#include "type_safe_hash.h"
+#include "plugin/plugin_header.h"
+#include "plugin/plugin_set.h"
+#include "key.h"
+
+#include <linux/types.h>	/* for __u??  */
+#include <linux/fs.h>		/* for struct super_block, etc.  */
+#include <linux/dcache.h>	/* for struct super_block, etc.  */
+
+typedef enum {
+	LNODE_DENTRY,
+	LNODE_INODE,
+	LNODE_REISER4_INODE,
+	LNODE_LW,
+	LNODE_PSEUDO,
+	LNODE_NR_TYPES
+} lnode_type;
+
+typedef union lnode lnode;
+
+/* declare hash table of lnode_lw's */
+TYPE_SAFE_HASH_DECLARE(ln, lnode);
+
+/* common part of various lnode types */
+typedef struct lnode_header {
+	/* lnode type. Taken from lnode_type enum. Never changed after
+	   initialisation, so needs no locking.  */
+	__u8 type;
+	/* unused. Alignment requires this anyway. */
+	__u8 flags;
+	/* condition variable to wake up waiters */
+	kcond_t cvar;
+	/* hash table linkage. Updated under hash-table spinlock. */
+	ln_hash_link link;
+	/* objectid of underlying file system object. Never changed after
+	   initialisation, so needs no locking.  */
+	oid_t oid;
+	/* reference counter. Updated under hash-table spinlock. */
+	int ref;
+} lnode_header;
+
+typedef struct lnode_dentry {
+	lnode_header h;
+	atomic_t * lock;
+	struct dentry *dentry;
+	struct vfsmount *mnt;
+} lnode_dentry;
+
+typedef struct lnode_inode {
+	lnode_header h;
+	struct inode *inode;
+} lnode_inode;
+
+typedef struct lnode_reiser4_inode {
+	lnode_header h;
+	struct reiser4_inode *inode;
+} lnode_reiser4_inode;
+
+typedef struct lnode_lw {
+	lnode_header h;
+	struct super_block * lw_sb;
+	reiser4_key key;
+} lnode_lw;
+
+struct assign_result {
+	loff_t len ;
+	int return_code ;
+};
+
+typedef struct lnode_pseudo {
+	lnode_header h;
+	struct assign_result rez;
+
+	//	lnode *host;
+	/* something to identify pseudo file type, like name or plugin */
+} lnode_pseudo;
+
+union lnode {
+	lnode_header h;
+	lnode_dentry l_dentry;
+	lnode_inode l_inode;
+	lnode_reiser4_inode l_reiser4_inode;
+	lnode_lw l_lw;
+	lnode_pseudo l_pseudo;
+};
+
+extern int lnodes_init(void);
+extern int lnodes_done(void);
+
+extern lnode *lget( lnode_type type, oid_t oid);
+extern void lput(lnode * node);
+extern int lnode_eq(const lnode * node1, const lnode * node2);
+extern lnode *lref(lnode * node);
+
+extern struct inode *inode_by_lnode(const lnode * node);
+extern reiser4_key *lnode_key(const lnode * node, reiser4_key * result);
+
+extern int get_lnode_plugins(const lnode * node, plugin_set * area);
+extern int set_lnode_plugins(lnode * node, const plugin_set * area);
+
+/* __LNODE_H__ */
+#endif
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   End:
+*/
diff -puN lock.c~profile-stat-trace-repacker lock.c
--- reiser4/lock.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/lock.c	2005-02-01 12:26:46.000000000 +0300
@@ -222,6 +222,9 @@ static int request_is_deadlock_safe(znod
 				    znode_lock_request);
 #endif
 
+#define ADDSTAT(node, counter) 						\
+	reiser4_stat_inc_at_level(znode_get_level(node), znode.counter)
+
 /* Returns a lock owner associated with current thread */
 reiser4_internal lock_stack *
 get_current_lock_stack(void)
@@ -321,6 +324,9 @@ lock_object(lock_stack * owner)
 	if (owner->curpri) {
 		node->lock.nr_hipri_owners++;
 	}
+	ON_TRACE(TRACE_LOCKS,
+		 "%spri lock: %p node: %p: hipri_owners: %u: nr_readers: %d\n",
+		 owner->curpri ? "hi" : "lo", owner, node, node->lock.nr_hipri_owners, node->lock.nr_readers);
 }
 
 /* Check for recursive write locking */
@@ -430,6 +436,7 @@ check_lock_object(lock_stack * owner)
 
 	/* See if the node is disconnected. */
 	if (unlikely(ZF_ISSET(node, JNODE_IS_DYING))) {
+		ON_TRACE(TRACE_LOCKS, "attempt to lock dying znode: %p", node);
 		return RETERR(-EINVAL);
 	}
 
@@ -452,8 +459,15 @@ static int
 can_lock_object(lock_stack * owner)
 {
 	int result;
+	znode *node = owner->request.node;
 
 	result = check_lock_object(owner);
+	if (REISER4_STATS && znode_get_level(node) > 0) {
+		if (result != 0)
+			ADDSTAT(node, lock_contented);
+		else
+			ADDSTAT(node, lock_uncontented);
+	}
 	return result;
 }
 
@@ -481,6 +495,10 @@ set_high_priority(lock_stack * owner)
 
 			node->lock.nr_hipri_owners++;
 
+			ON_TRACE(TRACE_LOCKS,
+				 "set_hipri lock: %p node: %p: hipri_owners after: %u nr_readers: %d\n",
+				 item, node, node->lock.nr_hipri_owners, node->lock.nr_readers);
+
 			/* we can safely set signaled to zero, because
 			   previous statement (nr_hipri_owners ++) guarantees
 			   that signaled will be never set again. */
@@ -511,6 +529,9 @@ set_low_priority(lock_stack * owner)
 			WLOCK_ZLOCK(&node->lock);
 			/* this thread just was hipri owner of @node, so
 			   nr_hipri_owners has to be greater than zero. */
+			ON_TRACE(TRACE_LOCKS,
+				 "set_lopri lock: %p node: %p: hipri_owners before: %u nr_readers: %d\n",
+				 handle, node, node->lock.nr_hipri_owners, node->lock.nr_readers);
 			assert("nikita-1835", node->lock.nr_hipri_owners > 0);
 			node->lock.nr_hipri_owners--;
 			/* If we have deadlock condition, adjust a nr_signaled
@@ -570,12 +591,15 @@ wake_up_requestor(znode *node)
 	assert("nikita-3180", node != NULL);
 	assert("nikita-3181", rw_zlock_is_locked(&node->lock));
 
+	ADDSTAT(node, wakeup);
+
 	convoyused = 0;
 	convoylimit = min(num_online_cpus() - 1, MAX_CONVOY_SIZE);
 	creditors = &node->lock.requestors;
 	if (!requestors_list_empty(creditors)) {
 		convoy[0] = requestors_list_front(creditors);
 		convoyused = 1;
+		ADDSTAT(node, wakeup_found);
 		/*
 		 * it has been verified experimentally, that there are no
 		 * convoys on the leaf level.
@@ -585,10 +609,13 @@ wake_up_requestor(znode *node)
 		    convoylimit > 1) {
 			lock_stack *item;
 
+			ADDSTAT(node, wakeup_found_read);
 			for (item = requestors_list_next(convoy[0]);
 			          ! requestors_list_end(creditors, item);
 			     item = requestors_list_next(item)) {
+				ADDSTAT(node, wakeup_scan);
 				if (item->request.mode == ZNODE_READ_LOCK) {
+					ADDSTAT(node, wakeup_convoy);
 					convoy[convoyused] = item;
 					++ convoyused;
 					/*
@@ -657,6 +684,7 @@ longterm_unlock_znode(lock_handle * hand
 
 	LOCK_CNT_DEC(long_term_locked_znode);
 
+	ADDSTAT(node, unlock);
 
 	/*
 	 * to minimize amount of operations performed under lock, pre-compute
@@ -681,6 +709,14 @@ longterm_unlock_znode(lock_handle * hand
 	node->lock.nr_hipri_owners += hipri;
 	assert("nikita-1836", node->lock.nr_hipri_owners >= 0);
 
+	ON_TRACE(TRACE_LOCKS,
+		 "%spri unlock: %p node: %p: hipri_owners: %u nr_readers %d\n",
+		 oldowner->curpri ? "hi" : "lo",
+		 handle,
+		 node,
+		 node->lock.nr_hipri_owners,
+		 node->lock.nr_readers);
+
 	/* Handle znode deallocation on last write-lock release. */
 	if (znode_is_wlocked_once(node)) {
 		if (youdie) {
@@ -689,6 +725,7 @@ longterm_unlock_znode(lock_handle * hand
 			zput(node);
 			return;
 		}
+		znode_post_write(node);
 	}
 
 	if (handle->signaled)
@@ -740,6 +777,10 @@ lock_tail(lock_stack *owner, int wake_up
 		owner->request.mode = 0;
 		if (mode == ZNODE_READ_LOCK)
 			wake_up_next = 1;
+		if (REISER4_DEBUG_MODIFY) {
+			if (znode_is_wlocked_once(node))
+				znode_post_write(node);
+		}
 	}
 
 	if (wake_up_next)
@@ -757,6 +798,10 @@ lock_tail(lock_stack *owner, int wake_up
 		zref(node);
 
 		LOCK_CNT_INC(long_term_locked_znode);
+		if (REISER4_DEBUG_NODE && mode == ZNODE_WRITE_LOCK) {
+			node_check(node, 0);
+			ON_DEBUG_MODIFY(znode_pre_write(node));
+		}
 	}
 
 	ON_DEBUG(check_lock_data());
@@ -866,6 +911,7 @@ longterm_lock_znode(
 	}
 
 	level = znode_get_level(node);
+	ADDSTAT(node, lock);
 
 	/* Fill request structure with our values. */
 	owner->request.mode = mode;
@@ -883,6 +929,19 @@ longterm_lock_znode(
 
 	has_atom = (txnh->atom != NULL);
 
+	/* update statistics */
+	if (REISER4_STATS) {
+		if (mode == ZNODE_READ_LOCK)
+			ADDSTAT(node, lock_read);
+		else
+			ADDSTAT(node, lock_write);
+
+		if (hipri)
+			ADDSTAT(node, lock_hipri);
+		else
+			ADDSTAT(node, lock_lopri);
+	}
+
 	/* Synchronize on node's zlock guard lock. */
 	WLOCK_ZLOCK(lock);
 
@@ -891,6 +950,8 @@ longterm_lock_znode(
 		return lock_tail(owner, 0, 0, mode);
 
 	for (;;) {
+		ADDSTAT(node, lock_iteration);
+
 		/* Check the lock's availability: if it is unavaiable we get
 		   E_REPEAT, 0 indicates "can_lock", otherwise the node is
 		   invalid.  */
@@ -900,6 +961,7 @@ longterm_lock_znode(
 			/* @node is dying. Leave it alone. */
 			/* wakeup next requestor to support lock invalidating */
 			wake_up_next = 1;
+			ADDSTAT(node, lock_dying);
 			break;
 		}
 
@@ -907,6 +969,7 @@ longterm_lock_znode(
 			/* either locking of @node by the current thread will
 			 * lead to the deadlock, or lock modes are
 			 * incompatible. */
+			ADDSTAT(node, lock_cannot_lock);
 			break;
 		}
 
@@ -968,7 +1031,7 @@ longterm_lock_znode(
 		 */
 
 		if (likely(has_atom && ZJNODE(node)->atom == txnh->atom)) {
-			;
+			ADDSTAT(node, lock_no_capture);
 		} else {
 			/*
 			 * unlock zlock spin lock here. It is possible for
@@ -1004,6 +1067,7 @@ longterm_lock_znode(
 		/* This time, a return of (ret == 0) means we can lock, so we
 		   should break out of the loop. */
 		if (likely(ret != -E_REPEAT || non_blocking)) {
+			ADDSTAT(node, lock_can_lock);
 			break;
 		}
 
@@ -1042,7 +1106,7 @@ longterm_lock_znode(
 		   a znode ...*/
 		WUNLOCK_ZLOCK(lock);
 		/* ... and sleep */
-		go_to_sleep(owner);
+		go_to_sleep(owner, level);
 
 		WLOCK_ZLOCK(lock);
 
@@ -1098,7 +1162,7 @@ invalidate_lock(lock_handle * handle	/* 
 		prepare_to_sleep(owner);
 
 		WUNLOCK_ZLOCK(&node->lock);
-		go_to_sleep(owner);
+		go_to_sleep(owner, znode_get_level(node));
 		WLOCK_ZLOCK(&node->lock);
 
 		requestors_list_remove(owner);
@@ -1129,7 +1193,7 @@ reiser4_init_lock(zlock * lock	/* pointe
 				   * uninitialized lock object
 				   * structure. */ )
 {
-	memset(lock, 0, sizeof (zlock));
+	xmemset(lock, 0, sizeof (zlock));
 	rw_zlock_init(lock);
 	requestors_list_init(&lock->requestors);
 	owners_list_init(&lock->owners);
@@ -1139,7 +1203,7 @@ reiser4_init_lock(zlock * lock	/* pointe
 reiser4_internal void
 init_lh(lock_handle * handle)
 {
-	memset(handle, 0, sizeof *handle);
+	xmemset(handle, 0, sizeof *handle);
 	locks_list_clean(handle);
 	owners_list_clean(handle);
 }
@@ -1276,12 +1340,32 @@ __reiser4_wake_up(lock_stack * owner)
 
 /* Puts a thread to sleep */
 reiser4_internal void
-go_to_sleep(lock_stack * owner)
+__go_to_sleep(lock_stack * owner
+#if REISER4_STATS
+	    , int node_level
+#endif
+)
 {
+#if REISER4_STATS
+	unsigned long sleep_start = jiffies;
+#endif
 	/* Well, we might sleep here, so holding of any spinlocks is no-no */
 	assert("nikita-3027", schedulable());
 	/* return down_interruptible(&owner->sema); */
 	down(&owner->sema);
+#if REISER4_STATS
+	switch (node_level) {
+	    case ADD_TO_SLEPT_IN_WAIT_EVENT:
+		    reiser4_stat_add(txnmgr.slept_in_wait_event, jiffies - sleep_start);
+		    break;
+	    case ADD_TO_SLEPT_IN_WAIT_ATOM:
+		    reiser4_stat_add(txnmgr.slept_in_wait_atom, jiffies - sleep_start);
+		    break;
+	    default:
+		    reiser4_stat_add_at_level(node_level, time_slept,
+					      jiffies - sleep_start);
+	}
+#endif
 }
 
 reiser4_internal int
@@ -1295,7 +1379,7 @@ lock_stack_isclean(lock_stack * owner)
 	return 0;
 }
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 /* Debugging help */
 reiser4_internal void
 print_lock_stack(const char *prefix, lock_stack * owner)
@@ -1323,13 +1407,16 @@ print_lock_stack(const char *prefix, loc
 
 	spin_unlock_stack(owner);
 }
+#endif
+
+#if REISER4_DEBUG
 
 /*
  * debugging functions
  */
 
 /* check consistency of locking data-structures hanging of the @stack */
-static void
+void
 check_lock_stack(lock_stack * stack)
 {
 	spin_lock_stack(stack);
diff -puN lock.h~profile-stat-trace-repacker lock.h
--- reiser4/lock.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/lock.h	2005-02-01 11:51:11.000000000 +0300
@@ -190,7 +190,25 @@ extern void done_lh(lock_handle *);
 extern znode_lock_mode lock_mode(lock_handle *);
 
 extern int prepare_to_sleep(lock_stack * owner);
-extern void go_to_sleep(lock_stack * owner);
+
+#if REISER4_STATS
+
+#define ADD_TO_SLEPT_IN_WAIT_EVENT (-1)
+#define ADD_TO_SLEPT_IN_WAIT_ATOM  (-2)
+
+/* if REISER4_STATS __go_to_sleep() accepts additional parameter @level for
+ * gathering per-level sleep statistics. The go_to_sleep wrapper hides the
+ * __go_to_sleep() function prototypes difference. */
+void __go_to_sleep(lock_stack*, int);
+#define go_to_sleep(owner, level) __go_to_sleep(owner, level);
+
+#else
+
+void __go_to_sleep(lock_stack*);
+#define go_to_sleep(owner, level) __go_to_sleep(owner)
+
+#endif
+
 extern void __reiser4_wake_up(lock_stack * owner);
 
 extern int lock_stack_isclean(lock_stack * owner);
diff -puN /dev/null log.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/log.c	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,522 @@
+/* Copyright 2001, 2002, 2003 by Hans Reiser, licensing governed by
+ * reiser4/README */
+
+/* Tree-tracing facility. Copied from reiserfs v3.x patch, never released */
+
+/*
+ * Tree-tracing is enabled by REISER4_EVENT_LOG compile option, and
+ * log_file=<path> mount option.
+ *
+ * File at <path> is opened (created if needed) and filled with log records
+ * while file system is mounted.
+ *
+ * Special path /dev/null disables logging.
+ *
+ *
+ * Special path /dev/console is interpreted as outputting log records through
+ * printk().
+ *
+ * Low-level functions to output log record are write_log() and
+ * write_log_raw(). Various macros defined in log.h are used as wrappers.
+ *
+ * Output to log file is buffered to reduce overhead, but as target file
+ * system (one where log file lives) also buffers data in memory, tracing
+ * can distort file system behavior significantly. It has been experimentally
+ * found that optimal was to log is by using log_file=<pipe> and piping
+ * log records to another host (through netcat(1) or similar, for example).
+ *
+ */
+
+#include "forward.h"
+#include "debug.h"
+#include "key.h"
+#include "log.h"
+#include "super.h"
+#include "inode.h"
+#include "page_cache.h" /* for jprivate() */
+
+#include <asm/uaccess.h>
+#include <linux/types.h>
+#include <linux/fs.h>		/* for struct super_block  */
+#include <linux/slab.h>
+#include <linux/bio.h>
+#include <linux/vmalloc.h>
+#include <linux/hardirq.h>
+
+#if REISER4_LOG
+
+static int log_flush(reiser4_log_file * log);
+static int free_space(reiser4_log_file * log, size_t * len);
+static int lock_log(reiser4_log_file * log);
+static void unlock_log(reiser4_log_file * log);
+
+/* helper macro: lock log file, return with error if locking failed. */
+#define LOCK_OR_FAIL( log )			\
+({						\
+	int __result;				\
+						\
+	__result = lock_log( log );		\
+	if( __result != 0 )			\
+		return __result;		\
+})
+
+/* open log file. This is called by mount, when log_file=<path> option is
+ * used. */
+int
+open_log_file(struct super_block *super,
+		const char *file_name,
+		size_t size,
+		reiser4_log_file * log)
+{
+	int gfp_mask;
+
+	assert("nikita-2498", file_name != NULL);
+	assert("nikita-2499", log != NULL);
+	assert("nikita-2500", size > 0);
+
+	xmemset(log, 0, sizeof *log);
+
+	spin_lock_init(&log->lock);
+	INIT_LIST_HEAD(&log->wait);
+
+	/* special case: disable logging */
+	if (!strcmp(file_name, "/dev/null")) {
+		log->type = log_to_bucket;
+		return 0;
+	}
+	log->buf = vmalloc(size);
+	if (log->buf == NULL)
+		return RETERR(-ENOMEM);
+	log->size = size;
+
+	/* special case: log through printk() */
+	if (!strcmp(file_name, "/dev/console")) {
+		log->type = log_to_console;
+		return 0;
+	}
+	log->fd = filp_open(file_name, O_CREAT | O_WRONLY, S_IFREG | S_IWUSR);
+	if (IS_ERR(log->fd)) {
+		warning("nikita-2501", "cannot open log file '%s': %li", file_name, PTR_ERR(log->fd));
+		log->fd = NULL;
+		return PTR_ERR(log->fd);
+	}
+	if (log->fd->f_dentry->d_inode->i_sb == super) {
+		warning("nikita-2506", "Refusing to log onto logd fs");
+		return RETERR(-EINVAL);
+	}
+	log->fd->f_dentry->d_inode->i_flags |= S_NOATIME;
+	log->fd->f_flags |= O_APPEND;
+
+	/* avoid complications with calling memory allocator by ->write()
+	 * method of target file system, but setting GFP_NOFS bit in
+	 * mapping->gfp_mask */
+	gfp_mask = mapping_gfp_mask(log->fd->f_dentry->d_inode->i_mapping);
+	gfp_mask &= ~__GFP_FS;
+	gfp_mask |= GFP_NOFS;
+	mapping_set_gfp_mask(log->fd->f_dentry->d_inode->i_mapping, gfp_mask);
+	log->type = log_to_file;
+	return 0;
+}
+
+/* write message (formatted according to @format) into log file @file */
+int
+write_log(reiser4_log_file * file, const char *format, ...)
+{
+	size_t len;
+	int result;
+	va_list args;
+
+	if (file == NULL || file->type == log_to_bucket ||
+	    file->buf == NULL || file->disabled > 0)
+		return 0;
+
+	va_start(args, format);
+	len = vsnprintf((char *) format, 0, format, args) + 1;
+	va_end(args);
+
+	LOCK_OR_FAIL(file);
+	result = free_space(file, &len);
+	if (result == 0) {
+		va_start(args, format);
+		file->used += vsnprintf(file->buf + file->used,
+					file->size - file->used, format, args);
+		va_end(args);
+	}
+	unlock_log(file);
+	return result;
+}
+
+/* write buffer @data into @file */
+int
+write_log_raw(reiser4_log_file * file, const void *data, size_t len)
+{
+	int result;
+
+	if (file == NULL || file->type == log_to_bucket ||
+	    file->buf == NULL || file->disabled > 0)
+		return 0;
+
+	LOCK_OR_FAIL(file);
+	result = free_space(file, &len);
+	if (result == 0) {
+		xmemcpy(file->buf + file->used, data, (size_t) len);
+		file->used += len;
+	}
+	unlock_log(file);
+	return result;
+}
+
+/* close log file. This is called by umount. */
+void
+close_log_file(reiser4_log_file * log)
+{
+	if (log->buf == NULL)
+		/* log file is not opened. There is nothing to close */
+		return;
+	if (log->type == log_to_file && lock_log(log) == 0) {
+		log_flush(log);
+		unlock_log(log);
+	}
+	if (log->fd != NULL)
+		filp_close(log->fd, NULL);
+	if (log->buf != NULL) {
+		vfree(log->buf);
+		log->buf = NULL;
+	}
+}
+
+/* temporary suspend (or resume) tracing */
+int
+hold_log(reiser4_log_file * file, int flag)
+{
+	if (flag)
+		return lock_log(file);
+	else {
+		unlock_log(file);
+		return 0;
+	}
+}
+
+/* disable or enable tracing */
+int
+disable_log(reiser4_log_file * file, int flag)
+{
+	LOCK_OR_FAIL(file);
+	file->disabled += flag ? +1 : -1;
+	unlock_log(file);
+	return 0;
+}
+
+#define START_KERNEL_IO				\
+        {					\
+		mm_segment_t __ski_old_fs;	\
+						\
+		__ski_old_fs = get_fs();	\
+		set_fs( KERNEL_DS )
+
+#define END_KERNEL_IO				\
+		set_fs( __ski_old_fs );		\
+	}
+
+struct __wlink {
+	struct list_head link;
+	struct semaphore sema;
+};
+
+/* lock log file for exclusive use */
+static int
+lock_log(reiser4_log_file * log)
+{
+	int ret = 0;
+
+	spin_lock(&log->lock);
+
+	while (log->long_term) {
+		/* sleep on a semaphore */
+		struct __wlink link;
+		sema_init(&link.sema, 0);
+		list_add(&link.link, &log->wait);
+		spin_unlock(&log->lock);
+
+		ret = down_interruptible(&link.sema);
+
+		spin_lock(&log->lock);
+		list_del(&link.link);
+	}
+
+	return ret;
+}
+
+/* unlock log file */
+static void
+unlock_log(reiser4_log_file * log)
+{
+	spin_unlock(&log->lock);
+}
+
+static void convert_to_longterm (reiser4_log_file * log)
+{
+	assert ("zam-833", log->long_term == 0);
+	log->long_term = 1;
+	spin_unlock(&log->lock);
+}
+
+static void convert_to_shortterm (reiser4_log_file * log)
+{
+	struct list_head * pos;
+
+	spin_lock(&log->lock);
+	assert ("zam-834", log->long_term);
+	log->long_term = 0;
+	list_for_each(pos, &log->wait) {
+		struct __wlink * link;
+		link = list_entry(pos, struct __wlink, link);
+		up(&link->sema);
+	}
+}
+
+/*
+ * flush content of the file->buf to the logging target. Free space in buffer.
+ */
+static int
+log_flush(reiser4_log_file * file)
+{
+	int result;
+
+	result = 0;
+	switch (file->type) {
+	case log_to_file:{
+		struct file *fd;
+
+		convert_to_longterm(file);
+
+		/*
+		 * if logging to the file, call vfs_write() until all data are
+		 * written
+		 */
+
+		fd = file->fd;
+		if (fd && fd->f_op != NULL && fd->f_op->write != NULL) {
+			int written;
+
+			written = 0;
+			START_KERNEL_IO;
+			while (file->used > 0) {
+				result = vfs_write(fd, file->buf + written,
+						   file->used, &fd->f_pos);
+				if (result > 0) {
+					file->used -= result;
+					written += result;
+				} else {
+					static int log_io_failed = 0;
+
+					if (IS_POW(log_io_failed))
+						warning("nikita-2502",
+							"Error writing log: %i",
+							result);
+					++ log_io_failed;
+					break;
+				}
+			}
+			END_KERNEL_IO;
+		} else {
+			warning("nikita-2504", "no ->write() in log-file");
+			result = RETERR(-EINVAL);
+		}
+
+		convert_to_shortterm(file);
+
+		break;
+	}
+	default:
+		warning("nikita-2505",
+			"unknown log-file type: %i. Dumping to console",
+			file->type);
+	case log_to_console:
+		if (file->buf != NULL)
+			printk(file->buf);
+	case log_to_bucket:
+		file->used = 0;
+		break;
+	}
+
+	return result;
+}
+
+/*
+ * free *@len bytes in the file->buf
+ */
+static int
+free_space(reiser4_log_file * file, size_t * len)
+{
+	if (*len > file->size) {
+		warning("nikita-2503",
+			"log record too large: %i > %i. Truncating",
+			*len, file->size);
+		*len = file->size;
+	}
+	while (*len > file->size - file->used) {
+		int result;
+
+		/* flushing can sleep, so loop */
+		result = log_flush(file);
+		if (result < 0)
+			return result;
+	}
+	return 0;
+}
+
+/*
+ * log tree operation @op on the @tree.
+ */
+void
+write_tree_log(reiser4_tree * tree, reiser4_log_op op, ...)
+{
+	va_list args;
+	char buf[200];
+	char *rest;
+	reiser4_key *key;
+
+	if (unlikely(in_interrupt() || in_irq())) {
+		printk("cannot write log from interrupt\n");
+		return;
+	}
+
+	/*
+	 * For each operation arguments are provided by the caller. Number and
+	 * type of arguments depends on operation type. Use va_args to extract
+	 * them.
+	 */
+
+	/*
+	 * tree_cut:    opcode, key_from, key_to
+	 *
+	 * tree_lookup: opcode, key
+	 *
+	 * tree_insert: opcode, item_data, coord, flags
+	 *
+	 * tree_paste:  opcode, item_data, coord, flags
+	 *
+	 * tree_cached: opcode
+	 *
+	 * tree_exit:   opcode
+	 *
+	 */
+	va_start(args, op);
+
+	rest = buf;
+	rest += sprintf(rest, "....tree %c ", op);
+
+	if (op != tree_cached && op != tree_exit) {
+		key = va_arg(args, reiser4_key *);
+		rest += sprintf_key(rest, key);
+		*rest++ = ' ';
+		*rest = '\0';
+
+		switch (op) {
+		case tree_cut: {
+			reiser4_key *to;
+
+			to = va_arg(args, reiser4_key *);
+			rest += sprintf_key(rest, to);
+			break;
+		}
+		case tree_lookup:
+		default:
+			break;
+		case tree_insert:
+		case tree_paste: {
+			reiser4_item_data *data;
+			coord_t *coord;
+			__u32 flags;
+
+			data = va_arg(args, reiser4_item_data *);
+			coord = va_arg(args, coord_t *);
+			flags = va_arg(args, __u32);
+
+			rest += sprintf(rest, "%s (%u,%u) %x",
+					data->iplug->h.label,
+					coord->item_pos, coord->unit_pos, flags);
+		}
+		}
+	}
+	va_end(args);
+	write_current_logf(WRITE_TREE_LOG, "%s", buf);
+}
+
+/* construct in @buf jnode description to be output in the log */
+char *
+jnode_short_info(const jnode *j, char *buf)
+{
+	if (j == NULL) {
+		sprintf(buf, "null");
+	} else {
+		sprintf(buf, "%i %c %c %i",
+			jnode_get_level(j),
+			jnode_is_znode(j) ? 'Z' :
+			jnode_is_unformatted(j) ? 'J' : '?',
+			JF_ISSET(j, JNODE_OVRWR) ? 'O' :
+			JF_ISSET(j, JNODE_RELOC) ? 'R' : ' ',
+			j->atom ? j->atom->atom_id : -1);
+	}
+	return buf;
+}
+
+
+/* write jnode description in the log */
+void
+write_node_log(const jnode *node)
+{
+	char jbuf[100];
+
+	jnode_short_info(node, jbuf);
+	write_current_logf(WRITE_NODE_LOG, ".....node %s %s",
+			   sprint_address(jnode_get_block(node)), jbuf);
+}
+
+/* write page description in the log */
+void
+write_page_log(const struct address_space *mapping, unsigned long index)
+{
+	write_current_logf(WRITE_PAGE_LOG, ".....page %llu %lu", get_inode_oid(mapping->host),
+			   index);
+}
+
+/* write block IO request description in the log */
+void
+write_io_log(const char *moniker, int rw, struct bio *bio)
+{
+	struct super_block *super;
+	reiser4_super_info_data *sbinfo;
+	reiser4_block_nr start;
+	char jbuf[100];
+
+	/*
+	 * sbinfo->last_touched is last block where IO was issued to. It is
+	 * used to output seek distance into log.
+	 */
+
+	super = reiser4_get_current_sb();
+	sbinfo = get_super_private(super);
+
+	start = bio->bi_sector >> (super->s_blocksize_bits - 9);
+	jnode_short_info(jprivate(bio->bi_io_vec[0].bv_page), jbuf);
+	write_current_logf(WRITE_IO_LOG, "......bio %s %c %+lli  (%llu,%u) %s",
+			   moniker, (rw == READ) ? 'r' : 'w',
+			   start - sbinfo->last_touched - 1,
+			   start, bio->bi_vcnt, jbuf);
+	sbinfo->last_touched = start + bio->bi_vcnt - 1;
+}
+
+#endif
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   scroll-step: 1
+   End:
+*/
diff -puN /dev/null log.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/log.h	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,122 @@
+/* Copyright 2000, 2001, 2002, 2003 by Hans Reiser, licensing governed by
+ * reiser4/README */
+
+/* Tree-tracing facility. Copied from reiserfs v3.x patch, never released. See
+ * log.c for comments. */
+
+#if !defined( __REISER4_LOG_H__ )
+#define __REISER4_LOG_H__
+
+#include "forward.h"
+#include "debug.h"
+
+#include <linux/types.h>
+#include <linux/fs.h>		/* for struct super_block, etc  */
+#include <asm/semaphore.h>
+
+/*
+ * Log targets
+ */
+typedef enum {
+	log_to_file,    /* file */
+	log_to_console  /* printk */,
+	log_to_bucket   /* nowhere */
+} log_file_type;
+
+#if REISER4_LOG
+
+/*
+ * data structure describing log file.
+ */
+typedef struct {
+	log_file_type type;      /* type of log file */
+	struct file *fd;         /* actual file */
+	char *buf;               /* logging buffer where records are
+				  * accumulated */
+	size_t size;             /* buffer size */
+	size_t used;             /* bytes used in the buffer */
+	spinlock_t lock;         /* spinlock protecting this structure */
+	struct list_head wait;   /* threads waiting for the free space in the
+				  * buffer */
+	int disabled;            /* if > 0, logging is temporarily disabled */
+	int long_term;           /* if != 0, then ->wait is used for
+				  * synchronization, otherwise--- ->lock.*/
+} reiser4_log_file;
+
+/*
+ * markers for tree operations logged. Self-describing.
+ */
+typedef enum {
+	tree_cut = 'c',
+	tree_lookup = 'l',
+	tree_insert = 'i',
+	tree_paste = 'p',
+	tree_cached = 'C',
+	tree_exit = 'e'
+} reiser4_log_op;
+
+extern int open_log_file(struct super_block *super, const char *file_name, size_t size, reiser4_log_file * log);
+extern int write_log(reiser4_log_file * file, const char *format, ...)
+    __attribute__ ((format(printf, 2, 3)));
+
+extern int write_log_raw(reiser4_log_file * file, const void *data, size_t len);
+extern int hold_log(reiser4_log_file * file, int flag);
+extern int disable_log(reiser4_log_file * file, int flag);
+extern void close_log_file(reiser4_log_file * file);
+
+#define write_syscall_log(format, ...)	\
+	write_current_logf(WRITE_SYSCALL_LOG, "%s "format, __FUNCTION__ , ## __VA_ARGS__)
+extern void write_node_log(const jnode *node);
+struct address_space;
+extern void write_page_log(const struct address_space *mapping,
+			     unsigned long index);
+extern void write_io_log(const char *moniker, int rw, struct bio *bio);
+extern void write_tree_log(reiser4_tree * tree, reiser4_log_op op, ...);
+
+extern char *jnode_short_info(const jnode *j, char *buf);
+
+
+#else /* NO LOG */
+
+typedef struct {
+} reiser4_log_file;
+
+#define open_log_file(super, file_name, size, log) (0)
+#define write_log(file, format, ...) (0)
+#define write_log_raw(file, data, len) (0)
+#define hold_log(file, flag) (0)
+#define disable_log(file, flag) (0)
+#define close_log_file(file) noop
+
+#define write_syscall_log(format, ...) noop
+#define write_tree_log(tree, op, ...) noop
+#define write_node_log(node) noop
+#define write_page_log(mapping, index) noop
+#define jnode_short_info(j, buf) buf
+
+#endif
+
+#define write_current_logf(log_flag, format, ...)				\
+({										\
+	struct super_block *super;						\
+										\
+	super = reiser4_get_current_sb();					\
+	IF_LOG(log_flag, write_log(&get_super_private(super)->log_file,		\
+                                   "%s %s %s " format "\n",			\
+				   current->comm,				\
+				   super->s_id, __FUNCTION__ , ## __VA_ARGS__));	\
+})
+
+/* __REISER4_LOG_H__ */
+#endif
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   scroll-step: 1
+   End:
+*/
diff -puN Makefile~profile-stat-trace-repacker Makefile
--- reiser4/Makefile~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/Makefile	2005-02-01 11:51:11.000000000 +0300
@@ -4,8 +4,37 @@
 
 obj-$(CONFIG_REISER4_FS) += reiser4.o
 
-reiser4-y := \
+EXTRA_CFLAGS += \
+           -Wformat \
+	       -Wundef \
+           -Wunused \
+	       -Wcomment \
+           \
+	       -Wno-nested-externs \
+	       -Wno-write-strings \
+	       -Wno-sign-compare
+
+#	       -Wpointer-arith \
+#	       -Wlarger-than-16384 \
+#	       -Winline \
+
+ifeq ($(CONFIG_REISER4_NOOPT),y)
+	EXTRA_CFLAGS += -O0 -fno-inline
+else
+# this warning is only supported when optimization is on.
+	EXTRA_CFLAGS += \
+           -Wuninitialized
+endif
+
+ifeq ($(CONFIG_REISER4_ALL_IN_ONE),y)
+
+reiser4-objs := all-reiser4.o
+
+else
+
+reiser4-objs := \
 		   debug.o \
+		   stats.o \
 		   jnode.o \
 		   znode.o \
 		   key.o \
@@ -27,11 +56,14 @@ reiser4-y := \
 		   eottl.o \
 		   search.o \
 		   page_cache.o \
+		   lnode.o \
 		   kcond.o \
 		   seal.o \
 		   dscale.o \
+		   log.o \
 		   flush_queue.o \
 		   ktxnmgrd.o \
+		   kattr.o \
 		   blocknrset.o \
 		   super.o \
 		   oid.o \
@@ -42,9 +74,13 @@ reiser4-y := \
 		   file_ops.o \
 		   as_ops.o \
 		   emergency_flush.o \
+		   spinprof.o\
 		   entd.o\
 		   readahead.o \
 		   crypt.o \
+		   diskmap.o \
+		   prof.o \
+		   repacker.o \
 		   status_flags.o \
 		   init_super.o \
 		   safe_link.o \
@@ -72,6 +108,7 @@ reiser4-y := \
 		   plugin/item/extent_item_ops.o \
 		   plugin/item/extent_file_ops.o \
 		   plugin/item/extent_flush_ops.o \
+		   plugin/item/extent_repack_ops.o \
            \
 		   plugin/hash.o \
 		   plugin/fibration.o \
@@ -94,3 +131,35 @@ reiser4-y := \
 		   plugin/file/pseudo.o \
 		   plugin/file/file.o \
 		   plugin/file/tail_conversion.o
+
+ifeq ($(CONFIG_REISER4_FS_SYSCALL),y)
+
+  reiser4-objs += sys_reiser4.o
+  ifeq ($(CONFIG_REISER4_FS_SYSCALL_YACC),y)
+
+      YFLAGS= -d -v -r -b $(obj)/parser/parser
+
+   $(obj)/parser/parser.code.c: $(obj)/parser/parser.y
+
+	$(YACC) $(YFLAGS) $(obj)/parser/parser.y
+
+  endif
+
+  sys_reiser4.o: $/sys_reiser4.c       \
+                 $/parser/parser.code.c \
+                 $/parser/parser.tab.c \
+                 $/parser/parser.tab.h \
+                 $/parser/lib.c        \
+                 $/parser/pars.cls.h   \
+                 $/parser/pars.yacc.h  \
+                 $/parser/parser.h
+
+
+#	$(MAKE)  $(obj)/parser/parser
+#clean-files := parser/parser.code.c
+##clean-rule =@$(MAKE) -C $/parser clean
+#clean-rule =@$(MAKE) $(obj)/parser/parser.code.c
+endif
+
+endif
+
diff -puN /dev/null not-for-inclusion/dont-use-rwlocks.patch
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/dont-use-rwlocks.patch	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,358 @@
+diff -ru bk/reiser4/lock.c /home/vs/bitstream-reiser4/linux-2.6.9-rc2-mm4/fs/reiser4/lock.c
+--- bk/reiser4/lock.c	2004-10-27 18:47:03.467643409 +0400
++++ /home/vs/bitstream-reiser4/linux-2.6.9-rc2-mm4/fs/reiser4/lock.c	2004-10-26 19:01:41.524131133 +0400
+@@ -238,7 +238,8 @@
+ {
+ 	lock_handle *handle;
+ 
+-	assert("nikita-1824", rw_zlock_is_locked(&node->lock));
++	/*XXXXassert("nikita-1824", rw_zlock_is_locked(&node->lock));XXXX*/
++	assert("nikita-1824", spin_zlock_is_locked(&node->lock));
+ 	for_all_type_safe_list(owners, &node->lock.owners, handle) {
+ 		spin_lock_stack(handle->owner);
+ 
+@@ -265,7 +266,8 @@
+ {
+ 	assert("jmacd-810", handle->owner == NULL);
+ 	assert("nikita-1828", owner == get_current_lock_stack());
+-	assert("nikita-1830", rw_zlock_is_locked(&node->lock));
++	/*XXXXassert("nikita-1830", rw_zlock_is_locked(&node->lock));XXXX*/
++	assert("nikita-1830", spin_zlock_is_locked(&node->lock));
+ 
+ 	handle->owner = owner;
+ 	handle->node = node;
+@@ -284,7 +286,8 @@
+ {
+ 	assert("zam-354", handle->owner != NULL);
+ 	assert("nikita-1608", handle->node != NULL);
+-	assert("nikita-1633", rw_zlock_is_locked(&handle->node->lock));
++	/*XXXXassert("nikita-1633", rw_zlock_is_locked(&handle->node->lock));XXXX*/
++	assert("nikita-1633", spin_zlock_is_locked(&handle->node->lock));
+ 	assert("nikita-1829", handle->owner == get_current_lock_stack());
+ 
+ 	assert("reiser4-5", handle->owner->nr_locks > 0);
+@@ -308,7 +311,8 @@
+ 
+ 	request = &owner->request;
+ 	node    = request->node;
+-	assert("nikita-1834", rw_zlock_is_locked(&node->lock));
++	/*XXXXassert("nikita-1834", rw_zlock_is_locked(&node->lock));XXXX*/
++	assert("nikita-1834", spin_zlock_is_locked(&node->lock));
+ 	if (request->mode == ZNODE_READ_LOCK) {
+ 		node->lock.nr_readers++;
+ 	} else {
+@@ -341,7 +345,8 @@
+ 	/* Owners list is not empty for a locked node */
+ 	assert("zam-314", !owners_list_empty(&node->lock.owners));
+ 	assert("nikita-1841", owner == get_current_lock_stack());
+-	assert("nikita-1848", rw_zlock_is_locked(&node->lock));
++	/*XXXXassert("nikita-1848", rw_zlock_is_locked(&node->lock));XXXX*/
++	assert("nikita-1848", spin_zlock_is_locked(&node->lock));
+ 
+ 	ret = (owners_list_front(&node->lock.owners)->owner == owner);
+ 
+@@ -421,7 +426,8 @@
+ static inline int
+ check_deadlock_condition(znode * node)
+ {
+-	assert("nikita-1833", rw_zlock_is_locked(&node->lock));
++	/*XXXXassert("nikita-1833", rw_zlock_is_locked(&node->lock));XXXX*/
++	assert("nikita-1833", spin_zlock_is_locked(&node->lock));
+ 	return node->lock.nr_hipri_requests > 0 && node->lock.nr_hipri_owners == 0;
+ }
+ 
+@@ -432,7 +438,8 @@
+ 	znode *node = owner->request.node;
+ 
+ 	assert("nikita-1842", owner == get_current_lock_stack());
+-	assert("nikita-1843", rw_zlock_is_locked(&node->lock));
++	/*XXXXassert("nikita-1843", rw_zlock_is_locked(&node->lock));XXXX*/
++	assert("nikita-1843", spin_zlock_is_locked(&node->lock));
+ 
+ 	/* See if the node is disconnected. */
+ 	if (unlikely(ZF_ISSET(node, JNODE_IS_DYING))) {
+@@ -754,7 +761,8 @@
+ 	else
+ 		WUNLOCK_ZLOCK(&node->lock);
+ 
+-	assert("nikita-3182", rw_zlock_is_not_locked(&node->lock));
++	/*XXXXassert("nikita-3182", rw_zlock_is_not_locked(&node->lock));XXXX*/
++	assert("nikita-3182", spin_zlock_is_not_locked(&node->lock));
+ 	/* minus one reference from handle->node */
+ 	handle->node = NULL;
+ 	assert("nikita-2190", znode_invariant(node));
+@@ -769,7 +777,8 @@
+ {
+ 	znode *node = owner->request.node;
+ 
+-	assert("jmacd-807", rw_zlock_is_locked(&node->lock));
++	/*XXXXassert("jmacd-807", rw_zlock_is_locked(&node->lock));XXXX*/
++	assert("jmacd-807", spin_zlock_is_locked(&node->lock));
+ 
+ 	/* If we broke with (ok == 0) it means we can_lock, now do it. */
+ 	if (ok == 0) {
+@@ -830,7 +839,8 @@
+ 						       ZNODE_READ_LOCK,
+ 						       ZNODE_LOCK_LOPRI));
+ 
+-	result = UNDER_RW(zlock, lock, read, can_lock_object(owner));
++	/*XXXXresult = UNDER_RW(zlock, lock, read, can_lock_object(owner));XXXX*/
++	result = UNDER_SPIN(zlock, lock, can_lock_object(owner));
+ 
+ 	if (likely(result != -EINVAL)) {
+ 		spin_lock_znode(node);
+@@ -1081,7 +1091,8 @@
+ 			break;
+ 		}
+ 
+-		assert("nikita-1837", rw_zlock_is_locked(&node->lock));
++		/*XXXXassert("nikita-1837", rw_zlock_is_locked(&node->lock));XXXX*/
++		assert("nikita-1837", spin_zlock_is_locked(&node->lock));
+ 		if (hipri) {
+ 			/* If we are going in high priority direction then
+ 			   increase high priority requests counter for the
+@@ -1118,7 +1129,8 @@
+ 		requestors_list_remove(owner);
+ 	}
+ 
+-	assert("jmacd-807/a", rw_zlock_is_locked(&node->lock));
++	/*XXXXassert("jmacd-807/a", rw_zlock_is_locked(&node->lock));XXXX*/
++	assert("jmacd-807/a", spin_zlock_is_locked(&node->lock));
+ 	return lock_tail(owner, wake_up_next, ret, mode);
+ }
+ 
+@@ -1140,7 +1152,8 @@
+ 	assert("nikita-1793", !ZF_ISSET(node, JNODE_RIGHT_CONNECTED));
+ 	assert("nikita-1394", ZF_ISSET(node, JNODE_HEARD_BANSHEE));
+ 	assert("nikita-3097", znode_is_wlocked_once(node));
+-	assert("nikita-3338", rw_zlock_is_locked(&node->lock));
++	/*XXXXassert("nikita-3338", rw_zlock_is_locked(&node->lock));XXXX*/
++	assert("nikita-3338", spin_zlock_is_locked(&node->lock));
+ 
+ 	if (handle->signaled)
+ 		atomic_dec(&owner->nr_signaled);
+@@ -1194,7 +1207,8 @@
+ 				   * structure. */ )
+ {
+ 	xmemset(lock, 0, sizeof (zlock));
+-	rw_zlock_init(lock);
++	/*XXXXrw_zlock_init(lock);XXXX*/
++	spin_zlock_init(lock);
+ 	requestors_list_init(&lock->requestors);
+ 	owners_list_init(&lock->owners);
+ }
+diff -ru bk/reiser4/lock.h /home/vs/bitstream-reiser4/linux-2.6.9-rc2-mm4/fs/reiser4/lock.h
+--- bk/reiser4/lock.h	2004-10-27 18:47:03.488640821 +0400
++++ /home/vs/bitstream-reiser4/linux-2.6.9-rc2-mm4/fs/reiser4/lock.h	2004-10-26 19:01:39.022439496 +0400
+@@ -41,7 +41,8 @@
+ 
+ /* Per-znode lock object */
+ struct zlock {
+-	reiser4_rw_data guard;
++	reiser4_spin_data guard;
++	/*XXXXreiser4_rw_data guard;XXXX*/
+ 	/* The number of readers if positive; the number of recursively taken
+ 	   write locks if negative. Protected by zlock spin lock. */
+ 	int nr_readers;
+@@ -61,7 +62,8 @@
+ 	  (lock_counters()->spin_locked_stack == 0)
+ 
+ /* Define spin_lock_zlock, spin_unlock_zlock, etc. */
+-RW_LOCK_FUNCTIONS(zlock, zlock, guard);
++/*XXXXRW_LOCK_FUNCTIONS(zlock, zlock, guard);XXXX*/
++SPIN_LOCK_FUNCTIONS(zlock, zlock, guard);
+ 
+ #define lock_is_locked(lock)          ((lock)->nr_readers != 0)
+ #define lock_is_rlocked(lock)         ((lock)->nr_readers > 0)
+diff -ru bk/reiser4/search.c /home/vs/bitstream-reiser4/linux-2.6.9-rc2-mm4/fs/reiser4/search.c
+--- bk/reiser4/search.c	2004-10-27 18:48:20.794112011 +0400
++++ /home/vs/bitstream-reiser4/linux-2.6.9-rc2-mm4/fs/reiser4/search.c	2004-10-27 17:58:23.955507653 +0400
+@@ -65,7 +65,8 @@
+ 		cbk_cache_init_slot(cache->slot + i);
+ 		cbk_cache_list_push_back(&cache->lru, cache->slot + i);
+ 	}
+-	rw_cbk_cache_init(cache);
++	/*XXXXrw_cbk_cache_init(cache);XXXX*/
++	spin_cbk_cache_init(cache);
+ 	return 0;
+ }
+ 
+@@ -130,7 +131,8 @@
+ 	assert("nikita-2469", cache != NULL);
+ 	unused = 0;
+ 	result = 1;
+-	read_lock_cbk_cache((cbk_cache *) cache);
++	/*XXXXread_lock_cbk_cache((cbk_cache *) cache);XXXX*/
++	spin_lock_cbk_cache((cbk_cache *) cache);
+ 	for_all_slots(cache, slot) {
+ 		/* in LRU first go all `used' slots followed by `unused' */
+ 		if (unused && (slot->node != NULL))
+@@ -153,7 +155,8 @@
+ 		if (!result)
+ 			break;
+ 	}
+-	read_unlock_cbk_cache((cbk_cache *) cache);
++	/*XXXXread_unlock_cbk_cache((cbk_cache *) cache);XXXX*/
++	spin_unlock_cbk_cache((cbk_cache *) cache);
+ 	return result;
+ }
+ 
+@@ -174,7 +177,8 @@
+ 	cache = &tree->cbk_cache;
+ 	assert("nikita-2470", cbk_cache_invariant(cache));
+ 
+-	write_lock_cbk_cache(cache);
++	/*XXXXwrite_lock_cbk_cache(cache);XXXX*/
++	spin_lock_cbk_cache(cache);
+ 	for (i = 0, slot = cache->slot; i < cache->nr_slots; ++ i, ++ slot) {
+ 		if (slot->node == node) {
+ 			cbk_cache_list_remove(slot);
+@@ -183,7 +187,8 @@
+ 			break;
+ 		}
+ 	}
+-	write_unlock_cbk_cache(cache);
++	/*XXXXwrite_unlock_cbk_cache(cache);XXXX*/
++	spin_unlock_cbk_cache(cache);
+ 	assert("nikita-2471", cbk_cache_invariant(cache));
+ }
+ 
+@@ -204,7 +209,8 @@
+ 	if (cache->nr_slots == 0)
+ 		return;
+ 
+-	write_lock_cbk_cache(cache);
++	/*XXXXwrite_lock_cbk_cache(cache);XXXX*/
++	spin_lock_cbk_cache(cache);
+ 	/* find slot to update/add */
+ 	for (i = 0, slot = cache->slot; i < cache->nr_slots; ++ i, ++ slot) {
+ 		/* oops, this node is already in a cache */
+@@ -218,7 +224,8 @@
+ 	}
+ 	cbk_cache_list_remove(slot);
+ 	cbk_cache_list_push_front(&cache->lru, slot);
+-	write_unlock_cbk_cache(cache);
++	/*XXXXwrite_unlock_cbk_cache(cache);XXXX*/
++	spin_unlock_cbk_cache(cache);
+ 	assert("nikita-2473", cbk_cache_invariant(cache));
+ }
+ 
+@@ -1242,7 +1249,8 @@
+ 	 */
+ 
+ 	rcu_read_lock();
+-	read_lock_cbk_cache(cache);
++	/*XXXXread_lock_cbk_cache(cache);XXXX*/
++	spin_lock_cbk_cache(cache);
+ 	slot = cbk_cache_list_prev(cbk_cache_list_front(&cache->lru));
+ 	while (1) {
+ 
+@@ -1271,7 +1279,8 @@
+ 			break;
+ 		}
+ 	}
+-	read_unlock_cbk_cache(cache);
++	/*XXXXread_unlock_cbk_cache(cache);XXXX*/
++	spin_unlock_cbk_cache(cache);
+ 
+ 	assert("nikita-2475", cbk_cache_invariant(cache));
+ 
+@@ -1317,14 +1326,16 @@
+ 			/* good. Either item found or definitely not found. */
+ 			result = 0;
+ 
+-			write_lock_cbk_cache(cache);
++			/*XXXXwrite_lock_cbk_cache(cache);XXXX*/
++			spin_lock_cbk_cache(cache);
+ 			if (slot->node == h->active_lh->node/*node*/) {
+ 				/* if this node is still in cbk cache---move
+ 				   its slot to the head of the LRU list. */
+ 				cbk_cache_list_remove(slot);
+ 				cbk_cache_list_push_front(&cache->lru, slot);
+ 			}
+-			write_unlock_cbk_cache(cache);
++			/*XXXXwrite_unlock_cbk_cache(cache);XXXX*/
++			spin_unlock_cbk_cache(cache);
+ 		}
+ 	} else {
+ 		/* race. While this thread was waiting for the lock, node was
+diff -ru bk/reiser4/spin_macros.h /home/vs/bitstream-reiser4/linux-2.6.9-rc2-mm4/fs/reiser4/spin_macros.h
+--- bk/reiser4/spin_macros.h	2004-10-27 18:47:03.490640574 +0400
++++ /home/vs/bitstream-reiser4/linux-2.6.9-rc2-mm4/fs/reiser4/spin_macros.h	2004-10-27 09:58:08.892303450 +0400
+@@ -800,8 +800,10 @@
+ #define WLOCK_TREE(tree) write_lock_tree(tree)
+ #define RLOCK_DK(tree) read_lock_dk(tree)
+ #define WLOCK_DK(tree) write_lock_dk(tree)
+-#define RLOCK_ZLOCK(lock) read_lock_zlock(lock)
+-#define WLOCK_ZLOCK(lock) write_lock_zlock(lock)
++/*XXXX#define RLOCK_ZLOCK(lock) read_lock_zlock(lock)XXXX*/
++/*XXXX#define WLOCK_ZLOCK(lock) write_lock_zlock(lock)XXXX*/
++#define RLOCK_ZLOCK(lock) spin_lock_zlock(lock)
++#define WLOCK_ZLOCK(lock) spin_lock_zlock(lock)
+ #endif
+ 
+ #define UNLOCK_JNODE(node) spin_unlock_jnode(node)
+@@ -813,8 +815,10 @@
+ #define WUNLOCK_TREE(tree) write_unlock_tree(tree)
+ #define RUNLOCK_DK(tree) read_unlock_dk(tree)
+ #define WUNLOCK_DK(tree) write_unlock_dk(tree)
+-#define RUNLOCK_ZLOCK(lock) read_unlock_zlock(lock)
+-#define WUNLOCK_ZLOCK(lock) write_unlock_zlock(lock)
++/*XXXX#define RUNLOCK_ZLOCK(lock) read_unlock_zlock(lock)XXXX*/
++/*XXXX#define WUNLOCK_ZLOCK(lock) write_unlock_zlock(lock)XXXX*/
++#define RUNLOCK_ZLOCK(lock) spin_unlock_zlock(lock)
++#define WUNLOCK_ZLOCK(lock) spin_unlock_zlock(lock)
+ 
+ /* __SPIN_MACROS_H__ */
+ #endif
+diff -ru bk/reiser4/tree.c /home/vs/bitstream-reiser4/linux-2.6.9-rc2-mm4/fs/reiser4/tree.c
+--- bk/reiser4/tree.c	2004-10-27 19:01:47.542670753 +0400
++++ /home/vs/bitstream-reiser4/linux-2.6.9-rc2-mm4/fs/reiser4/tree.c	2004-10-18 15:47:10.449168509 +0400
+@@ -747,7 +747,8 @@
+ 
+ 	assert("vs-164", znode_is_write_locked(node));
+ 	assert("nikita-1280", ZF_ISSET(node, JNODE_HEARD_BANSHEE));
+-	assert("nikita-3337", rw_zlock_is_locked(&node->lock));
++	/*XXXXassert("nikita-3337", rw_zlock_is_locked(&node->lock));XXXX*/
++	assert("nikita-3337", spin_zlock_is_locked(&node->lock));
+ 
+ 	/* We assume that this node was detached from its parent before
+ 	 * unlocking, it gives no way to reach this node from parent through a
+@@ -771,10 +772,12 @@
+ 	 * loop, trying to lock dying object.  The exception is in the flush
+ 	 * code when we take node directly from atom's capture list.*/
+ 
+-	write_unlock_zlock(&node->lock);
++	/*XXXXwrite_unlock_zlock(&node->lock);XXXX*/
++	spin_unlock_zlock(&node->lock);
+ 	/* and, remove from atom's capture list. */
+ 	uncapture_znode(node);
+-	write_lock_zlock(&node->lock);
++	/*XXXXwrite_lock_zlock(&node->lock);XXXX*/
++	spin_lock_zlock(&node->lock);
+ 
+ 	invalidate_lock(handle);
+ }
+diff -ru bk/reiser4/tree.h /home/vs/bitstream-reiser4/linux-2.6.9-rc2-mm4/fs/reiser4/tree.h
+--- bk/reiser4/tree.h	2004-10-27 18:47:03.491640451 +0400
++++ /home/vs/bitstream-reiser4/linux-2.6.9-rc2-mm4/fs/reiser4/tree.h	2004-10-07 15:00:58.782380923 +0400
+@@ -64,7 +64,8 @@
+ */
+ typedef struct cbk_cache {
+ 	/* serializator */
+-	reiser4_rw_data guard;
++	/*XXXXreiser4_rw_data guard;XXXX*/
++	reiser4_spin_data guard;
+ 	int nr_slots;
+ 	/* head of LRU list of cache slots */
+ 	cbk_cache_list_head lru;
+@@ -75,7 +76,8 @@
+ #define rw_ordering_pred_cbk_cache(cache) (1)
+ 
+ /* defined read-write locking functions for cbk_cache */
+-RW_LOCK_FUNCTIONS(cbk_cache, cbk_cache, guard);
++/*XXXXRW_LOCK_FUNCTIONS(cbk_cache, cbk_cache, guard);XXXX*/
++SPIN_LOCK_FUNCTIONS(cbk_cache, cbk_cache, guard);
+ 
+ /* define list manipulation functions for cbk_cache LRU list */
+ TYPE_SAFE_LIST_DEFINE(cbk_cache, cbk_cache_slot, lru);
diff -puN /dev/null not-for-inclusion/interpolate.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/interpolate.c	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,20 @@
+/* We will use @ as the symbol for dereferencing, we won't use * because
+we want to reserve it for use as a wildcard someday.
+
+Inheriting stat data from source_filename can be done as:
+
+target_filename/mode<=@source_filename/mode
+
+File body inheritance is accomplished by extending symlink functionality:
+
+file_body_inheritance example:
+
+target_filename/symlink<=`@freshly_interpolate_this_filename_whenever_resolving_target_filename+`here is some text stored directly in the symlink''+@interpolate_this_filename_at_symlink_creation_time+`@freshly_interpolate_this_filename2_whenever_resolving_target_filename+"this is some more text that is directly embedded in the symlink"'
+
+Mr. Demidov, flesh this out in detail, being careful to worry about
+how to write to interpolated files.  I think you need to interpret
+strings that are between interpolations as the delimiters of those
+interpolations, and changing those strings can then only be done by
+writing to filename/sym.
+
+*/
diff -puN /dev/null not-for-inclusion/linux-5_reiser4_syscall.patch
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/linux-5_reiser4_syscall.patch	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,38 @@
+===== arch/um/kernel/sys_call_table.c 1.5 vs edited =====
+--- 1.5/arch/um/kernel/sys_call_table.c	Wed Nov  6 17:36:22 2002
++++ edited/arch/um/kernel/sys_call_table.c	Fri Dec  6 22:15:35 2002
+@@ -232,6 +232,7 @@
+ extern syscall_handler_t sys_io_cancel;
+ extern syscall_handler_t sys_exit_group;
+ extern syscall_handler_t sys_lookup_dcookie;
++extern syscall_handler_t sys_eriser4;
+
+ #if CONFIG_NFSD
+ #define NFSSERVCTL sys_nfsserctl
+@@ -483,6 +484,7 @@
+ 	[ __NR_free_hugepages ] = sys_ni_syscall,
+ 	[ __NR_exit_group ] = sys_exit_group,
+ 	[ __NR_lookup_dcookie ] = sys_lookup_dcookie,
++	[ __NR_reiser4_sys_call ] = sys_reiser4,
+
+ 	ARCH_SYSCALLS
+ 	[ LAST_SYSCALL + 1 ... NR_syscalls ] =
+===== include/asm-i386/unistd.h 1.19 vs edited =====
+--- 1.19/include/asm-i386/unistd.h	Thu Oct 31 18:28:28 2002
++++ edited/include/asm-i386/unistd.h	Fri Dec  6 22:45:24 2002
+@@ -262,6 +262,7 @@
+ #define __NR_sys_epoll_ctl	255
+ #define __NR_sys_epoll_wait	256
+ #define __NR_remap_file_pages	257
++#define __NR_reiser4_sys_call	258
+
+
+ /* user-visible error numbers are in the range -1 - -124: see <asm-i386/errno.h> */
+@@ -378,6 +379,7 @@
+ static inline _syscall1(int,close,int,fd)
+ static inline _syscall1(int,_exit,int,exitcode)
+ static inline _syscall3(pid_t,waitpid,pid_t,pid,int *,wait_stat,int,options)
++static inline _syscall1(long,_reiser4_sys_call,char*,p_strIng)
+
+ #endif
+
diff -puN /dev/null not-for-inclusion/parser/lex.l
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/lex.l	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,65 @@
+%Start Normal
+
+LETTER          [A-Za-z_]
+DIG             [0-9]
+WRD             ({LETTER}|{DIG})+
+SP              [ \t\n]+
+SPECIAL         [\[\]\{\}\/\\\,\:\;\*\$\@\!\`\']
+
+
+
+%%
+
+%{
+BEGIN Normal;
+%}
+
+{SP}"/"{SP}                                       {return BLANK_SLASH_BLANK;}
+
+{SP}?";"{SP}?                                     {return SEMICOLON;}
+{SP}?","{SP}?                                     {return COMMA;}
+{SP}?"+"{SP}?                                     {return PLUS;}
+{SP}?"("{SP}?                                     {return L_PARENT;}
+{SP}?")"{SP}?                                     {return R_PARENT;}
+{SP}?"{"{SP}?                                     {return L_FLX_PARENT;}
+{SP}?"}"{SP}?                                     {return R_FLX_PARENT;}
+{SP}?"["{SP}?                                     {return L_SKW_PARENT;}
+{SP}?"]"{SP}?                                     {return R_SKW_PARENT;}
+
+{SP}?eq{SP}?                                      {return EQ;}
+{SP}?ne{SP}?                                      {return NE;}
+{SP}?le{SP}?                                      {return LE;}
+{SP}?ge{SP}?                                      {return GE;}
+{SP}?lt{SP}?                                      {return LT;}
+{SP}?gt{SP}?                                      {return GT;}
+{SP}?is{SP}?                                      {return IS;}
+{SP}?and{SP}?                                     {return AND;}
+{SP}?or{SP}?                                      {return OR;}
+{SP}?not{SP}?                                     {return NOT;}
+{SP}?if{SP}?                                      {return IF;}
+{SP}?then{SP}?                                    {return THEN;}
+{SP}?else{SP}?                                    {return ELSE;}
+{SP}?exist{SP}?                                   {return EXIST;}
+
+{SP}?"<""-"{SP}?                                  {return L_ASSIGN;}
+{SP}?"<""-""="{SP}?                               {return L_SYMLINK;}
+
+{SP}?tw"/""("{SP}?                                {return TRANSCRASH;}
+
+"/"process                                        {return SLASH_PROCESS;}
+"/"stat                                           {return SLASH_STAT;}
+"/"range                                          {return SLASH_RANGE;}
+"/""("                                            {return SLASH_L_PARENT;}
+"/"                                               {return SLASH;}
+
+
+{SP}?"]"{SP}?                                     {return BLANK_SLASH_BLANK;}
+
+
+{WRD}                                             { return  WORD ;}
+
+.                                                 { return  0 ;}
+%%
+
+
+
diff -puN /dev/null not-for-inclusion/parser/lib.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/lib.c	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,2187 @@
+/*
+ * Copyright 2001, 2002 by Hans Reiser, licensing governed by reiser4/README
+ */
+
+/*
+ * functions for parser.y
+ */
+
+
+#include "lib.h"
+
+#include <linux/mount.h>
+
+
+void print_pwd_count(char * mess)
+{
+	printk ("\n%s rootmnt=%d, root_de=%d,pwdmnt=%d, pwd_de=%d\n",
+		mess,
+		current->fs->rootmnt->mnt_count,
+		current->fs->root->d_count,
+		current->fs->pwdmnt->mnt_count,
+		current->fs->pwd->d_count);
+}
+
+
+//	walk_init_root( "/", (&ws->nd));   /* from namei.c walk_init_root */
+#if 0
+static int reiser4_get ( struct path_walk * path, struct vfsmount *mnt, struct dentry *de )
+{
+	read_lock(&current->fs->lock);
+	path->mnt = mntget( mnt); 
+	path->de = dget( de );
+	read_unlock(&current->fs->lock);
+	printk ("get    %d,  name %s\n", de->d_count, de->d_name.name);
+	print_pwd_count("dget");
+}
+
+static int reiser4_get( ws, atomic_t * lock, struct vfsmount *mnt, struct dentry *de )
+{
+	read_lock( &current->fs->lock );
+	ws->nd.mnt = mntget( mnt); 
+	ws->nd.dentry = dget( de );
+	read_unlock(&current->fs->lock);
+
+	printk ("get    %d,  name %s\n", de->d_count, de->d_name.name);
+	print_pwd_count("dget");
+}
+#else
+
+
+
+#define reiser4_get( ws, current_fs, mnt, de )\
+{\
+	read_lock( &(current_fs)->lock );\
+	ws->nd.mnt = mntget( (current_fs)->(mnt)); \
+	ws->nd.dentry = dget( (current_fs)->(de) );\
+	read_unlock(&(current_fs)->lock);\
+	printk ("get    %d,  name %s\n", (current_fs)->(de)->d_count, (current_fs)->(de)->d_name.name);\
+	print_pwd_count("dget");\
+}
+#endif
+
+lnode_dentry * reiser4_get_ln(struct reiser4_syscall_w_space *ws, lnode_dentry * l_de)
+{
+	assert("VD-reiser4_get_ln: l_de ==NULL",   l_de != NULL);
+	assert("VD-reiser4_get_ln: LNODE_DENTRY",  l_de->h.type == LNODE_DENTRY );
+	assert("VD-reiser4_get_ln: dentry",        l_de->dentry != NULL );
+	assert("VD-reiser4_get_ln: mnt",           l_de->mnt != NULL );
+	read_lock(&current->fs->lock);
+	//	l_de->lock   = &current->fs->lock;
+	l_de->mnt    = mntget( ws->nd.mnt );
+	l_de->dentry = dget  ( ws->nd.dentry ) ;
+	read_unlock(&current->fs->lock);
+	return l_de;
+}
+
+void path4_release(lnode_dentry * l_de )
+{
+	assert("VD-path4_release: l_de ==NULL",   l_de != NULL);
+	assert("VD-path4_release: LNODE_DENTRY",  l_de->h.type == LNODE_DENTRY );
+	assert("VD-path4_release: dentry",        l_de->dentry != NULL );
+	assert("VD-path4_release: mnt",           l_de->mnt != NULL );
+	dput( l_de->dentry );
+	mntput( l_de->mnt );
+	printk (" path4_release %d %d %s\n",
+		l_de->dentry->d_count,
+		l_de->mnt->mnt_count,
+		l_de->dentry->d_name.name);
+	print_pwd_count("release");
+}
+
+
+#if 0
+void print_pwd_count_ws(struct reiser4_syscall_w_space *ws, char * mess)
+{
+	printk ("\n%s rootmnt=%d, root_de=%d,pwdmnt=%d, pwd_de=%d\n",
+		mess,
+		ws->root_e->->mnt_count,
+		current->fs->root->d_count,
+		current->fs->pwdmnt->mnt_count,
+		current->fs->pwd->d_count);
+}
+#endif
+
+
+#define LEX_XFORM  1001
+#define LEXERR2    1002
+#define LEX_Ste    1003
+
+/* printing errors for parsing */
+static void yyerror( struct reiser4_syscall_w_space *ws  /* work space ptr */,
+		                             int msgnum  /* message number */, ...)
+{
+	char errstr[120]={"\nreiser4 parser:"};
+	char * s;
+	va_list args;
+	va_start(args, msgnum);
+	switch (msgnum) {
+	case   101:
+		strcat(errstr,"yacc stack overflow");
+		break;
+	case LEX_XFORM:
+		strcat(errstr,"x format has odd number of symbols");
+		break;
+	case LEXERR2:
+/*			int state = va_arg(args, int);*/
+		strcat(errstr,"internal lex table error");
+		break;
+	case LEX_Ste:
+		strcat(errstr,"wrong lexem");
+		break;
+	case 11111:
+		{
+			int state = va_arg(args, int);
+			{
+				char ss[16];
+				/*				int s = va_arg(args, int);*/
+				sprintf( ss,"%4d ", state);
+				strcat( errstr, ss );
+			}
+			strcat( errstr, " syntax error:" );
+			switch(state) {
+				//		case 4:
+				//			strcat(errstr," wrong operation");
+				//			break;
+			case 6:
+				strcat(errstr," wrong assign operation");
+				break;
+			case 7:
+			case 12:
+				strcat(errstr," wrong name");
+				break;
+			case 27:
+				strcat(errstr," wrong logical operation");
+				break;
+			case 10:
+				strcat(errstr," wrong THEN keyword");
+				break;
+			case 34:
+			case 50:
+				strcat(errstr," wrong separatop");
+				break;
+			default:
+				strcat(errstr," strange error");
+				break;
+			}
+		}
+		break;
+	}
+	va_end(args);
+	printk( "\n%s\n", ws->ws_inline );
+	for (s=ws->ws_inline; s<curr_symbol(ws); s++)
+		{
+			if (*s=='\t' ) {
+				printk("\t");
+			} else {
+				printk(" ");
+			}
+		}
+	printk("^");
+	printk(errstr);
+	printk("\n");
+//	printk("\n%s",curr_symbol(ws));
+}
+
+/* free lists of work space*/
+static void freeList(free_space_t * list /* head of list to be fee */)
+{
+	free_space_t * curr,* next;
+	next = list;
+	while (next) {
+		curr = next;
+		next = curr->free_space_next;
+		kfree(curr);
+	}
+}
+
+static void pop_all_val(struct reiser4_syscall_w_space * ws , pars_var_t  * var )
+{
+	while ( (var->val) != NULL ) {
+		pop_var_val_stack( ws, var->val, 0 );
+	}
+}
+
+/* free work space*/
+static int reiser4_pars_free(struct reiser4_syscall_w_space * ws /* work space ptr */)
+{
+	pars_var_t  * var;
+	//	pars_var_value_t * val;
+	assert("VD-reiser4_pars_free:ws_level",        ws->ws_level >= 0);
+	assert("VD-reiser4_pars_free:cur_exp" ,        ws->cur_level->cur_exp != NULL);
+
+	var = ws->Head_pars_var;
+	while( var!=NULL ) {
+		printk("\n free vallues of %s",var->w->u.name);
+		pop_all_val( ws, var );
+		var = var->next;
+	}
+
+	//	free_expr( ws, ws->cur_level->cur_exp );
+	//	free_expr( ws, ws->root_e );
+	if ( ws->freeSpHead ) {
+		freeList(ws->freeSpHead);
+	}
+
+	kfree(ws);
+	return 0;
+}
+
+static void print_all_val( pars_var_t  * var )
+{
+	pars_var_value_t * val;
+	val=var->val;
+	while ( val != NULL ) {
+		printk( "\n%p %d %d %s",
+			val,
+			val->vtype,
+			//			val->u.ln,
+			val->u.ln->l_dentry.dentry->d_count,
+			val->u.ln->l_dentry.dentry->d_name.name );
+		val=val->prev;
+	}
+}
+
+/* free work space*/
+static void print_var_values(struct reiser4_syscall_w_space * ws /* work space ptr */)
+{
+	pars_var_t  * var;
+	var = ws->Head_pars_var;
+	while( var!=NULL ) {
+		printk("\n\n values of %s",var->w->u.name);
+		print_all_val( var );
+		var = var->next;
+	}
+}
+
+
+
+/* FIXME:NIKITA->VOVA code below looks like custom made memory allocator. Why
+ * not to use slab? */
+#define INITNEXTFREESPACE(fs)	(fs)->free_space_next = NULL;                                      \
+                                (fs)->freeSpaceMax   = (fs)->freeSpaceBase+FREESPACESIZE;         \
+			        (fs)->freeSpace      = (fs)->freeSpaceBase
+
+
+/* allocate work space */
+static free_space_t * free_space_alloc()
+{
+	free_space_t * fs;
+	fs = ( free_space_t * ) kmalloc( sizeof( free_space_t ),GFP_KERNEL ) ;
+	assert("VD kmalloc work space",fs!=NULL);
+	memset( fs , 0, sizeof( free_space_t ));
+	INITNEXTFREESPACE(fs);
+	return fs;
+}
+
+#define GET_FIRST_FREESPHEAD(ws) (ws)->freeSpHead
+#define GET_NEXT_FREESPHEAD(curr) (curr)->free_space_next
+
+
+/* allocate next work space */
+static free_space_t * freeSpaceNextAlloc(struct reiser4_syscall_w_space * ws /* work space ptr */ )
+{
+	free_space_t * curr,* next;
+	curr=NULL;
+	next = GET_FIRST_FREESPHEAD(ws);
+	while (next) {
+		curr = next;
+		next = GET_NEXT_FREESPHEAD(curr);
+	}
+	next = free_space_alloc();
+	if(curr==NULL) 		{
+		ws->freeSpHead=next;
+	}
+	else {
+		curr->free_space_next=next;
+	}
+	next->free_space_next=NULL;
+	return next;
+}
+
+/* allocate field lenth=len in work space */
+static char* list_alloc(struct reiser4_syscall_w_space * ws/* work space ptr */,
+			int len/* lenth of structures to be allocated in bytes */)
+{
+	char * rez;
+	if( (ws->freeSpCur->freeSpace+len) > (ws->freeSpCur->freeSpaceMax) ) {
+		ws->freeSpCur = freeSpaceNextAlloc(ws);
+	}
+	rez = ws->freeSpCur->freeSpace;
+	ws->freeSpCur->freeSpace += ROUND_UP(len);
+	return rez;
+}
+
+/* allocate new level of parsing in work space */
+static streg_t *alloc_new_level(struct reiser4_syscall_w_space * ws /* work space ptr */ )
+{
+	return ( streg_t *)  list_alloc(ws,sizeof(streg_t));
+}
+
+/* allocate structure of new variable of input expression */
+static pars_var_t * alloc_pars_var(struct reiser4_syscall_w_space * ws /* work space ptr */,
+			     pars_var_t * last_pars_var /* last of allocated pars_var or NULL if list is empty */)
+{
+	pars_var_t * pars_var;
+	pars_var = (pars_var_t *)list_alloc( ws, sizeof( pars_var_t ) );
+	if ( last_pars_var == NULL ) {
+		ws->Head_pars_var = pars_var;
+	}
+	else {
+		last_pars_var->next = pars_var;
+	}
+	pars_var->val  = NULL;
+	pars_var->next = NULL;
+	return pars_var;
+}
+
+/* free lnodes used in expression */
+static int free_expr( struct reiser4_syscall_w_space * ws,  expr_v4_t * expr)
+{
+	expr_list_t * tmp;
+	int ret = 0;
+	assert("VD-free_expr", expr!=NULL);
+
+	printk("free_expr: %d\n", expr->h.type );
+	switch (expr->h.type) {
+	case EXPR_WRD:
+		break;
+	case EXPR_PARS_VAR:
+		printk ("free EXPR_PARS_VAR\n");
+		pop_var_val_stack( ws, expr->pars_var.v->val, 1 );
+		break;
+	case EXPR_LIST:
+		tmp=&expr->list;
+		while (tmp) {
+			assert("VD-free_expr.EXPR_LIST", tmp->h.type==EXPR_LIST);
+			ret |= free_expr( ws, tmp->source );
+			tmp = tmp->next;
+		}
+		break;
+	case EXPR_ASSIGN:
+		ret = pop_var_val_stack( ws, expr->assgn.target->val, 1 );
+		ret |= free_expr( ws, expr->assgn.source );
+		break;
+	case EXPR_LNODE:
+		printk ("free EXPR_LNODE\n");
+		assert("VD-free_expr.lnode.lnode", expr->lnode.lnode != NULL );
+		if ( expr->lnode.lnode->h.type == LNODE_DENTRY ) {
+		path4_release( &(expr->lnode.lnode->l_dentry) );
+		}
+		lput( expr->lnode.lnode );
+		break;
+	case EXPR_FLOW:
+		break;
+	case EXPR_OP2:
+		ret  = free_expr( ws, expr->op2.op_r );
+		ret |= free_expr( ws, expr->op2.op_l );
+		break;
+	case EXPR_OP:
+		ret = free_expr( ws, expr->op.op );
+		break;
+	}
+	return ret;
+}
+
+
+//ln->inode.inode->i_op->lookup(struct inode *,struct dentry *);
+//current->fs->pwd->d_inode->i_op->lookup(struct inode *,struct dentry *);
+
+#if 0
+/* alloca te space for lnode */
+static lnode * alloc_lnode(struct reiser4_syscall_w_space * ws /* work space ptr */ )
+{
+	lnode * ln;
+	ln = ( lnode * ) kmalloc( sizeof( lnode ), GFP_KERNEL);
+	assert("VD-alloc_pars_var", ln != NULL );
+	memset( ln , 0, sizeof( lnode ));
+	return ln;
+}
+#endif
+
+/* make lnode_dentry from inode for root and pwd */
+static lnode * get_lnode(struct reiser4_syscall_w_space * ws /* work space ptr */ )
+{
+	lnode * ln;
+	//	reiser4_key key, * k_rez,* l_rez;
+
+#if 0                      /*def NOT_YET*/
+	if ( is_reiser4_inode( ws->nd.dentry->inode ) ) {
+
+		k_rez             = build_sd_key( ws->nd.dentry->inode, &key);
+		ln                = lget(  LNODE_REISER4_INODE, get_inode_oid( ws->nd.dentry->inode) );
+		//			ln->lw.lw_sb = ws->nd.dentry->inode->isb;
+		ln->reiser4_inode.inode = /*????*/  ws->nd.dentry->inode->isb;
+		ln->reiser4_inode.inode = /*????*/  ws->nd.dentry->inode->isb;
+		PTRACE( ws, "r4: lnode=%p", ln );
+	}
+	else
+#endif
+		{
+			ln                = lget( LNODE_DENTRY, get_inode_oid( ws->nd.dentry->d_inode) );
+
+		}
+	return ln;
+}
+
+/*  allocate work space, initialize work space, tables, take root inode and PWD inode */
+static struct reiser4_syscall_w_space * reiser4_pars_init(void)
+{
+	struct reiser4_syscall_w_space * ws;
+
+	/* allocate work space for parser working variables, attached to this call */
+	ws = kmalloc( sizeof( struct reiser4_syscall_w_space ), GFP_KERNEL );
+	assert("VD_allock work space", ws != NULL);
+	memset( ws, 0, sizeof( struct reiser4_syscall_w_space ));
+	ws->ws_yystacksize = MAXLEVELCO; /* must be 500 by default */
+	ws->ws_yymaxdepth  = MAXLEVELCO; /* must be 500 by default */
+	                                                    /* allocate first part of working tables
+							       and initialise headers */
+	ws->freeSpHead          = free_space_alloc();
+	ws->freeSpCur           = ws->freeSpHead;
+	ws->wrdHead             = NULL;
+	ws->cur_level           = alloc_new_level(ws);
+	//	ws->root_e              = init_root(ws);
+	//	ws->cur_level->cur_exp  = init_pwd(ws);
+	ws->root_e              = init_root( ws, NULL, "/" );
+	ws->cur_level->cur_exp  = init_root( ws, ws->root_e->pars_var.v, current->fs->pwd->d_name.name );
+	ws->cur_level->wrk_exp  = ws->cur_level->cur_exp;                        /* current wrk for new level */
+	ws->cur_level->prev     = NULL;
+	ws->cur_level->next     = NULL;
+	ws->cur_level->level    = 0;
+	ws->cur_level->stype    = 0;
+	return ws;
+}
+
+#if 0
+static expr_v4_t * named_level_down(struct reiser4_syscall_w_space *ws /* work space ptr */,
+			     expr_v4_t * e /* name for expression  */,
+			     expr_v4_t * e1,
+			     long type /* type of level we going to */)
+{
+
+	static int push_var_val_stack( ws, struct pars_var * var, long type )
+
+	rezult->u.data  = kmalloc( SIZEFOR_ASSIGN_RESULT, GFP_KERNEL ) ;
+	sprintf( rezult->u.data, "%d", ret_code );
+
+	level_down( ws, , type2 );
+	return e1;
+}
+
+
+/* level up of parsing level */
+static void level_up_named(struct reiser4_syscall_w_space *ws /* work space ptr */,
+			   expr_v4_t * e1 /* name for expression  */,
+			   long type /* type of level we going to */)
+{
+	pars_var_t * rezult;
+
+	assert("wrong type of named expression", type == CD_BEGIN );
+
+	rezult =  e1->pars_var.v;
+	switch ( e1->pars_var.v->val->vtype) {
+	case VAR_EMPTY:
+		break;
+	case VAR_LNODE:
+		break;
+	case VAR_TMP:
+		break;
+	}
+
+	/* make name for w in this level. ????????
+	   not yet worked */
+
+
+	rezult =  lookup_pars_var_word( ws , sink, make_new_word(ws, ASSIGN_RESULT ), VAR_TMP);
+	rezult->u.data  = kmalloc( SIZEFOR_ASSIGN_RESULT, GFP_KERNEL ) ;
+	sprintf( rezult->u.data, "%d", ret_code );
+
+?????
+
+	level_up( ws, type );
+}
+
+#endif
+
+
+static expr_v4_t *target_name( expr_v4_t *assoc_name, expr_v4_t *target )
+{
+	target->pars_var.v->val->associated = assoc_name->pars_var.v;
+	return target;
+}
+
+/* level up of parsing level */
+static void level_up(struct reiser4_syscall_w_space *ws /* work space ptr */,
+		     long type /* type of level we going to */)
+{
+	if (ws->cur_level->next==NULL) {
+		ws->cur_level->next        = alloc_new_level(ws);
+		ws->cur_level->next->next  = NULL;
+		ws->cur_level->next->prev  = ws->cur_level;
+		ws->cur_level->next->level = ws->cur_level->level+1;
+	}
+	ws->cur_level           = ws->cur_level->next;
+	ws->cur_level->stype    = type;
+	ws->cur_level->cur_exp  = ws->cur_level->prev->wrk_exp;                  /* current pwd for new level */
+	ws->cur_level->wrk_exp  = ws->cur_level->cur_exp;                        /* current wrk for new level */
+}
+
+
+/* level down of parsing level */
+static  void  level_down(struct reiser4_syscall_w_space * ws /* work space ptr */,
+			 long type1 /* type of level that was up( for checking) */,
+			 long type2 /* type of level that is down(for checking)*/)
+{
+	pars_var_value_t * ret,*next;
+	assert("VD-level_down: type mithmatch", type1 == type2 );
+	assert("VD-level_down: type mithmatch with level", type1 == ws->cur_level->stype );
+	assert("VD-level_down: This is top level, prev == NULL", ws->cur_level->prev != NULL);
+	ret = ws->cur_level->val_level;
+	while( ret != NULL )
+		{
+			next = ret->next_level;
+			assert("VD: level down: not top value was pop", ret == ret->host->val);
+			pop_var_val_stack( ws, ret, 1 );
+			ret = next;
+		}
+	free_expr( ws, ws->cur_level->prev->wrk_exp );
+	ws->cur_level->prev->wrk_exp = ws->cur_level->wrk_exp ;           /* current wrk for prev level */
+	ws->cur_level                = ws->cur_level->prev;
+}
+
+/* copy name from param to free space,*/
+static  wrd_t * make_new_word(struct reiser4_syscall_w_space * ws /* work space ptr */,
+	      char *txt /* string to put in name table */)
+{
+	ws->tmpWrdEnd = ws->freeSpCur->freeSpace;
+	strcat( ws->tmpWrdEnd, txt );
+	ws->tmpWrdEnd += strlen(txt) ;
+	*ws->tmpWrdEnd++ = 0;
+	return _wrd_inittab( ws );
+}
+
+
+/* move_selected_word - copy term from input bufer to free space.
+ * if it need more, move freeSpace to the end.
+ * otherwise next term will owerwrite it
+ *  freeSpace is a kernel space no need make getnam().
+ * exclude is for special for string: store without ''
+ */
+static void move_selected_word(struct reiser4_syscall_w_space * ws /* work space ptr */,
+			       int exclude  /* TRUE - for storing string without first and last symbols
+					       FALS - for storing names */,
+			       int press )
+{
+	int i;
+	/*	char * s= ws->ws_pline;*/
+	if (exclude) {
+		ws->yytext++;
+	}
+	for( ws->tmpWrdEnd = ws->freeSpCur->freeSpace; ws->yytext < curr_symbol(ws); ) {
+		i=0;
+#if 0
+		if ( lcls == Ste ) {
+			while( *ws->yytext == '\"' ) {
+				ws->yytext++;
+				i++;
+			}
+			while ( ws->yytext >  curr_symbol(ws) ) {
+				i--;
+				ws->yytext--;
+			}
+		}
+		if ( i ) for ( i/=2; i; i-- )      *ws->tmpWrdEnd++='\"';    /*   in source text for each "" - result will "   */
+#endif
+		/*         \????????   */
+		if ( press && *ws->yytext == '\\' ) {
+			int tmpI;
+			ws->yytext++;
+			switch ( tolower( (int)*(ws->yytext) ) ) {
+			case 'x':                       /*  \x01..9a..e  */
+				i = 0;
+				tmpI = 1;
+				while( tmpI) {
+					if (isdigit( (int)*(ws->yytext) ) ) {
+						i = (i << 4) + ( *ws->yytext++ - '0' );
+					}
+					else if( tolower( (int) *(ws->yytext) ) >= 'a' && tolower( (int)*(ws->yytext) ) <= 'e' ) {
+						i = (i << 4) + ( *ws->yytext++ - 'a' + 10 );
+						}
+					else {
+						if ( tmpI & 1 ) {
+							yyerror( ws, LEX_XFORM ); /* x format has odd number of symbols */
+						}
+						tmpI = 0;
+					}
+					if ( tmpI && !( tmpI++ & 1 ) ) {
+						*ws->tmpWrdEnd++ = (unsigned char) i;
+						i = 0;
+					}
+				}
+				break;
+			}
+		}
+		else *ws->tmpWrdEnd++ = *ws->yytext++;
+		if( ws->tmpWrdEnd > (ws->freeSpCur->freeSpaceMax - sizeof(wrd_t)) ) {
+			free_space_t * tmp;
+			int i;
+			assert ("VD sys_reiser4. selectet_word:Internal space buffer overflow: input token exceed size of bufer",
+				ws->freeSpCur->freeSpace > ws->freeSpCur->freeSpaceBase);
+			/* we can reallocate new space and copy all
+			   symbols of current token inside it */
+			tmp=ws->freeSpCur;
+			ws->freeSpCur = freeSpaceNextAlloc(ws);
+			assert ("VD sys_reiser4:Internal text buffer overflow: no enouse mem", ws->freeSpCur !=NULL);
+			i = ws->tmpWrdEnd - tmp->freeSpace;
+			memmove( ws->freeSpCur->freeSpace, tmp->freeSpace, i );
+			ws->tmpWrdEnd = ws->freeSpCur->freeSpace + i;
+		}
+	}
+	if (exclude) {
+		ws->tmpWrdEnd--;
+	}
+	*ws->tmpWrdEnd++ = '\0';
+}
+
+
+/* compare parsed word with keywords*/
+static int b_check_word(struct reiser4_syscall_w_space * ws /* work space ptr */)
+{
+	int i, j, l;
+	j=sizeof(pars_key)/(sizeof(char*)+sizeof(int))-1;
+	l=0;
+	while( ( j - l ) >= 0 ) {
+		i  =  ( j + l /*+ 1*/ ) >> 1;
+		switch( strcmp( pars_key[i].wrd, ws->freeSpCur->freeSpace ) ) {
+		case  0:
+			return( pars_key[i].class );
+			break;
+		case  1: j = i - 1;               break;
+		default: l = i + 1;               break;
+		}
+	}
+	return(0);
+}
+
+
+/* comparing parsed word with already stored words, if not compared, storing it */
+static
+//__inline__
+wrd_t * _wrd_inittab(struct reiser4_syscall_w_space * ws /* work space ptr */ )
+{
+	wrd_t * cur_wrd;
+	wrd_t * new_wrd;
+	int len;
+	new_wrd =  ws->wrdHead;
+#if 0
+	len = strlen( ws->freeSpCur->freeSpace) ;
+#else
+	len = ws->tmpWrdEnd - ws->freeSpCur->freeSpace - 1 ;
+#endif
+	cur_wrd = NULL;
+	while ( !( new_wrd == NULL ) ) {
+		cur_wrd = new_wrd;
+		if ( cur_wrd->u.len == len ) {
+			if( !memcmp( cur_wrd->u.name, ws->freeSpCur->freeSpace, cur_wrd->u.len ) ) {
+				return cur_wrd;
+			}
+		}
+		new_wrd = cur_wrd->next;
+	}
+	new_wrd         = ( wrd_t *)(ws->freeSpCur->freeSpace + ROUND_UP( len+1 ));
+	new_wrd->u.name = ws->freeSpCur->freeSpace;
+	new_wrd->u.len  = len;
+	ws->freeSpCur->freeSpace= (char*)new_wrd + ROUND_UP(sizeof(wrd_t));
+	new_wrd->next   = NULL;
+	if (cur_wrd==NULL) {
+		ws->wrdHead   = new_wrd;
+	}
+	else {
+		cur_wrd->next = new_wrd;
+	}
+	return new_wrd;
+}
+
+/* lexical analisator for yacc automat */
+static int reiser4_lex( struct reiser4_syscall_w_space * ws /* work space ptr */)
+{
+	char term, n, i = 0;
+	int ret = 0;
+	char lcls;
+//	char * s ;
+
+//	s = curr_symbol(ws);              /* first symbol or Last readed symbol of the previous token parsing */
+	if ( *curr_symbol(ws) == 0 ) return  0;        /* end of string is EOF */
+
+	while(ncl[(int)*curr_symbol(ws)]==Blk) {
+		next_symbol(ws);
+		if ( *curr_symbol(ws) == 0 ) return  0;  /* end of string is EOF */
+	}
+
+
+	lcls    =       ncl[(int)*curr_symbol(ws)];
+	ws->yytext  = curr_symbol(ws);
+	term = 1;
+	while( term ) {
+		n=lcls;
+		while (  n > 0   ) {
+			next_symbol(ws);
+			lcls=n;
+			n = lexcls[ (int)lcls ].c[ (int)i=ncl[ (int)*curr_symbol(ws) ] ];
+		}
+		if ( n == OK ) {
+			term=0;
+		}
+		else {
+			yyerror ( ws, LEXERR2, (lcls-1)* 20+i );
+			return(0);
+		}
+	}
+	switch (lcls) {
+	case Blk:
+		yyerror(ws,LEX_Ste);
+		break;
+	case Wrd:
+	case W_e: /*`......"*/
+		if ( lcls == W_e ) {
+			move_selected_word( ws, lexcls[(int) lcls ].c[0], 0 );
+		}
+		else {
+			move_selected_word( ws, lexcls[(int) lcls ].c[0], 1 );
+		}
+		                                                    /* if ret>0 this is keyword */
+		if ( !(ret = b_check_word(ws)) ) {                          /*  this is not keyword. tray check in worgs. ret = Wrd */
+			ret=lexcls[(int) lcls ].term;
+			ws->ws_yylval.wrd = _wrd_inittab(ws);
+		}
+		break;
+	case Int:
+	case Ptr:
+	case Pru:
+	case Ste: 
+		move_selected_word( ws, lexcls[(int) lcls ].c[0], 1 );
+		ret=lexcls[(int) lcls ].term;
+		ws->ws_yylval.wrd = _wrd_inittab(ws);
+		break;
+		/*
+		  move_selected_word( ws, lexcls[ lcls ].c[0], 1 );
+		  ret=lexcls[ lcls ].term;
+		  ws->ws_yyval.w = _wrd_inittab(ws);
+		  break;
+		*/
+	case Com:
+	case Mns:
+	case Les:
+	case Slh:
+	case Bsl: /*\ */
+	case Sp1: /*;*/
+	case Sp2: /*:*/
+	case Dot: /*.*/
+	case Sp4: /*=*/
+	case Sp5: /*>*/
+	case Sp6: /*?*/
+	case ASG:/*<-*/
+	case App:/*<<-*/ /*???*/
+	case Lnk:/*->*/
+	case Pls:/*+*/
+	case Nam:/*<=*/
+		ret=lexcls[(int) lcls ].term;
+		break;
+	case Lpr:
+	case Rpr:
+		ws->ws_yylval.charType = CD_BEGIN ;
+		ret=lexcls[(int) lcls ].term;
+		break;
+	case Lsq:
+	case Rsq:
+		ws->ws_yylval.charType = UNORDERED ;
+		ret=lexcls[(int) lcls ].term;
+		break;
+	case Lfl:
+	case Rfl:
+		ws->ws_yylval.charType = ASYN_BEGIN ;
+		ret=lexcls[(int) lcls ].term;
+		break;
+	default :                                /*  others  */
+		ret=*ws->yytext;
+		break;
+	}
+	printk("lexer:%d\n", ret );
+	return ret;
+}
+
+
+
+/*==========================================================*/
+
+/* allocate new expression @type */
+static expr_v4_t * alloc_new_expr(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				  int type /* type of new expression */)
+{
+	expr_v4_t * e;
+	e         = ( expr_v4_t *)  list_alloc( ws, sizeof(expr_v4_t));
+	e->h.type = type;
+	return e;
+}
+
+/* store NULL name in word table */
+wrd_t * nullname(struct reiser4_syscall_w_space * ws /* work space ptr */)
+{
+	return make_new_word(ws,"");
+}
+
+#if 0
+/* initialize node  for root lnode */
+static expr_v4_t *  init_root(struct reiser4_syscall_w_space * ws /* work space ptr */)
+{
+	expr_v4_t * e;
+	e                     = alloc_new_expr( ws, EXPR_PARS_VAR );
+	e->pars_var.v         = alloc_pars_var( ws, NULL );
+	e->pars_var.v->w      = make_new_word(ws,"/") ; /* or '/' ????? */
+	e->pars_var.v->parent = NULL;
+	ws->nd.flags          = LOOKUP_NOALT;
+//	walk_init_root( "/", (&ws->nd));   /* from namei.c walk_init_root */
+	{
+		read_lock(&current->fs->lock);
+		ws->nd.mnt = my_mntget("root", current->fs->rootmnt);
+		ws->nd.dentry = my_dget("root", current->fs->root);
+		read_unlock(&current->fs->lock);
+	}
+
+	if ( push_var_val_stack( ws, e->pars_var.v, VAR_LNODE ) ) {
+		printk("VD-init_root: push_var_val_stack error\n");
+	}
+	else {
+		e->pars_var.v->val->u.ln                = get_lnode( ws );
+		e->pars_var.v->val->u.ln->dentry.mnt    = ws->nd.mnt;
+		e->pars_var.v->val->u.ln->dentry.dentry = ws->nd.dentry;
+	}
+	return e;
+}
+
+
+/* initialize node  for PWD lnode */
+static expr_v4_t *  init_pwd(struct reiser4_syscall_w_space * ws /* work space ptr */)
+{
+	expr_v4_t * e;
+	e                     = alloc_new_expr(ws,EXPR_PARS_VAR);
+	e->pars_var.v         = alloc_pars_var(ws,ws->root_e->pars_var.v);
+	e->pars_var.v->parent = ws->root_e->pars_var.v;
+//	path_lookup(".",,&(ws->nd));   /* from namei.c path_lookup */
+	{
+		read_lock(&current->fs->lock);
+		ws->nd.mnt    = my_mntget("pwd",current->fs->pwdmnt);
+		ws->nd.dentry = my_dget("pwd",current->fs->pwd);
+		read_unlock(&current->fs->lock);
+	}
+	e->pars_var.v->w          = make_new_word( ws, current->fs->pwd->d_name.name) ;
+	current->total_link_count = 0;
+	if ( push_var_val_stack( ws, e->pars_var.v, VAR_LNODE ) ) {
+		printk("VD-init_pwd: push_var_val_stack error\n");
+	}
+	else {
+		e->pars_var.v->val->u.ln                = get_lnode( ws );
+		e->pars_var.v->val->u.ln->dentry.mnt    = ws->nd.mnt;
+		e->pars_var.v->val->u.ln->dentry.dentry = ws->nd.dentry;
+	}
+	return e;
+}
+
+
+
+
+/* initialize node  for PWD lnode */
+static expr_v4_t *  init_pseudo_name(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				     char *name /* name of pseudo */)
+{
+	expr_v4_t * e;
+	e                     = alloc_new_expr(ws,EXPR_PARS_VAR);
+	e->pars_var.v         = alloc_pars_var(ws,ws->root_e->pars_var.v);
+	e->pars_var.v->w      = make_new_word(ws, name);
+	e->pars_var.v->parent = ws->root_e->pars_var.v;
+
+	current->total_link_count = 0;
+	push_var_val_stack( ws, e->pars_var.v, VAR_LNODE );
+	e->pars_var.v->val->u.ln = get_lnode( ws );
+	return e;
+}
+
+static expr_v4_t *  pars_lookup(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2)
+{
+	not ready;
+	pars_var_t * rez_pars_var;
+	pars_var_t * this_l;
+	this_l = getFirstPars_Var(e1);
+	while(this_l != NULL ) {
+	}
+	assert("pars_lookup:lnode is null",rez_pars_var->ln!=NULL);
+	memcpy( &curent_dentry.d_name   , w, sizeof(struct qstr));<---------------
+		if( ( rez_pars_var->ln = pars_var->ln->d_inode->i_op->lookup( pars_var->ln->d_inode, &curent_dentry) ) == NULL ) {
+			/* lnode not exist: we will not need create it. this is error*/
+		}
+}
+
+#endif
+
+/* initialize node  for ROOT and PWD lnode  */
+static expr_v4_t *  init_root(struct reiser4_syscall_w_space * ws /* work space ptr */,
+			   pars_var_t * parent,
+			   char * name)
+{
+	expr_v4_t * e;
+	e                     = alloc_new_expr( ws, EXPR_PARS_VAR);
+	e->pars_var.v         = alloc_pars_var( ws, parent);
+	e->pars_var.v->parent = parent;
+	if ( parent == NULL ) {
+		//	walk_init_root( "/", (&ws->nd));   /* from namei.c walk_init_root */
+		read_lock(&current->fs->lock);
+		ws->nd.mnt    = mntget( current->fs->rootmnt); 
+		ws->nd.dentry = dget( current->fs->root);
+		read_unlock(&current->fs->lock);
+		printk ("get  root\n");
+		print_pwd_count("dget root ");
+	}
+	else {
+		//	path_lookup(".",,&(ws->nd));   /* from namei.c path_lookup */
+		read_lock(&current->fs->lock);
+		ws->nd.mnt    = mntget(current->fs->pwdmnt);
+		ws->nd.dentry = dget(current->fs->pwd);
+		read_unlock(&current->fs->lock);
+		printk ("get    pwd\n");
+		print_pwd_count("dget pwd ");
+	}
+	e->pars_var.v->w          = make_new_word( ws, name ) ;
+	current->total_link_count = 0;
+	if ( push_var_val_stack( ws, e->pars_var.v, VAR_LNODE ) ) {
+		printk("VD-init_pwd: push_var_val_stack error\n");
+	}
+	else {
+		e->pars_var.v->val->u.ln                  = get_lnode( ws );
+		e->pars_var.v->val->u.ln->l_dentry.mnt    = ws->nd.mnt;
+		e->pars_var.v->val->u.ln->l_dentry.dentry = ws->nd.dentry;
+	}
+	return e;
+}
+
+/*    Object_Name : begin_from name                 %prec ROOT       { $$ = pars_expr( ws, $1, $2 ) ; }
+                  | Object_Name SLASH name                           { $$ = pars_expr( ws, $1, $3 ) ; }  */
+static expr_v4_t *  pars_expr(struct reiser4_syscall_w_space * ws /* work space ptr */,
+			      expr_v4_t * e1 /* first expression ( not yet used)*/,
+			      expr_v4_t * e2 /* second expression*/)
+{
+	ws->cur_level->wrk_exp = e2;
+	print_var_values(ws);
+	return e2;
+}
+
+/* not yet */
+static pars_var_t * getFirstPars_VarFromExpr(struct reiser4_syscall_w_space * ws )
+{
+	pars_var_t * ret = 0;
+	expr_v4_t * e = ws->cur_level->wrk_exp;
+	switch (e->h.type) {
+	case EXPR_PARS_VAR:
+		ret = e->pars_var.v;
+		break;
+		//	default:
+
+	}
+	return ret;
+}
+
+/* seach @parent/w in internal table. if found return it, else @parent->lookup(@w) */
+static pars_var_t * lookup_pars_var_word(struct reiser4_syscall_w_space * ws /* work space ptr */,
+					 pars_var_t * parent /* parent for w       */,
+					 wrd_t * w        /* to lookup for word */,
+					 int type)
+{
+	pars_var_t * rez_pars_var;
+	struct dentry *de;
+	//	int rez;
+	pars_var_t * last_pars_var;
+	last_pars_var  = NULL;
+	rez_pars_var   = ws->Head_pars_var;
+	printk("lookup_pars_var_word: parent: %p \n", parent);
+	while ( rez_pars_var != NULL ) {
+		if( rez_pars_var->parent == parent &&
+		    rez_pars_var->w      == w ) {
+			rez_pars_var->val->count++;
+			return rez_pars_var;
+		}
+		last_pars_var = rez_pars_var;
+		rez_pars_var  = rez_pars_var->next;
+	}
+//	reiser4_fs        = 0;
+	rez_pars_var         = alloc_pars_var(ws, last_pars_var);
+	rez_pars_var->w      = w;
+	rez_pars_var->parent = parent;
+
+	switch (parent->val->vtype) {
+	case VAR_EMPTY:
+		break;
+	case VAR_LNODE:
+		switch (parent->val->u.ln->h.type) {
+		case LNODE_INODE:  /* not use it ! */
+			de = d_alloc_anon(parent->val->u.ln->l_inode.inode);
+			break;
+		case LNODE_DENTRY:
+			ws->nd.dentry = parent->val->u.ln->l_dentry.dentry;
+			ws->nd.mnt    = parent->val->u.ln->l_dentry.mnt;
+			ws->nd.flags  = LOOKUP_NOALT ;
+			if ( link_path_walk( w->u.name, &(ws->nd) ) ) /* namei.c */ {
+				printk("lookup error\n");
+				push_var_val_stack( ws, rez_pars_var, VAR_TMP );
+				rez_pars_var->val->u.ln = NULL;
+			}
+			else {
+				push_var_val_stack( ws, rez_pars_var, VAR_LNODE );
+				lnode_type type = get_inode_oid( ws->nd.dentry->d_inode);
+				rez_pars_var->val->u.ln = reiser4_get_ln( ws, lget( LNODE_DENTRY, type ) );
+#if 0
+				{
+#if 0
+					read_lock(&current->fs->lock);
+					rez_pars_var->val->u.ln->l_dentry.mnt    = my_mntget("lget", ws->nd.mnt); 
+					rez_pars_var->val->u.ln->l_dentry.dentry = my_dget("lget", ws->nd.dentry);
+					read_unlock(&current->fs->lock);
+#else
+					rez_pars_var->val->u.ln->l_dentry.mnt    = mntget(ws->nd.mnt);
+					rez_pars_var->val->u.ln->l_dentry.dentry = ws->nd.dentry;
+//					rez_pars_var->val->u.ln->l_dentry.dentry = dget(ws->nd.dentry);
+#endif
+				}
+#endif
+				printk ("get    %d,  name %s\n", ws->nd.dentry->d_count, ws->nd.dentry->d_name.name);
+				print_pwd_count("link_path");
+			}
+			break;
+			/*
+			  case LNODE_PSEUDO:
+			  PTRACE(ws, "parent pseudo=%p",parent->ln->pseudo.host);
+			  break;
+			*/
+		case LNODE_LW:
+			break;
+		case LNODE_REISER4_INODE:
+			rez_pars_var->val->u.ln->h.type        = LNODE_REISER4_INODE /* LNODE_LW */;
+#if 0                   /*   NOT_YET  ???? */
+			//			ln                = lget( LNODE_DENTRY, get_key_objectid(&key ) );
+			result = coord_by_key(get_super_private(parent->val->ln->lw.lw_sb)->tree,
+					      parent->val->ln->lw.key,
+					      &coord,
+					      &lh,
+					      ZNODE_READ_LOCK,
+					      FIND_EXACT,
+					      LEAF_LEVEL,
+					      LEAF_LEVEL,
+					      CBK_UNIQUE,
+					      0);
+			//			if (REISER4_DEBUG && result == 0)
+			//				check_sd_coord(coord, key);
+			if (result != 0) {
+				lw_key_warning(parent->val->ln->lw.key, result);
+			}
+			else {
+				switch(item_type_by_coord(coord)) {
+				case STAT_DATA_ITEM_TYPE:
+					printk("VD-item type is STAT_DATA\n");
+				case DIR_ENTRY_ITEM_TYPE:
+					printk("VD-item type is DIR_ENTRY\n");
+					iplug = item_plugin_by_coord(coord);
+					if (iplug->b.lookup != NULL) {
+						iplug->b.lookup();   /*????*/
+					}
+
+				case INTERNAL_ITEM_TYPE:
+					printk("VD-item type is INTERNAL\n");
+				case ORDINARY_FILE_METADATA_TYPE:
+				case OTHER_ITEM_TYPE:
+					printk("VD-item type is OTHER\n");
+				}
+			}
+			/*??  lookup_sd     find_item_obsolete */
+#endif
+		case LNODE_NR_TYPES:
+			break;
+		}
+		break;
+	case VAR_TMP:
+		push_var_val_stack( ws, rez_pars_var, VAR_TMP );
+		rez_pars_var->val->u.ln = NULL;
+		break;
+	}
+
+	return rez_pars_var;
+}
+
+
+/* search pars_var for @w */
+static expr_v4_t *  lookup_word(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				wrd_t * w /* word to search for */)
+{
+	expr_v4_t * e;
+	pars_var_t * cur_pars_var;
+#if 1           /* tmp.  this is fist version.  for II we need do "while" throus expression for all pars_var */
+	cur_pars_var        = ws->cur_level->wrk_exp->pars_var.v;
+#else
+	cur_pars_var       = getFirstPars_VarFromExpr(ws);
+	while(cur_pars_var!=NULL) {
+#endif
+		e                = alloc_new_expr( ws, EXPR_PARS_VAR );
+		e->pars_var.v    = lookup_pars_var_word( ws, cur_pars_var, w , VAR_LNODE);
+#if 0
+		cur_pars_var=getNextPars_VarFromExpr(ws);
+	}
+	all rezult mast be connected to expression.
+#endif
+	return e;
+}
+
+/* set work path in level to current in level */
+static inline expr_v4_t * pars_lookup_curr(struct reiser4_syscall_w_space * ws /* work space ptr */)
+{
+	printk("lookup curr\n");
+	ws->cur_level->wrk_exp  = ws->cur_level->cur_exp;                        /* current wrk for pwd of level */
+	return ws->cur_level->wrk_exp;
+}
+
+/* set work path in level to root */
+static inline expr_v4_t * pars_lookup_root(struct reiser4_syscall_w_space * ws)
+{
+	ws->cur_level->wrk_exp  = ws->root_e;                                    /* set current to root */
+	return ws->cur_level->wrk_exp;
+}
+
+
+
+#if 0
+/*?????*/
+
+/* implementation of lookup_name() method for hashed directories
+
+   it looks for name specified in @w in reiser4_inode @parent and if name is found - key of object found entry points
+   to is stored in @key */
+reiser4_internal int
+lookup_name_hashed_reiser4(reiser4_inode *parent /* reiser4 inode of directory to lookup for name in */,
+			    wrd_t *w             /* name to look for */,
+			    reiser4_key *key     /* place to store key */)
+{
+	int result;
+	coord_t *coord;
+	lock_handle lh;
+	const char *name;
+	int len;
+	reiser4_dir_entry_desc entry;
+
+	assert("nikita-1247", parent != NULL);
+	assert("nikita-1248", w != NULL);
+
+??	assert("vs-1486", dentry->d_op == &reiser4_dentry_operations);
+
+	result = reiser4_perm_chk(parent, lookup, parent, &w->u);
+
+
+	if (result != 0)
+		return 0;
+
+	name = w->u.name;
+	len = w->u.len;
+
+	if ( len > parent->pset->dir_item)
+		/* some arbitrary error code to return */
+		return RETERR(-ENAMETOOLONG);
+
+	coord = &reiser4_get_dentry_fsdata(dentry)->dec.entry_coord; ???????
+	coord_clear_iplug(coord);
+
+
+
+
+	init_lh(&lh);
+
+	ON_TRACE(TRACE_DIR | TRACE_VFS_OPS, "lookup inode: %lli \"%s\"\n", get_inode_oid(parent), dentry->d_name.name);
+
+	/* find entry in a directory. This is plugin method. */
+
+
+	//	result = find_entry(parent, dentry, &lh, ZNODE_READ_LOCK, &entry);
+
+
+	if (result == 0) {
+		/* entry was found, extract object key from it. */
+		result = WITH_COORD(coord, item_plugin_by_coord(coord)->s.dir.extract_key(coord, key));
+	}
+	done_lh(&lh);
+	return result;
+
+}
+
+node_plugin_by_node(coord->node)->lookup(coord->node, key, FIND_MAX_NOT_MORE_THAN, &twin);
+item_type_by_coord(coord)
+
+/*
+ * try to look up built-in pseudo file by its name.
+ */
+reiser4_internal int
+lookup_pseudo_file(reiser4_inode *parent /* reiser4 inode of directory to lookup for name in */,
+			    wrd_t *w             /* name to look for */,
+			    reiser4_key *key     /* place to store key */)
+     //		   struct dentry * dentry)
+{
+	reiser4_plugin *plugin;
+	const char     *name;
+	struct inode   *pseudo;
+	int             result;
+
+
+
+
+
+
+	assert("nikita-2999", parent != NULL);
+	assert("nikita-3000", dentry != NULL);
+
+	/* if pseudo files are disabled for this file system bail out */
+	if (reiser4_is_set(parent->i_sb, REISER4_NO_PSEUDO))
+		return RETERR(-ENOENT);
+
+	name = dentry->d_name.name;
+	pseudo = ERR_PTR(-ENOENT);
+	/* scan all pseudo file plugins and check each */
+	for_all_plugins(REISER4_PSEUDO_PLUGIN_TYPE, plugin) {
+		pseudo_plugin *pplug;
+
+		pplug = &plugin->pseudo;
+		if (pplug->try != NULL && pplug->try(pplug, parent, name)) {
+			pseudo = add_pseudo(parent, pplug, dentry);
+			break;
+		}
+	}
+	if (!IS_ERR(pseudo))
+		result = 0;
+	else
+		result = PTR_ERR(pseudo);
+	return result;
+}
+
+#endif
+
+static int lookup_pars_var_lnode(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				    pars_var_t * parent /* parent for w       */,
+				    wrd_t * w        /* to lookup for word */)
+{
+	//	struct dentry  * de, * de_rez;
+	int rez;
+	//	pars_var_t * rez_pars_var;
+	//	reiser4_key key,* k_rez;
+	//	coord_t coord;
+	//	lock_handle lh;
+	//	item_plugin *iplug;
+
+//		case EXPR_PARS_VAR:
+//			/* not yet */
+//			ws->nd.dentry=parent->ln->dentry.dentry;
+//			de_rez = link_path_walk( w->u.name, &(ws->nd) ); /* namei.c */
+//			break;
+
+	PTRACE(ws, " w->u.name= %p, u.name->%s, u.len=%d",w->u.name,w->u.name,w->u.len);
+
+	return rez;
+
+}
+
+
+
+
+/* if_then_else procedure */
+static expr_v4_t * if_then_else(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				expr_v4_t * e1 /* expression of condition */,
+				expr_v4_t * e2 /* expression of then */,
+				expr_v4_t * e3 /* expression of else */ )
+{
+	PTRACE(ws, "%s", "begin");
+	return e1;
+}
+
+/* not yet */
+static expr_v4_t * if_then(struct reiser4_syscall_w_space * ws /* work space ptr */,
+			   expr_v4_t * e1 /**/,
+			   expr_v4_t * e2 /**/ )
+{
+	PTRACE(ws, "%s", "begin");
+	return e1;
+}
+
+/* not yet */
+static void goto_end(struct reiser4_syscall_w_space * ws /* work space ptr */)
+{
+}
+
+
+/* STRING_CONSTANT to expression */
+static expr_v4_t * const_to_expr(struct reiser4_syscall_w_space * ws /* work space ptr */,
+			       wrd_t * e1 /* constant for convert to expression */)
+{
+	expr_v4_t * new_expr = alloc_new_expr(ws, EXPR_WRD );
+	new_expr->wd.s = e1;
+	return new_expr;
+}
+
+/* allocate EXPR_OP2  */
+static expr_v4_t * allocate_expr_op2(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr */,
+				      expr_v4_t * e2 /* second expr */,
+				      int  op        /* expression code */)
+{
+	expr_v4_t * ret;
+	ret = alloc_new_expr( ws, EXPR_OP2 );
+	assert("VD alloc op2", ret!=NULL);
+	ret->h.exp_code = op;
+	ret->op2.op_l = e1;
+	ret->op2.op_r = e2;
+	return ret;
+}
+
+/* allocate EXPR_OP  */
+static expr_v4_t * allocate_expr_op(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr */,
+ 				      int  op        /* expression code */)
+{
+	expr_v4_t * ret;
+	ret = alloc_new_expr(ws, EXPR_OP2 );
+	assert("VD alloc op2", ret!=NULL);
+	ret->h.exp_code = op;
+	ret->op.op = e1;
+	return ret;
+}
+
+
+/* concatenate expressions */
+static expr_v4_t * concat_expression(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of concating */,
+				      expr_v4_t * e2 /* second expr of concating */)
+{
+	return allocate_expr_op2( ws, e1, e2, CONCAT );
+}
+
+
+/* compare expressions */
+static expr_v4_t * compare_EQ_expression(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of comparing */,
+				      expr_v4_t * e2 /* second expr of comparing */)
+{
+	return allocate_expr_op2( ws, e1, e2, COMPARE_EQ );
+}
+
+
+static expr_v4_t * compare_NE_expression(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of comparing */,
+				      expr_v4_t * e2 /* second expr of comparing */)
+{
+	return allocate_expr_op2( ws, e1, e2, COMPARE_NE );
+}
+
+
+static expr_v4_t * compare_LE_expression(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of comparing */,
+				      expr_v4_t * e2 /* second expr of comparing */)
+{
+	return allocate_expr_op2( ws, e1, e2, COMPARE_LE );
+}
+
+
+static expr_v4_t * compare_GE_expression(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of comparing */,
+				      expr_v4_t * e2 /* second expr of comparing */)
+{
+	return allocate_expr_op2( ws, e1, e2, COMPARE_GE );
+}
+
+
+static expr_v4_t * compare_LT_expression(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of comparing */,
+				      expr_v4_t * e2 /* second expr of comparing */)
+{
+	return allocate_expr_op2( ws, e1, e2, COMPARE_LT );
+}
+
+
+static expr_v4_t * compare_GT_expression(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of comparing */,
+				      expr_v4_t * e2 /* second expr of comparing */)
+{
+	return allocate_expr_op2( ws, e1, e2, COMPARE_GT );
+}
+
+
+static expr_v4_t * compare_OR_expression(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of comparing */,
+				      expr_v4_t * e2 /* second expr of comparing */)
+{
+	return allocate_expr_op2( ws, e1, e2, COMPARE_OR );
+}
+
+
+static expr_v4_t * compare_AND_expression(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of comparing */,
+				      expr_v4_t * e2 /* second expr of comparing */)
+{
+	return allocate_expr_op2( ws, e1, e2, COMPARE_AND );
+}
+
+
+static expr_v4_t * not_expression(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of comparing */)
+{
+	return allocate_expr_op( ws, e1, COMPARE_NOT );
+}
+
+
+/**/
+static expr_v4_t * check_exist(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of comparing */)
+{
+	return e1;
+}
+
+/* union lists */
+static expr_v4_t * union_lists(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of connecting */,
+				      expr_v4_t * e2 /* second expr of connecting */)
+{
+	expr_list_t *next, *last;
+	assert("VD-connect_list", e1->h.type == EXPR_LIST);
+
+	last = (expr_list_t *)e1;
+	next = e1->list.next;
+                   /* find last in list */
+	while ( next ) {
+		last = next;
+		next = next->next;
+	}
+	if ( e2->h.type == EXPR_LIST ) {                       /* connect 2 lists */
+		last->next = (expr_list_t *) e2;
+	}
+	else {                      /* add 2 EXPR to 1 list */
+		next = (expr_list_t *) alloc_new_expr(ws, EXPR_LIST );
+		assert("VD alloct list", next!=NULL);
+		next->next = NULL;
+		next->source = e2;
+		last->next = next;
+	}
+	return e1;
+}
+
+
+/*  make list from expressions */
+static expr_v4_t * list_expression(struct reiser4_syscall_w_space * ws /* work space ptr */,
+				      expr_v4_t * e1 /* first expr of list */,
+				      expr_v4_t * e2 /* second expr of list */)
+{
+	expr_v4_t * ret;
+
+	if ( e1->h.type == EXPR_LIST ) {
+		ret = union_lists( ws, e1, e2);
+	}
+	else {
+
+		if ( e2->h.type == EXPR_LIST ) {
+			ret = union_lists( ws, e2, e1);
+		}
+		else {
+			ret = alloc_new_expr(ws, EXPR_LIST );
+			assert("VD alloct list 1", ret!=NULL);
+			ret->list.source = e1;
+			ret->list.next = (expr_list_t *)alloc_new_expr(ws, EXPR_LIST );
+			assert("VD alloct list 2",ret->list.next!=NULL);
+			ret->list.next->next = NULL;
+			ret->list.next->source = e2;
+		}
+	}
+	return ret;
+}
+
+
+
+static expr_v4_t * list_async_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2 )
+{
+	return list_expression( ws, e1 , e2  );
+}
+
+
+static expr_v4_t * unname( struct reiser4_syscall_w_space * ws, expr_v4_t * e1 )
+{
+	return e1;
+}
+
+
+
+static expr_v4_t * assign(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2)
+{
+	/* while for each pars_var in e1 */
+	return pump( ws, e1->pars_var.v, e2 );   /* tmp.  */
+}
+
+
+
+static expr_v4_t * assign_invert(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2)
+{
+	return e2;
+}
+
+/* not yet */
+static expr_v4_t * symlink(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2)
+{
+	return e2;
+}
+
+
+
+/*
+ A flow is a source from which data can be obtained. A Flow can be one of these types:
+
+   1. memory area in user space. (char *area, size_t length)
+   2. memory area in kernel space. (caddr_t *area, size_t length)
+   3. file-system object (lnode *obj, loff_t offset, size_t length)
+*/
+#if 0
+typedef struct connect connect_t;
+
+struct connect
+{
+	expr_v4_t * (*u)(pars_var_t *dst, expr_v4_t *src);
+};
+
+static expr_v4_t * reiser4_assign( pars_var_t *dst, expr_v4_t *src )
+{
+    int           ret_code;
+    file_plugin  *src_fplug;
+    file_plugin  *dst_fplug;
+    connect_t     connection;
+
+    /*
+     * select how to transfer data from @src to @dst.
+     *
+     * Default implementation of this is common_transfer() (see below).
+     *
+     * Smart file plugin can choose connection based on type of @dst.
+     *
+     */
+#if 0
+    connection = dst->v->fplug -> select_connection( src, dst );
+#else
+    /*    connection.u=common_transfer;*/
+#endif
+
+    /* do transfer */
+    return common_transfer( &dst, &src );
+}
+
+#endif
+
+
+static  int source_not_empty(expr_v4_t *source)
+{
+	return 0;
+}
+
+static mm_segment_t __ski_old_fs;
+
+
+#define START_KERNEL_IO_GLOB	                \
+		__ski_old_fs = get_fs();	\
+		set_fs( KERNEL_DS )
+
+#define END_KERNEL_IO_GLOB			\
+		set_fs( __ski_old_fs );
+
+#define PUMP_BUF_SIZE (PAGE_CACHE_SIZE)
+
+
+static int push_tube_stack( tube_t * tube, long type, void * pointer )
+{
+	sourece_stack_t * ret;
+	ret = kmalloc( sizeof(struct sourece_stack), GFP_KERNEL );
+	if (!IS_ERR(ret)) {
+		ret->prev        = tube->st_current;
+		ret->type        = type;
+		ret->u.pointer   = pointer;
+		tube->st_current = ret;
+		return 0;
+	}
+	else {
+		return PTR_ERR(ret);
+	}
+}
+
+static int push_tube_list_stack_done(tube_t * tube)
+{
+	tube->next->prev = tube->st_current;
+	tube->st_current = tube->last;
+	tube->last       = NULL;
+	tube->next       = NULL;
+	return 0;
+}
+
+
+static int push_tube_list_stack_init( tube_t * tube, long type, void * pointer )
+{
+	//	sourece_stack_t * ret;
+	tube->last = kmalloc( sizeof(struct sourece_stack), GFP_KERNEL );
+	if (!IS_ERR(tube->last)) {
+		tube->next            = tube->last;
+		tube->last->type      = type;
+		tube->last->u.pointer = pointer;
+		return 0;
+	}
+	else {
+		return PTR_ERR(tube->last);
+	}
+}
+
+static int push_tube_list_stack(tube_t * tube, long type, void * pointer )
+{
+	sourece_stack_t * ret;
+	ret = kmalloc( sizeof(struct sourece_stack), GFP_KERNEL );
+	if (!IS_ERR(ret)) {
+		tube->next->prev = ret;
+		ret->type        = type;
+		ret->u.pointer   = pointer;
+		tube->next       = ret;
+		return 0;
+	}
+	else {
+		return PTR_ERR(ret);
+	}
+}
+
+static int change_tube_stack(tube_t * tube, long type, void * pointer )
+{
+	tube->st_current->type       = type;
+	tube->st_current->u.pointer  = pointer;
+	return 0;
+}
+
+static int pop_tube_stack( tube_t * tube )
+{
+	sourece_stack_t * ret;
+	if ( tube->st_current == NULL ) {
+		return -1;
+	}
+	else {
+		ret              = tube->st_current;
+		tube->st_current = tube->st_current->prev;
+		kfree( ret );
+		return 0;
+	}
+}
+
+static int push_var_val_stack(struct reiser4_syscall_w_space *ws /* work space ptr */,
+			      struct pars_var * var,
+			      long type)
+{
+	pars_var_value_t * ret;
+	ret = kmalloc( sizeof(pars_var_value_t), GFP_KERNEL );
+	if (!IS_ERR(ret)) {
+		memset( ret , 0, sizeof( pars_var_value_t ));
+		ret->prev       = var->val;
+		ret->vtype      = type;
+		ret->host       = var;
+		ret->count      = 1;
+		ret->len        = -1;
+		ret->off        = 0;
+		ret->next_level = ws->cur_level->val_level;
+		ws->cur_level->val_level = ret;
+		var->val        = ret;
+		return 0;
+	}
+	else {
+		return PTR_ERR(ret);
+	}
+}
+
+static int pop_var_val_stack( struct reiser4_syscall_w_space *ws /* work space ptr */,
+			      pars_var_value_t * val, /* value for free */
+			      int tmp_only /* free only if tmp value */)
+{
+	//	pars_var_value_t * ret;
+	if ( val == NULL ) {
+		return -1;
+	}
+	else {
+		switch(val->vtype) {
+		case VAR_EMPTY:
+			break;
+		case VAR_LNODE:
+			if ( !tmp_only )
+				{
+					assert("VD-pop_var_val_stack.VAR_LNODE", val->u.ln!=NULL);
+					printk("var->val->count %d\n", val->count );
+					//		if ( !--var->val->count )
+					{
+						path4_release( &(val->u.ln->l_dentry) );
+						lput( val->u.ln );
+					}
+					val->host->val           = val->prev;  // ???????
+//					ws->cur_level->val_level = val->next_level;
+					kfree( val );
+				}
+			break;
+		case VAR_TMP:
+			if (val->u.data!=NULL) {
+				kfree( val->u.data );
+			}
+			val->host->val           = val->prev;
+			ws->cur_level->val_level = val->next_level;
+			kfree( val );
+			break;
+		}
+		return 0;
+	}
+}
+
+
+/*  pop onto stack for calculate expressions one step */
+static void put_tube_src(tube_t * tube)
+{
+	/*  close readed file and pop stack */
+	switch (tube->st_current->type) {
+	case 	ST_FILE:
+		filp_close(tube->st_current->u.file, current->files );
+	case 	ST_DE:
+	case 	ST_WD:
+	case 	ST_DATA:
+		pop_tube_stack(tube);
+		break;
+	}
+}
+
+/* push & pop onto stack for calculate expressions one step */
+static int get_tube_next_src(tube_t * tube)
+{
+	expr_v4_t * s;
+	expr_list_t * tmp;
+	int ret;
+	struct file * fl;
+
+	tube->readoff=0;
+	assert ("VD stack is empty", tube->st_current != NULL );
+
+	/* check stack and change its head */
+	switch (tube->st_current->type) {
+	case 	ST_FILE:
+	case 	ST_DE:
+	case 	ST_WD:
+		ret = 0;
+		break;
+	case 	ST_EXPR:
+		s = tube->st_current->u.expr;
+		switch (s->h.type) {
+		case EXPR_WRD:
+			change_tube_stack( tube, ST_WD , s->wd.s );
+			break;
+		case EXPR_PARS_VAR:
+			assert("VD-free_expr.EXPR_PARS_VAR", s->pars_var.v!=NULL);
+			switch( s->pars_var.v->val->vtype) {
+			case VAR_EMPTY:
+				break;
+			case VAR_LNODE:
+				assert("VD-free_expr.EXPR_PARS_VAR.ln", s->pars_var.v->val->u.ln!=NULL);
+				//					if ( S_ISREG(s->pars_var.v->val->u.ln->dentry.dentry->d_inode) )
+				{
+					fl=  dentry_open( s->pars_var.v->val->u.ln->l_dentry.dentry,
+							  s->pars_var.v->val->u.ln->l_dentry.mnt, O_RDONLY ) ;
+					if ( !IS_ERR(fl) ) {
+						change_tube_stack( tube, ST_FILE , fl);
+					}
+					else printk("error for open source\n");
+				}
+#if 0          // not yet
+				else if ( S_ISDIR(s->pars_var.v->val->u.ln->dentry.dentry->d_inode) ) {
+					while(NOT EOF)
+						{
+							readdir();
+						}
+				}
+#endif
+				ret = 0;
+				break;
+			case VAR_TMP:
+				if ( s->pars_var.v->val->u.data == NULL )
+					{
+						pop_tube_stack( tube );
+						ret = 1;
+					}
+				else
+					{
+						change_tube_stack( tube, ST_DATA , s->pars_var.v->val->u.data);
+						ret = 0;
+					}
+				break;
+			}
+			break;
+		case EXPR_LIST:
+			tmp = &s->list;
+			push_tube_list_stack_init( tube, ST_EXPR , tmp->source );
+			while (tmp) {
+				tmp = tmp->next;
+				push_tube_list_stack( tube, ST_EXPR, tmp->source );
+			}
+			pop_tube_stack( tube );
+			push_tube_list_stack_done( tube );
+			ret = 1;
+			break;
+		case EXPR_ASSIGN:
+#if 0   // not yet
+			assert("VD-free_expr.EXPR_ASSIGN", s->assgn.target!=NULL);
+			assert("VD-free_expr.EXPR_ASSIGN.ln", s->assgn.target->ln!=NULL);
+			assert("VD-free_expr.EXPR_ASSIGN.count", s->assgn.target->val->count>0);
+			( s->assgn.target->ln);
+			( s->assgn.source );
+#endif
+			break;
+		case EXPR_LNODE:
+			assert("VD-free_expr.lnode.lnode", s->lnode.lnode!=NULL);
+//					if ( S_ISREG(s->lnode.lnode->dentry.dentry->d_inode) )
+			{
+				change_tube_stack( tube, ST_FILE ,
+						   dentry_open( s->lnode.lnode->l_dentry.dentry,
+								s->lnode.lnode->l_dentry.mnt, O_RDONLY ) );
+			}
+			ret = 0;
+			break;
+		case EXPR_FLOW:
+			break;
+		case EXPR_OP2:
+			change_tube_stack( tube, ST_EXPR , s->op2.op_r );
+			push_tube_stack( tube, ST_EXPR , s->op2.op_l );
+			ret = 1;
+			break;
+		case EXPR_OP:
+			change_tube_stack( tube, ST_EXPR , s->op.op );
+			ret = 1;
+			break;
+		}
+		break;
+	}
+	return ret;
+}
+
+
+static tube_t *  get_tube_general(tube_t * tube, pars_var_t *sink, expr_v4_t *source)
+{
+
+	//	char * buf;
+	tube = kmalloc( sizeof(struct tube), GFP_KERNEL);
+	if (!IS_ERR(tube)) {
+		START_KERNEL_IO_GLOB;
+		memset( tube , 0, sizeof( struct tube ));
+		assert("VD get_tube_general: no tube",!IS_ERR(tube));
+		printk("get_tube_general:%d\n",sink->val->vtype);
+		tube->target = sink;
+		switch( sink->val->vtype ) {
+		case VAR_EMPTY:
+			break;
+		case VAR_LNODE:
+			printk("VAR_LNODE\n");
+			assert("VD get_tube_general: dst no dentry",sink->val->u.ln->h.type== LNODE_DENTRY);
+			tube->dst         = dentry_open( sink->val->u.ln->l_dentry.dentry,
+							 sink->val->u.ln->l_dentry.mnt,
+							 O_WRONLY|O_TRUNC );
+			tube->writeoff    = 0;
+			tube->st_current  = NULL;
+			push_tube_stack( tube, ST_EXPR, (long *)source );
+			break;
+		case VAR_TMP:
+			printk("VAR_TMP\n");
+			break;
+		}
+	}
+	return tube;
+}
+
+static size_t reserv_space_in_sink(tube_t * tube )
+{
+	tube->buf = kmalloc( PUMP_BUF_SIZE, GFP_KERNEL);
+	if (!IS_ERR(tube->buf)) {
+		memset( tube->buf  , 0, PUMP_BUF_SIZE);
+		return PUMP_BUF_SIZE;
+	}
+	else {
+		return 0;
+	}
+}
+
+static size_t get_available_src_len(tube_t * tube)
+{
+	size_t len;
+	size_t s_len;
+	int ret = 1;
+	len = PUMP_BUF_SIZE;
+	while ( tube->st_current != NULL && ret ) {
+		ret = 0;
+		switch( tube->st_current->type ) {
+		case 	ST_FILE:
+			s_len = tube->st_current->u.file->f_dentry->d_inode->i_size;
+			/* for reiser4 find_file_size() */
+			break;
+		case 	ST_DE:
+			break;
+		case 	ST_WD:
+			s_len = tube->st_current->u.wd->u.len;
+			break;
+		case 	ST_EXPR:
+			while( tube->st_current != NULL && get_tube_next_src( tube ) ) ;
+			len = -1;
+			ret = 1;
+			break;
+		case ST_DATA:
+			s_len = strlen((char *)tube->st_current->u.pointer);
+			break;
+			}
+	}
+	s_len -= tube->readoff;
+	if (tube->st_current == NULL) {
+		len = 0;
+	}
+	else {
+		if ( len > s_len ) len = s_len;
+	}
+	return len;
+}
+
+static size_t prep_tube_general(tube_t * tube)
+{
+	size_t ret;
+	if ( tube->st_current != NULL ) {
+		ret = get_available_src_len( tube ) ;
+	}
+	else {
+		ret = 0;
+	}
+	tube->len = ret;
+	return ret;
+}
+
+
+
+static size_t source_to_tube_general(tube_t * tube)
+{
+	//	tube->source->fplug->read(tube->offset,tube->len);
+	size_t ret;
+	switch( tube->st_current->type ) {
+	case 	ST_FILE:
+		ret = vfs_read(tube->st_current->u.file, tube->buf, tube->len, &tube->readoff);
+		tube->len = ret;
+		break;
+	case 	ST_DE:
+		break;
+	case 	ST_WD:
+		if ( tube->readoff < tube->st_current->u.wd->u.len ) {
+			assert ("VD source to tube(wd)", tube->readoff+tube->len <= tube->st_current->u.wd->u.len);
+			memcpy( tube->buf,  tube->st_current->u.wd->u.name + tube->readoff, ret = tube->len );
+			tube->readoff += ret;
+		}
+		else ret = 0;
+		break;
+	case ST_DATA:
+		if ( tube->readoff < strlen((char *)tube->st_current->u.pointer) ) {
+			memcpy( tube->buf,  tube->st_current->u.pointer + tube->readoff, ret = tube->len );
+			tube->readoff += ret;
+		}
+		else ret = 0;
+		break;
+	}
+	return ret;
+}
+
+static size_t tube_to_sink_general(tube_t * tube)
+{
+	size_t ret;
+//	tube->sink->fplug->write(tube->offset,tube->len);
+//	tube->offset += tube->len;
+	switch(tube->target->val->vtype) {
+	case VAR_EMPTY:
+		break;
+	case VAR_LNODE:
+		ret = vfs_write(tube->dst, tube->buf, tube->len, &tube->writeoff);
+		break;
+	case VAR_TMP:
+		// memncpy(tube->target->data,tube->buf,tube->len);
+		// or
+		// tube->target->data=tube->buf;
+		// ?
+		printk("write to pseudo not yet work\n");
+		tube->writeoff+=tube->len;
+		break;
+	}
+	return ret;
+
+}
+
+static void put_tube(tube_t * tube)
+{
+	PTRACE1( "%s\n", "begin");
+	END_KERNEL_IO_GLOB;
+	assert("VD :stack not empty ",tube->st_current == NULL);
+	switch(tube->target->val->vtype) {
+	case VAR_EMPTY:
+		break;
+	case VAR_LNODE:
+		do_truncate( tube->dst->f_dentry, tube->writeoff);
+		filp_close(tube->dst, current->files );
+		break;
+	case VAR_TMP:
+		break;
+	}
+	kfree(tube->buf);
+	kfree(tube);
+}
+
+static int create_result_field(struct reiser4_syscall_w_space * ws,
+			       pars_var_t *parent,   /* parent for name */
+			       char * name ,         /* created name    */
+			       int result_len,       /* length of allocated space for value */
+			       int result)
+{
+	int ret;
+	wrd_t * tmp_wrd;
+	pars_var_t * rezult;
+
+	tmp_wrd = make_new_word(ws, name );
+	rezult =  lookup_pars_var_word( ws , parent, tmp_wrd, VAR_TMP);
+	if ( rezult != NULL ) {
+		rezult->val->u.data  = kmalloc( result_len, GFP_KERNEL ) ;
+		if ( rezult->val->u.data ) {
+			sprintf( rezult->val->u.data, "%d", result );
+			ret=0;
+		}
+	}
+	else {
+		ret = 1;
+	}
+	return ret;
+}
+
+static int create_result(struct reiser4_syscall_w_space * ws,
+			      pars_var_t *parent,   /* parent for name       */
+			      int err_code ,        /* error code of assign  */
+			      int length)           /* length of assign      */
+{
+	int ret;
+	ret  = create_result_field( ws, parent,
+			     ASSIGN_RESULT, SIZEFOR_ASSIGN_RESULT, err_code );
+	ret += create_result_field( ws, parent,
+			     ASSIGN_LENGTH, SIZEFOR_ASSIGN_LENGTH, length );
+	return ret;
+}
+
+
+
+/*
+  Often connection() will be a method that employs memcpy(). Sometimes
+  copying data from one file plugin to another will mean transforming
+  the data. What reiser4_assign does depends on the type of the flow
+  and sink. If @flow is based on the kernel-space area, memmove() is
+  used to copy data. If @flow is based on the user-space area,
+  copy_from_user() is used. If @flow is based on a file-system object,
+  flow_place() uses the page cache as a universal translator, loads
+  the object's data into the page cache, and then copies them into
+  @area. Someday methods will be written to copy objects more
+  efficiently than using the page cache (e.g. consider copying holes
+  [add link to definition of a hole]), but this will not be
+  implemented in V4.0.
+*/
+static expr_v4_t *  pump(struct reiser4_syscall_w_space * ws, pars_var_t *sink, expr_v4_t *source )
+{
+	//	pars_var_t * assoc;
+	expr_v4_t * ret;
+	tube_t * tube;
+	int ret_code;
+	size_t (*prep_tube)(tube_t *);
+	size_t (*source_to_tube)(tube_t *);
+	size_t (*tube_to_sink)(tube_t *);
+	PTRACE1( "%s", "begin");
+
+	/* remember to write code for freeing tube, error handling, etc. */
+#if 0
+	ret_code = sink->fplug -> get_tube( tube, sink, source);
+	prep_tube = sink->fplug->prep_tube (tube);
+	source_to_tube = source->fplug->source_to_tube;
+	tube_to_sink = sink->fplug->tube_to_sink;
+#else
+	tube       = get_tube_general( tube, sink, source);
+	if ( tube == NULL ) {
+		ret_code = -1;
+	}
+	else {
+		prep_tube      = prep_tube_general;
+		source_to_tube = source_to_tube_general;
+		tube_to_sink   = tube_to_sink_general;
+#endif
+		reserv_space_in_sink( tube );
+
+		while ( tube->st_current != NULL ) {
+			if ( ret_code = prep_tube( tube ) >0 ) {
+				while ( ret_code = source_to_tube( tube ) > 0 ) {
+					ret_code = tube_to_sink( tube );
+				}
+				if ( ret_code < 0 ) {
+					printk("IO error\n");
+				}
+				put_tube_src( tube );
+			}
+		}
+
+
+		ret=alloc_new_expr( ws, EXPR_PARS_VAR );
+		ret->pars_var.v = sink;
+
+		if ( sink->val->associated == NULL) {
+			create_result( ws, sink, ret_code, tube->writeoff );
+			//			ret->pars_var.v = sink;
+		}
+		else {
+			create_result( ws, sink->val->associated, ret_code, tube->writeoff );
+			//			ret->pars_var.v = sink->val->associated;
+			sink->val->associated = NULL;
+		}
+
+#if 0
+		tmp_wrd = make_new_word(ws, ASSIGN_RESULT );
+		rezult =  lookup_pars_var_word( ws , assoc, tmp_wrd, VAR_TMP);
+		rezult->val->u.data  = kmalloc( SIZEFOR_ASSIGN_RESULT, GFP_KERNEL ) ;
+		sprintf( rezult->val->u.data, "%d", ret_code );
+
+		tmp_wrd = make_new_word(ws, ASSIGN_LENGTH );
+		length =  lookup_pars_var_word( ws , assoc, tmp_wrd, VAR_TMP);
+		length->val->u.data  = kmalloc( SIZEFOR_ASSIGN_LENGTH, GFP_KERNEL ) ;
+		sprintf( length->val->u.data, "%d", tube->writeoff );
+
+
+		/*
+		ret1=alloc_new_expr( ws, EXPR_PARS_VAR );
+		ret->pars_var.v = rezult;
+		ret1=alloc_new_expr( ws, EXPR_PARS_VAR );
+		ret->pars_var.v = length;
+		ret = list_expression( ws, list_expression( ws, ret, ret1 ), ret2 ) ;
+		 */
+#endif
+		put_tube( tube );
+      }
+      return ret;
+}
+
+
+
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   End:
+*/
diff -puN /dev/null not-for-inclusion/parser/lib.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/lib.h	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,84 @@
+/*
+ * Copyright 2001, 2002 by Hans Reiser, licensing governed by reiser4/README
+ */
+
+/*
+ * functions for parser.y
+ */
+
+
+
+
+
+
+static void yyerror( struct reiser4_syscall_w_space *ws, int msgnum , ...);
+static int yywrap(void);
+static free_space_t * free_space_alloc(void);
+static void freeList(free_space_t * list);
+static int reiser4_pars_free(struct reiser4_syscall_w_space * ws);
+//static free_space_t * freeSpaceAlloc(void);
+static free_space_t * freeSpaceNextAlloc(struct reiser4_syscall_w_space * ws);
+static char* list_alloc(struct reiser4_syscall_w_space * ws, int size);
+static streg_t *alloc_new_level(struct reiser4_syscall_w_space * ws);
+static pars_var_t * alloc_pars_var(struct reiser4_syscall_w_space * ws, pars_var_t * last_pars_var);
+static int free_expr( struct reiser4_syscall_w_space * ws, expr_v4_t * expr);
+static lnode * get_lnode(struct reiser4_syscall_w_space * ws);
+static struct reiser4_syscall_w_space * reiser4_pars_init(void);
+static void level_up(struct reiser4_syscall_w_space *ws, long type);
+static  void  level_down(struct reiser4_syscall_w_space * ws, long type1, long type2);
+static void move_selected_word(struct reiser4_syscall_w_space * ws, int exclude, int press );
+static int b_check_word(struct reiser4_syscall_w_space * ws );
+static __inline__ wrd_t * _wrd_inittab(struct reiser4_syscall_w_space * ws );
+static int reiser4_lex( struct reiser4_syscall_w_space * ws );
+static expr_v4_t * alloc_new_expr(struct reiser4_syscall_w_space * ws, int type);
+wrd_t * nullname(struct reiser4_syscall_w_space * ws);
+static expr_v4_t *  init_root(struct reiser4_syscall_w_space * ws,pars_var_t * parent, char * name);
+//static expr_v4_t *  init_pwd(struct reiser4_syscall_w_space * ws);
+static expr_v4_t *  pars_expr(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static expr_v4_t *  lookup_word(struct reiser4_syscall_w_space * ws, wrd_t * w);
+static inline expr_v4_t * pars_lookup_curr(struct reiser4_syscall_w_space * ws);
+static inline expr_v4_t * pars_lookup_root(struct reiser4_syscall_w_space * ws);
+static pars_var_t *  lookup_pars_var_word(struct reiser4_syscall_w_space * ws, pars_var_t * pars_var, wrd_t * w, int type);
+//static expr_v4_t * make_do_it(struct reiser4_syscall_w_space * ws, expr_v4_t * e1 );
+static expr_v4_t * if_then_else(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2 , expr_v4_t * e3  );
+static expr_v4_t * if_then(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2 );
+static void goto_end(struct reiser4_syscall_w_space * ws);
+//static expr_v4_t * constToExpr(struct reiser4_syscall_w_space * ws, wrd_t * e1 );
+//static expr_v4_t * connect_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static expr_v4_t * compare_EQ_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static expr_v4_t * compare_NE_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static expr_v4_t * compare_LE_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static expr_v4_t * compare_GE_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static expr_v4_t * compare_LT_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static expr_v4_t * compare_GT_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static expr_v4_t * compare_OR_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static expr_v4_t * compare_AND_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static expr_v4_t * not_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1);
+static expr_v4_t * check_exist(struct reiser4_syscall_w_space * ws, expr_v4_t * e1);
+static expr_v4_t * list_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2 );
+static expr_v4_t * list_async_expression(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2 );
+static expr_v4_t * assign(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static expr_v4_t * assign_invert(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static expr_v4_t * symlink(struct reiser4_syscall_w_space * ws, expr_v4_t * e1, expr_v4_t * e2);
+static  int source_not_empty(expr_v4_t *source);
+static tube_t * get_tube_general(tube_t * tube, pars_var_t *sink, expr_v4_t *source);
+static size_t reserv_space_in_sink(tube_t * tube);
+//static size_t get_available_len(tube_t * tube);
+static size_t prep_tube_general(tube_t * tube);
+static size_t source_to_tube_general(tube_t * tube);
+static size_t tube_to_sink_general(tube_t * tube);
+static void put_tube(tube_t * tube);
+static expr_v4_t *  pump(struct reiser4_syscall_w_space * ws, pars_var_t *sink, expr_v4_t *source );
+
+static int pop_var_val_stack( struct reiser4_syscall_w_space *ws /* work space ptr */,
+			      pars_var_value_t * val, int tmp_only );
+static int push_var_val_stack(struct reiser4_syscall_w_space *ws /* work space ptr */,
+			      struct pars_var * var,
+			      long type );
+static expr_v4_t *target_name( expr_v4_t *assoc_name, expr_v4_t *target );
+
+#define curr_symbol(ws) ((ws)->ws_pline)
+#define next_symbol(ws)  (++curr_symbol(ws))
+#define tolower(a) a
+#define isdigit(a) ((a)>=0 && (a)<=9)
+
diff -puN /dev/null not-for-inclusion/parser/Makefile
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/Makefile	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,35 @@
+
+.SUFFIXES= .l .y .c
+
+GENSRCS= parser.code.c
+GENHDRS= y.t.h
+
+SRCS=	${GENSRCS} ${CSRCS}
+CLEANFILES= ${GENSRCS} ${GENHDRS} y.output
+
+# Override default kernel CFLAGS.  This is a userland app.
+# PARS_CFLAGS:= -I/usr/include -I. -ldb
+YFLAGS= -d -t -v -r -b parser
+
+
+YACC=./yacc
+
+#ifdef DEBUG
+CFLAGS+= -DDEBUG -g
+YFLAGS+= -t -v -r -b parser
+LFLAGS= -d
+#endif
+
+#$(PROG):  $(SRCS) $(GENHDRS)
+#	$(CC) $(PARS_CFLAGS) $(CFLAGS)  $(CSRCS) -o $(PROG)
+#	$(CC) $(PARS_CFLAGS) $(CFLAGS)  $(SRCS) -o $(PROG)
+
+clean:
+	rm -f $(CLEANFILES) $(PROG)
+
+parser.code.c: parser.y
+	$(YACC) $(YFLAGS) parser.y
+
+
+
+
diff -puN /dev/null not-for-inclusion/parser/pars.cls.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/pars.cls.h	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,242 @@
+/*
+ * Copyright 2001, 2002 by Hans Reiser, licensing governed by reiser4/README
+ */
+
+/*
+ * definitions of common constants for lex component of parser.y
+ */
+
+
+
+#define ERR  -128
+
+
+typedef enum {
+    OK   ,
+    Blk  ,   /* blank */
+    Wrd  ,   /* any symbol exept spec symbl */
+    Int  ,   /* numeric */
+
+    Ptr  ,   /* pointer */
+
+    Pru  ,   /* _pruner */
+
+    W_b  ,   /* ` string begin */
+    W_e  ,   /* ' string end */
+    Lpr  ,   /* ( */
+    Rpr  ,   /* ) */
+    Com  ,   /* , */
+    Mns  ,   /* - */
+
+
+    Les  ,   /* < */
+    Slh  ,   /* / */
+
+    Lsq  ,   /* [ */
+    Rsq  ,   /* ] */
+
+    Bsl  ,   /* \ */
+
+    Lfl  ,   /* { */
+    Rfl  ,   /* } */
+
+    Pip  ,   /* | */
+    Sp1  ,   /* : */
+    Sp2  ,   /* ; */
+
+    Dot  ,   /* . */
+
+    Sp4  ,   /* = */
+    Sp5  ,   /* > */
+    Sp6  ,   /* ? */
+    Pls  ,   /* +  ???*/
+    Res  ,   /*  */
+
+    Str  ,   /* " */
+    Ste  , 
+    ASG  ,
+    App  ,
+    Lnk  ,
+    Ap2  ,
+    Nam  ,
+    LastState
+} state;
+
+#define STRING_CONSTANT_EMPTY STRING_CONSTANT   /* tmp */
+
+static char   ncl     [256] = {
+	Blk,  ERR,  ERR,  ERR,  ERR,  ERR,  ERR,  ERR,
+	ERR,  ERR,  ERR,  ERR,  ERR,  ERR,  ERR,  ERR,
+	ERR,  ERR,  ERR,  ERR,  ERR,  ERR,  ERR,  ERR,
+	ERR,  ERR,  ERR,  ERR,  ERR,  ERR,  ERR,  ERR,
+	/* 32*/
+      /*        !     "    #     $     %     &     ' */
+	Blk,  Res,  Str,  Res,  Res,  Res,  Res,  W_e,
+      /* (      )     *    +     ,     -     .     / */
+        Lpr,  Rpr,  Res,  Pls,  Com,  Mns,  Dot,  Slh,
+      /* 0      1     2    3     4     5     6     7 */
+	Int,  Int,  Int,  Int,  Int,  Int,  Int,  Int,
+      /* 8      9     :    ;     <     =     >     ? */
+	Int,  Int,  Sp1,  Sp2,  Les,  Sp4,  Sp5,  Sp6,
+
+	/* 64*/
+      /* @      A     B    C     D     E     F     G */
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+      /* H      I     J    K     L     M     N     O */
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+      /* P      Q     R    S     T     U     V     W */
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+      /* X      Y     Z    [     \     ]     ^     _ */
+	Wrd,  Wrd,  Wrd,  Lsq,  Bsl,  Rsq,  Res,  Pru,
+	/* 96*/
+      /* `      a     b    c     d     e     f     g */
+        W_b,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+      /* h      i     j    k     l     m     n     o */
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+      /* p      q     r    s     t     u     v     w */
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+      /* x      y     z    {     |     }     ~       */
+	Wrd,  Wrd,  Wrd,  Lfl,  Pip,  Rfl,  Wrd,  ERR,
+
+	/*128*/
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	/*160*/
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	/*192*/
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	/*224*/
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,
+	Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  Wrd,  ERR
+};
+
+struct lexcls {
+  int term;
+  char c[32];
+} ;
+
+static struct {
+	char    *       wrd;
+	int             class;
+}
+pars_key [] = {
+  { "and"         ,    AND            },
+  { "else"        ,    ELSE           },
+  { "eq"          ,    EQ             },
+  { "ge"          ,    GE             },
+  { "gt"          ,    GT             },
+  { "if"          ,    IF             },
+  { "le"          ,    LE             },
+  { "lt"          ,    LT             },
+  { "ne"          ,    NE             },
+  { "not"         ,    NOT            },
+  { "or"          ,    OR             },
+  { "then"        ,    THEN           },
+  { "tw/"         ,    TRANSCRASH     }
+};
+
+
+struct lexcls lexcls[] = {
+/*
+..   a   1       _   `   '     (   )   ,   -   <   /   [   ]     \   {   }   |   ;   :   .   =     >   ?   +       "
+Blk Wrd Int Ptr Pru W_b W_e   Lpr Rpr Com Mns Les Slh Lsq Rsq   Bsl Lfl Rfl Pip Sp1 Sp2 Dot Sp4   Sp5 Sp6 Pls ... Str */
+[Blk]={ 0, {0,
+Blk,Wrd,Int,Ptr,Pru,Str,ERR,  Lpr,Rpr,Com,Mns,Les,Slh,Lsq,Rsq,  Bsl,Lfl,Rfl,Pip,Sp1,Sp2,Dot,Sp4,  Sp5,Sp6,ERR,ERR,ERR,ERR,ERR,ERR}},
+[Wrd]={  WORD, {0,
+OK ,Wrd,Wrd,Wrd,Wrd,Wrd,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  Bsl,OK ,OK ,OK ,OK ,OK ,Wrd,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+
+[Int]={  WORD, {0,
+OK ,Wrd,Int,Wrd,Wrd,OK ,OK ,  OK ,OK ,OK ,Wrd,OK ,OK ,OK ,OK ,  Wrd,OK ,OK ,OK ,OK ,OK ,Wrd,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+
+[Ptr]={  WORD,{0,
+OK ,Wrd,Wrd,Wrd,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  Wrd,OK ,OK ,OK ,OK ,OK ,Wrd,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Pru]={  P_RUNNER,{0,
+OK ,Pru,Pru,Pru,Pru,OK ,OK ,  OK ,OK ,OK ,Pru,OK ,OK ,OK ,OK ,  Pru,OK ,OK ,OK ,OK ,OK ,Pru,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+
+[W_b]={  0, {1,
+W_b,W_b,W_b,W_b,W_b,W_b,W_e,  W_b,W_b,W_b,W_b,W_b,W_b,W_b,W_b,  W_b,W_b,W_b,W_b,W_b,W_b,W_b,W_b,  W_b,W_b,W_b,W_b,W_b,W_b,W_b,W_b}},
+[W_e]={  WORD, {1,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+
+[Lpr]={  L_BRACKET /*L_PARENT*/,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Rpr]={  R_BRACKET,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Com]={  COMMA,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Mns]={  0,{0,
+ERR,ERR,ERR,ERR,ERR,ERR,ERR,  ERR,ERR,ERR,ERR,ERR,ERR,ERR,ERR,  ERR,ERR,ERR,ERR,ERR,ERR,ERR,ERR,  Lnk,ERR,ERR,ERR,ERR,ERR,ERR,ERR}},
+[Les]{  LT,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,ASG,App,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,Nam,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+
+[Slh]={  SLASH,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,Slh,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+
+[Lsq]={  L_BRACKET,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Rsq]={  R_BRACKET,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Bsl]={  0,{0,
+Wrd,Wrd,Wrd,Wrd,Wrd,Wrd,Wrd,  Wrd,Wrd,Wrd,Wrd,Wrd,Wrd,Wrd,Wrd,  Wrd,Wrd,Wrd,Wrd,Wrd,Wrd,Wrd,Wrd,  Wrd,Wrd,Wrd,Wrd,Wrd,Wrd,Wrd,Wrd}},
+[Lfl]={  L_BRACKET,{0,            /*mast removed*/
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Rfl]={  R_BRACKET,{0,            /*mast removed*/
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Pip]={  0,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Sp1]={  0,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Sp2]={  SEMICOLON,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Dot]={ WORD,{0,
+OK ,Wrd,Wrd,Wrd,Wrd,Wrd,Wrd,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,Dot,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Sp4]={  0,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Sp5]={  0,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+
+[Sp6]={  0,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Pls]={  PLUS,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[Res]={  0,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+/*
+[Str]={  STRING_CONSTANT,{1,
+Str,Str,Str,Str,Str,Str,OK ,  Str,Str,Str,Str,Str,Str,Str,Str,  Str,Str,Str,Str,Str,Str,Str,Str,  Str,Str,Str,Str,Str,Str,Str,Str}},
+*/
+
+[Str]={  0,{0,
+Str,Str,Str,Str,Str,Str,Str,  Str,Str,Str,Str,Str,Str,Str,Str,  Str,Str,Str,Str,Str,Str,Str,Str,  Str,Str,Str,Str,Ste ,Str,Str,Str}},
+[Ste]={  STRING_CONSTANT,{1,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,Str ,OK ,OK ,OK }},
+
+[ASG]={  L_ASSIGN,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+[App]={  L_ASSIGN,{0,
+ERR,ERR,ERR,ERR,ERR,ERR,ERR,  ERR,ERR,ERR,ERR,Ap2,ERR,ERR,ERR,  ERR,ERR,ERR,ERR,ERR,ERR,ERR,ERR,  ERR,ERR,ERR,ERR,ERR,ERR,ERR,ERR}},
+/*
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,Ap2,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+*/
+[Lnk]={ L_SYMLINK,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  ERR ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+
+[Ap2]={  L_APPEND,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }},
+
+[Nam]={  NAMED,{0,
+OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK ,  OK ,OK ,OK ,OK ,OK ,OK ,OK ,OK }}
+
+};
+
+
diff -puN /dev/null not-for-inclusion/parser/parser.code.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/parser.code.c	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,484 @@
+#ifndef lint
+/*static char yysccsid[] = "from: @(#)yaccpar	1.9 (Berkeley) 02/21/93";*/
+static char yyrcsid[] = "$Id: skeleton.c,v 1.4 1993/12/21 18:45:32 jtc Exp $\n 2002/10/22 VD reiser4";
+#endif
+#define YYBYACC 1
+#define YYMAJOR 1
+#define YYMINOR 9
+#define yyclearin (yychar=(-1))
+#define yyerrok (yyerrflag=0)
+#define YYRECOVERING (yyerrflag!=0)
+#define YYPREFIX "yy"
+#line 9 "fs/reiser4/parser/parser.y"
+typedef union
+{
+	long charType;
+	expr_v4_t * expr;
+	wrd_t * wrd;
+} YYSTYPE;
+#line 20 "fs/reiser4/parser/parser.code.c"
+#define L_BRACKET 257
+#define R_BRACKET 258
+#define WORD 259
+#define P_RUNNER 260
+#define STRING_CONSTANT 261
+#define TRANSCRASH 262
+#define SEMICOLON 263
+#define COMMA 264
+#define L_ASSIGN 265
+#define L_APPEND 266
+#define L_SYMLINK 267
+#define PLUS 268
+#define SLASH 269
+#define INV_L 270
+#define INV_R 271
+#define EQ 272
+#define NE 273
+#define LE 274
+#define GE 275
+#define LT 276
+#define GT 277
+#define IS 278
+#define AND 279
+#define OR 280
+#define NOT 281
+#define IF 282
+#define THEN 283
+#define ELSE 284
+#define EXIST 285
+#define NAME 286
+#define UNNAME 287
+#define NAMED 288
+#define ROOT 289
+#define YYERRCODE 256
+#define YYTABLESIZE 422
+#define YYFINAL 5
+#ifndef YYDEBUG
+#define YYDEBUG 0
+#endif
+#define YYMAXTOKEN 289
+#if defined(YYREISER4_DEF)
+#define extern static
+#endif
+extern short yylhs[];
+extern short yylen[];
+extern short yydefred[];
+extern short yydgoto[];
+extern short yysindex[];
+extern short yyrindex[];
+extern short yygindex[];
+extern short yytable[];
+extern short yycheck[];
+#if YYDEBUG
+extern char *yyname[];
+extern char *yyrule[];
+#endif
+#if defined(YYREISER4_DEF)
+#define YYSTACKSIZE 500
+#define YYMAXDEPTH 500
+#define yydebug ws->ws_yydebug
+#define yynerrs ws->ws_yynerrs
+#define yyerrflag ws->ws_yyerrflag
+#define yychar ws->ws_yychar
+#define yyssp ws->ws_yyssp
+#define yyvsp ws->ws_yyvsp
+#define yyval ws->ws_yyval
+#define yylval ws->ws_yylval
+#define yyss ws->ws_yyss
+#define yyvs ws->ws_yyvs
+#define yystacksize ws->ws_yystacksize
+#else
+#ifdef YYSTACKSIZE
+#undef YYMAXDEPTH
+#define YYMAXDEPTH YYSTACKSIZE
+#else
+#ifdef YYMAXDEPTH
+#define YYSTACKSIZE YYMAXDEPTH
+#else
+#define YYSTACKSIZE 500
+#define YYMAXDEPTH 500
+#endif
+#endif
+int yydebug;
+int yynerrs;
+int yyerrflag;
+int yychar;
+short *yyssp;
+YYSTYPE *yyvsp;
+YYSTYPE yyval;
+YYSTYPE yylval;
+short yyss[YYSTACKSIZE];
+YYSTYPE yyvs[YYSTACKSIZE];
+#define yystacksize YYSTACKSIZE
+#endif
+#line 160 "fs/reiser4/parser/parser.y"
+
+
+#define yyversion "4.0.0"
+#include "pars.cls.h"
+#include "parser.tab.c"
+#include "pars.yacc.h"
+#include "lib.c"
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   End:
+*/
+#line 132 "fs/reiser4/parser/parser.code.c"
+#define YYABORT goto yyabort
+#define YYREJECT goto yyabort
+#define YYACCEPT goto yyaccept
+#define YYERROR goto yyerrlab
+int
+#if defined(YYREISER4_DEF)
+yyparse(struct reiser4_syscall_w_space  * ws)
+#else
+#if defined(__STDC__)
+yyparse(void)
+#else
+yyparse()
+#endif
+#endif
+{
+    register int yym, yyn, yystate;
+#if YYDEBUG
+    register char *yys;
+    static char *getenv();
+
+    if (yys = getenv("YYDEBUG"))
+    {
+        yyn = *yys;
+        if (yyn >= '0' && yyn <= '9')
+            yydebug = yyn - '0';
+    }
+#endif
+
+    yynerrs = 0;
+    yyerrflag = 0;
+    yychar = (-1);
+
+    yyssp = yyss;
+    yyvsp = yyvs;
+    *yyssp = yystate = 0;
+
+yyloop:
+    if ((yyn = yydefred[yystate]) != 0) goto yyreduce;
+    if (yychar < 0)
+    {
+        if ((yychar = yylex()) < 0) yychar = 0;
+#if YYDEBUG
+        if (yydebug)
+        {
+            yys = 0;
+            if (yychar <= YYMAXTOKEN) yys = yyname[yychar];
+            if (!yys) yys = "illegal-symbol";
+            printf("%sdebug: state %d, reading %d (%s)\n",
+                    YYPREFIX, yystate, yychar, yys);
+        }
+#endif
+    }
+    if ((yyn = yysindex[yystate]) && (yyn += yychar) >= 0 &&
+            yyn <= YYTABLESIZE && yycheck[yyn] == yychar)
+    {
+#if YYDEBUG
+        if (yydebug)
+            printf("%sdebug: state %d, shifting to state %d\n",
+                    YYPREFIX, yystate, yytable[yyn]);
+#endif
+        if (yyssp >= yyss + yystacksize - 1)
+        {
+            goto yyoverflow;
+        }
+        *++yyssp = yystate = yytable[yyn];
+        *++yyvsp = yylval;
+        yychar = (-1);
+        if (yyerrflag > 0)  --yyerrflag;
+        goto yyloop;
+    }
+    if ((yyn = yyrindex[yystate]) && (yyn += yychar) >= 0 &&
+            yyn <= YYTABLESIZE && yycheck[yyn] == yychar)
+    {
+        yyn = yytable[yyn];
+        goto yyreduce;
+    }
+    if (yyerrflag) goto yyinrecovery;
+#if defined(YYREISER4_DEF)
+    yyerror(ws,11111,yystate,yychar);
+#else
+    yyerror("syntax error");
+#endif
+#ifdef lint
+    goto yyerrlab;
+#endif
+yyerrlab:
+    ++yynerrs;
+yyinrecovery:
+    if (yyerrflag < 3)
+    {
+        yyerrflag = 3;
+        for (;;)
+        {
+            if ((yyn = yysindex[*yyssp]) && (yyn += YYERRCODE) >= 0 &&
+                    yyn <= YYTABLESIZE && yycheck[yyn] == YYERRCODE)
+            {
+#if YYDEBUG
+                if (yydebug)
+                    printf("%sdebug: state %d, error recovery shifting\
+ to state %d\n", YYPREFIX, *yyssp, yytable[yyn]);
+#endif
+                if (yyssp >= yyss + yystacksize - 1)
+                {
+                    goto yyoverflow;
+                }
+                *++yyssp = yystate = yytable[yyn];
+                *++yyvsp = yylval;
+                goto yyloop;
+            }
+            else
+            {
+#if YYDEBUG
+                if (yydebug)
+                    printf("%sdebug: error recovery discarding state %d\n",
+                            YYPREFIX, *yyssp);
+#endif
+                if (yyssp <= yyss) goto yyabort;
+                --yyssp;
+                --yyvsp;
+            }
+        }
+    }
+    else
+    {
+        if (yychar == 0) goto yyabort;
+#if YYDEBUG
+        if (yydebug)
+        {
+            yys = 0;
+            if (yychar <= YYMAXTOKEN) yys = yyname[yychar];
+            if (!yys) yys = "illegal-symbol";
+            printf("%sdebug: state %d, error recovery discards token %d (%s)\n",
+                    YYPREFIX, yystate, yychar, yys);
+        }
+#endif
+        yychar = (-1);
+        goto yyloop;
+    }
+yyreduce:
+#if YYDEBUG
+    if (yydebug)
+        printf("%sdebug: state %d, reducing by rule %d (%s)\n",
+                YYPREFIX, yystate, yyn, yyrule[yyn]);
+#endif
+    yym = yylen[yyn];
+    yyval = yyvsp[1-yym];
+    switch (yyn)
+    {
+case 1:
+#line 79 "fs/reiser4/parser/parser.y"
+{ yyval.charType = free_expr( ws, yyvsp[0].expr ); }
+break;
+case 2:
+#line 83 "fs/reiser4/parser/parser.y"
+{ yyval.expr = yyvsp[0].expr;}
+break;
+case 3:
+#line 84 "fs/reiser4/parser/parser.y"
+{ yyval.expr = const_to_expr( ws, yyvsp[0].wrd ); }
+break;
+case 4:
+#line 85 "fs/reiser4/parser/parser.y"
+{ yyval.expr = unname( ws, yyvsp[0].expr ); }
+break;
+case 5:
+#line 86 "fs/reiser4/parser/parser.y"
+{ yyval.expr = concat_expression( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 6:
+#line 87 "fs/reiser4/parser/parser.y"
+{ yyval.expr = list_expression( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 7:
+#line 88 "fs/reiser4/parser/parser.y"
+{ yyval.expr = list_async_expression( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 8:
+#line 89 "fs/reiser4/parser/parser.y"
+{ yyval.expr = yyvsp[0].expr; level_down( ws, IF_STATEMENT, IF_STATEMENT ); }
+break;
+case 9:
+#line 91 "fs/reiser4/parser/parser.y"
+{ yyval.expr = assign( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 10:
+#line 92 "fs/reiser4/parser/parser.y"
+{ yyval.expr = assign( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 11:
+#line 93 "fs/reiser4/parser/parser.y"
+{ yyval.expr = assign_invert( ws, yyvsp[-4].expr, yyvsp[-1].expr ); }
+break;
+case 12:
+#line 94 "fs/reiser4/parser/parser.y"
+{ yyval.expr = symlink( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 13:
+#line 103 "fs/reiser4/parser/parser.y"
+{ yyval.expr = if_then_else( ws, yyvsp[-3].expr, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 14:
+#line 104 "fs/reiser4/parser/parser.y"
+{ yyval.expr = if_then( ws, yyvsp[-1].expr, yyvsp[0].expr) ;         }
+break;
+case 15:
+#line 108 "fs/reiser4/parser/parser.y"
+{ yyval.expr = yyvsp[0].expr; }
+break;
+case 16:
+#line 111 "fs/reiser4/parser/parser.y"
+{ level_up( ws, IF_STATEMENT ); }
+break;
+case 17:
+#line 115 "fs/reiser4/parser/parser.y"
+{ yyval.expr = not_expression( ws, yyvsp[0].expr ); }
+break;
+case 18:
+#line 116 "fs/reiser4/parser/parser.y"
+{ yyval.expr = check_exist( ws, yyvsp[0].expr ); }
+break;
+case 19:
+#line 117 "fs/reiser4/parser/parser.y"
+{ yyval.expr = compare_EQ_expression( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 20:
+#line 118 "fs/reiser4/parser/parser.y"
+{ yyval.expr = compare_NE_expression( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 21:
+#line 119 "fs/reiser4/parser/parser.y"
+{ yyval.expr = compare_LE_expression( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 22:
+#line 120 "fs/reiser4/parser/parser.y"
+{ yyval.expr = compare_GE_expression( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 23:
+#line 121 "fs/reiser4/parser/parser.y"
+{ yyval.expr = compare_LT_expression( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 24:
+#line 122 "fs/reiser4/parser/parser.y"
+{ yyval.expr = compare_GT_expression( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 25:
+#line 123 "fs/reiser4/parser/parser.y"
+{ yyval.expr = compare_OR_expression( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 26:
+#line 124 "fs/reiser4/parser/parser.y"
+{ yyval.expr = compare_AND_expression( ws, yyvsp[-2].expr, yyvsp[0].expr ); }
+break;
+case 27:
+#line 128 "fs/reiser4/parser/parser.y"
+{ goto_end( ws );}
+break;
+case 28:
+#line 132 "fs/reiser4/parser/parser.y"
+{ yyval.expr = yyvsp[0].expr;}
+break;
+case 29:
+#line 133 "fs/reiser4/parser/parser.y"
+{ yyval.expr = target_name( yyvsp[-2].expr, yyvsp[0].expr );}
+break;
+case 30:
+#line 137 "fs/reiser4/parser/parser.y"
+{ yyval.expr = pars_expr( ws, yyvsp[-1].expr, yyvsp[0].expr ) ; }
+break;
+case 31:
+#line 138 "fs/reiser4/parser/parser.y"
+{ yyval.expr = pars_expr( ws, yyvsp[-2].expr, yyvsp[0].expr ) ; }
+break;
+case 32:
+#line 142 "fs/reiser4/parser/parser.y"
+{ yyval.expr = pars_lookup_root( ws ) ; }
+break;
+case 33:
+#line 143 "fs/reiser4/parser/parser.y"
+{ yyval.expr = pars_lookup_curr( ws ) ; }
+break;
+case 34:
+#line 147 "fs/reiser4/parser/parser.y"
+{ yyval.expr = lookup_word( ws, yyvsp[0].wrd ); }
+break;
+case 35:
+#line 148 "fs/reiser4/parser/parser.y"
+{ yyval.expr = yyvsp[-1].expr; level_down( ws, yyvsp[-2].charType, yyvsp[0].charType );}
+break;
+case 36:
+#line 152 "fs/reiser4/parser/parser.y"
+{ yyval.charType = yyvsp[0].charType; level_up( ws, yyvsp[0].charType ); }
+break;
+#line 425 "fs/reiser4/parser/parser.code.c"
+    }
+    yyssp -= yym;
+    yystate = *yyssp;
+    yyvsp -= yym;
+    yym = yylhs[yyn];
+    if (yystate == 0 && yym == 0)
+    {
+#if YYDEBUG
+        if (yydebug)
+            printf("%sdebug: after reduction, shifting from state 0 to\
+ state %d\n", YYPREFIX, YYFINAL);
+#endif
+        yystate = YYFINAL;
+        *++yyssp = YYFINAL;
+        *++yyvsp = yyval;
+        if (yychar < 0)
+        {
+            if ((yychar = yylex()) < 0) yychar = 0;
+#if YYDEBUG
+            if (yydebug)
+            {
+                yys = 0;
+                if (yychar <= YYMAXTOKEN) yys = yyname[yychar];
+                if (!yys) yys = "illegal-symbol";
+                printf("%sdebug: state %d, reading %d (%s)\n",
+                        YYPREFIX, YYFINAL, yychar, yys);
+            }
+#endif
+        }
+        if (yychar == 0) goto yyaccept;
+        goto yyloop;
+    }
+    if ((yyn = yygindex[yym]) && (yyn += yystate) >= 0 &&
+            yyn <= YYTABLESIZE && yycheck[yyn] == yystate)
+        yystate = yytable[yyn];
+    else
+        yystate = yydgoto[yym];
+#if YYDEBUG
+    if (yydebug)
+        printf("%sdebug: after reduction, shifting from state %d \
+to state %d\n", YYPREFIX, *yyssp, yystate);
+#endif
+    if (yyssp >= yyss + yystacksize - 1)
+    {
+        goto yyoverflow;
+    }
+    *++yyssp = yystate;
+    *++yyvsp = yyval;
+    goto yyloop;
+yyoverflow:
+#if defined(YYREISER4_DEF)
+    yyerror(ws,101); /*yacc stack overflow*/
+#else
+    yyerror("yacc stack overflow");
+#endif
+yyabort:
+    return (1);
+yyaccept:
+    return (0);
+}
diff -puN /dev/null not-for-inclusion/parser/parser.doc
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/parser.doc	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,473 @@
+/* Parser for the reiser4() system call */
+
+/* Takes a string and parses it into a set of commands which are
+   executed.  */
+
+/*
+
+If you want to read about where future versions of this syntax will
+go, and what the grand scheme is, please go to
+www.namesys.com/future_vision.html.
+
+Names resolve into sets of keys.  In Reiser4, the sets of keys all
+consist of exactly one key, but this will change in future versions.
+
+Keys are not immutable objectids ala inode numbers.  The use of
+immutable objectids that all objects could be found by was the
+original architecture, and before coding was started this was realized
+to require lower performance due to creating immutable, and therefor
+poor, locality of reference when resolving them.  Keys currently do
+contain unique objectids, but this objectid does not suffice for
+finding the object.
+
+Name compounders construct names from subnames.  / and [] ([] is not
+implemented in reiser4, see www.namesys.com/future_vision.html for
+what it will do in a later version) are name compounders.  Name
+compounders can use any name which can be resolved into a key as a
+subname.  This provides "closure", in which the type of the result of
+every name operation is the same as the type of what the name
+operators operate on.  (Persons who create abstract models tend to
+place a high value on achieving closure in their design.  For more
+about closure, read www.namesys.com/future_vision.html.)
+
+A/B indicates that B is to be passed to A, and A will resolve its
+meaning.  This is consistent with Unix usage of /.  B is considered
+a subname of A in this example.
+
+Reiser4 supports a plugin that implements Unix regular files (regfile),
+and a plugin that implements Unix regular directories (regdir). (NIKITA-FIXME-HANS: use those names in the code)
+
+Plugins may resolve a subname by invoking a plugin of another object,
+or by invoking methods built into themselves.
+
+Special characters are whitespace plus []{}()/\,:;*$@!`' and keywords
+are <- and ->
+
+<-, ->,  are assignment operators.
+
+
+'A<-B' uses B's read method to read B, and uses A'S write method to
+write to A what was read from B.  It is a copy command similar to
+sendfile().
+
+The righthand side of an assignment defines a flow.  We calculate the flow,
+and then invoke the the write method defined by the lefthand side of
+the assignment.
+
+Example:
+
+A<-B
+
+assigns the contents of the object named B to A, overwriting the contents of A if A exists.
+
+` and ' indicate that all special characters between them should be
+ignored and parsed as a single string. That is, A<-`some text' causes A to have
+contents equal to a file named `some text'.  Quotes are allowed to nest.
+
+" indicates that the next word is inlined text.  Sorry, " is the symbol least useful for something else, so it got used.
+
+A<-"(this is a string not a name of a file)  // German style quoting: ,,ksdajfhkasdh``
+
+assigns (sans the single quotes) the string `this is a string not a name of a file' to A.
+
+A<-"`I think that using " in a language for delimiting quoting is bad style because delimiters should be matching pairs not matching identical singletons if nesting is to work at all.'
+
+assigns the string `I think that using " in a language for delimiting quoting is bad style because delimiters should be matching pairs not matching identical singletons if nesting is to work at all.' to A
+
+
+
+
+
+
+named assign.
+
+name<=A<-B
+
+The "name" is a name for result of assign . This is not a object of file system.(need to test) ok tested
+Rule for it name is common rule for object of FS, exept one rule: names in path no need coresponded object in FS.??? (need to test.)
+Time of a life of it limited to covering brackets or end of command string. (tested.) (need check using this name afte covering brackets)
+After this operator this name will have subnames "assign_result" and "assign_length", (ok tested)
+wich will contane error code of assign and number of bytes wroten to file A. (ok tested)
+
+
+After name is dead the previously value of name is restored. (ok tested)
+This rule not depended of exist or not file in FS with same name.
+
+if file "name" exist in current directory, then
+
+This names is avalable in any expression as a file. (Only body of file. no any meta data) ?? (ok tested)
+parent of it is a current directory, or defined path. (tested current directory, need test permition for full pathname)
+It means we can use full pathname for access to it. ( tested, need more test)
+
+for example
+
+C<-name/assign_result; D<-name/assign_length
+
+files C an D will contain error code of assign and number of bytes, wroten to file A. (ok tested)
+
+
+
+special case ??? (not yet work.)
+
+E<-name
+
+where E is directory.
+in this case in directory E will create or owerwrite files assign_length assign_result with correspended values.
+
+
+
+Deneral rules for tmp names.
+If lookup can't find any name in FS for specified path, this nema is a TMP name. It can have a value and a children. but no metadata.
+Offcose it have a parent. Life time of this name limited by covering brackets or end of command string.
+Fist name in path, which is TMP name my have a subtree of TMP names, and ony TMP names.
+It can be used on the left hand of assign. In this case it will have value as a copy of value of the right hand.
+
+
+
+Different between TMP names and named assign.
+1. The name of named assign can be exist in file system. TMP name - not.
+2. We can recursively define named assign with same name as stack of value. TMP name has only one value.
+(need to check if we use TMP name and same named assign )
+3. The name of named assign will have 2 child for assign result with fixed names.
+
+All other properties is equvalent.
+while life time we can add any new name as child, if it not exist.
+
+A<<-B
+
+appends file B to file A (not yet ready)
+
+
+
+
+
+We need to define multiple aspects of the object when creating it.
+Additionally, we need to assign default values to those aspects of the
+definition not defined.  The problem arises when we have a multi-part
+definition.  We should avoid assigning one part, then assigning
+default values for all other parts, then overwriting those default
+values, some of which actually cannot be overwritten (e.g. pluginid).
+
+This means we need to name the object, and then perform multiple
+assignments in its creation.
+
+(x_ and )x_ where x is any sequence (including the null sequence) of
+non-special characters, are `named parenthesis'.  They have the usual meaning of
+parenthesis in most languages, and delimit what should be treated as a
+single unit by operators.  If you use named parenthesis you can avoid
+the "LISP bird nest" effect.  The disadvantage is that if you leave
+off the whitespace following the open parenthesis you will get an
+unintended effect.  Note that there must be no space between ( and x.
+(not yet ready)
+
+Referencing the contents of parenthesis by the name of the parenthesis
+is planned in later versions..
+
+It is an unenforced but encouraged style convention that subnames which contain
+meta-information about the object, and pseudo-files that implement
+methods of the object, begin with `..'.  IT IS NOT A REQUIREMENT
+THAT THEY START WITH `..',  READ THAT AGAIN!  Sorry, got tired of the complaints about
+the non-existent requirement.  It all depends on how you write your plugins that
+use the meta-information whether the meta-data starts with `..'.
+
+Since what is meta-information, what is a method of the object, and
+what is contained information, or methods of sub-objects, are not
+necessarily always inherently susceptible to precise natural
+distinction, and since we desire to allow users maximal stylistic
+freedom to extend reiser4 into emulating other syntaxes, this is only
+an optional plugin design convention for use when appropriate.
+
+One can specify whether a file is listed by readdir in reiser4.  Using
+that feature, subnames of files containing meta-information about
+other files are by convention not listed by readdir, but can be listed
+by using the command reiser4("A_listing<-A/..list"), and then reading
+the file A_listing.
+
+For instance, if A is a regfile or regdir, then A/..owner resolves to
+a file containing the owner of A, and reading the A directory shows no
+file named ..owner.  More generally, all of the fields returned by
+stat() have a corresponding name of the form A/..field_name for all
+regfiles and regdirs.  The use of'..' avoids clashes between method
+names and filenames.  More extreme measures could be taken using
+something more obscure than '..' as a prefix, but I remember that
+Clearcase and WAFL never really had much in the way of problems with
+namespace collisions affecting users seriously, so I don't think one
+should excessively inconvenience a syntax for such reasons.
+
+DEMIDOV-FIXME-HANS: the paragraph below conflicts with the above
+*A (similar to C language dereference) means take the contents of
+that object which A is the name for, and treat those contents as a name.
+
+
+*`A B' is a reference to a file whose name consists of the characters
+A and a space and a B.
+
+
+A;B indicates that B is not to be executed until A completes.  So, `/'
+orders subnames within a compound name, and `;' orders operations.
+
+
+A,B indicates that A and B are independent of each other and
+unordered.
+
+A/B indicates that the plugin for A is to be passed B,
+and asked to handle it in its way, whatever that way is.
+
+/ and \ are considered equivalent, as a kindness to former windows users
+
+C/..invert<-A +"(some text)+ B
+
+indicates that C when read shall return the contents of A followed by
+'some text' as a delimiter followed by the contents of B.
+
+if  A  and   B  are object expressions then
+               A+B  is object expression
+               A\B  is object expression
+               A<-B is possible operation
+
+
+
+
+--------------
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+
+So, let us discuss the following example:
+
+Assume 357 is the user id of Michael Jackson.
+
+The following 3 expressions are equivalent:
+
+ascii_command = "/home/teletubbies/(..new(..name<-glove_location, ..object_t<-audit/regular, ..perm_t<-acl); glove_location/..acl<-( uid<-357, access<-denied ); glove_location/..audit<-mailto<-teletubbies@pbs.org; glove_location<-'we stole it quite some number of years ago, and put it in the very first loot pile (in the hole near the purple flower.')";
+
+ascii_command = "/home/teletubbies/(glove_location<-( ..object_t<-audit/regular, ..perm_t<-acl); glove_location/..acl<-  ( uid<-357, access<-denied ); glove_location/..audit<-mailto<-teletubbies@pbs.org; glove_location<-'we stole it quite some number of years ago, and put it in the very first loot pile (in the hole near the purple flower)')";
+
+
+ascii_command = "/home/teletubbies/(glove_location<-( ..object_t<-audit/regular, ..perm_t<-acl); glove_location / ( ..acl<-(uid<-357, access<-denied) ; ..audit<-mailto<-teletubbies@pbs.org); glove_location<-'we stole it quite some number of years ago, and put it in the very first loot pile (in the hole near the purple flower).')";
+
+DEMIDOV-FIXME-HANS: what is the meaning of the line below, and should it be ..new rather than new
+a/b/(new/(name<-"new_file_name"; type<-"regular file"; perm_t<-"acl"); new_file_name/acl<- ( uid<-"357", access<-"denied" ))
+
+DEMIDOV-FIXME-HANS: update this example
+ascii_command =
+   "/home/teletubbies/glove_location<-
+             ( (..object_t<-audit, ..perm_t<-acl) ;
+                ..acl<-  ( uid<-'357', access<-denied );
+                ..audit/(backing<-..anon<=(..object_t<-regular); // lookup<-/home/teletubbies/some-existing-file),
+                         log<-(mailto<-teletubbies@pbs.org));
+                ..body<-'we stole it quite some number of years ago, and put it in the very first loot pile (in the hole near the purple flower)';)";
+
+(a b)
+result<-/subject/[elves strike]
+(result /subject/[elves strike])
+/subject/[elves strike]->result
+
+
+
+
+DEMIDOV-FIXME-HANS: cleanup the explanation below
+The components of this example have the following meanings:
+/home/teletubbies/       - directory name
+/(..name                 - specifies that its argument is the name of the new file - parameter for ..new plugin
+/glove_location, - name of new file - parameter for name submethod of ..new method
+..object_t     -  name of submethod that assigns object type to new files - parameter for ..new plugin
+/audit         - plugin for file
+/regular,      - plugin for backing store for audit plugin
+..perm_t       - security plugin to be assigned
+)              - end of parameters for ..new plugin
+;              - next system call
+glove_location - file name
+/..acl         - plugin ..acl
+(              - begin parameters for ..new plugin of ..acl plugin
+uid            - plugin of ..acl plugin
+/357           - its value(parameter)
+,              -
+access         - ..
+/denied        -  value to assign
+)              - end of parameter list
+)              - ? unbalanced brakes
+;
+..audit        - plugin - file is unknown!
+/..new
+/mailto
+/"teletubbies@pbs.org"
+;
+glove_location_file - file name
+/
+
+"we stole it quite some number of years ago, and put it in the very first loot pile (in the hole near the purple flower)." - body of file
+
+reiser4(&ascii_command, ascii_command_length, stack_binary_parameters_referenced_in_ascii_command, stack_length);
+
+
+*/
+
+/*
+
+     w=\$v v=\$u u=5 z=\$w+$w
+               echo $z
+          eval echo $z
+     eval eval echo $z
+
+eval eval eval echo $z
+
+result is:
+
+$w+$v
+$v+$u
+$u+5
+5+5
+
+tw/transcrash_33[ /home/reiser/(a <- b, c <- d) ]
+
+        chgrp --      changes group ownership
+        chown --      changes ownership
+        chmod --      changes permissions
+        cp --	      copies
+        dd --	      copies and converts
+        df --	      shows filesystem disk usage.
+        dir --	      gives brief directory listing
+        du --	      shows disk usage
+        ln --	      creates links
+        ls --	      lists directory contents
+        mkdir --      creates directories
+        mkfifo --     creates FIFOs (named pipes)
+        mknod --      creates special files
+        mv --	      renames
+        rm --	      removes (deletes)
+        rmdir --      removes empty directories
+        shred --      deletes a file securely
+        sync --	      synchronizes memory and disk
+*/
+
+
+
+/*
+
+
+Assignment, and transaction, will be the commands supported in Reiser4(); more commands will appear in Reiser5. -> and <- will be the assignment operators.
+
+The amount transferred by an assignment is the minimum of the size of the left hand side and the size of the right hand side.  This amount is usually made one of the return values.
+
+    * lhs (assignment target) values:
+
+    /..process/..range/(first_byte<-(loff_t),last_byte<-(loff_t),bytes_written<-(ssize_t*) )
+              assigns (writes) to the buffer starting at address first_byte in the process address space, ending at last_byte, with the number of bytes actually written
+	      (The assignment source may be smaller or larger than the assignment target.) being written to address bytes_written.
+	      Representation of first_byte,last_byte, and bytes_written is left to the coder to determine.
+	      It is an issue that will be of much dispute and little importance.
+	      Notice / is used to indicate that the order of the operands matters; see www.namesys.com/future_vision.html for details of why this is appropriate syntax design.
+	      Note the lack of a file descriptor.
+
+    /filename
+              assigns to the file named filename, wholly obliterating its body with what is assigned.
+
+    /filename/..range/(first_byte<-(loff_t),last_byte<-(loff_t),bytes_written<-(ssize_t*) )
+              writes to the body, starting at first_byte, ending not past last_byte,
+	      recording number of bytes written in bytes_written
+
+    /filename/..range/(first_byte<-(loff_t),bytes_written<-(ssize_t*) )
+              writes to the body starting at offset, recording number of bytes written in bytes_written
+
+    * rhs (assignment source) values:
+
+    /..process/..range/(first_byte<-(loff_t),last_byte<-(loff_t),bytes_read<-(ssize_t*) )
+              reads from the buffer starting at address first_byte in the process address space, ending at last_byte.
+	      The number of bytes actually read (assignment source may be smaller or larger than assignment target) is written to address bytes_read.
+	      Representation of first_byte, last_byte, and bytes_read is left to the coder to determine, as it is an issue that will be of much dispute and little importance.
+
+    /filename
+              reads the entirety of the file named filename.
+
+    /filename/..range/(first_byte<-(loff_t),last_byte<-(loff_t),bytes_read<-(ssize_t*) )
+              reads from the body, starting at first_byte, ending not past last_byte,
+              recording number of bytes read in bytes_read
+
+    /filename/..range/(first_byte<-(loff_t),bytes_read<-(ssize_t*) )
+              reads from the body starting at offset until the end, recording number of bytes read in bytes_read
+
+    /filename/..stat/owner
+              reads from the ownership field of the stat data (stat data is that which is returned by the
+              stat() system call (owner, permissions, etc.) and stored on a per file basis by the FS.)
+
+
+
+
+
+*/
+
+
+
+
+/*
+
+example:
+
+
+
+       /path0/path1/filename/..range/(offset<-100,bytes_written<-0xff001258,last_byte<-256)<-/path0/path2/filename/..range/(first_byte<-0,bytes_readed<-0xff001250)
+
+       /path0/(path1/filename/..range/(offset<-100,bytes_written<-0xff001258,last_byte<-256)<-path2/filename/..range(first_byte<-0,bytes_readed<-0xff001250) )
+
+       /path0/(path1/filename/..range/(100,256)<-path2/filename/..range(0,256) )
+
+
+                                                                          ?
+       /path0/path1/filename/..range/(offset<-100,bytes_written<-0xff001258),last_byte<-256,/path0/path2/filename/..range(first_byte<-0,p_bytes_readed<-0xff001250)
+
+ssize_t bytes_readed;
+
+sprintf( string_pointer_bytes_read, "%8.8p", &bytes_readed );
+
+ */
+
+
+examples:
+
+
+.....b/(new/(name<-"new_file_name"; type<-regular_file; permition<-acl); new_file_name/acl/( uid<-"357", access<-denied );new_file_name<-/etc/passwd)
+
+where:
+  b is a directory
+we have lnode for it.and make:
+b_lnode->lookup(new)
+it that meen we find lnode for directory plugin "new"
+   and then we find new_lnode->lookup(name). this is lnode for name of new file and we assign to it string constant "new_file_name".
+
+   then we find new_lnode->lookup(type). this is lnode of type of new file
+   then we find new_lnode->lookup(regular_file) this is lnode of constants of types of plugin "new" for regular file
+   then we copy contens regular_file_lnode throuse tube to type_lnode.
+
+   then we find new_lnode->lookup(permition). this is lnode of type of permition of new file
+   then we find new_lnode->lookup(acl). this is lnode of constants of type of permition of "new" plugin, correcponding to acl
+   then we copy contens acl_lnode throuse tube to permition_lnode.
+
+then we find b_lnode->lookup(new_file_name). this is lnode for new file we jast created.
+then we find new_file_name_lnode->lookup(acl) . this is lnode of acl plugin .
+   then we find acl_lnode->lookup(uid)this is lnode for uid field of acl and assign to it string constant "357".
+   then we find acl_lnode->lookup(access).
+   then we find acl_lnode->lookup(denied).
+   then we copy contens denied_lnode throuse tube to access_lnode.
+
+then we find root_lnode->lookup(etc),
+then we find etc_lnode->lookup(passwd)
+then we read contens passwd_lnode throuse tube and write to new_file_name_lnode lnode.
+
+ok. command string is executed.
+
+
diff -puN /dev/null not-for-inclusion/parser/parser.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/parser.h	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,345 @@
+ /*
+ * Copyright, 2002 by Hans Reiser, licensing governed by reiser4/README
+ */
+
+/*
+ * definitions of common constants and data-types used by
+ * parser.y
+ */
+
+                                 /* level type defines */
+
+#include "../forward.h"
+#include "../debug.h"
+#include "../dformat.h"
+#include "../key.h"
+#include "../type_safe_list.h"
+#include "../plugin/plugin_header.h"
+#include "../plugin/item/static_stat.h"
+#include "../plugin/item/internal.h"
+#include "../plugin/item/sde.h"
+#include "../plugin/item/cde.h"
+#include "../plugin/item/extent.h"
+#include "../plugin/item/tail.h"
+#include "../plugin/file/file.h"
+#include "../plugin/symlink.h"
+#include "../plugin/dir/hashed_dir.h"
+#include "../plugin/dir/dir.h"
+#include "../plugin/item/item.h"
+#include "../plugin/node/node.h"
+#include "../plugin/node/node40.h"
+#include "../plugin/security/perm.h"
+#include "../plugin/space/bitmap.h"
+#include "../plugin/space/space_allocator.h"
+#include "../plugin/disk_format/disk_format40.h"
+#include "../plugin/disk_format/disk_format.h"
+
+#include <linux/fs.h>		/* for struct super_block, address_space  */
+#include <linux/mm.h>		/* for struct page */
+#include <linux/buffer_head.h>	/* for struct buffer_head */
+#include <linux/dcache.h>	/* for struct dentry */
+#include <linux/types.h>
+
+typedef enum {
+	TW_BEGIN,
+	ASYN_BEGIN,
+	CD_BEGIN,
+	OP_LEVEL,
+	NOT_HEAD,
+	IF_STATEMENT,
+	UNORDERED
+} def;
+
+//#define printf(p1,...) PTRACE(ws,p1,...)
+#define yylex()  reiser4_lex(ws)
+#define register
+#define  yyacc
+//#define  bizon
+
+#define  PARSER_DEBUG
+
+
+#if 1
+#define PTRACE(ws, format, ... )						\
+({										\
+	ON_TRACE(TRACE_PARSE, "parser:%s %p %s: " format "\n",	                \
+		 __FUNCTION__, ws, (ws)->ws_pline, __VA_ARGS__);		\
+})
+#else
+#define PTRACE(ws, format, ... )						\
+({										\
+	printk("parser:%s %p %s: " format "\n",	                \
+		 __FUNCTION__, ws, (ws)->ws_pline, __VA_ARGS__);		\
+})
+#endif
+
+#define PTRACE1( format, ... )				        		\
+({										\
+	ON_TRACE(TRACE_PARSE, "parser:%s  " format "\n",	                \
+		 __FUNCTION__,  __VA_ARGS__);					\
+})
+
+
+#define ASSIGN_RESULT "assign_result"
+#define ASSIGN_LENGTH "assign_length"
+
+#define SIZEFOR_ASSIGN_RESULT 16
+#define SIZEFOR_ASSIGN_LENGTH 16
+
+
+
+
+
+typedef struct pars_var pars_var_t;
+typedef union expr_v4  expr_v4_t;
+typedef struct wrd wrd_t;
+typedef struct tube tube_t;
+typedef struct sourece_stack sourece_stack_t;
+
+typedef enum {
+	ST_FILE,
+	ST_EXPR,
+	ST_DE,
+	ST_WD,
+	ST_DATA
+} stack_type;
+
+typedef enum {
+	noV4Space,
+	V4Space,
+	V4Plugin
+} SpaceType;
+
+typedef enum {
+	CONCAT,
+	COMPARE_EQ,
+	COMPARE_NE,
+	COMPARE_LE,
+	COMPARE_GE,
+	COMPARE_LT,
+	COMPARE_GT,
+	COMPARE_OR,
+	COMPARE_AND,
+	COMPARE_NOT
+} expr_code_type;
+
+
+                                 /* sizes defines      */
+#define FREESPACESIZE_DEF PAGE_SIZE*4
+#define FREESPACESIZE (FREESPACESIZE_DEF - sizeof(char*)*2 - sizeof(int) )
+
+#define _ROUND_UP_MASK(n) ((1UL<<(n))-1UL)
+
+#define _ROUND_UP(x,n) (((long)(x)+_ROUND_UP_MASK(n)) & ~_ROUND_UP_MASK(n))
+
+// to be ok for alpha and others we have to align structures to 8 byte  boundary.
+
+
+#define ROUND_UP(x) _ROUND_UP((x),3)
+
+
+
+struct tube {
+	int type_offset;
+	char * offset;       /* pointer to reading position */
+	size_t len;            /* lenth of current operation
+                               (min of (max_of_read_lenth and max_of_write_lenth) )*/
+	long used;
+	char * buf;          /* pointer to bufer */
+	loff_t readoff;      /* reading offset   */
+	loff_t writeoff;     /* writing offset   */
+
+ 	sourece_stack_t * last;        /* work. for special case to push list of expressions */
+	sourece_stack_t * next;        /* work. for special case to push list of expressions */
+	sourece_stack_t * st_current;  /* stack of source expressions */
+	pars_var_t * target;
+	struct file *dst;    /* target file      */
+};
+
+struct wrd {
+	wrd_t * next ;                /* next word                   */
+	struct qstr u ;               /* u.name  is ptr to space     */
+};
+
+
+struct path_walk {
+	struct dentry *de;
+	struct vfsmount *mnt;
+};
+
+
+/* types for vtype of struct pars_var */
+typedef enum {
+	VAR_EMPTY,
+	VAR_LNODE,
+	VAR_TMP
+} VAR_TYPE;
+
+typedef struct pars_var_value pars_var_value_t;
+
+struct pars_var {
+	pars_var_t * next ;         /* next                                */
+	pars_var_t * parent;        /* parent                              */
+	wrd_t * w ;                 /* name: pair (parent,w) is unique     */
+	pars_var_value_t * val;
+};
+
+struct pars_var_value {
+	pars_var_value_t * prev;    /* previous value in stack for variable */
+	pars_var_value_t * next_level; /* next tmp value  in this level */
+	pars_var_t * host;          /* host variable structure for this value */
+	pars_var_t * associated;    /*  */
+	int vtype;                  /* Type of value                       */
+	union {
+	lnode * ln;                 /* file/dir name lnode                 */
+	char *data;                 /*  ptr to data in mem (for result of assign) */
+	} u;
+	int count;                  /* ref counter                         */
+	size_t off;	            /* current offset read/write of object */
+	size_t len;		    /* length of sequence of units for read/write (-1 no limit) */
+	int units_type;             /* for byte = 0 for records =1 for delimiter = 3 (delimiter mast be specified)*/
+	int vSpace  ;               /* v4  space name or not ???           */
+	int vlevel  ;               /* level :     lives of the name       */
+} ;
+
+typedef struct expr_common {
+	__u8          type;
+	__u8          exp_code;
+} expr_common_t;
+
+typedef struct expr_lnode {
+	expr_common_t   h;
+	lnode  *lnode;
+} expr_lnode_t;
+
+typedef struct expr_flow {
+	expr_common_t    h;
+	flow_t     *   flw;
+} expr_flow_t;
+
+typedef struct expr_pars_var {
+	expr_common_t   h;
+	pars_var_t  *  v;
+} expr_pars_var_t;
+
+
+typedef struct expr_wrd {
+	expr_common_t   h;
+	wrd_t  *  s;
+} expr_wrd_t;
+
+typedef struct expr_op3 {
+	expr_common_t   h;
+	expr_v4_t  *  op;
+	expr_v4_t  *  op_l;
+	expr_v4_t  *  op_r;
+} expr_op3_t;
+
+typedef struct expr_op2 {
+	expr_common_t   h;
+	expr_v4_t  *  op_l;
+	expr_v4_t  *  op_r;
+} expr_op2_t;
+
+typedef struct expr_op {
+	expr_common_t   h;
+	expr_v4_t  *  op;
+} expr_op_t;
+
+typedef struct expr_assign {
+	expr_common_t   h;
+	pars_var_t       *  target;
+	expr_v4_t       *  source;
+//	expr_v4_t       *  (* construct)( lnode *, expr_v4_t *  );
+} expr_assign_t;
+
+typedef struct expr_list expr_list_t;
+struct expr_list {
+	expr_common_t   h;
+	expr_list_t     *  next;
+	expr_v4_t       *  source;
+} ;
+
+typedef enum {
+	EXPR_WRD,
+	EXPR_PARS_VAR,
+	EXPR_LIST,
+	EXPR_ASSIGN,
+	EXPR_LNODE,
+	EXPR_FLOW,
+	EXPR_OP3,
+	EXPR_OP2,
+	EXPR_OP
+} expr_v4_type;
+
+union expr_v4 {
+	expr_common_t   h;
+	expr_wrd_t      wd;
+	expr_pars_var_t pars_var;
+	expr_list_t     list;
+        expr_assign_t   assgn;
+	expr_lnode_t    lnode;
+	expr_flow_t     flow;
+//	expr_op3_t      op3;
+	expr_op2_t      op2;
+	expr_op_t       op;
+};
+
+/* ok this is space for names, constants and tmp*/
+typedef struct free_space free_space_t;
+
+struct free_space {
+	free_space_t * free_space_next;                /* next buffer   */
+	char         * freeSpace;                      /* pointer to free space */
+	char         * freeSpaceMax;                   /* for overflow control */
+	char           freeSpaceBase[FREESPACESIZE];   /* current buffer */
+};
+
+struct sourece_stack {
+	sourece_stack_t * prev;
+	long type;                     /* type of current stack head */
+	union {
+		struct file   * file;
+		expr_v4_t     * expr;
+//		struct dentry * de;    /*  ??????? what for  */
+		wrd_t         * wd;
+		long          * pointer;
+	} u;
+};
+
+typedef struct streg  streg_t;
+
+struct streg {
+        streg_t * next;
+        streg_t * prev;
+	expr_v4_t * cur_exp;          /* current (pwd)  expression for this level */
+	expr_v4_t * wrk_exp;          /* current (work) expression for this level */
+	pars_var_value_t * val_level;
+	int stype;                  /* cur type of level        */
+	int level;                  /* cur level                */
+};
+
+
+static struct {
+	unsigned char numOfParam;
+	unsigned char typesOfParam[4]       ;
+} typesOfCommand[] = {
+	{0,{0,0,0,0}}
+};
+
+static struct {
+	void (*	call_function)(void) ;
+	unsigned char type;            /* describe parameters, and its types */
+} 	Code[] = {
+};
+
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   End:
+*/
diff -puN /dev/null not-for-inclusion/parser/parser.tab.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/parser.tab.c	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,194 @@
+short yylhs[] = {                                        -1,
+    0,    6,    6,    6,    6,    6,    6,    6,    6,    6,
+    6,    6,    7,    7,    9,   11,    8,    8,    8,    8,
+    8,    8,    8,    8,    8,    8,   10,    4,    4,    2,
+    2,    5,    5,    3,    3,    1,
+};
+short yylen[] = {                                         2,
+    1,    1,    1,    2,    3,    3,    3,    1,    3,    3,
+    5,    3,    4,    2,    2,    1,    2,    2,    3,    3,
+    3,    3,    3,    3,    3,    3,    2,    1,    3,    2,
+    3,    1,    0,    1,    3,    1,
+};
+short yydefred[] = {                                      0,
+    3,   32,   16,    0,    0,    0,    0,    0,    0,    8,
+    0,    0,    4,    0,    0,    0,    0,    0,   36,   34,
+    0,   30,    0,    0,    0,    0,    0,    0,    0,    0,
+   15,   31,    0,    0,    0,    0,    0,    0,    0,    0,
+    5,   27,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,   35,   13,    0,    0,    0,    0,
+    0,    0,    0,    0,   11,
+};
+short yydgoto[] = {                                       5,
+   21,    6,   22,    7,    8,    9,   10,   31,   11,   27,
+   12,
+};
+short yysindex[] = {                                   -223,
+    0,    0,    0, -223,    0, -266, -250, -199, -259,    0,
+ -283, -248,    0, -199, -258, -226, -223, -223,    0,    0,
+ -223,    0, -223, -223, -223, -223, -274, -223, -223, -201,
+    0,    0, -240, -223, -236, -236, -236, -256, -236, -236,
+    0,    0, -223, -259, -259, -223, -223, -223, -223, -223,
+ -223, -223, -223, -183,    0,    0, -259, -259, -259, -259,
+ -259, -259, -259, -259,    0,
+};
+short yyrindex[] = {                                   -191,
+    0,    0,    0, -191,    0,    1,    0,    0,   57,    0,
+    0, -191,    0,    0, -191, -191, -191, -191,    0,    0,
+ -191,    0, -191, -191, -191, -191,  139, -191, -191,    0,
+    0,    0, -225, -191,   24,   47,   70,    0,   93,  116,
+    0,    0, -191, -218, -214, -191, -191, -191, -191, -191,
+ -191, -191, -191,    0,    0,    0, -206, -200, -197, -196,
+ -194, -193, -283, -192,    0,
+};
+short yygindex[] = {                                      0,
+    0,   67,   78,    0,    0,    2,    0,    0,    0,    0,
+    0,
+};
+short yytable[] = {                                      26,
+    2,   55,   14,   23,   24,   13,   23,   24,   25,   43,
+    2,   25,    1,   30,   16,   17,   18,   35,   36,   37,
+    2,   15,   38,    9,   39,   40,   41,   42,   14,   44,
+   45,   25,   28,    3,    1,   54,   29,    1,    4,   29,
+   29,   29,    2,   34,   56,    2,   10,   57,   58,   59,
+   60,   61,   62,   63,   64,    3,    1,   19,    3,   20,
+    4,   23,   24,    4,   17,   33,   25,   33,   18,   12,
+   46,   47,   48,   49,   50,   51,   19,   52,   53,   23,
+   24,   33,   20,    0,   25,   21,   22,   65,   23,   24,
+   25,   32,    6,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    7,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,   14,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,
+    0,    0,    0,    0,    0,    0,    0,    0,    2,    0,
+    0,    0,    0,    2,    2,   28,   28,   28,    2,    0,
+    0,    2,    2,    2,    2,    2,    2,    2,    0,    2,
+    2,    9,    0,    2,    2,    0,    9,    9,    0,    0,
+    0,    0,    0,    0,    9,    9,    9,    9,    9,    9,
+    9,    0,    9,    9,   10,    0,    9,    9,    0,   10,
+   10,    0,    0,    0,    0,    0,    0,   10,   10,   10,
+   10,   10,   10,   10,    0,   10,   10,   12,    0,   10,
+   10,    0,   12,   12,    0,    0,    0,    0,    0,    0,
+   12,   12,   12,   12,   12,   12,   12,    0,   12,   12,
+    6,    0,   12,   12,    0,    6,    6,    0,    0,    0,
+    0,    0,    0,    6,    6,    6,    6,    6,    6,    6,
+    0,    6,    6,    7,    0,    6,    6,    0,    7,    7,
+    0,    0,    0,    0,    0,    0,    7,    7,    7,    7,
+    7,    7,    7,    0,    7,    7,   14,    0,    7,    7,
+    0,   14,   14,    0,    0,    0,   14,    0,    0,   14,
+   14,   14,   14,   14,   14,   14,    0,   14,   14,    0,
+    0,   14,
+};
+short yycheck[] = {                                     283,
+    0,  258,  269,  263,  264,    4,  263,  264,  268,  284,
+  269,  268,  261,   12,  265,  266,  267,   16,   17,   18,
+  269,  288,   21,    0,   23,   24,   25,   26,  269,   28,
+   29,  268,  281,  282,  261,   34,  285,  261,  287,  265,
+  266,  267,  269,  270,   43,  269,    0,   46,   47,   48,
+   49,   50,   51,   52,   53,  282,    0,  257,  282,  259,
+  287,  263,  264,  287,  283,  257,  268,  259,  283,    0,
+  272,  273,  274,  275,  276,  277,  283,  279,  280,  263,
+  264,   15,  283,   -1,  268,  283,  283,  271,  283,  283,
+  283,   14,    0,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,    0,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,    0,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,
+   -1,   -1,   -1,   -1,   -1,   -1,   -1,   -1,  258,   -1,
+   -1,   -1,   -1,  263,  264,  265,  266,  267,  268,   -1,
+   -1,  271,  272,  273,  274,  275,  276,  277,   -1,  279,
+  280,  258,   -1,  283,  284,   -1,  263,  264,   -1,   -1,
+   -1,   -1,   -1,   -1,  271,  272,  273,  274,  275,  276,
+  277,   -1,  279,  280,  258,   -1,  283,  284,   -1,  263,
+  264,   -1,   -1,   -1,   -1,   -1,   -1,  271,  272,  273,
+  274,  275,  276,  277,   -1,  279,  280,  258,   -1,  283,
+  284,   -1,  263,  264,   -1,   -1,   -1,   -1,   -1,   -1,
+  271,  272,  273,  274,  275,  276,  277,   -1,  279,  280,
+  258,   -1,  283,  284,   -1,  263,  264,   -1,   -1,   -1,
+   -1,   -1,   -1,  271,  272,  273,  274,  275,  276,  277,
+   -1,  279,  280,  258,   -1,  283,  284,   -1,  263,  264,
+   -1,   -1,   -1,   -1,   -1,   -1,  271,  272,  273,  274,
+  275,  276,  277,   -1,  279,  280,  258,   -1,  283,  284,
+   -1,  263,  264,   -1,   -1,   -1,  268,   -1,   -1,  271,
+  272,  273,  274,  275,  276,  277,   -1,  279,  280,   -1,
+   -1,  283,
+};
+#ifndef YYDEBUG
+#define YYDEBUG 0
+#endif
+#if YYDEBUG
+char *yyname[] = {
+"end-of-file",0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,
+0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,"L_BRACKET","R_BRACKET","WORD",
+"P_RUNNER","STRING_CONSTANT","TRANSCRASH","SEMICOLON","COMMA","L_ASSIGN",
+"L_APPEND","L_SYMLINK","PLUS","SLASH","INV_L","INV_R","EQ","NE","LE","GE","LT",
+"GT","IS","AND","OR","NOT","IF","THEN","ELSE","EXIST","NAME","UNNAME","NAMED",
+"ROOT",
+};
+char *yyrule[] = {
+"$accept : reiser4",
+"reiser4 : Expression",
+"Expression : Object_Name",
+"Expression : STRING_CONSTANT",
+"Expression : UNNAME Expression",
+"Expression : Expression PLUS Expression",
+"Expression : Expression SEMICOLON Expression",
+"Expression : Expression COMMA Expression",
+"Expression : if_statement",
+"Expression : target L_ASSIGN Expression",
+"Expression : target L_APPEND Expression",
+"Expression : target L_ASSIGN INV_L Expression INV_R",
+"Expression : target L_SYMLINK Expression",
+"if_statement : if_Begin then_operation ELSE Expression",
+"if_statement : if_Begin then_operation",
+"if_Begin : if if_Expression",
+"if : IF",
+"if_Expression : NOT Expression",
+"if_Expression : EXIST Expression",
+"if_Expression : Expression EQ Expression",
+"if_Expression : Expression NE Expression",
+"if_Expression : Expression LE Expression",
+"if_Expression : Expression GE Expression",
+"if_Expression : Expression LT Expression",
+"if_Expression : Expression GT Expression",
+"if_Expression : Expression OR Expression",
+"if_Expression : Expression AND Expression",
+"then_operation : THEN Expression",
+"target : Object_Name",
+"target : Object_Name NAMED Object_Name",
+"Object_Name : begin_from name",
+"Object_Name : Object_Name SLASH name",
+"begin_from : SLASH",
+"begin_from :",
+"name : WORD",
+"name : level_up Expression R_BRACKET",
+"level_up : L_BRACKET",
+};
+#endif
diff -puN /dev/null not-for-inclusion/parser/parser.tab.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/parser.tab.h	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,40 @@
+#define L_BRACKET 257
+#define R_BRACKET 258
+#define WORD 259
+#define P_RUNNER 260
+#define STRING_CONSTANT 261
+#define TRANSCRASH 262
+#define SEMICOLON 263
+#define COMMA 264
+#define L_ASSIGN 265
+#define L_APPEND 266
+#define L_SYMLINK 267
+#define PLUS 268
+#define SLASH 269
+#define INV_L 270
+#define INV_R 271
+#define EQ 272
+#define NE 273
+#define LE 274
+#define GE 275
+#define LT 276
+#define GT 277
+#define IS 278
+#define AND 279
+#define OR 280
+#define NOT 281
+#define IF 282
+#define THEN 283
+#define ELSE 284
+#define EXIST 285
+#define NAME 286
+#define UNNAME 287
+#define NAMED 288
+#define ROOT 289
+typedef union
+{
+	long charType;
+	expr_v4_t * expr;
+	wrd_t * wrd;
+} YYSTYPE;
+extern YYSTYPE yylval;
diff -puN /dev/null not-for-inclusion/parser/parser.y
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/parser.y	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,175 @@
+/*
+ * Copyright 2001, 2002 by Hans Reiser, licensing governed by reiser4/README
+ */
+
+/* Parser for the reiser4() system call */
+
+
+/* type definitions */
+%union
+{
+	long charType;
+	expr_v4_t * expr;
+	wrd_t * wrd;
+}
+
+%type <charType> L_BRACKET R_BRACKET level_up reiser4
+
+%type <wrd> WORD
+%type <wrd> P_RUNNER
+//%type <wrd> named_level_up
+%type <wrd> STRING_CONSTANT
+
+%type <expr> Object_Name name  target
+//%type <expr> named_expr
+%type <expr> begin_from
+%type <expr> Expression
+
+%type <expr> if_statement
+%type <expr> if_statement if_Expression if_Begin
+%type <expr> then_operation
+
+%token TRANSCRASH
+%token SEMICOLON          /* ; */
+%token COMMA              /* , */
+%token L_ASSIGN L_APPEND  L_SYMLINK
+%token PLUS               /* + */
+%token L_BRACKET R_BRACKET
+%token SLASH
+%token INV_L INV_R
+%token EQ NE  LE GE   LT  GT
+%token IS
+%token AND
+%token OR
+%token P_RUNNER
+%token NOT
+%token IF
+%token THEN ELSE
+%token EXIST
+%token NAME UNNAME NAMED
+%token WORD STRING_CONSTANT
+%token ROOT
+
+
+%left SEMICOLON COMMA
+%right L_SYMLINK L_APPEND L_ASSIGN
+
+%left PLUS               /* + */
+%left UNNAME NAME
+%left EQ NE  LE GE   LT  GT
+%left NOT AND OR
+
+%right ELSE
+
+%left SLASH              /* / */
+
+/*
+For bison:
+%pure_parser
+*/
+
+/*
+  Starting production of our grammar.
+ */
+%start reiser4
+
+%%
+
+reiser4
+    : Expression                                      { $$ = free_expr( ws, $1 ); }
+;
+
+Expression
+    : Object_Name                                     { $$ = $1;}
+    | STRING_CONSTANT                                 { $$ = const_to_expr( ws, $1 ); }
+    | UNNAME Expression                               { $$ = unname( ws, $2 ); }
+    | Expression PLUS       Expression                { $$ = concat_expression( ws, $1, $3 ); }
+    | Expression SEMICOLON  Expression                { $$ = list_expression( ws, $1, $3 ); }
+    | Expression COMMA      Expression                { $$ = list_async_expression( ws, $1, $3 ); }
+    | if_statement                                    { $$ = $1; level_down( ws, IF_STATEMENT, IF_STATEMENT ); }
+                                                                            /* the ASSIGNMENT operator return a value: the expression of target */
+    |  target  L_ASSIGN        Expression             { $$ = assign( ws, $1, $3 ); }            /*  <-  direct assign  */
+    |  target  L_APPEND        Expression             { $$ = assign( ws, $1, $3 ); }            /*  <-  direct assign  */
+    |  target  L_ASSIGN  INV_L Expression INV_R       { $$ = assign_invert( ws, $1, $4 ); }     /*  <-  invert assign. destination must have ..invert method  */
+    |  target  L_SYMLINK       Expression             { $$ = symlink( ws, $1, $3 ); }           /*   ->  symlink  the SYMLINK operator return a value: bytes ???? */
+
+//    | named_level_up Expression R_BRACKET             { $$ = named_level_down( ws, $1, $2, $3 ); }
+;
+//| level_up  Expression R_BRACKET                   { $$ = $2  level_down( ws, $1, $3 );}
+//| Expression            Expression                { $$ = list_unordered_expression( ws, $1, $2 ); }
+
+
+if_statement
+    : if_Begin then_operation ELSE Expression %prec PLUS   { $$ = if_then_else( ws, $1, $2, $4 ); }
+    | if_Begin then_operation                 %prec PLUS   { $$ = if_then( ws, $1, $2) ;         }
+;
+
+if_Begin
+    : if if_Expression                                   { $$ = $2; }
+;
+
+if: IF                                            { level_up( ws, IF_STATEMENT ); }
+;
+
+if_Expression
+    : NOT  Expression                                 { $$ = not_expression( ws, $2 ); }
+    | EXIST  Expression                               { $$ = check_exist( ws, $2 ); }
+    | Expression EQ   Expression                      { $$ = compare_EQ_expression( ws, $1, $3 ); }
+    | Expression NE   Expression                      { $$ = compare_NE_expression( ws, $1, $3 ); }
+    | Expression LE   Expression                      { $$ = compare_LE_expression( ws, $1, $3 ); }
+    | Expression GE   Expression                      { $$ = compare_GE_expression( ws, $1, $3 ); }
+    | Expression LT   Expression                      { $$ = compare_LT_expression( ws, $1, $3 ); }
+    | Expression GT   Expression                      { $$ = compare_GT_expression( ws, $1, $3 ); }
+    | Expression OR   Expression                      { $$ = compare_OR_expression( ws, $1, $3 ); }
+    | Expression AND  Expression                      { $$ = compare_AND_expression( ws, $1, $3 ); }
+;
+
+then_operation
+    : THEN Expression                %prec PLUS       { goto_end( ws );}
+;
+
+target
+    : Object_Name                                     { $$ = $1;}
+    | Object_Name NAMED Object_Name                   { $$ = target_name( $1, $3 );}
+;
+
+Object_Name
+    : begin_from name                 %prec ROOT       { $$ = pars_expr( ws, $1, $2 ) ; }
+    | Object_Name SLASH name                           { $$ = pars_expr( ws, $1, $3 ) ; }
+;
+
+begin_from
+    : SLASH                                            { $$ = pars_lookup_root( ws ) ; }
+    |                                                  { $$ = pars_lookup_curr( ws ) ; }
+;
+
+name
+    : WORD                                             { $$ = lookup_word( ws, $1 ); }
+    | level_up  Expression R_BRACKET                   { $$ = $2; level_down( ws, $1, $3 );}
+;
+
+level_up
+    : L_BRACKET                                        { $$ = $1; level_up( ws, $1 ); }
+;
+
+//named_level_up
+//    : Object_Name NAMED level_up                   { $$ = $1; level_up_named( ws, $1, $3 );}
+//;
+
+%%
+
+
+#define yyversion "4.0.0"
+#include "pars.cls.h"
+#include "parser.tab.c"
+#include "pars.yacc.h"
+#include "lib.c"
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   End:
+*/
diff -puN /dev/null not-for-inclusion/parser/pars.yacc.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/pars.yacc.h	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,66 @@
+/*
+ * Copyright 2001, 2002 by Hans Reiser, licensing governed by reiser4/README
+ */
+
+/*
+ * definitions of work space for yacc generated  from
+ * parser.y
+ */
+
+#define MAXLEVELCO 500
+#define BEGIN_FROM_ROOT 222
+#define BEGIN_FROM_CURRENT 333
+
+struct reiser4_syscall_w_space {
+	char * ws_inline;    /* this two field used for parsing string, one (inline) stay on begin */
+	char * ws_pline;     /*   of token, second (pline) walk to end to token                   */
+#ifdef yyacc
+	                     /* next field need for yacc                   */
+	                     /* accesing to this fields from rules: ws->... */
+	int ws_yystacksize; /*500*/
+	int ws_yymaxdepth ; /*500*/
+	int ws_yydebug;
+	int ws_yynerrs;
+	int ws_yyerrflag;
+	int ws_yychar;
+	int * ws_yyssp;
+	YYSTYPE * ws_yyvsp;
+	YYSTYPE ws_yyval;
+	YYSTYPE ws_yylval;
+	int     ws_yyss[YYSTACKSIZE];
+	YYSTYPE ws_yyvs[YYSTACKSIZE];
+#else
+	/* declare for bison */
+#endif
+	int	ws_yyerrco;
+	int	ws_level;              /* current level            */
+	int	ws_errco;              /* number of errors         */
+	                               /* working fields  */
+	char        * tmpWrdEnd;       /* pointer for parsing input string */
+	char        * yytext;          /* pointer for parsing input string */
+	                               /* space for   */
+	free_space_t * freeSpHead;      /* work spaces list Header */
+	free_space_t * freeSpCur;       /* current work space */
+	wrd_t       * wrdHead;         /* names list Header */
+	pars_var_t  * Head_pars_var;   /* parsed variables Header */
+	streg_t     * Head_level;      /* parsers level list Header */
+	streg_t     * cur_level;       /* current level */
+
+	expr_v4_t   * root_e;          /* root expression  for this task */
+	struct nameidata nd;           /* work field for pass to VFS mount points */
+	atomic_t * lock;
+};
+
+
+
+#define printf prink
+
+/*
+ * Make Linus happy.
+ * Local variables:
+ * c-indentation-style: "K&R"
+ * mode-name: "LC"
+ * c-basic-offset: 8
+ * tab-width: 8
+ * End:
+ */
diff -puN /dev/null not-for-inclusion/parser/tmp.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/tmp.c	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,32 @@
+
+/*
+#define SP      1
+#define SP_SIM  2
+#define WRD     3
+#define SP 22
+#define SP_SIM 23
+#define WRD 24
+*/
+
+#include "../sys_reiser4.c"
+
+int
+main()
+{
+	int i;
+	i = 0;
+	while (i != 307) {
+		printf("-------->%d\n", i = sys_reiser4("a<-b;");
+		       }
+		       return 0;
+		       }
+
+/*
+ * Make Linus happy.
+ * Local variables:
+ * c-indentation-style: "K&R"
+ * mode-name: "LC"
+ * c-basic-offset: 8
+ * tab-width: 8
+ * End:
+ */
diff -puN /dev/null not-for-inclusion/parser/yacc_reiser4.patch
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/parser/yacc_reiser4.patch	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,127 @@
+--- ../yacc/skeleton.c	1993-12-22 14:28:01.000000000 +0300
++++ skeleton.c	2004-01-29 23:05:26.000000000 +0300
+@@ -16,7 +16,7 @@
+ {
+     "#ifndef lint",
+     "/*static char yysccsid[] = \"from: @(#)yaccpar	1.9 (Berkeley) 02/21/93\";*/",
+-    "static char yyrcsid[] = \"$Id: skeleton.c,v 1.4 1993/12/21 18:45:32 jtc Exp $\";",
++    "static char yyrcsid[] = \"$Id: skeleton.c,v 1.4 1993/12/21 18:45:32 jtc Exp $\\n 2002/10/22 VD reiser4\";",
+     "#endif",
+     "#define YYBYACC 1",
+     "#define YYMAJOR 1",
+@@ -30,6 +30,9 @@
+
+ char *tables[] =
+ {
++    "#if defined(YYREISER4_DEF)",
++    "#define extern static",
++    "#endif",
+     "extern short yylhs[];",
+     "extern short yylen[];",
+     "extern short yydefred[];",
+@@ -49,28 +52,45 @@
+
+ char *header[] =
+ {
+-    "#ifdef YYSTACKSIZE",
+-    "#undef YYMAXDEPTH",
+-    "#define YYMAXDEPTH YYSTACKSIZE",
+-    "#else",
+-    "#ifdef YYMAXDEPTH",
+-    "#define YYSTACKSIZE YYMAXDEPTH",
++    "#if defined(YYREISER4_DEF)",
++      "#define YYSTACKSIZE 500",
++      "#define YYMAXDEPTH 500",
++      "#define yydebug ws->ws_yydebug ",
++      "#define yynerrs ws->ws_yynerrs",
++      "#define yyerrflag ws->ws_yyerrflag",
++      "#define yychar ws->ws_yychar",
++      "#define yyssp ws->ws_yyssp",
++      "#define yyvsp ws->ws_yyvsp",
++      "#define yyval ws->ws_yyval",
++      "#define yylval ws->ws_yylval",
++      "#define yyss ws->ws_yyss",
++      "#define yyvs ws->ws_yyvs",
++      "#define yystacksize ws->ws_yystacksize",
+     "#else",
+-    "#define YYSTACKSIZE 500",
+-    "#define YYMAXDEPTH 500",
++      "#ifdef YYSTACKSIZE",
++        "#undef YYMAXDEPTH",
++        "#define YYMAXDEPTH YYSTACKSIZE",
++      "#else",
++        "#ifdef YYMAXDEPTH",
++          "#define YYSTACKSIZE YYMAXDEPTH",
++        "#else",
++          "#define YYSTACKSIZE 500",
++          "#define YYMAXDEPTH 500",
++        "#endif",
++      "#endif",
++      "int yydebug;",
++      "int yynerrs;",
++      "int yyerrflag;",
++      "int yychar;",
++      "short *yyssp;",
++      "YYSTYPE *yyvsp;",
++      "YYSTYPE yyval;",
++      "YYSTYPE yylval;",
++      "short yyss[YYSTACKSIZE];",
++      "YYSTYPE yyvs[YYSTACKSIZE];",
++      "#define yystacksize YYSTACKSIZE",
+     "#endif",
+-    "#endif",
+-    "int yydebug;",
+-    "int yynerrs;",
+-    "int yyerrflag;",
+-    "int yychar;",
+-    "short *yyssp;",
+-    "YYSTYPE *yyvsp;",
+-    "YYSTYPE yyval;",
+-    "YYSTYPE yylval;",
+-    "short yyss[YYSTACKSIZE];",
+-    "YYSTYPE yyvs[YYSTACKSIZE];",
+-    "#define yystacksize YYSTACKSIZE",
++
+     0
+ };
+
+@@ -82,11 +102,15 @@
+     "#define YYACCEPT goto yyaccept",
+     "#define YYERROR goto yyerrlab",
+     "int",
++    "#if defined(YYREISER4_DEF)",
++    "yyparse(struct reiser4_syscall_w_space  * ws)",
++    "#else",
+     "#if defined(__STDC__)",
+     "yyparse(void)",
+     "#else",
+     "yyparse()",
+     "#endif",
++    "#endif",
+     "{",
+     "    register int yym, yyn, yystate;",
+     "#if YYDEBUG",
+@@ -150,7 +174,11 @@
+     "        goto yyreduce;",
+     "    }",
+     "    if (yyerrflag) goto yyinrecovery;",
++    "#if defined(YYREISER4_DEF)",
++    "    yyerror(ws,11111,yystate,yychar);",
++    "#else ",
+     "    yyerror(\"syntax error\");",
++    "#endif",
+     "#ifdef lint",
+     "    goto yyerrlab;",
+     "#endif",
+@@ -275,7 +303,11 @@
+     "    *++yyvsp = yyval;",
+     "    goto yyloop;",
+     "yyoverflow:",
++    "#if defined(YYREISER4_DEF)",
++    "    yyerror(ws,101); /*yacc stack overflow*/",
++    "#else ",
+     "    yyerror(\"yacc stack overflow\");",
++    "#endif",
+     "yyabort:",
+     "    return (1);",
+     "yyaccept:",
diff -puN /dev/null not-for-inclusion/plugin/name/invterp.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/plugin/name/invterp.c	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,11 @@
+/* Invterp is short for invertable interpolate, and interpolate means to
+substitute in.
+
+Example:
+
+/filenameA/<>
+will resolve to
+/filenameA<-`The contents of filenameA'
+wherever used.
+
+*/
diff -puN /dev/null not-for-inclusion/reiser4-for-2.6.9.patch
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/reiser4-for-2.6.9.patch	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,186 @@
+
+This patch is to get reiser4 runable under not mm serie of kernel
+
+diff -puN fs/reiser4/as_ops.c~reiser4-for-2.6.9 fs/reiser4/as_ops.c
+
+
+ fs/reiser4/as_ops.c               |   18 +++++++++---------
+ fs/reiser4/page_cache.c           |    8 ++++----
+ fs/reiser4/plugin/file/file.c     |    8 ++++----
+ fs/reiser4/plugin/object.c        |    1 -
+ fs/reiser4/plugin/security/perm.c |    2 +-
+ 5 files changed, 18 insertions(+), 19 deletions(-)
+
+diff -puN fs/reiser4/as_ops.c~reiser4-for-2.6.9 fs/reiser4/as_ops.c
+--- linux-2.6.9/fs/reiser4/as_ops.c~reiser4-for-2.6.9	2004-12-08 16:27:45.008736629 +0300
++++ linux-2.6.9-vs/fs/reiser4/as_ops.c	2004-12-08 16:28:54.056614275 +0300
+@@ -75,7 +75,7 @@ reiser4_clear_page_dirty(struct page *pa
+ 	mapping = page->mapping;
+ 	BUG_ON(mapping == NULL);
+ 
+-	read_lock_irqsave(&mapping->tree_lock, flags);
++	spin_lock_irqsave(&mapping->tree_lock, flags);
+ 	if (TestClearPageDirty(page)) {
+ 		/* clear dirty tag of page in address space radix tree */
+ 		radix_tree_tag_clear(&mapping->page_tree, page->index,
+@@ -84,12 +84,12 @@ reiser4_clear_page_dirty(struct page *pa
+ 		radix_tree_tag_clear(&mapping->page_tree, page->index,
+ 				     PAGECACHE_TAG_REISER4_MOVED);
+ 
+-		read_unlock_irqrestore(&mapping->tree_lock, flags);
++		spin_unlock_irqrestore(&mapping->tree_lock, flags);
+ 		if (!mapping->backing_dev_info->memory_backed)
+ 			dec_page_state(nr_dirty);
+ 		return;
+ 	}
+-	read_unlock_irqrestore(&mapping->tree_lock, flags);
++	spin_unlock_irqrestore(&mapping->tree_lock, flags);
+ }
+ 
+ /* as_ops->set_page_dirty() VFS method in reiser4_address_space_operations.
+@@ -114,7 +114,7 @@ static int reiser4_set_page_dirty(struct
+ 		struct address_space *mapping = page->mapping;
+ 
+ 		if (mapping) {
+-			read_lock_irq(&mapping->tree_lock);
++			spin_lock_irq(&mapping->tree_lock);
+ 			/* check for race with truncate */
+ 			if (page->mapping) {
+ 				assert("vs-1652", page->mapping == mapping);
+@@ -126,7 +126,7 @@ static int reiser4_set_page_dirty(struct
+ 				radix_tree_tag_set(&mapping->page_tree,
+ 						   page->index, PAGECACHE_TAG_REISER4_MOVED);
+ 			}
+-			read_unlock_irq(&mapping->tree_lock);
++			spin_unlock_irq(&mapping->tree_lock);
+ 			__mark_inode_dirty(mapping->host, I_DIRTY_PAGES);
+ 		}
+ 	}
+@@ -145,14 +145,14 @@ int reiser4_set_page_dirty2(struct page 
+ 		struct address_space *mapping = page->mapping;
+ 
+ 		if (mapping) {
+-			read_lock_irq(&mapping->tree_lock);
++			spin_lock_irq(&mapping->tree_lock);
+ 			/* check for race with truncate */
+ 			if (page->mapping) {
+ 				assert("vs-1652", page->mapping == mapping);
+ 				if (!mapping->backing_dev_info->memory_backed)
+ 					inc_page_state(nr_dirty);
+ 			}
+-			read_unlock_irq(&mapping->tree_lock);
++			spin_unlock_irq(&mapping->tree_lock);
+ 			__mark_inode_dirty(mapping->host, I_DIRTY_PAGES);
+ 		}
+ 	}
+@@ -600,13 +600,13 @@ reiser4_releasepage(struct page *page, i
+ 		/* we are under memory pressure so release jnode also. */
+ 		jput(node);
+ 
+-		write_lock_irq(&mapping->tree_lock);
++		spin_lock_irq(&mapping->tree_lock);
+ 		/* shrink_list() + radix-tree */
+ 		if (page_count(page) == 2) {
+ 			__remove_from_page_cache(page);
+ 			__put_page(page);
+ 		}
+-		write_unlock_irq(&mapping->tree_lock);
++		spin_unlock_irq(&mapping->tree_lock);
+ 
+ 		return 1;
+ 	} else {
+diff -puN fs/reiser4/page_cache.c~reiser4-for-2.6.9 fs/reiser4/page_cache.c
+--- linux-2.6.9/fs/reiser4/page_cache.c~reiser4-for-2.6.9	2004-12-08 16:27:45.014737053 +0300
++++ linux-2.6.9-vs/fs/reiser4/page_cache.c	2004-12-08 16:27:45.035738537 +0300
+@@ -533,7 +533,7 @@ int set_page_dirty_internal (struct page
+ 		struct address_space *mapping = page->mapping;
+ 
+ 		if (mapping) {
+-			read_lock_irq(&mapping->tree_lock);
++			spin_lock_irq(&mapping->tree_lock);
+ 			if (page->mapping) {	/* Race with truncate? */
+ 				BUG_ON(page->mapping != mapping);
+ 				if (!mapping->backing_dev_info->memory_backed)
+@@ -551,7 +551,7 @@ int set_page_dirty_internal (struct page
+ 						PAGECACHE_TAG_REISER4_MOVED);
+ 				}
+ 			}
+-			read_unlock_irq(&mapping->tree_lock);
++			spin_unlock_irq(&mapping->tree_lock);
+ 			__mark_inode_dirty(mapping->host, I_DIRTY_PAGES);
+ 		}
+ 	}
+@@ -595,13 +595,13 @@ reiser4_internal void capture_reiser4_in
+ 			struct address_space * mapping = inode->i_mapping;
+ 			unsigned long flags;
+ 
+-			read_lock_irqsave(&mapping->tree_lock, flags);
++			spin_lock_irqsave(&mapping->tree_lock, flags);
+ 			if (!radix_tree_tagged(&mapping->page_tree, PAGECACHE_TAG_DIRTY) &&
+ 			    !radix_tree_tagged(&mapping->page_tree, PAGECACHE_TAG_REISER4_MOVED))
+ 			{
+ 				inode->i_state &= ~(I_DIRTY);
+ 			}
+-			read_unlock_irqrestore(&mapping->tree_lock, flags);
++			spin_unlock_irqrestore(&mapping->tree_lock, flags);
+ 		}
+ 		spin_unlock(&inode_lock);
+ 
+diff -puN fs/reiser4/plugin/file/file.c~reiser4-for-2.6.9 fs/reiser4/plugin/file/file.c
+--- linux-2.6.9/fs/reiser4/plugin/file/file.c~reiser4-for-2.6.9	2004-12-08 16:27:45.019737406 +0300
++++ linux-2.6.9-vs/fs/reiser4/plugin/file/file.c	2004-12-08 16:27:45.038738749 +0300
+@@ -1363,7 +1363,7 @@ sync_page_list(struct inode *inode)
+ 	mapping = inode->i_mapping;
+ 	from = 0;
+ 	result = 0;
+-	read_lock_irq(&mapping->tree_lock);
++	spin_lock_irq(&mapping->tree_lock);
+ 	while (result == 0) {
+ 		struct page *page;
+ 
+@@ -1375,17 +1375,17 @@ sync_page_list(struct inode *inode)
+ 		/* page may not leave radix tree because it is protected from truncating by inode->i_sem downed by
+ 		   sys_fsync */
+ 		page_cache_get(page);
+-		read_unlock_irq(&mapping->tree_lock);
++		spin_unlock_irq(&mapping->tree_lock);
+ 
+ 		from = page->index + 1;
+ 
+ 		result = sync_page(page);
+ 
+ 		page_cache_release(page);
+-		read_lock_irq(&mapping->tree_lock);
++		spin_lock_irq(&mapping->tree_lock);
+ 	}
+ 
+-	read_unlock_irq(&mapping->tree_lock);
++	spin_unlock_irq(&mapping->tree_lock);
+ 	return result;
+ }
+ 
+diff -puN fs/reiser4/plugin/object.c~reiser4-for-2.6.9 fs/reiser4/plugin/object.c
+--- linux-2.6.9/fs/reiser4/plugin/object.c~reiser4-for-2.6.9	2004-12-08 16:27:45.024737760 +0300
++++ linux-2.6.9-vs/fs/reiser4/plugin/object.c	2004-12-08 16:27:45.040738890 +0300
+@@ -991,7 +991,6 @@ static void delete_inode_common(struct i
+ 	 * FIXME: this resembles generic_delete_inode
+ 	 */
+ 	list_del_init(&object->i_list);
+-	list_del_init(&object->i_sb_list);
+ 	object->i_state |= I_FREEING;
+ 	inodes_stat.nr_inodes--;
+ 	spin_unlock(&inode_lock);
+diff -puN fs/reiser4/plugin/security/perm.c~reiser4-for-2.6.9 fs/reiser4/plugin/security/perm.c
+--- linux-2.6.9/fs/reiser4/plugin/security/perm.c~reiser4-for-2.6.9	2004-12-08 16:27:45.028738042 +0300
++++ linux-2.6.9-vs/fs/reiser4/plugin/security/perm.c	2004-12-08 16:27:45.041738961 +0300
+@@ -14,7 +14,7 @@
+ static int
+ mask_ok_common(struct inode *inode, int mask)
+ {
+-	return generic_permission(inode, mask, NULL);
++	return vfs_permission(inode, mask);
+ }
+ 
+ static int
+
+_
diff -puN /dev/null not-for-inclusion/sys_reiser4_2.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/sys_reiser4_2.c	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,1174 @@
+
+/*
+ * Below is an implementation of hand crafted "recursive descent" parser. It
+ * is not based on the yacc toolkit.
+ *
+ * This parser was initially supposed to be a prototype implementation created
+ * to develop and test back end methods to be used by the yacc parser. For
+ * this reason, parser's functions are placed into proto_* name space.
+ *
+ * Parser is actually almost non-recursive. That is, it all information
+ * required during the parsing is kept in a special stack, allocated by
+ * kmalloc, rather than on the native C stack. Parser uses C recursion, but
+ * only for the simplicity of prototyping---the only information communicated
+ * via C stack is integer return codes. It should be trivial to maintain it in
+ * the allocated stack and to re-write parser in the iterative manner.
+ *
+ * Grammar:
+ *
+ *     expression ::= binary_exp { ; binary_exp }
+ *
+ *     binary_exp ::= path | path binop binary_exp
+ *
+ *     path       ::= literal | rel_path | / rel_path
+ *
+ *     literal    ::= "string" | #number
+ *
+ *     rel_path   ::= name { / name }
+ *
+ *     name       ::= name_token | ( expression )
+ *
+ *     binop      ::= <-
+ *
+ *
+ * Examples:
+ *
+ *     (1) a/b <- /etc/passwd
+ *
+ *     (2) "foo"
+ *
+ *     (3) #3
+ *
+ *
+ * Implementation:
+ *
+ * parsing is done in the context represented by data type proto_ctx_t.
+ *
+ * Types of terminal tokens are represented by values of proto_token_type_t
+ * enumeration. Particular tokens, met during parsing are represented by
+ * instances of proto_token_t.
+ *
+ * proto_ctx_t contains a stack used to recursively parse
+ * sub-expressions. Each subexpression has a value represented by instance of
+ * proto_val_t. Values have types, types are represented by proto_val_type_t
+ * enumeration.
+ *
+ * Each non-terminal token is parsed by special function, and all terminals
+ * are parsed by next_token().
+ *
+ * TO BE DONE:
+ *
+ *     1. more sophisticated fs_point_t with support for lnodes
+ *
+ *     2. hub-based assignment
+ *
+ *     3. locking during name resolutions
+ *
+ *
+ *
+ *
+ */
+
+
+#include "debug.h"
+#include "lnode.h"
+
+#include <linux/ctype.h>
+#include <linux/mount.h> /* mnt{get,put}() */
+
+/* maximal recursion depth */
+#define PROTO_LEVELS (100)
+
+/* types of terminal tokens */
+typedef enum proto_token_type {
+	TOKEN_NAME,		/* file name, part of a pathname */
+	TOKEN_SLASH,		/* / */
+	TOKEN_ASSIGNMENT,	/* <- */
+	TOKEN_LPAREN,		/* ( */
+	TOKEN_RPAREN,		/* ) */
+	TOKEN_STRING,		/* "foo" string literal */
+	TOKEN_NUMBER,		/* #100  decimal number */
+	TOKEN_LESS_THAN,	/* < */
+	TOKEN_GREATER_THAN,	/* > */
+	TOKEN_EQUAL_TO,		/* = */
+	TOKEN_SEMICOLON,	/* ; */
+	TOKEN_COMMA,    	/* , */
+	TOKEN_EOF,		/* eof-of-file reached */
+	TOKEN_INVALID		/* syntax-error */
+} proto_token_type_t;
+
+/* terminal token */
+typedef struct proto_token {
+	/* type of the token */
+	proto_token_type_t  type;
+	/* position within command, where this token starts */
+	int                 pos;
+	/* union of data associated with this token */
+	union {
+		struct {
+			/* for name and string literal: token length */
+			int len;
+			/* offset from ->pos to position where actual token
+			 * content starts */
+			int delta;
+		} name, string;
+		struct {
+			/* for number---its value */
+			long val;
+		} number;
+	} u;
+} proto_token_t;
+
+/* types of values that expressions can result in */
+typedef enum proto_val_type {
+	/* file system object---pathname results in this */
+	VAL_FSOBJ,
+	/* number---number literal and assignment result in this */
+	VAL_NUMBER,
+	/* string---string literal results in this */
+	VAL_STRING,
+	/* error---ill-formed expression, and execution error result in
+	 * this */
+	VAL_ERROR,
+	/* no value */
+	VAL_VOID
+} proto_val_type_t;
+
+/* file system object representation. This is needed to interface with VFS */
+typedef struct fs_point {
+	struct dentry   *dentry;
+	struct vfsmount *mnt;
+} fs_point_t;
+
+/* value of expression */
+typedef struct proto_val {
+	/* value type */
+	proto_val_type_t type;
+	/* value itself. Union by various value types. */
+	union {
+		/* VAL_FSOBJ */
+		fs_point_t fsobj;
+		/* VAL_NUMBER */
+		long       number;
+		/* VAL_STRING */
+		struct {
+			char *string;
+			int   len;
+		} string;
+		/* VAL_ERROR */
+		struct {
+			/* error message */
+			char  *error;
+			/* position in a command, where error occurred */
+			int    error_pos;
+		} error;
+	} u;
+} proto_val_t;
+
+/* data maintained for each recursion level. */
+typedef struct proto_level {
+	/* error message, if error occurred at this level */
+	const char    *error;
+	/* error position within command, if error occurred at this level */
+	int            error_pos;
+	/* value of expression, calculated at this level */
+	proto_val_t    val;
+	/* point in a file system from which relative names are resolved at
+	 * this level */
+	fs_point_t     cur;
+} proto_level_t;
+
+/* global parsing flags */
+typedef enum proto_flags {
+	/* set whenever syntax error is detected */
+	CTX_PARSE_ERROR = (1 << 0)
+} proto_flags_t;
+
+/* parsing context. */
+typedef struct proto_ctx {
+	/* global flags */
+	__u32          flags;
+	/* command being parsed and executed */
+	const char    *command;
+	/* length of ->command */
+	int            len;
+	/* current parsing position within ->command */
+	int            pos;
+	/* recursion depth */
+	int            depth;
+	/* array of levels */
+	proto_level_t *level;
+	/* where to resolve relative pathnames from */
+	fs_point_t     cwd;
+	/* where to resolve absolute pathnames from */
+	fs_point_t     root;
+} proto_ctx_t;
+
+static int parse_exp(proto_ctx_t *ctx);
+
+#define PTRACE(ctx, format, ... )						\
+({										\
+	ON_TRACE(TRACE_PARSE, "parse: %02i at %i[%c]: %s: " format "\n",	\
+		 ctx->depth,							\
+		 ctx->pos, char_at(ctx, ctx->pos) ? : '.',			\
+		 __FUNCTION__ , __VA_ARGS__);					\
+})
+
+/* methods to manipulate fs_point_t objects */
+
+/* acquire a reference to @fsobj */
+static fs_point_t *fsget(fs_point_t *fsobj)
+{
+	dget(fsobj->dentry);
+	mntget(fsobj->mnt);
+	return fsobj;
+}
+
+/* release a reference to @fsobj */
+static void fsput(fs_point_t *fsobj)
+{
+	if (fsobj->dentry != NULL) {
+		dput(fsobj->dentry);
+		fsobj->dentry = NULL;
+	}
+	if (fsobj->mnt != NULL) {
+		mntput(fsobj->mnt);
+		fsobj->mnt = NULL;
+	}
+}
+
+/* duplicate a reference to @src in @dst */
+static fs_point_t *fscpy(fs_point_t *dst, fs_point_t *src)
+{
+	*dst = *src;
+	return fsget(dst);
+}
+
+/* current character in a command */
+static char char_at(proto_ctx_t *ctx, int pos)
+{
+	if (pos < ctx->len)
+		return ctx->command[pos];
+	else
+		return 0;
+}
+
+/* current level */
+static proto_level_t *get_level(proto_ctx_t *ctx)
+{
+	assert("nikita-3233", ctx->depth < PROTO_LEVELS);
+	return &ctx->level[ctx->depth];
+}
+
+/* current value---value stored in the current level */
+static proto_val_t *get_val(proto_ctx_t *ctx)
+{
+	return &get_level(ctx)->val;
+}
+
+/* from where relative names should be resolved */
+static fs_point_t *get_cur(proto_ctx_t *ctx)
+{
+	int i;
+
+	for (i = ctx->depth; i >= 0; -- i) {
+		if (ctx->level[i].cur.dentry != NULL)
+			return &ctx->level[i].cur;
+	}
+	return &ctx->cwd;
+}
+
+/* move typed value from one location to another */
+static void proto_val_move(proto_val_t *dst, proto_val_t *src)
+{
+	xmemmove(dst, src, sizeof *dst);
+	src->type = VAL_VOID;
+}
+
+/* finish with value */
+static void proto_val_put(proto_val_t *val)
+{
+	switch(val->type) {
+	case VAL_FSOBJ:
+		fsput(&val->u.fsobj);
+		break;
+	case VAL_STRING:
+		if (val->u.string.string != NULL) {
+			kfree(val->u.string.string);
+			val->u.string.string = NULL;
+		}
+		break;
+	case VAL_NUMBER:
+	case VAL_ERROR:
+	case VAL_VOID:
+		break;
+	}
+	val->type = VAL_VOID;
+}
+
+/* move value one level up. Useful when value produced by an expression is the
+ * value of its sub-expression. */
+static void proto_val_up(proto_ctx_t *ctx)
+{
+	assert("nikita-3236", ctx->depth > 0);
+	proto_val_move(&ctx->level[ctx->depth - 1].val, get_val(ctx));
+}
+
+/* signal an error */
+static void post_error(proto_ctx_t *ctx, char *error)
+{
+	proto_val_t *val;
+
+	PTRACE(ctx, "%s", error);
+
+	get_level(ctx)->error = error;
+	get_level(ctx)->error_pos = ctx->pos;
+	ctx->flags |= CTX_PARSE_ERROR;
+	val = get_val(ctx);
+	proto_val_put(val);
+	val->type = VAL_ERROR;
+	val->u.error.error = error;
+	val->u.error.error_pos = ctx->pos;
+}
+
+/* parse string literal */
+static proto_token_type_t extract_string(proto_ctx_t *ctx, int *outpos,
+					 proto_token_t *token)
+{
+	int len;
+	int pos;
+
+	/* simplistic string literal---no escape handling. Feel free to
+	 * improve. */
+	pos = *outpos;
+	for (len = 0; ; ++ len, ++ pos) {
+		char ch;
+
+		ch = char_at(ctx, pos);
+		if (ch == '"') {
+			token->type = TOKEN_STRING;
+			token->u.string.len = len;
+			/* string literal start with a quote that should be
+			 * skipped */
+			token->u.string.delta = 1;
+			*outpos = pos + 1;
+			PTRACE(ctx, "%i", len);
+			break;
+		} else if (ch == 0) {
+			token->type = TOKEN_INVALID;
+			post_error(ctx, "eof in string");
+			break;
+		}
+	}
+	return token->type;
+}
+
+static int unhex(char ch)
+{
+	ch = tolower(ch);
+
+	if (ch >= '0' && ch <= '9')
+		return ch - '0';
+	else if (ch >= 'a' && ch <= 'f')
+		return ch - 'a' + 0xa;
+	return 0xff;
+}
+
+/* construct zero number */
+static proto_token_type_t number_zero(proto_token_t *token)
+{
+	token->type = TOKEN_NUMBER;
+	token->u.number.val = 0;
+	return TOKEN_NUMBER;
+}
+
+/* parse number literal */
+static proto_token_type_t extract_number(proto_ctx_t *ctx, int *pos,
+					 proto_token_t *token)
+{
+	char ch;
+	int  sign;
+	int  base;
+	long val;
+
+	ch = char_at(ctx, *pos);
+
+	sign = +1;
+
+	if (ch == '+')
+		++ *pos;
+	else if (ch == '-') {
+		++ *pos;
+		sign = -1;
+	} else if (!isdigit(ch)) {
+		token->type = TOKEN_INVALID;
+		*pos = token->pos;
+		return TOKEN_INVALID;
+	}
+
+	val = (ch - '0');
+	base = 10;
+	++ *pos;
+	if (val == 0) {
+		base = 010;
+		if (!isxdigit(char_at(ctx, *pos)) &&
+		    isxdigit(char_at(ctx, *pos + 1))) {
+			/* 0[xXoOdDtT]<digits> */
+			switch (char_at(ctx, *pos)) {
+			case 'x':
+			case 'X':
+				base = 0x10;
+				break;
+			case 'o':
+			case 'O':
+				base = 010;
+				break;
+			case 'd':
+			case 'D':
+				base = 10;
+				break;
+			case 't':
+			case 'T':
+				base = 2;
+				break;
+			default:
+				return number_zero(token);
+			}
+			if (unhex(char_at(ctx, *pos + 1)) >= base)
+				return number_zero(token);
+			++ *pos;
+		}
+	}
+	for (;; ++ *pos) {
+		int  digit;
+		long newval;
+
+		ch = char_at(ctx, *pos);
+		if (!isxdigit(ch))
+			break;
+		digit = unhex(ch);
+		if (digit < 0 || digit >= base)
+			break;
+		newval = val * base + digit;
+		if (newval > val || (val == newval && digit == 0))
+			val = newval;
+		else {
+			token->type = TOKEN_INVALID;
+			post_error(ctx, "integer overflow");
+			*pos = token->pos;
+			return TOKEN_INVALID;
+		}
+	}
+	token->type = TOKEN_NUMBER;
+	PTRACE(ctx, "%li", val);
+	token->u.number.val = sign * val;
+	return token->type;
+}
+
+/* parse name token */
+static proto_token_type_t extract_name(proto_ctx_t *ctx, int *pos,
+				       proto_token_t *token)
+{
+	int len;
+
+	/* name is sequence of any characters save for /, <, and + */
+	for (len = 0;  ; ++ *pos, ++ len) {
+		char ch;
+
+		ch = char_at(ctx, *pos);
+		if (isspace(ch))
+			break;
+		if (ch == 0)
+			break;
+		if (strchr("/+-=()[]<>;,", ch) != NULL)
+			break;
+	}
+	if (len == 0) {
+		token->type = TOKEN_INVALID;
+	} else {
+		token->type = TOKEN_NAME;
+		token->u.name.len = len;
+		token->u.name.delta = 0;
+		PTRACE(ctx, "%i", len);
+	}
+	return token->type;
+}
+
+static proto_token_type_t extract_extended_string(proto_ctx_t *ctx, int *pos,
+						  proto_token_t *token,
+						  proto_token_type_t ttype)
+{
+	proto_token_t width;
+
+	/* s<width>:bytes */
+	token->type = TOKEN_INVALID;
+	++ *pos;
+	/* <width>:bytes */
+	if (extract_number(ctx, pos, &width) == TOKEN_NUMBER) {
+		/* :bytes */
+		if (char_at(ctx, *pos) == ':') {
+			++ *pos;
+			/* bytes */
+			token->type = ttype;
+			token->u.string.len = width.u.number.val;
+			token->u.string.delta = *pos - token->pos;
+			*pos += token->u.string.len;
+		}
+	}
+	if (token->type == TOKEN_INVALID)
+		*pos = token->pos;
+	return token->type;
+}
+
+/* parse #-literal */
+static proto_token_type_t extract_extended_literal(proto_ctx_t *ctx, int *pos,
+						   proto_token_t *token)
+{
+	char ch;
+
+	ch = char_at(ctx, *pos);
+	if (isdigit(ch))
+		return extract_number(ctx, pos, token);
+
+	/* "#s<width>:bytes" */
+	if (ch == 's')
+		return extract_extended_string(ctx, pos, token, TOKEN_STRING);
+	if (ch == 'n')
+		return extract_extended_string(ctx, pos, token, TOKEN_NAME);
+	/* put "#" back */
+	-- *pos;
+	token->type = TOKEN_INVALID;
+	return TOKEN_INVALID;
+}
+
+/* return next token */
+static proto_token_type_t next_token(proto_ctx_t *ctx,
+				     proto_token_t *token)
+{
+	proto_token_type_t ttype;
+	int pos;
+
+	/* skip white spaces */
+	for (; isspace(char_at(ctx, ctx->pos)) ; ++ ctx->pos)
+	{;}
+
+	pos = token->pos = ctx->pos;
+	switch (char_at(ctx, pos ++)) {
+	case '/':
+		ttype = TOKEN_SLASH;
+		break;
+	case '(':
+		ttype = TOKEN_LPAREN;
+		break;
+	case ')':
+		ttype = TOKEN_RPAREN;
+		break;
+	case ';':
+		ttype = TOKEN_SEMICOLON;
+		break;
+	case ',':
+		ttype = TOKEN_COMMA;
+		break;
+	case '"':
+		ttype = extract_string(ctx, &pos, token);
+		break;
+	case '<':
+		if (char_at(ctx, pos) == '-') {
+			ttype = TOKEN_ASSIGNMENT;
+			++ pos;
+		} else
+			ttype = TOKEN_LESS_THAN;
+		break;
+	case 0:
+		ttype = TOKEN_EOF;
+		-- pos;
+		break;
+	case '#':
+		ttype = extract_extended_literal(ctx, &pos, token);
+		break;
+	default:
+		-- pos;
+		ttype = extract_name(ctx, &pos, token);
+		break;
+	}
+	token->type = ttype;
+	ctx->pos = pos;
+	PTRACE(ctx, "%i", ttype);
+	return ttype;
+}
+
+/* push token back into command, so that next_token() will return @token
+ * again */
+static void back_token(proto_ctx_t *ctx, proto_token_t *token)
+{
+	assert("nikita-3237", ctx->pos >= token->pos);
+	/* it is -that- simple */
+	ctx->pos = token->pos;
+}
+
+/* finish with context, release all resources */
+static void ctx_done(proto_ctx_t *ctx)
+{
+	if (ctx->level != NULL) {
+		kfree(ctx->level);
+		ctx->level = NULL;
+	}
+	fsput(&ctx->cwd);
+	fsput(&ctx->root);
+}
+
+/* initialize context for parsing and executing @command */
+static int ctx_init(proto_ctx_t *ctx, const char *command)
+{
+	int result;
+
+	xmemset(ctx, 0, sizeof *ctx);
+	ctx->command = command;
+	ctx->len = strlen(command);
+	ctx->level = kmalloc(sizeof (ctx->level[0]) * PROTO_LEVELS,
+			     GFP_KERNEL);
+	xmemset(ctx->level, 0, sizeof (ctx->level[0]) * PROTO_LEVELS);
+	if (ctx->level != NULL) {
+
+		read_lock(&current->fs->lock);
+		ctx->cwd.dentry  = dget(current->fs->pwd);
+		ctx->cwd.mnt     = mntget(current->fs->pwdmnt);
+		ctx->root.dentry = dget(current->fs->root);
+		ctx->root.mnt    = mntget(current->fs->rootmnt);
+		read_unlock(&current->fs->lock);
+
+		result = 0;
+	} else
+		result = -ENOMEM;
+	if (result != 0)
+		ctx_done(ctx);
+	return result;
+}
+
+/* go one level deeper to parse and execute sub-expression */
+static int inlevel(proto_ctx_t *ctx)
+{
+	if (ctx->depth >= PROTO_LEVELS - 1) {
+		/* handle stack overflow */
+		post_error(ctx, "stack overflow");
+		return -EOVERFLOW;
+	}
+	++ ctx->depth;
+	xmemset(get_level(ctx), 0, sizeof *get_level(ctx));
+	get_val(ctx)->type = VAL_VOID;
+	return 0;
+}
+
+/* go one level up */
+static void exlevel(proto_ctx_t *ctx)
+{
+	assert("nikita-3235", ctx->depth > 0);
+	proto_val_put(get_val(ctx));
+	fsput(&get_level(ctx)->cur);
+	-- ctx->depth;
+}
+
+/* given @token which should be token for string literal, produce string
+ * value */
+static void build_string_val(proto_ctx_t *ctx,
+			     proto_token_t *token, proto_val_t *val)
+{
+	int len;
+
+	assert("nikita-3238",
+	       token->type == TOKEN_STRING || token->type == TOKEN_NAME);
+
+	len = token->u.string.len;
+	val->type = VAL_STRING;
+	val->u.string.string = kmalloc(len + 1, GFP_KERNEL);
+	if (val->u.string.string != NULL) {
+		strncpy(val->u.string.string,
+			ctx->command + token->pos + token->u.string.delta, len);
+		val->u.string.string[len] = 0;
+		val->u.string.len = len;
+	}
+}
+
+/* given @token which should be token for a number literal, produce number
+ * value */
+static void build_number_val(proto_ctx_t *ctx,
+			     proto_token_t *token, proto_val_t *val)
+{
+	assert("nikita-3245", token->type == TOKEN_NUMBER);
+
+	val->type = VAL_NUMBER;
+	val->u.number = token->u.number.val;
+}
+
+/* follow mount points. COPIED from fs/namei.c */
+static void follow_mount(fs_point_t * fsobj)
+{
+	while (d_mountpoint(fsobj->dentry)) {
+		struct vfsmount *mounted;
+
+		spin_lock(&dcache_lock);
+		mounted = lookup_mnt(fsobj->mnt, fsobj->dentry);
+		if (!mounted) {
+			spin_unlock(&dcache_lock);
+			break;
+		}
+		fsobj->mnt = mntget(mounted);
+		spin_unlock(&dcache_lock);
+		dput(fsobj->dentry);
+		mntput(mounted->mnt_parent);
+		fsobj->dentry = dget(mounted->mnt_root);
+	}
+}
+
+/* resolve @name within @parent and return resulting object in @fsobj.
+ * COPIED from fs/namei.c, fs/dcache.c */
+static int lookup(fs_point_t * parent, const char * name, fs_point_t * fsobj)
+{
+	unsigned long hash;
+	struct qstr qname;
+	int result;
+	unsigned int c;
+
+	qname.name = name;
+	c = *(const unsigned char *)name;
+
+	hash = init_name_hash();
+	do {
+		name++;
+		hash = partial_name_hash(c, hash);
+		c = *(const unsigned char *)name;
+	} while (c != 0);
+	qname.len = name - (const char *) qname.name;
+	qname.hash = end_name_hash(hash);
+
+	result = 0;
+	fsobj->dentry = __d_lookup(parent->dentry, &qname);
+	if (fsobj->dentry == NULL) {
+		struct inode *dir;
+
+		dir = parent->dentry->d_inode;
+		down(&dir->i_sem);
+		fsobj->dentry = d_lookup(parent->dentry, &qname);
+		if (fsobj->dentry == NULL) {
+			struct dentry * new;
+
+			new = d_alloc(parent->dentry, &qname);
+			if (new != NULL) {
+				fsobj->dentry = dir->i_op->lookup(dir, new);
+				if (fsobj->dentry != NULL) {
+					dput(new);
+					result = PTR_ERR(fsobj->dentry);
+				} else if (new->d_inode != NULL)
+					fsobj->dentry = new;
+				else {
+					dput(new);
+					result = RETERR(-ENOENT);
+				}
+			} else
+				result = RETERR(-ENOMEM);
+		}
+		up(&dir->i_sem);
+	}
+	if (result == 0) {
+		fsobj->mnt = parent->mnt;
+		follow_mount(fsobj);
+	}
+	return result;
+}
+
+#define START_KERNEL_IO				\
+        {					\
+		mm_segment_t __ski_old_fs;	\
+						\
+		__ski_old_fs = get_fs();	\
+		set_fs(KERNEL_DS)
+
+#define END_KERNEL_IO				\
+		set_fs(__ski_old_fs);		\
+	}
+
+#define PUMP_BUF_SIZE (PAGE_CACHE_SIZE)
+
+/* perform actual assignment (copying) from @righthand to @lefthand */
+static int pump(fs_point_t *lefthand, fs_point_t *righthand)
+{
+	int result;
+	char *buf;
+	loff_t readoff;
+	loff_t writeoff;
+	struct file *dst;
+	struct file *src;
+
+	buf = kmalloc(PUMP_BUF_SIZE, GFP_KERNEL);
+	if (buf == NULL)
+		return RETERR(-ENOMEM);
+
+	src = dentry_open(righthand->dentry, righthand->mnt, O_RDONLY);
+	if (!IS_ERR(src)) {
+		mntget(righthand->mnt); /* simulate open_namei() */
+		dget(righthand->dentry);
+		dst = dentry_open(lefthand->dentry, lefthand->mnt, O_WRONLY);
+		if (!IS_ERR(dst)) {
+			mntget(lefthand->mnt); /* simulate open_namei() */
+			dget(lefthand->dentry);
+			readoff = writeoff = 0;
+			result = 0;
+			START_KERNEL_IO;
+			while (result >= 0) {
+				result = vfs_read(src,
+						  buf, PUMP_BUF_SIZE, &readoff);
+				if (result <= 0)
+					break;
+				/* give other threads chance to run */
+				preempt_point();
+				result = vfs_write(dst, buf, result, &writeoff);
+			}
+			END_KERNEL_IO;
+			if (result == 0)
+				result = writeoff;
+			filp_close(dst, current->files);
+		} else
+			result = PTR_ERR(dst);
+		filp_close(src, current->files);
+	} else
+		result = PTR_ERR(src);
+
+	kfree(buf);
+	return result;
+}
+
+/* perform actual assignment (copying) from buffer to @lefthand */
+static int pump_buf(fs_point_t *lefthand, char *buf, int len)
+{
+	int result;
+	loff_t writeoff;
+	struct file *dst;
+
+	dst = dentry_open(lefthand->dentry, lefthand->mnt, O_WRONLY);
+	if (!IS_ERR(dst)) {
+		writeoff = 0;
+		result = 0;
+		START_KERNEL_IO;
+		while (len > writeoff && result >= 0)
+			result = vfs_write(dst, buf + writeoff,
+					   len - writeoff, &writeoff);
+		END_KERNEL_IO;
+		if (result == 0)
+			result = writeoff;
+		filp_close(dst, current->files);
+	} else
+		result = PTR_ERR(dst);
+
+	return result;
+}
+
+/* prepare and perform assignment, store result at the level */
+static int proto_assign(proto_ctx_t *ctx, proto_val_t *lhs, proto_val_t *rhs)
+{
+	int result;
+	fs_point_t dst;
+
+	if (lhs->type != VAL_FSOBJ) {
+		post_error(ctx, "cannot assign");
+		return -EINVAL;
+	}
+
+	fscpy(&dst, &lhs->u.fsobj);
+	switch (rhs->type) {
+	case VAL_FSOBJ: {
+		result = pump(&dst, &rhs->u.fsobj);
+		break;
+	}
+	case VAL_NUMBER: {
+		char buf[20];
+
+		snprintf(buf, sizeof buf, "%li", rhs->u.number);
+		result = pump_buf(&dst, buf, strlen(buf));
+		break;
+	}
+	case VAL_STRING: {
+		result = pump_buf(&dst, rhs->u.string.string, rhs->u.string.len);
+		break;
+	}
+	default:
+		post_error(ctx, "lnode expected");
+		result = -EINVAL;
+	}
+	fsput(&dst);
+	if (result >= 0) {
+		proto_val_t *ret;
+
+		ret = get_val(ctx);
+		proto_val_put(ret);
+		ret->type = VAL_NUMBER;
+		ret->u.number = result;
+		result = 0;
+	}
+	return result;
+}
+
+/* parse "name" token */
+static int parse_name(proto_ctx_t *ctx)
+{
+	int result;
+	proto_token_t token;
+
+	/* name ::= name_token | ( expression ) */
+
+	next_token(ctx, &token);
+	PTRACE(ctx, "%i", token.type);
+
+	result = 0;
+	switch (token.type) {
+	case TOKEN_NAME: {
+		proto_val_t name;
+		fs_point_t  child;
+
+		build_string_val(ctx, &token, &name);
+		result = lookup(get_cur(ctx), name.u.string.string, &child);
+		if (result == -ENOENT || child.dentry->d_inode == NULL) {
+			post_error(ctx, "not found");
+			result = -ENOENT;
+		} else if (result == 0) {
+			proto_val_put(get_val(ctx));
+			get_val(ctx)->type = VAL_FSOBJ;
+			fscpy(&get_val(ctx)->u.fsobj, &child);
+		} else
+			post_error(ctx, "lookup failure");
+		proto_val_put(&name);
+		break;
+	}
+	case TOKEN_LPAREN: {
+		proto_token_t rparen;
+
+		result = inlevel(ctx);
+		if (result == 0) {
+			result = parse_exp(ctx);
+			proto_val_up(ctx);
+			exlevel(ctx);
+			if (next_token(ctx, &rparen) != TOKEN_RPAREN) {
+				post_error(ctx, "expecting `)'");
+				result = -EINVAL;
+			}
+		}
+		break;
+	}
+	case TOKEN_INVALID:
+		post_error(ctx, "huh");
+		result = -EINVAL;
+	default:
+		back_token(ctx, &token);
+		break;
+	}
+	return result;
+}
+
+/* parse "path" token */
+static int parse_rel_path(proto_ctx_t *ctx, fs_point_t *start)
+{
+	int result;
+
+	/* rel_path ::= name { / name } */
+
+	result = inlevel(ctx);
+	if (result != 0)
+		return result;
+
+	fscpy(&get_level(ctx)->cur, start);
+
+	while (1) {
+		proto_token_t token;
+		proto_val_t  *val;
+
+		result = parse_name(ctx);
+		if (result != 0)
+			break;
+
+		val = get_val(ctx);
+		if (val->type != VAL_FSOBJ) {
+			post_error(ctx, "name is not an file system object");
+			break;
+		}
+
+		fsput(&get_level(ctx)->cur);
+		fscpy(&get_level(ctx)->cur, &val->u.fsobj);
+
+		next_token(ctx, &token);
+		PTRACE(ctx, "%i", token.type);
+
+		if (token.type != TOKEN_SLASH) {
+			back_token(ctx, &token);
+			break;
+		}
+	}
+	proto_val_up(ctx);
+	exlevel(ctx);
+	return result;
+}
+
+/* parse "path" token */
+static int parse_path(proto_ctx_t *ctx)
+{
+	int result;
+	proto_token_t token;
+
+	/* path ::= literal | rel_path | / rel_path */
+
+	next_token(ctx, &token);
+	PTRACE(ctx, "%i", token.type);
+
+	result = 0;
+	switch (token.type) {
+	case TOKEN_STRING:
+		build_string_val(ctx, &token, get_val(ctx));
+		break;
+	case TOKEN_NUMBER:
+		build_number_val(ctx, &token, get_val(ctx));
+		break;
+	case TOKEN_SLASH:
+		result = parse_rel_path(ctx, &ctx->root);
+		break;
+	default:
+		back_token(ctx, &token);
+		result = parse_rel_path(ctx, get_cur(ctx));
+		break;
+	case TOKEN_INVALID:
+		post_error(ctx, "cannot parse path");
+		result = -EINVAL;
+		back_token(ctx, &token);
+		break;
+	}
+	return result;
+}
+
+/* parse "binary_exp" token */
+static int parse_binary_exp(proto_ctx_t *ctx)
+{
+	int result;
+	proto_val_t *lhs;
+
+	/* binary_exp ::= path | path binop binary_exp */
+
+	result = inlevel(ctx);
+	if (result != 0)
+		return result;
+
+	result = parse_path(ctx);
+	if (result == 0) {
+		proto_token_t  token;
+
+		lhs = get_val(ctx);
+
+		next_token(ctx, &token);
+		PTRACE(ctx, "%i", token.type);
+
+		if (token.type == TOKEN_ASSIGNMENT) {
+			result = inlevel(ctx);
+			if (result == 0) {
+				result = parse_binary_exp(ctx);
+				if (result == 0) {
+					proto_val_t *rhs;
+
+					rhs = get_val(ctx);
+					result = proto_assign(ctx, lhs, rhs);
+				}
+				proto_val_up(ctx);
+				exlevel(ctx);
+			}
+		} else
+			back_token(ctx, &token);
+	}
+	proto_val_up(ctx);
+	exlevel(ctx);
+	return result;
+}
+
+/* parse "expression" token */
+static int parse_exp(proto_ctx_t *ctx)
+{
+	int result;
+
+	/* expression ::= binary_exp { ; binary_exp } */
+
+	result = inlevel(ctx);
+	if (result != 0)
+		return result;
+
+	while (1) {
+		proto_token_t  token;
+
+		result = parse_binary_exp(ctx);
+		proto_val_up(ctx);
+		if (result != 0)
+			break;
+
+		next_token(ctx, &token);
+		PTRACE(ctx, "%i", token.type);
+
+		if (token.type != TOKEN_SEMICOLON) {
+			back_token(ctx, &token);
+			break;
+		}
+		/* discard value */
+		proto_val_put(get_val(ctx));
+	}
+	exlevel(ctx);
+	return result;
+}
+
+/* execute @command */
+static int execute(proto_ctx_t *ctx)
+{
+	int result;
+
+	inlevel(ctx);
+	fscpy(&get_level(ctx)->cur, &ctx->cwd);
+	result = parse_exp(ctx);
+	if (get_val(ctx)->type == VAL_NUMBER)
+		result = get_val(ctx)->u.number;
+	exlevel(ctx);
+	assert("nikita-3234", ctx->depth == 0);
+	if (char_at(ctx, ctx->pos) != 0) {
+		post_error(ctx, "garbage after expression");
+		if (result == 0)
+			result = -EINVAL;
+	}
+
+	if (ctx->flags & CTX_PARSE_ERROR) {
+		int i;
+
+		printk("Syntax error in ``%s''\n", ctx->command);
+		for (i = PROTO_LEVELS - 1; i >= 0; --i) {
+			proto_level_t *level;
+
+			level = &ctx->level[i];
+			if (level->error != NULL) {
+				printk("    %02i: %s at %i\n",
+				       i, level->error, level->error_pos);
+			}
+		}
+		result = -EINVAL;
+	}
+	return result;
+}
+
+/* entry point */
+asmlinkage long sys_reiser4(const char __user * command)
+{
+	int    result;
+	char * inkernel;
+
+	inkernel = getname(command);
+	if (!IS_ERR(inkernel)) {
+		proto_ctx_t ctx;
+
+		result = ctx_init(&ctx, inkernel);
+		if (result == 0) {
+			result = execute(&ctx);
+			ctx_done(&ctx);
+		}
+		putname(inkernel);
+	} else
+		result = PTR_ERR(inkernel);
+	return result;
+}
diff -puN /dev/null not-for-inclusion/sys_reiser4.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/sys_reiser4.c	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,106 @@
+/* System call for accessing enhanced semantics of the Reiser Filesystem Version 4 (reiser4). */
+
+/* This system call feeds a string to parser.c, parser.c converts the
+   string into a set of commands which are executed, and then this
+   system call returns after the completion of those commands. */
+
+
+#include <linux/types.h>
+#include <linux/fs.h>
+#include <linux/mm.h>
+#include <linux/buffer_head.h>
+#include <linux/dcache.h>
+#include <linux/namei.h>
+#include <linux/list.h>
+#include <linux/pagemap.h>
+#include <linux/slab.h>
+#include <linux/seq_file.h>
+#include <linux/init.h>
+#include <linux/module.h>
+#include <linux/writeback.h>
+#include <linux/backing-dev.h>
+#include <linux/errno.h>
+
+#if defined(CONFIG_REISER4_FS_SYSCALL)
+
+#include "forward.h"
+#include "debug.h"
+#include "key.h"
+#include "kassign.h"
+#include "coord.h"
+#include "seal.h"
+#include "plugin/item/item.h"
+#include "plugin/security/perm.h"
+#include "plugin/plugin.h"
+#include "plugin/object.h"
+#include "znode.h"
+#include "vfs_ops.h"
+#include "inode.h"
+#include "super.h"
+#include "reiser4.h"
+
+#include "lnode.h"
+
+#include "parser/parser.h"
+
+#define YYREISER4_DEF
+
+#include "parser/parser.code.c"
+
+
+/* @p_string is a command string for parsing
+this function allocates work area for yacc,
+initializes fields, calls yacc, free space
+and call for execute the generated code */
+
+asmlinkage long
+sys_reiser4(char *p_string)
+{
+	long ret;
+	int *Gencode;
+	char * str;
+	struct reiser4_syscall_w_space * work_space ;
+	str=getname(p_string);
+	if (!IS_ERR(str)) {
+
+		print_pwd_count("\n--------------------\ninit");
+
+		/* allocate work space for parser
+		   working variables, attached to this call */
+		if ( (work_space = reiser4_pars_init() ) == NULL ) {
+			return -ENOMEM;
+		}
+		/* initialize fields */
+		/* this field used for parsing string, one (inline) stay on begin of string*/
+		work_space->ws_pline  = str;
+		work_space->ws_inline = work_space->ws_pline;
+		PTRACE(work_space, "%s", "begin parsing");
+		ret = yyparse(work_space);	/* parse command */
+		reiser4_pars_free(work_space);
+		putname(str);
+		print_pwd_count("end");
+
+	}
+	else {
+		ret = PTR_ERR(str);
+	}
+	return ret;
+}
+
+#else
+asmlinkage long
+sys_reiser4(void *p_string)
+{
+	return -ENOSYS;
+}
+#endif
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   End:
+*/
diff -puN /dev/null not-for-inclusion/ulevel/bench/driver.sh
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/driver.sh	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,59 @@
+#! /bin/sh
+
+#set -x
+
+TOPDIR=/root/bench
+CURRENT=$TOPDIR/current
+TODO=$TOPDIR/todo
+DONE=$TOPDIR/done
+KERNEL="$(cat $TOPDIR/kernel)"
+
+export LANG=C
+
+cd $TOPDIR || exit 1
+. functions.sh                                                           || die
+
+CONTEXT=driver
+LOGFILE=$TOPDIR/logfile
+
+mount -oremount,rw /                                                     || die
+output ----BENCHMARKING-STARTS----
+
+getfrom $CURRENT
+if [ -z $filefound ] ;then
+    getfrom $TODO                                                        || die
+    if [ -z $filefound ] ;then
+	output Nothing to do. Rebooting.
+	# restart default kernel
+	mv $TOPDIR/do-bench $TOPDIR/do-not-bench
+	systemrestart
+	exit 0
+    else
+	do_it mv $TODO/$filefound $CURRENT                               || die
+    fi
+fi
+
+TEST=$CURRENT/$filefound
+if [ ! -d $TEST ] ;then
+    abort $TEST is not a directory.
+fi
+
+if [ ! -x $TEST/run.me ] ;then
+    abort Cannot execute $TEST/run.me
+fi
+
+cd $TEST                                                                 || die
+output Entering $TEST
+
+CONTEXT=TEST:$filefound
+. ./run.me                                                               || die
+CONTEXT=driver
+
+cd $TOPDIR                                                               || die
+
+if [ x$OUTCOME = xDONE ] ;then
+    output $filefound done.
+    do_it mv $TEST $DONE                                                 || die
+fi
+
+systemrestart $KERNEL
diff -puN /dev/null not-for-inclusion/ulevel/bench/functions.sh
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/functions.sh	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,115 @@
+#! /bin/sh
+
+LOGFILE=/dev/null
+CONTEXT=''
+
+function getfrom()
+{
+    local dir
+    local file
+
+    dir=$1
+    set $(ls -A $dir) NOSUCHFILE
+    file=$1
+    if [ x$file = xNOSUCHFILE ]
+    then
+	filefound=''
+    else
+	filefound=$file
+    fi
+}
+
+function logit()
+{
+    echo $CONTEXT $(date) $* >> $LOGFILE
+}
+
+function output()
+{
+    echo $*
+    logit $*
+}
+
+function abort()
+{
+    output $*. Aborting.
+    exit 1
+}
+
+function die()
+{
+    abort Command failed.
+}
+
+function do_it()
+{
+    output Executing $*
+    $*
+}
+
+function systemrestart()
+{
+    do_it lilo -R $*                                                  || die
+    output Bootstring is set to $*
+    do_it shutdown -r now                                             || die
+}
+
+function do_mkfs()
+{
+    local fstype
+    local device
+    local opts
+
+    fstype=$1
+    device=$2
+    opts=$3
+
+    output Creating $fstype file system on $device with options '"'$opts'"'
+    do_it /sbin/mkfs.$fstype $opts $device
+}
+
+function do_mount()
+{
+    local fstype
+    local device
+    local mpoint
+    local mopts
+
+    fstype=$1
+    device=$2
+    mpoint=$3
+    opts=$4
+
+    output Mounting $fstype from $device on $mpoint with '"'$opts'"'
+    do_it mount -t$fstype $opts $device $mpoint
+}
+
+function reportheader()
+{
+    local rep
+
+    rep=$1
+    echo Started at   >  $rep
+    date              >> $rep
+    echo -------------------------------------------------- >> $rep
+    echo Environment: >> $rep
+    uname -a          >> $rep
+    echo -------------------------------------------------- >> $rep
+    echo CPU          >> $rep
+    cat /proc/cpuinfo >> $rep
+    echo -------------------------------------------------- >> $rep
+    echo Memory       >> $rep
+    cat /proc/meminfo >> $rep
+    echo -------------------------------------------------- >> $rep
+}
+
+function reportfooter()
+{
+    local rep
+
+    rep=$1
+    echo -------------------------------------------------- >> $rep
+    echo Finished at  >> $rep
+    date              >> $rep
+    echo -------------------------------------------------- >> $rep
+}
diff -puN /dev/null not-for-inclusion/ulevel/bench/kernel
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/kernel	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1 @@
+test s
diff -puN /dev/null not-for-inclusion/ulevel/bench/rc1.d.sample
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/rc1.d.sample	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,65 @@
+#! /bin/sh
+# Copyright (c) 1996-2002 SuSE Linux AG, Nuernberg, Germany.
+# All rights reserved.
+#
+# Author: Florian La Roche <feedback@suse.de>, 1996
+#	  Werner Fink <werner@suse.de>, 1996,98,2000
+#	  Burchard Steinbild <feedback@suse.de>, 1996
+#
+# /etc/init.d/single
+#
+
+. /etc/rc.status
+. /etc/rc.config
+
+#
+# Avoid being interrupted by child or keyboard
+#
+trap "echo" SIGINT SIGSEGV SIGQUIT SIGTERM
+set +e
+
+rc_reset
+case "$1" in
+    start)
+	if test -n "$KBD_RATE" -a -n "$KBD_DELAY" -a -x /sbin/kbdrate; then
+	    echo Setting keyboard repeat rate and delay time
+	    /sbin/kbdrate -r $KBD_RATE -d $KBD_DELAY
+	    rc_status -v1
+	fi
+	echo "Sending all processes the TERM signal..."
+	killall5 -15
+	echo -e "$rc_done_up"
+	sleep 3
+	echo "Sending all processes the KILL signal..."
+	killall5 -9
+	echo -e "$rc_done_up"
+
+	if [ -f /root/bench/do-bench ]
+	then
+	    echo Entering benchmarking mode.
+	    mount /boot
+	    /sbin/agetty -i -h -L 38400 ttyS0 ansi &
+	    /root/bench/driver.sh
+	fi
+
+	#
+	# If we're not in single user mode we should go down there.
+	#
+	if test -n "$RUNLEVEL" -a "$RUNLEVEL" != "S" ; then
+	    exec init S
+	fi
+	;;
+    stop)
+	case `uname -r` in
+            0.*|1.*|2.[01].*|2.2.?|2.2.10)
+		echo -n "Running update (bdflush) daemon"
+		/sbin/update
+		rc_status -v1
+		;;
+	esac
+	;;
+    *)
+	echo "Usage: $0 {start|stop}"
+	exit 1
+esac
+rc_exit
diff -puN /dev/null not-for-inclusion/ulevel/bench/README
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/README	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,20 @@
+README file for bench package.
+
+Bench is a set of simple shell scripts to perform automated benchmarking.
+
+Goal of bench package is to run (potentially long) series of benchmarks
+varying some parameters from run to run.
+
+At the top level bench main entry point is driver.sh. This script is supposed
+to be called directly from rc.d (powerhouse.namesys.com has hook for this in
+/etc/init.d/rc1.d).
+
+driver.sh:    handles queues of tests: todo/, current/, and done/ with obvious
+meaning.
+
+functions.sh: contains common functions that tests are supposed to use:
+create, mount, umount file system, reboot, create report file, etc.
+
+Each test is represented by directory (initially within todo/). The only thing
+driver.sh requires from test is existence of executable run.me file within
+test directory.
diff -puN /dev/null not-for-inclusion/ulevel/bench/start-bench.sh
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/start-bench.sh	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,7 @@
+#! /bin/sh
+
+touch do-bench
+
+. functions.sh
+
+systemrestart "$(cat kernel)"
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/mongo/ext3.htree.mkfs
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/mongo/ext3.htree.mkfs	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1 @@
+MKFS=mkfs.ext3 -O dir_index
\ No newline at end of file
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/mongo/options
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/mongo/options	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,23 @@
+#! /bin/sh
+
+baseoptions="DD_MBCOUNT=768 \
+             NPROC=1 \
+             DIR=/mnt/testfs \
+             SYNC=off \
+             PHASE_COPY=cp \
+             REP_COUNTER=1 \
+             GAMMA=0.2 \
+             PHASE_OVERWRITE=off \
+             BYTES=512000000 \
+             PHASE_APPEND=off \
+             PHASE_READ=find \
+             DEV=/dev/hdb3 \
+             WRITE_BUFFER=131072 \
+             PHASE_DELETE=rm \
+             PHASE_MODIFY=off"
+
+r4_common="FSTYPE=reiser4 INFO_R4=''"
+
+ext3_common="FSTYPE=ext3"
+
+PATH=$PATH:/usr/local/sbin
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/mongo/run.me
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/mongo/run.me	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,87 @@
+#! /bin/sh
+
+STAGE=$(cat stage)
+
+. options
+
+SRC=$TOPDIR/linux-2.4.19.tar.gz
+READNUM=30
+WRITENUM=30
+
+output ---ENTERING-STAGE: $STAGE---
+CONTEXT=$CONTEXT:$STAGE
+
+REPFILE=$TEST/report
+
+fourk="FILE_SIZE=8000"
+eighk="FILE_SIZE=8000"
+
+LANG=C
+logdir=$(date +%Y.%m.%d)
+mongodir="/root/bk/reiser3/reiserfsprogs/benchmarks/mongo/"
+
+s1_name="v4"
+s1_options="$baseoptions $r4_common $fourk"
+
+s2_name="v4.ext"
+s2_options="$baseoptions $r4_common $fourk @$TEST/v4.ext.mkfs"
+
+s3_name="ext3.writeback"
+s3_options="$baseoptions $ext3_common $fourk MOUNT_OPTIONS=data=writeback"
+
+s4_name="ext3.journal"
+s4_options="$baseoptions $ext3_common $fourk MOUNT_OPTIONS=data=journal"
+
+s5_name="ext3.ordered"
+s5_options="$baseoptions $ext3_common $fourk MOUNT_OPTIONS=data=ordered"
+
+s6_name="ext3.htree"
+s6_options="$baseoptions $ext3_common $fourk \
+            MOUNT_OPTIONS=data=ordered @$TEST/ext3.htree.mkfs"
+
+s7_name="end"
+
+
+function enterstage()
+{
+	echo RUNNING > stage
+}
+
+function switchto()
+{
+	local stage
+
+	stage=$1
+
+	cd $TEST                                                     || die
+	echo $stage > stage
+	systemrestart $KERNEL
+}
+
+case "$STAGE" in
+	RUNNING)
+	    abort Previous run failed. Aborting.
+        ;;
+	*)
+	    enterstage
+	    eval name=\$s${STAGE}_name
+            if [ x$name = xend ] ;then
+		OUTCOME=DONE
+		echo DONE > stage
+	    else
+		eval opt=\$s${STAGE}_options
+		cd $mongodir                                             || die
+                mkdir -p ./$logdir                                       || die
+                ./mongo.pl $opt LOG=$logdir/$name RUN                    || die
+                if [ -r /proc/profile ] ;then
+                    cp /proc/profile $logdir/$name.profile               || die
+                fi
+		cd $TEST
+		switchto $(($STAGE + 1))
+	    fi
+esac
+
+# Local variables:
+# mode: shell-script
+# tab-width: 8
+# End:
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/mongo/stage
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/mongo/stage	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1 @@
+1
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/mongo/v4.ext.mkfs
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/mongo/v4.ext.mkfs	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1 @@
+MKFS=mkfs.reiser4 -q -o policy=extents
\ No newline at end of file
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/read-write/ext2/options
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/read-write/ext2/options	2005-02-01 11:51:11.000000000 +0300
@@ -0,0 +1,8 @@
+#! /bin/sh
+
+FSTYPE=ext2
+MOPTS=''
+MPOINT=/mnt/b1
+DEVICE=/dev/hdb1
+MKOPTS=''
+
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/read-write/ext2/run.me
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/read-write/ext2/run.me	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,159 @@
+#! /bin/sh
+
+STAGE=$(cat stage)
+
+. options
+
+SRC=$TOPDIR/linux-2.4.19.tar.gz
+READNUM=30
+WRITENUM=30
+
+output ---ENTERING-STAGE: $STAGE---
+CONTEXT=$CONTEXT:$STAGE
+
+ORDERED=$TEST/$FSTYPE-ordered.tar.gz
+REPFILE=$TEST/report
+
+function mount_me()
+{
+	do_mount $FSTYPE $DEVICE $MPOINT $MOPTS                          || die
+}
+
+function reinit()
+{
+	# umount may fail
+	do_it umount $MPOINT 2>/dev/null
+	do_mkfs  $FSTYPE $DEVICE "$MKOPTS"                               || die
+	mount_me
+}
+
+function readprepare()
+{
+	local SRC
+	local DST
+	local NUM
+
+	SRC=$1
+	DST=$2
+	NUM=$3
+
+	output Making $NUM copies of $SRC on $DST...
+
+	cd $DST                                                          || die
+
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it mkdir $i                                               || die
+	    cd $i >/dev/null                                             || die
+	    do_it tar xzf $SRC                                           || die
+	    cd ..                                                        || die
+	done
+}
+
+function readbench()
+{
+	SRC=$1
+	NUM=$2
+
+	echo Testing read from $SRC...
+
+	cd $SRC                                                          || die
+
+	time \
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it mount -tramfs ramfs /mnt/ramfs                         || die
+	    do_it cp -r $i /mnt/ramfs                                    || die
+	    do_it umount /mnt/ramfs                                      || die
+	done
+}
+
+function writebench()
+{
+	local DST
+	local NUM
+
+	DST=$1
+	NUM=$2
+
+	output Testing writing $NUM copied from $DST...
+
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it cp -r /mnt/ramfs $DST/$i                               || die
+	done
+
+	do_it umount /mnt/ramfs                                          || die
+	do_it umount $DST                                                || die
+}
+
+function enterstage()
+{
+	echo RUNNING > stage
+}
+
+function switchto()
+{
+	local stage
+
+	stage=$1
+
+	cd $TEST                                                     || die
+	do_it umount $MPOINT                                         || die
+	echo $stage > stage
+	systemrestart $KERNEL
+}
+
+case "$STAGE" in
+	INIT)
+	    enterstage
+	    reportheader $REPFILE
+	    echo FSTYPE:    $FSTYPE   >> $REPFILE
+	    echo MOPTS:     $MOPTS    >> $REPFILE
+	    echo MPOINT:    $MPOINT   >> $REPFILE
+	    echo DEVICE:    $DEVICE   >> $REPFILE
+	    echo MKOPTS:    $MKOPTS   >> $REPFILE
+	    echo SRC:       $SRC      >> $REPFILE
+	    echo READNUM:   $READNUM  >> $REPFILE
+	    echo WRITENUM:  $WRITENUM >> $REPFILE
+
+	    reinit
+	    cd $MPOINT                                                   || die
+	    do_it tar xzf $SRC                                           || die
+	    do_it tar czf $ORDERED *                                     || die
+	    cd $TEST
+	    reinit
+	    readprepare $ORDERED $MPOINT $READNUM
+	    switchto READ
+	;;
+	READ)
+	    enterstage
+	    mount_me
+	    echo Read timing >> $REPFILE
+	    readbench $MPOINT $READNUM 2>> $REPFILE
+	    switchto WRITE
+	;;
+	WRITE)
+	    enterstage
+	    reinit
+	    mount -tramfs ramfs /mnt/ramfs                               || die
+	    cd /mnt/ramfs                                                || die
+	    tar xzf $ORDERED                                             || die
+	    cd $TEST
+	    echo Write timing >> $REPFILE
+	    (time writebench $MPOINT $WRITENUM) 2>> $REPFILE
+	    reportfooter $REPFILE
+	    OUTCOME=DONE
+	    echo DONE > stage
+	;;
+	RUNNING)
+	    abort Previous run failed. Aborting.
+esac
+
+# Local variables:
+# mode: shell-script
+# tab-width: 8
+# End:
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/read-write/ext2/stage
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/read-write/ext2/stage	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1 @@
+INIT
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/read-write/reiser4/options
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/read-write/reiser4/options	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,8 @@
+#! /bin/sh
+
+FSTYPE=reiser4
+MOPTS=''
+MPOINT=/mnt/b1
+DEVICE=/dev/hdb1
+MKOPTS='-q'
+
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/read-write/reiser4/run.me
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/read-write/reiser4/run.me	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,159 @@
+#! /bin/sh
+
+STAGE=$(cat stage)
+
+. options
+
+SRC=$TOPDIR/linux-2.4.19.tar.gz
+READNUM=30
+WRITENUM=30
+
+output ---ENTERING-STAGE: $STAGE---
+CONTEXT=$CONTEXT:$STAGE
+
+ORDERED=$TEST/$FSTYPE-ordered.tar.gz
+REPFILE=$TEST/report
+
+function mount_me()
+{
+	do_mount $FSTYPE $DEVICE $MPOINT $MOPTS                          || die
+}
+
+function reinit()
+{
+	# umount may fail
+	do_it umount $MPOINT 2>/dev/null
+	do_mkfs  $FSTYPE $DEVICE "$MKOPTS"                               || die
+	mount_me
+}
+
+function readprepare()
+{
+	local SRC
+	local DST
+	local NUM
+
+	SRC=$1
+	DST=$2
+	NUM=$3
+
+	output Making $NUM copies of $SRC on $DST...
+
+	cd $DST                                                          || die
+
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it mkdir $i                                               || die
+	    cd $i >/dev/null                                             || die
+	    do_it tar xzf $SRC                                           || die
+	    cd ..                                                        || die
+	done
+}
+
+function readbench()
+{
+	SRC=$1
+	NUM=$2
+
+	echo Testing read from $SRC...
+
+	cd $SRC                                                          || die
+
+	time \
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it mount -tramfs ramfs /mnt/ramfs                         || die
+	    do_it cp -r $i /mnt/ramfs                                    || die
+	    do_it umount /mnt/ramfs                                      || die
+	done
+}
+
+function writebench()
+{
+	local DST
+	local NUM
+
+	DST=$1
+	NUM=$2
+
+	output Testing writing $NUM copied from $DST...
+
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it cp -r /mnt/ramfs $DST/$i                               || die
+	done
+
+	do_it umount /mnt/ramfs                                          || die
+	do_it umount $DST                                                || die
+}
+
+function enterstage()
+{
+	echo RUNNING > stage
+}
+
+function switchto()
+{
+	local stage
+
+	stage=$1
+
+	cd $TEST                                                     || die
+	do_it umount $MPOINT                                         || die
+	echo $stage > stage
+	systemrestart $KERNEL
+}
+
+case "$STAGE" in
+	INIT)
+	    enterstage
+	    reportheader $REPFILE
+	    echo FSTYPE:    $FSTYPE   >> $REPFILE
+	    echo MOPTS:     $MOPTS    >> $REPFILE
+	    echo MPOINT:    $MPOINT   >> $REPFILE
+	    echo DEVICE:    $DEVICE   >> $REPFILE
+	    echo MKOPTS:    $MKOPTS   >> $REPFILE
+	    echo SRC:       $SRC      >> $REPFILE
+	    echo READNUM:   $READNUM  >> $REPFILE
+	    echo WRITENUM:  $WRITENUM >> $REPFILE
+
+	    reinit
+	    cd $MPOINT                                                   || die
+	    do_it tar xzf $SRC                                           || die
+	    do_it tar czf $ORDERED *                                     || die
+	    cd $TEST
+	    reinit
+	    readprepare $ORDERED $MPOINT $READNUM
+	    switchto READ
+	;;
+	READ)
+	    enterstage
+	    mount_me
+	    echo Read timing >> $REPFILE
+	    readbench $MPOINT $READNUM 2>> $REPFILE
+	    switchto WRITE
+	;;
+	WRITE)
+	    enterstage
+	    reinit
+	    mount -tramfs ramfs /mnt/ramfs                               || die
+	    cd /mnt/ramfs                                                || die
+	    tar xzf $ORDERED                                             || die
+	    cd $TEST
+	    echo Write timing >> $REPFILE
+	    (time writebench $MPOINT $WRITENUM) 2>> $REPFILE
+	    reportfooter $REPFILE
+	    OUTCOME=DONE
+	    echo DONE > stage
+	;;
+	RUNNING)
+	    abort Previous run failed. Aborting.
+esac
+
+# Local variables:
+# mode: shell-script
+# tab-width: 8
+# End:
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/read-write/reiser4/stage
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/read-write/reiser4/stage	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1 @@
+INIT
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/read-write/reiserfs/options
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/read-write/reiserfs/options	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,9 @@
+#! /bin/sh
+
+FSTYPE=reiserfs
+MOPTS=''
+MPOINT=/mnt/b1
+DEVICE=/dev/hdb1
+MKOPTS='-ff --format 3.6'
+
+
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/read-write/reiserfs/run.me
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/read-write/reiserfs/run.me	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,159 @@
+#! /bin/sh
+
+STAGE=$(cat stage)
+
+. options
+
+SRC=$TOPDIR/linux-2.4.19.tar.gz
+READNUM=30
+WRITENUM=30
+
+output ---ENTERING-STAGE: $STAGE---
+CONTEXT=$CONTEXT:$STAGE
+
+ORDERED=$TEST/$FSTYPE-ordered.tar.gz
+REPFILE=$TEST/report
+
+function mount_me()
+{
+	do_mount $FSTYPE $DEVICE $MPOINT $MOPTS                          || die
+}
+
+function reinit()
+{
+	# umount may fail
+	do_it umount $MPOINT 2>/dev/null
+	do_mkfs  $FSTYPE $DEVICE "$MKOPTS"                               || die
+	mount_me
+}
+
+function readprepare()
+{
+	local SRC
+	local DST
+	local NUM
+
+	SRC=$1
+	DST=$2
+	NUM=$3
+
+	output Making $NUM copies of $SRC on $DST...
+
+	cd $DST                                                          || die
+
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it mkdir $i                                               || die
+	    cd $i >/dev/null                                             || die
+	    do_it tar xzf $SRC                                           || die
+	    cd ..                                                        || die
+	done
+}
+
+function readbench()
+{
+	SRC=$1
+	NUM=$2
+
+	echo Testing read from $SRC...
+
+	cd $SRC                                                          || die
+
+	time \
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it mount -tramfs ramfs /mnt/ramfs                         || die
+	    do_it cp -r $i /mnt/ramfs                                    || die
+	    do_it umount /mnt/ramfs                                      || die
+	done
+}
+
+function writebench()
+{
+	local DST
+	local NUM
+
+	DST=$1
+	NUM=$2
+
+	output Testing writing $NUM copied from $DST...
+
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it cp -r /mnt/ramfs $DST/$i                               || die
+	done
+
+	do_it umount /mnt/ramfs                                          || die
+	do_it umount $DST                                                || die
+}
+
+function enterstage()
+{
+	echo RUNNING > stage
+}
+
+function switchto()
+{
+	local stage
+
+	stage=$1
+
+	cd $TEST                                                     || die
+	do_it umount $MPOINT                                         || die
+	echo $stage > stage
+	systemrestart $KERNEL
+}
+
+case "$STAGE" in
+	INIT)
+	    enterstage
+	    reportheader $REPFILE
+	    echo FSTYPE:    $FSTYPE   >> $REPFILE
+	    echo MOPTS:     $MOPTS    >> $REPFILE
+	    echo MPOINT:    $MPOINT   >> $REPFILE
+	    echo DEVICE:    $DEVICE   >> $REPFILE
+	    echo MKOPTS:    $MKOPTS   >> $REPFILE
+	    echo SRC:       $SRC      >> $REPFILE
+	    echo READNUM:   $READNUM  >> $REPFILE
+	    echo WRITENUM:  $WRITENUM >> $REPFILE
+
+	    reinit
+	    cd $MPOINT                                                   || die
+	    do_it tar xzf $SRC                                           || die
+	    do_it tar czf $ORDERED *                                     || die
+	    cd $TEST
+	    reinit
+	    readprepare $ORDERED $MPOINT $READNUM
+	    switchto READ
+	;;
+	READ)
+	    enterstage
+	    mount_me
+	    echo Read timing >> $REPFILE
+	    readbench $MPOINT $READNUM 2>> $REPFILE
+	    switchto WRITE
+	;;
+	WRITE)
+	    enterstage
+	    reinit
+	    mount -tramfs ramfs /mnt/ramfs                               || die
+	    cd /mnt/ramfs                                                || die
+	    tar xzf $ORDERED                                             || die
+	    cd $TEST
+	    echo Write timing >> $REPFILE
+	    (time writebench $MPOINT $WRITENUM) 2>> $REPFILE
+	    reportfooter $REPFILE
+	    OUTCOME=DONE
+	    echo DONE > stage
+	;;
+	RUNNING)
+	    abort Previous run failed. Aborting.
+esac
+
+# Local variables:
+# mode: shell-script
+# tab-width: 8
+# End:
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/read-write/reiserfs/stage
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/read-write/reiserfs/stage	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1 @@
+INIT
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/read-write/run.me
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/read-write/run.me	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,159 @@
+#! /bin/sh
+
+STAGE=$(cat stage)
+
+. options
+
+SRC=$TOPDIR/linux-2.4.19.tar.gz
+READNUM=30
+WRITENUM=30
+
+output ---ENTERING-STAGE: $STAGE---
+CONTEXT=$CONTEXT:$STAGE
+
+ORDERED=$TEST/$FSTYPE-ordered.tar.gz
+REPFILE=$TEST/report
+
+function mount_me()
+{
+	do_mount $FSTYPE $DEVICE $MPOINT $MOPTS                          || die
+}
+
+function reinit()
+{
+	# umount may fail
+	do_it umount $MPOINT 2>/dev/null
+	do_mkfs  $FSTYPE $DEVICE "$MKOPTS"                               || die
+	mount_me
+}
+
+function readprepare()
+{
+	local SRC
+	local DST
+	local NUM
+
+	SRC=$1
+	DST=$2
+	NUM=$3
+
+	output Making $NUM copies of $SRC on $DST...
+
+	cd $DST                                                          || die
+
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it mkdir $i                                               || die
+	    cd $i >/dev/null                                             || die
+	    do_it tar xzf $SRC                                           || die
+	    cd ..                                                        || die
+	done
+}
+
+function readbench()
+{
+	SRC=$1
+	NUM=$2
+
+	echo Testing read from $SRC...
+
+	cd $SRC                                                          || die
+
+	time \
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it mount -tramfs ramfs /mnt/ramfs                         || die
+	    do_it cp -r $i /mnt/ramfs                                    || die
+	    do_it umount /mnt/ramfs                                      || die
+	done
+}
+
+function writebench()
+{
+	local DST
+	local NUM
+
+	DST=$1
+	NUM=$2
+
+	output Testing writing $NUM copied from $DST...
+
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it cp -r /mnt/ramfs $DST/$i                               || die
+	done
+
+	do_it umount /mnt/ramfs                                          || die
+	do_it umount $DST                                                || die
+}
+
+function enterstage()
+{
+	echo RUNNING > stage
+}
+
+function switchto()
+{
+	local stage
+
+	stage=$1
+
+	cd $TEST                                                     || die
+	do_it umount $MPOINT                                         || die
+	echo $stage > stage
+	systemrestart $KERNEL
+}
+
+case "$STAGE" in
+	INIT)
+	    enterstage
+	    reportheader $REPFILE
+	    echo FSTYPE:    $FSTYPE   >> $REPFILE
+	    echo MOPTS:     $MOPTS    >> $REPFILE
+	    echo MPOINT:    $MPOINT   >> $REPFILE
+	    echo DEVICE:    $DEVICE   >> $REPFILE
+	    echo MKOPTS:    $MKOPTS   >> $REPFILE
+	    echo SRC:       $SRC      >> $REPFILE
+	    echo READNUM:   $READNUM  >> $REPFILE
+	    echo WRITENUM:  $WRITENUM >> $REPFILE
+
+	    reinit
+	    cd $MPOINT                                                   || die
+	    do_it tar xzf $SRC                                           || die
+	    do_it tar czf $ORDERED *                                     || die
+	    cd $TEST
+	    reinit
+	    readprepare $ORDERED $MPOINT $READNUM
+	    switchto READ
+	;;
+	READ)
+	    enterstage
+	    mount_me
+	    echo Read timing >> $REPFILE
+	    readbench $MPOINT $READNUM 2>> $REPFILE
+	    switchto WRITE
+	;;
+	WRITE)
+	    enterstage
+	    reinit
+	    mount -tramfs ramfs /mnt/ramfs                               || die
+	    cd /mnt/ramfs                                                || die
+	    tar xzf $ORDERED                                             || die
+	    cd $TEST
+	    echo Write timing >> $REPFILE
+	    (time writebench $MPOINT $WRITENUM) 2>> $REPFILE
+	    reportfooter $REPFILE
+	    OUTCOME=DONE
+	    echo DONE > stage
+	;;
+	RUNNING)
+	    abort Previous run failed. Aborting.
+esac
+
+# Local variables:
+# mode: shell-script
+# tab-width: 8
+# End:
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/reiserfs/run.me
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/reiserfs/run.me	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,159 @@
+#! /bin/sh
+
+STAGE=$(cat stage)
+
+. options
+
+SRC=$TOPDIR/linux-2.4.19.tar.gz
+READNUM=30
+WRITENUM=30
+
+output ---ENTERING-STAGE: $STAGE---
+CONTEXT=$CONTEXT:$STAGE
+
+ORDERED=$TEST/$FSTYPE-ordered.tar.gz
+REPFILE=$TEST/report
+
+function mount_me()
+{
+	do_mount $FSTYPE $DEVICE $MPOINT $MOPTS                          || die
+}
+
+function reinit()
+{
+	# umount may fail
+	do_it umount $MPOINT 2>/dev/null
+	do_mkfs  $FSTYPE $DEVICE "$MKOPTS"                               || die
+	mount_me
+}
+
+function readprepare()
+{
+	local SRC
+	local DST
+	local NUM
+
+	SRC=$1
+	DST=$2
+	NUM=$3
+
+	output Making $NUM copies of $SRC on $DST...
+
+	cd $DST                                                          || die
+
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it mkdir $i                                               || die
+	    cd $i >/dev/null                                             || die
+	    do_it tar xzf $SRC                                           || die
+	    cd ..                                                        || die
+	done
+}
+
+function readbench()
+{
+	SRC=$1
+	NUM=$2
+
+	echo Testing read from $SRC...
+
+	cd $SRC                                                          || die
+
+	time \
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it mount -tramfs ramfs /mnt/ramfs                         || die
+	    do_it cp -r $i /mnt/ramfs                                    || die
+	    do_it umount /mnt/ramfs                                      || die
+	done
+}
+
+function writebench()
+{
+	local DST
+	local NUM
+
+	DST=$1
+	NUM=$2
+
+	output Testing writing $NUM copied from $DST...
+
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it cp -r /mnt/ramfs $DST/$i                               || die
+	done
+
+	do_it umount /mnt/ramfs                                          || die
+	do_it umount $DST                                                || die
+}
+
+function enterstage()
+{
+	echo RUNNING > stage
+}
+
+function switchto()
+{
+	local stage
+
+	stage=$1
+
+	cd $TEST                                                     || die
+	do_it umount $MPOINT                                         || die
+	echo $stage > stage
+	systemrestart $KERNEL
+}
+
+case "$STAGE" in
+	INIT)
+	    enterstage
+	    reportheader $REPFILE
+	    echo FSTYPE:    $FSTYPE   >> $REPFILE
+	    echo MOPTS:     $MOPTS    >> $REPFILE
+	    echo MPOINT:    $MPOINT   >> $REPFILE
+	    echo DEVICE:    $DEVICE   >> $REPFILE
+	    echo MKOPTS:    $MKOPTS   >> $REPFILE
+	    echo SRC:       $SRC      >> $REPFILE
+	    echo READNUM:   $READNUM  >> $REPFILE
+	    echo WRITENUM:  $WRITENUM >> $REPFILE
+
+	    reinit
+	    cd $MPOINT                                                   || die
+	    do_it tar xzf $SRC                                           || die
+	    do_it tar czf $ORDERED *                                     || die
+	    cd $TEST
+	    reinit
+	    readprepare $ORDERED $MPOINT $READNUM
+	    switchto READ
+	;;
+	READ)
+	    enterstage
+	    mount_me
+	    echo Read timing >> $REPFILE
+	    readbench $MPOINT $READNUM 2>> $REPFILE
+	    switchto WRITE
+	;;
+	WRITE)
+	    enterstage
+	    reinit
+	    mount -tramfs ramfs /mnt/ramfs                               || die
+	    cd /mnt/ramfs                                                || die
+	    tar xzf $ORDERED                                             || die
+	    cd $TEST
+	    echo Write timing >> $REPFILE
+	    (time writebench $MPOINT $WRITENUM) 2>> $REPFILE
+	    reportfooter $REPFILE
+	    OUTCOME=DONE
+	    echo DONE > stage
+	;;
+	RUNNING)
+	    abort Previous run failed. Aborting.
+esac
+
+# Local variables:
+# mode: shell-script
+# tab-width: 8
+# End:
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/run.me
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/run.me	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,159 @@
+#! /bin/sh
+
+STAGE=$(cat stage)
+
+. options
+
+SRC=$TOPDIR/linux-2.4.19.tar.gz
+READNUM=30
+WRITENUM=30
+
+output ---ENTERING-STAGE: $STAGE---
+CONTEXT=$CONTEXT:$STAGE
+
+ORDERED=$TEST/$FSTYPE-ordered.tar.gz
+REPFILE=$TEST/report
+
+function mount_me()
+{
+	do_mount $FSTYPE $DEVICE $MPOINT $MOPTS                          || die
+}
+
+function reinit()
+{
+	# umount may fail
+	do_it umount $MPOINT 2>/dev/null
+	do_mkfs  $FSTYPE $DEVICE "$MKOPTS"                               || die
+	mount_me
+}
+
+function readprepare()
+{
+	local SRC
+	local DST
+	local NUM
+
+	SRC=$1
+	DST=$2
+	NUM=$3
+
+	output Making $NUM copies of $SRC on $DST...
+
+	cd $DST                                                          || die
+
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it mkdir $i                                               || die
+	    cd $i >/dev/null                                             || die
+	    do_it tar xzf $SRC                                           || die
+	    cd ..                                                        || die
+	done
+}
+
+function readbench()
+{
+	SRC=$1
+	NUM=$2
+
+	echo Testing read from $SRC...
+
+	cd $SRC                                                          || die
+
+	time \
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it mount -tramfs ramfs /mnt/ramfs                         || die
+	    do_it cp -r $i /mnt/ramfs                                    || die
+	    do_it umount /mnt/ramfs                                      || die
+	done
+}
+
+function writebench()
+{
+	local DST
+	local NUM
+
+	DST=$1
+	NUM=$2
+
+	output Testing writing $NUM copied from $DST...
+
+	for i in `seq 1 $NUM`
+	do
+	    output Copy $i...
+	    do_it cp -r /mnt/ramfs $DST/$i                               || die
+	done
+
+	do_it umount /mnt/ramfs                                          || die
+	do_it umount $DST                                                || die
+}
+
+function enterstage()
+{
+	echo RUNNING > stage
+}
+
+function switchto()
+{
+	local stage
+
+	stage=$1
+
+	cd $TEST                                                     || die
+	do_it umount $MPOINT                                         || die
+	echo $stage > stage
+	systemrestart $KERNEL
+}
+
+case "$STAGE" in
+	INIT)
+	    enterstage
+	    reportheader $REPFILE
+	    echo FSTYPE:    $FSTYPE   >> $REPFILE
+	    echo MOPTS:     $MOPTS    >> $REPFILE
+	    echo MPOINT:    $MPOINT   >> $REPFILE
+	    echo DEVICE:    $DEVICE   >> $REPFILE
+	    echo MKOPTS:    $MKOPTS   >> $REPFILE
+	    echo SRC:       $SRC      >> $REPFILE
+	    echo READNUM:   $READNUM  >> $REPFILE
+	    echo WRITENUM:  $WRITENUM >> $REPFILE
+
+	    reinit
+	    cd $MPOINT                                                   || die
+	    do_it tar xzf $SRC                                           || die
+	    do_it tar czf $ORDERED *                                     || die
+	    cd $TEST
+	    reinit
+	    readprepare $ORDERED $MPOINT $READNUM
+	    switchto READ
+	;;
+	READ)
+	    enterstage
+	    mount_me
+	    echo Read timing >> $REPFILE
+	    readbench $MPOINT $READNUM 2>> $REPFILE
+	    switchto WRITE
+	;;
+	WRITE)
+	    enterstage
+	    reinit
+	    mount -tramfs ramfs /mnt/ramfs                               || die
+	    cd /mnt/ramfs                                                || die
+	    tar xzf $ORDERED                                             || die
+	    cd $TEST
+	    echo Write timing >> $REPFILE
+	    (time writebench $MPOINT $WRITENUM) 2>> $REPFILE
+	    reportfooter $REPFILE
+	    OUTCOME=DONE
+	    echo DONE > stage
+	;;
+	RUNNING)
+	    abort Previous run failed. Aborting.
+esac
+
+# Local variables:
+# mode: shell-script
+# tab-width: 8
+# End:
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/untar-build/ext3/run.me
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/untar-build/ext3/run.me	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,150 @@
+#! /bin/sh
+
+STAGE=$(cat stage)
+
+FSTYPE=ext3
+MOPTS=''
+MPOINT=/mnt1
+DEVICE=/dev/hda6
+MKOPTS=''
+
+#SRC=$TOPDIR/linux-2.4.19.tar.gz
+SRC=/usr/src/kernel/v2.6/for-bench/linux-2.6.7.tar.gz
+MPOINTSRC=$MPOINT/linux-2.6.7
+
+output ---ENTERING-STAGE: $STAGE---
+CONTEXT=$CONTEXT:$STAGE
+
+ORDERED=$TEST/$FSTYPE-ordered.tar.gz
+REPFILE=$TEST/report
+
+function mount_me()
+{
+    do_mount $FSTYPE $DEVICE $MPOINT $MOPTS                             || die
+}
+
+function reinit()
+{
+    # umount may fail
+    do_it umount $MPOINT 2>/dev/null
+    do_mkfs  $FSTYPE $DEVICE "$MKOPTS"                                  || die
+    mount_me
+}
+
+function untarbench()
+{
+    SRC=$1
+
+    output UNTARing $SRC...	
+    
+    time \
+	do_it tar zxf $SRC			                        || die
+}
+
+function buildbench()
+{
+    SRC=$1
+
+    cd $SRC
+    echo Building kernel $SRC...
+
+    output Make defconfig $SRC...
+    do_it make defconfig			                        || die
+    output Make $SRC...
+    do_it make					                        || die
+}
+
+function findbench()
+{
+    SRC=$1
+
+    output Find $SRC...	
+    
+    time \
+	do_it find $SRC -type f >/dev/null	                        || die
+}
+
+case "$STAGE" in
+    INIT)
+	reportheader $REPFILE
+	echo FSTYPE:    $FSTYPE   >> $REPFILE
+	echo MOPTS:     $MOPTS    >> $REPFILE
+	echo MPOINT:    $MPOINT   >> $REPFILE
+	echo DEVICE:    $DEVICE   >> $REPFILE
+	echo MKOPTS:    $MKOPTS   >> $REPFILE
+	echo SRC:       $SRC      >> $REPFILE
+
+	# Prepare to untar
+	mount -tramfs ramfs /mnt/ramfs                                  || die
+	cp $SRC /mnt/ramfs/.
+
+	reinit
+	cd $MPOINT                                                      || die
+
+	echo Untar timing >> $REPFILE
+	untarbench /mnt/ramfs/linux-2.6.7.tar.gz 2>> $REPFILE
+
+	# Prepare to work with ordered set
+	do_it tar czf $ORDERED *                                        || die
+
+	cd $TEST
+	do_it umount $MPOINT                                            || die
+	echo BUILD > stage
+	systemrestart $KERNEL
+    ;;
+    BUILD)
+	mount_me
+	echo Build timing >> $REPFILE
+	#readbench $MPOINT $READNUM 2>> $REPFILE
+	(time buildbench $MPOINTSRC) 2>> $REPFILE
+
+	cd $TEST
+	do_it umount $MPOINT                                            || die
+	echo FIND > stage
+	systemrestart $KERNEL
+    ;;
+    FIND)
+	mount_me
+	echo Find timing >> $REPFILE
+	(time findbench $MPOINTSRC) 2>> $REPFILE
+
+	cd $TEST
+	do_it umount $MPOINT                                            || die
+	echo UNTARORDERED > stage
+	systemrestart $KERNEL
+    ;;
+
+    UNTARORDERED)
+	mount -tramfs ramfs /mnt/ramfs                                  || die
+	cp $ORDERED /mnt/ramfs/.
+	reinit
+	cd $MPOINT                                                      || die
+
+	echo Untar ordered timing >> $REPFILE
+	untarbench /mnt/ramfs/$FSTYPE-ordered.tar.gz 2>> $REPFILE
+	cd $TEST
+	do_it umount $MPOINT                                            || die
+	echo BUILDORDERED > stage
+	systemrestart $KERNEL
+   ;;
+    BUILDORDERED)
+	mount_me
+	echo Build ordered timing >> $REPFILE
+	(time buildbench $MPOINTSRC) 2>> $REPFILE
+
+	cd $TEST
+	do_it umount $MPOINT                                            || die
+	echo FINDORDERED > stage
+	systemrestart $KERNEL
+    ;;
+    FINDORDERED)
+	mount_me
+	echo Find ordered timing >> $REPFILE
+	(time findbench $MPOINTSRC) 2>> $REPFILE
+
+	cd $TEST
+	do_it umount $MPOINT                                            || die
+	OUTCOME=DONE
+    ;;
+
+esac
diff -puN /dev/null not-for-inclusion/ulevel/bench/template/untar-build/ext3/stage
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bench/template/untar-build/ext3/stage	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1 @@
+INIT
diff -puN /dev/null not-for-inclusion/ulevel/bio-out.py
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bio-out.py	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,78 @@
+#! /usr/bin/python
+
+# Parse a reiser4 even log, find all mark=* events, print
+# all bios as "<seq.number> <block> <rw>". And, print
+# optional <trace_mark> suffix by a trace_mark if
+# mark=<trace_mark> event was found earlier for the same
+# thread.
+
+import sys
+import re
+
+n = 1
+marks={}
+file_name_base="tmpfile"
+
+mark_cp = re.compile("mark=")
+bio_cp = re.compile("\.\.\.\.\.\.bio")
+
+files={}
+
+def get_file_name(rw, mark):
+    global file_name_base
+    if mark != "":
+        return file_name_base + "[" + rw + "," + mark + "]"
+    else:
+        return file_name_base + "[" + rw + "]"
+
+def get_file(rw, mark):
+    global files
+    name = get_file_name(rw, mark)
+    if files.has_key(name):
+        return files[name]
+    else:
+        file = open(name, "w")
+        files[name] = file
+        return file
+
+def close_all_files():
+    global files
+    for name in files.keys():
+        files[name].close()
+
+def dispatch_bio(n, block, rw, mark=""):
+    file = get_file(rw, mark)
+    file.write(str(n) + " " + str(block) + "\n")
+
+def out_bio(first, len):
+    global n
+    block = first
+    for i in xrange(1, len + 1):
+        if marks.has_key(pid):
+            # print str(n) + " " + str(block) + " " + rw + " " + marks[pid]
+            dispatch_bio(n, block, rw, marks[pid])
+        else:
+            # print str(n) + " " + str(block) + " " + rw
+            dispatch_bio(n, block, rw)
+        block = block + 1
+        n = n + 1
+
+for line in sys.stdin:
+    try:
+        (pid, comm, dev, jiffies, rest) = re.split(" +", line, 4)
+        if mark_cp.match(rest):
+            mark = re.match("mark=(\w+)", rest).group(1)
+            marks[pid] = mark
+            continue
+        if bio_cp.match(rest):
+            m = re.split(" +", rest)
+            rw = m[2]
+            blocks=m[4]
+            (first, len) = re.match("\((\d+),(\d+)\)", blocks).groups()
+            out_bio(long(first), long(len))
+    except ValueError:
+        pass
+
+close_all_files()
+
+
diff -puN /dev/null not-for-inclusion/ulevel/bio-out.sh
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/bio-out.sh	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,4 @@
+#! /bin/sh
+
+egrep '\.\.\.\.\.\.bio' | \
+awk 'BEGIN {cnt=1} { split($9, pair, "[(,)]"); for(i=0 ; i<pair[3] ; ++i) { print cnt " " pair[2]+i " " $7; cnt +=1; } }'
diff -puN /dev/null not-for-inclusion/ulevel/cp-r
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/cp-r	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,7 @@
+DIR=$1
+
+(
+	echo "mount $REISER4_MOUNT $REISER4_MOUNT_OPTS"
+	echo "cp-r $DIR"
+	echo "umount"
+) | ./a.out sh
diff -puN /dev/null not-for-inclusion/ulevel/driller.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/driller.c	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,45 @@
+#include <unistd.h>
+#include <stdio.h>
+
+static void print_percentage( unsigned long reached,
+			      unsigned long total, int gap )
+{
+	int percentage;
+
+	percentage = reached / ( ( ( double ) total ) / 100.0 );
+	if( percentage * ( total / 100 ) == reached )
+	{
+		if( ( percentage / 10 ) * 10 == percentage )
+		{
+			printf( "%i%%", percentage );
+		}
+		else if( percentage % 2 == 0 )
+		{
+			printf( "%c", gap );
+		}
+		fflush( stdout );
+	}
+}
+
+int main( int argc, char **argv )
+{
+	int depth;
+	int i;
+
+	depth = atoi( argv[ 1 ] );
+	for( i = 0 ; i < depth ; ++ i ) {
+		char dname[ 100 ];
+
+		sprintf( dname, "%i", i );
+		if( mkdir( dname, 0700 ) != 0 ) {
+			perror( "mkdir" );
+			return 1;
+		} else if( chdir( dname ) != 0 ) {
+			perror( "chdir" );
+			return 2;
+		}
+		print_percentage( i, depth, '.' );
+	}
+	printf( "\nDone.\n" );
+	return 0;
+}
diff -puN /dev/null not-for-inclusion/ulevel/loid.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/loid.c	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,206 @@
+#include <stdio.h>
+#include <unistd.h>
+#include <fcntl.h>
+#include <errno.h>
+#include <time.h>
+#include <sys/time.h>
+
+#define MAX_LEN   (2000)
+
+static double RAT( unsigned long long a, unsigned long long b )
+{
+  if( b == 0 )
+	return 0.0;
+  else
+	return ( ( double ) a ) / b;
+}
+
+static unsigned long long tdiff(struct timeval *t1, struct timeval *t2)
+{
+  return (t1->tv_sec - t2->tv_sec) * 1000000 + (t1->tv_usec - t2->tv_usec);
+}
+
+int main( int argc, char **argv )
+{
+  const char alphabet[] = "0123456789abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ";
+  unsigned long long i;
+  char name[ MAX_LEN + 1 ];
+  int min;
+  int base;
+  struct timeval start;
+  struct timeval instant;
+  unsigned long prev;
+  unsigned long N;
+  int ch;
+  int pad;
+  unsigned long cycle;
+  int dodirs;
+  int writelen;
+  int reverse;
+  char *buf;
+
+  N = 0;
+  pad = 0;
+  dodirs = 0;
+  cycle = 20000;
+  writelen = 0;
+  reverse = 0;
+  buf = 0;
+  while( ( ch = getopt( argc, argv, "dn:p:c:w:r" ) ) != -1 )
+	{
+	  switch( ch )
+		{
+		case 'n':
+		  N = atol( optarg );
+		  break;
+		case 'p':
+		  pad = atoi( optarg );
+		  break;
+		case 'c':
+		  cycle = atol( optarg );
+		  break;
+		case 'd':
+		  dodirs = 1;
+		  break;
+		case 'w':
+		  writelen = atoi( optarg );
+		  break;
+		case 'r':
+		  reverse = 1;
+		  break;
+		default:
+		  exit( 0 );
+		}
+	}
+
+  base = strlen( alphabet );
+  memset( name, base + 10, MAX_LEN + 1 );
+  prev = 0;
+  gettimeofday( &instant, 0 );
+  start = instant;
+
+  if( writelen > 0 )
+	{
+	  if( dodirs )
+		{
+		  fprintf( stderr, "Cannot write into directories\n" );
+		  exit( 1 );
+		}
+	  buf = ( char * )malloc( writelen );
+	  if( buf == NULL )
+		{
+		  perror( "malloc" );
+		  exit( 1 );
+		}
+	}
+
+  for( i = 0 ; N && i < N ; ++ i )
+	{
+	  int j;
+	  int c;
+	  int fd;
+	  int shift;
+	  char fname[ MAX_LEN + 1 ];
+
+	  for( j = MAX_LEN - 1, c = 1 ; ( j >= 0 ) && c ; -- j )
+		{
+		  c = 0;
+		  if( name[ j ] == base + 10 )
+			{
+			  name[ j ] = 1;
+			  min = j;
+			}
+		  else if( name[ j ] == base - 1 )
+			{
+			  c = 1;
+			  name[ j ] = 0;
+			}
+		  else
+			{
+			  name[ j ] ++;
+			}
+		}
+	  if( c == 1 )
+		{
+		  exit( 1 );
+		}
+	  if( pad )
+		{
+		  shift = pad - ( MAX_LEN - min );
+		  if( shift < 0 )
+			{
+			  shift = 0;
+			}
+		  for( j = 0 ; j < shift ; ++ j )
+			{
+			  fname[ j ] = '#';
+			}
+		}
+	  else
+		{
+		  shift = 0;
+		}
+	  for( j = min ; j < MAX_LEN ; ++ j )
+		{
+		  fname[ j - min + shift ] = alphabet[ ( int ) name[ j ] ];
+		}
+	  fname[ MAX_LEN - min + shift ] = 0;
+	  if( reverse )
+		{
+		  int len;
+
+		  len = MAX_LEN - min + shift;
+		  for( j = 0 ; j < len / 2 + 1 ; ++ j )
+			{
+			  char swap;
+
+			  swap = fname[ j ];
+			  fname[ j ] = fname[ len - j - 1 ];
+			  fname[ len - j - 1 ] = swap;
+			}
+		}
+	  if( dodirs )
+		{
+		  fd = mkdir( fname, 0744 );
+		}
+	  else
+		{
+		  fd = open( fname, O_CREAT | O_WRONLY, 0444 );
+		}
+	  if( fd == -1 )
+		{
+		  perror( "open" );
+		  printf( "%li files created\n", i );
+		  exit( 2 );
+		}
+	  if( !dodirs )
+		{
+		  if( writelen > 0 )
+			{
+			  int result;
+
+			  if( write( fd, buf, writelen ) != writelen )
+				{
+				  perror( "write" );
+				  exit( 3 );
+				}
+			}
+		  close( fd );
+		}
+	  if( ( i % cycle ) == 0 )
+		{
+		  struct timeval now;
+
+		  gettimeofday( &now, 0 );
+		  printf( "%lli\t files: %lli (%f/%f), %s\n", i,
+				  tdiff( &now, &instant ),
+				  RAT( i * 1000000, tdiff( &now, &start ) ),
+				  RAT( ( i - prev ) * 1000000, tdiff( &now, &instant ) ),
+				  fname );
+		  gettimeofday( &instant, 0 );
+		  prev = i;
+		}
+	}
+  if( buf != NULL )
+	free( buf );
+}
diff -puN /dev/null not-for-inclusion/ulevel/make-teeny-files.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/make-teeny-files.c	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,102 @@
+/*
+ * make-teeny-files.c by Andrew Morton <akpm@digeo.com>
+ *
+ * http://www.zip.com.au/~akpm/linux/patches/stuff/make-teeny-files.c
+ */
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/ioctl.h>
+#include <fcntl.h>
+#include <stdlib.h>
+#include <unistd.h>
+#include <stdio.h>
+#include <errno.h>
+#include <string.h>
+
+#ifndef O_LARGEFILE
+#define O_LARGEFILE	0100000
+#endif
+
+#ifndef O_DIRECT
+#define O_DIRECT	040000	/* direct disk access hint */
+#endif
+
+#ifndef BLKBSZSET
+#define BLKBSZSET  _IOW(0x12,113,sizeof(int))
+#endif
+
+#ifndef O_STREAMING
+#define O_STREAMING    04000000        /* Streaming access */
+#endif
+
+char *ourname;
+char _meg[1024*1024 + 40960];
+int do_fsync = 0;
+unsigned align_offset = 0;
+int o_streaming;
+int blocksize = 0;
+
+static void usage(void)
+{
+	fprintf(stderr,
+		"Usage: %s depth files-per-dir\n",
+		ourname);
+	exit(1);
+}
+
+static void doit(int depth, int fpd)
+{
+	int i;
+
+	for (i = 0; i < fpd; i++) {
+		char buf[100];
+		sprintf(buf, "%08d", i);
+
+		if (depth) {
+			mkdir(buf, 0777);
+			chdir(buf);
+			doit(depth - 1, fpd);
+			chdir("..");
+		} else {
+			int fd = creat(buf, 0666);
+			char x[1];
+
+			if (fd < 0) {
+				perror("creat");
+				exit(1);
+			}
+			write(fd, x, 1);
+			close(fd);
+		}
+	}
+}
+
+int main(int argc, char *argv[])
+{
+	int depth = 0;
+	int fpd = 0;
+	int c;
+
+	ourname = argv[0];
+
+	if (argc < 2)
+		usage();
+
+	while ((c = getopt(argc, argv, "")) != -1) {
+		switch (c) {
+		default:
+			usage();
+		}
+	}
+
+	if (optind == argc)
+		usage();
+	depth = atoi(argv[optind++]);
+	if (optind == argc)
+		usage();
+	fpd = atoi(argv[optind++]);
+	if (optind != argc)
+		usage();
+	doit(depth, fpd);
+	exit(0);
+}
diff -puN /dev/null not-for-inclusion/ulevel/massage-lockmeter-output
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/massage-lockmeter-output	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,17 @@
+#! /bin/sh
+
+# take lockmeter (http://oss.sgi.com/projects/lockmeter) output as input
+
+# add missing optional fields
+awk '/^.............              / { print substr($0, 0, 14) "0.0us( 0.0us)" substr($0, 28); next } { print $0 }' | \
+awk '/^..................................               / { print substr($0, 0, 34) "( 0.0us)(0.00%)" substr($0, 49); next } { print $0 }' | \
+# convert optional fields HOLD MAX and WAIT MAX
+sed 's/(\(.....\)s)/ \1s /g' | \
+# convert WAIT CPU field
+sed 's/(\(....\)%)/ \1% /g' | \
+# strip microsecond suffix
+sed 's/\([0-9]\)us /\1   /g' | \
+# convert milliseconds to microseconds
+sed 's/\([0-9]\)ms /\1000 /g' | \
+# add "total waited" and "total held" fields
+awk '{ if (NF == 12) { printf "%10li %10li %s\n", $3 * $8, $5 * $8, $0} }'
diff -puN /dev/null not-for-inclusion/ulevel/nfs_fh_stale.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/nfs_fh_stale.c	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,1065 @@
+/* -*- C -*- */
+
+/* cc -o nfs -O3 -Wformat -g nfs_fh_stale.c -pthread */
+
+#include <unistd.h>
+#include <stdio.h>
+#include <errno.h>
+#include <fcntl.h>
+#include <string.h>
+#include <sys/ioctl.h>
+#include <sys/types.h>
+#include <sys/stat.h>
+#include <sys/statfs.h>
+#include <pthread.h>
+#include <stdlib.h>
+#include <time.h>
+#include <sys/time.h>
+#include <sys/mman.h>
+#include <dirent.h>
+/* #define NDEBUG */
+#include <assert.h>
+#include <signal.h>
+
+extern char *optarg;
+extern int optind, opterr, optopt;
+
+typedef enum { ok = 0,
+	wrong_argc,
+	pthread_create_error
+} ret_t;
+
+typedef struct stats {
+	pthread_mutex_t lock;
+	unsigned long opens;
+	unsigned long lseeks;
+	unsigned long errors;
+	unsigned long naps;
+	unsigned long total;
+	unsigned long done;
+	struct timeval start;
+	struct timeval end;
+	int totfreq;
+	int stop;
+} stats_t;
+
+stats_t stats;
+
+static void *worker(void *arg);
+
+typedef struct {
+	void *start;
+	int   length;
+} mmapped_t;
+
+typedef struct params {
+	int         dirs;
+	int         files;
+	char       *buffer;
+	const char *filename;
+	int         fileno;
+	int         dirno;
+	DIR       **cwd;
+	int        *fd;
+	mmapped_t  *mmapped;
+} params_t;
+
+static void sync_file(params_t *params);
+static void read_file(params_t *params);
+static void write_file(params_t *params);
+static void rename_file(params_t *params);
+static void unlink_file(params_t *params);
+static void link_file(params_t *params);
+static void sym_file(params_t *params);
+static void trunc_file(params_t *params);
+static void pip_file(params_t *params);
+static void mmap_file(params_t *params);
+static void open_file(params_t *params);
+static void gc_file(params_t *params);
+
+static void nap(int secs, int nanos);
+static void _nap(int secs, int nanos);
+
+static void orderedname(params_t *params, char *name);
+
+#define DEFAULT_THREADS 10
+#define DEFAULT_FILES 100
+#define DEFAULT_DIRS 1
+#define DEFAULT_ITERATIONS 10
+#define DEFAULT_DELTA 1
+#define DEFAULT_MAX_SLEEP 0
+#define DEFAULT_BUF_SIZE 4096 * 100
+#define DEFAULT_MAX_SIZE 4096 * 100 * 1000
+#define DEFAULT_VERBOSE 0
+#define DEFAULT_LIMIT 0
+#define DEFAULT_BENCHMARK 0
+#define DEFAULT_OPERATIONS 0
+#define DEFAULT_OPEN_FD    10
+#define DEFAULT_MMAPED_AREAS  100
+
+int delta = DEFAULT_DELTA;
+int max_sleep = DEFAULT_MAX_SLEEP;
+int max_buf_size = DEFAULT_BUF_SIZE;
+int max_size = DEFAULT_MAX_SIZE;
+int verbose = DEFAULT_VERBOSE;
+unsigned long long limit = DEFAULT_LIMIT;
+unsigned long long operations = DEFAULT_OPERATIONS;
+int benchmark = DEFAULT_BENCHMARK;
+int files = DEFAULT_FILES;
+int dirs = DEFAULT_DIRS;
+int fd_num = DEFAULT_OPEN_FD;
+int nr_mmapped = DEFAULT_MMAPED_AREAS;
+int pgsize;
+int sigs = 0;
+
+DIR **cwds = NULL;
+
+/* random integer number in [0, n - 1] */
+#define RND(n) ((int)(((double)(n)) * rand() / (RAND_MAX + 1.0)))
+
+#define STRICT (0)
+
+#if STRICT
+#define STEX(e) \
+	pthread_mutex_lock(&stats.lock) ; e ; pthread_mutex_unlock(&stats.lock)
+#else
+#define STEX(e) e
+#endif
+
+typedef struct op {
+	const char *label;
+	int freq;
+	void (*handler)(params_t *params);
+	struct {
+		int subtotal;
+		int ok;
+		int failure;
+		int missed;
+		int busy;
+	} result;
+} op_t;
+
+typedef enum {
+	syncop,
+	readop,
+	writeop,
+	renameop,
+	unlinkop,
+	linkop,
+	symop,
+	truncop,
+	pipop,
+	openop,
+	mmapop,
+	gcop
+} op_id_t;
+
+#define DEFOPS(aname)				\
+[aname ## op ] = {				\
+	.label = #aname,			\
+	.freq  = 1,				\
+	.handler = aname ## _file		\
+}
+
+op_t ops[] = {
+	DEFOPS(sync),
+	DEFOPS(read),
+	DEFOPS(write),
+	DEFOPS(rename),
+	DEFOPS(unlink),
+	DEFOPS(link),
+	DEFOPS(sym),
+	DEFOPS(trunc),
+	DEFOPS(pip),
+	DEFOPS(mmap),
+	DEFOPS(open),
+	DEFOPS(gc),
+	{
+		.label = NULL
+	}
+};
+
+const char optstring[] = "p:f:d:D:i:s:b:M:BvF:L:O:o:m:j";
+
+static double
+rate(unsigned long events, int secs)
+{
+	return ((double) events) / secs;
+}
+
+static void
+usage(char *argv0)
+{
+	char *progname;
+	op_t *op;
+
+	progname = strrchr(argv0, '/');
+	if (progname == NULL)
+		progname = argv0;
+	else
+		progname ++;
+
+	fprintf(stderr,
+		"usage: %s options\n"
+		"\n\tRandomly creates and removes files from multiple threads."
+		"\n\tCan be used to test NFS stale handle detection."
+		"\n\tCompiled from " __FILE__ " at " __DATE__ "\n\n",
+		progname);
+	fprintf(stderr, "options, deafults in []\n"
+		"\t-p N   \tlaunch N concurrent processes [%i]\n"
+		"\t-f N   \toperate on N files [%i]\n"
+		"\t-d N   \tduplicate file set in N directories [%i]\n"
+		"\t-D N   \titeration takes N seconds [%i]\n"
+		"\t-i N   \tperform N iterations [%i]\n"
+		"\t-O N   \tperform N operations [%i]\n"
+		"\t-s N   \tsleep [0 .. N] nanoseconds between operations [%i]\n"
+		"\t-b N   \tmaximal buffer size is N bytes [%i]\n"
+		"\t-M N   \tmaximal file size is N bytes [%i]\n"
+		"\t-o N   \tkeep N file descriptors open [%i]\n"
+		"\t-m N   \tkeep N memory areas mmapped [%i]\n"
+		"\t-B     \tbenchmark mode: don't ever sleep [%i]\n"
+		"\t-v     \tincrease verbosity\n"
+		"\t-F op=N\tset relative frequence of op (see below) to N\n"
+		"\t-L N   \tlimit amount of used disk space to N kbytes [%i]\n"
+		"\t-j     \twait for the completion of all spawned threads\n",
+
+		DEFAULT_THREADS,
+		DEFAULT_FILES,
+		DEFAULT_DIRS,
+		DEFAULT_DELTA,
+		DEFAULT_ITERATIONS,
+		DEFAULT_OPERATIONS,
+		DEFAULT_MAX_SLEEP,
+		DEFAULT_BUF_SIZE,
+		DEFAULT_MAX_SIZE,
+		DEFAULT_OPEN_FD,
+		DEFAULT_MMAPED_AREAS,
+		DEFAULT_BENCHMARK,
+		DEFAULT_LIMIT);
+
+	fprintf(stderr, "\noperations with default frequencies\n");
+	for (op = &ops[0] ; op->label ; ++ op) {
+		fprintf(stderr, "\t%s\t%i\n", op->label, op->freq);
+	}
+}
+
+static void
+sighandler(int signo)
+{
+	++ sigs;
+}
+
+static unsigned long long
+getavail()
+{
+	int result;
+
+	struct statfs buf;
+
+	result = statfs(".", &buf);
+	if (result != 0) {
+		perror("statfs");
+		exit(1);
+	}
+	return buf.f_bsize * (buf.f_bavail >> 10);
+}
+
+int
+main(int argc, char **argv)
+{
+	ret_t result;
+	int threads = DEFAULT_THREADS;
+	int i;
+	int iterations = DEFAULT_ITERATIONS;
+	unsigned long long operations = DEFAULT_OPERATIONS;
+	int opt;
+	char dname[30];
+	unsigned long long initiallyavail;
+	unsigned long long used;
+	op_t *op;
+	pthread_t *id;
+	int join;
+
+	result = ok;
+	ops[gcop].freq = 0;
+	do {
+		opt = getopt(argc, argv, optstring);
+		switch (opt) {
+		case '?':
+			usage(argv[0]);
+			return wrong_argc;
+		case 'p':
+			threads = atoi(optarg);
+			break;
+		case 'f':
+			files = atoi(optarg);
+			break;
+		case 'd':
+			dirs = atoi(optarg);
+			break;
+		case 'D':
+			delta = atoi(optarg);
+			break;
+		case 'i':
+			iterations = atoi(optarg);
+			break;
+		case 'O':
+			operations = atoll(optarg);
+			break;
+		case 's':
+			max_sleep = atoi(optarg);
+			break;
+		case 'b':
+			max_buf_size = atoi(optarg);
+			if (max_buf_size < 255) {
+				fprintf(stderr, "%s: max_buf_size too small\n",
+					argv[0]);
+				return 1;
+			}
+			break;
+		case 'M':
+			max_size = atoi(optarg);
+			break;
+		case 'o':
+			fd_num = atoi(optarg);
+			break;
+		case 'm':
+			nr_mmapped = atoi(optarg);
+			break;
+		case 'B':
+			benchmark = 1;
+			break;
+		case 'v':
+			++verbose;
+			break;
+		case 'F': {
+			char *eq;
+			int   opfreq;
+
+			eq = strchr(optarg, '=');
+			if (eq == NULL) {
+				fprintf(stderr, "%s: Use -F op=freq\n", argv[0]);
+				return 1;
+			}
+			*eq = 0;
+			opfreq = atoi(eq + 1);
+			for (op = &ops[0] ; op->label ; ++ op) {
+				if (!strcmp(op->label, optarg)) {
+					op->freq = opfreq;
+					break;
+				}
+			}
+			if (!op->label) {
+				fprintf(stderr, "%s: Unknown op: %s\n",
+					argv[0], optarg);
+				return 1;
+			}
+			*eq = '=';
+		}
+			break;
+		case 'L':
+			limit = atoll(optarg);
+			break;
+		case -1:
+			break;
+		}
+	} while (opt != -1);
+	stats.total = operations;
+	stats.done = 0;
+	stats.stop = 0;
+
+	stats.totfreq = 0;
+	for (op = &ops[0] ; op->label ; ++ op)
+		stats.totfreq += op->freq;
+
+	if (gettimeofday(&stats.start, NULL) != 0) {
+		perror("gettimeofday");
+		return 1;
+	}
+	pthread_mutex_init(&stats.lock, NULL);
+
+	pgsize = getpagesize();
+	initiallyavail = getavail();
+
+	signal(SIGBUS, sighandler);
+	signal(SIGSEGV, sighandler);
+
+	cwds = calloc(dirs, sizeof cwds[0]);
+	if (cwds == NULL) {
+		perror("calloc");
+		return 1;
+	}
+
+	for (i = 0; i < dirs; ++i) {
+		sprintf(dname, "d%x", i);
+		if (mkdir(dname, 0700) == -1 && errno != EEXIST) {
+			perror("mkdir");
+			return 1;
+		}
+	}
+
+	fprintf(stderr,
+		"%s: %i processes, %i files, delta: %i"
+		"\n\titerations: %i, sleep: %i, buffer: %i, max size: %i\n",
+		argv[0], threads, files, delta, iterations,
+		max_sleep, max_buf_size, max_size);
+
+	id = calloc(threads, sizeof id[0]);
+	if (id == NULL) {
+		perror("calloc");
+		return 1;
+	}
+
+	for (i = 0; i < threads; ++i) {
+		int rv;
+
+		rv = pthread_create(&id[i], NULL, worker, NULL);
+		if (rv != 0) {
+			fprintf(stderr,
+				"%s: pthread_create fails: %s(%i) while creating %i-%s thread\n",
+				argv[0], strerror(rv), rv, i,
+				(i % 10 == 1) ? "st" : (i % 10 ==
+							2) ? "nd" : "th");
+			return 1;
+		}
+	}
+	for (i = 0; i < iterations; i += delta) {
+		used = initiallyavail - getavail();
+		printf("\nseconds: %i\topens: %lu [%f] lseeks: %lu [%f]\n"
+		       "\terrors: %lu, sigs: %i, "
+		       "used: %lli, gc: %i\n",
+		       i,
+		       stats.opens, rate(stats.opens, i),
+		       stats.lseeks, rate(stats.lseeks, i),
+		       stats.errors, sigs, used, ops[gcop].freq);
+		printf("op:\tok\tmiss\tbusy\terr\tdone\trate\tglobal rate\n");
+		for (op = &ops[0] ; op->label ; ++ op) {
+			int done;
+			int subtotal;
+			int ratio;
+
+			done = op->result.ok;
+			subtotal = op->result.subtotal;
+			op->result.subtotal = done;
+			if (op->freq != 0)
+				ratio = stats.totfreq / op->freq;
+			else
+				ratio = 0;
+
+			printf("%s:\t%i\t%i\t%i\t%i\t%i\t%.1f\t%.1f\n",
+			       op->label,
+			       done,
+			       op->result.missed,
+			       op->result.busy,
+			       op->result.failure,
+			       done - subtotal,
+			       rate((done - subtotal) * ratio, delta),
+			       rate(done * ratio, i));
+		}
+		fflush(stdout);
+		if (limit != 0) {
+			int origfreq;
+
+			origfreq = ops[gcop].freq;
+			if (used > limit / 2) {
+				if (used > limit)
+					ops[gcop].freq *= 2;
+				else
+					ops[gcop].freq = (used - limit / 2) * 100 / (limit / 2);
+			} else
+				ops[gcop].freq = 0;
+			stats.totfreq += (ops[gcop].freq - origfreq);
+		}
+		_nap(delta, 0);
+	}
+	stats.stop = 1;
+	if (join) {
+		for (i = 0; i < threads; ++i) {
+			int ret;
+
+			ret = pthread_join(id[i], NULL);
+			if (ret != 0)
+				fprintf(stderr, "pthread_join: %i\n", ret);
+		}
+	}
+	return result;
+}
+
+static void *
+worker(void *arg)
+{
+	params_t params;
+	char fileName[30];
+
+	if (signal(SIGBUS, sighandler) == SIG_ERR) {
+		perror("signal(SIGBUS)");
+		return NULL;
+	}
+	if (signal(SIGSEGV, sighandler) == SIG_ERR) {
+		perror("signal(SIGSEGV)");
+		return NULL;
+	}
+
+	memset(&params, 0, sizeof params);
+	params.files    = files;
+	params.dirs     = dirs;
+	params.buffer   = malloc(max_buf_size);
+	params.filename = fileName;
+	params.cwd      = cwds;
+	params.fd       = calloc(fd_num, sizeof params.fd[0]);
+	params.mmapped  = calloc(nr_mmapped, sizeof params.mmapped[0]);
+
+	while (1) {
+		op_t *op;
+		int   randum;
+		int   freqreached;
+
+		params.fileno = RND(params.files);
+		params.dirno = RND(params.dirs);
+		sprintf(fileName, "d%x/%x", params.dirno, params.fileno);
+		randum = RND(stats.totfreq);
+		freqreached = 0;
+		for (op = &ops[0] ; op->label ; ++ op) {
+			freqreached += op->freq;
+			if (randum < freqreached) {
+				op->handler(&params);
+				break;
+			}
+		}
+		STEX(++stats.done);
+		if (!benchmark)
+			nap(0, RND(max_sleep));
+		else if (stats.total && stats.done >= stats.total) {
+			pthread_mutex_lock(&stats.lock);
+			gettimeofday(&stats.end, NULL);
+			printf("start: %li.%li, end: %li.%li, diff: %li, %li\n",
+			       stats.start.tv_sec, stats.start.tv_usec,
+			       stats.end.tv_sec, stats.end.tv_usec,
+			       stats.end.tv_sec - stats.start.tv_sec,
+			       stats.end.tv_usec - stats.start.tv_usec);
+			break;
+		}
+		if (stats.stop)
+			break;
+	}
+}
+
+static void
+sync_file(params_t *params)
+{
+	int fd;
+	const char *fileName;
+
+	fileName = params->filename;
+	fd = open(fileName, O_WRONLY);
+	if (fd == -1) {
+		if (errno != ENOENT) {
+			fprintf(stderr, "%s open/sync: %s(%i)\n", fileName,
+				strerror(errno), errno);
+			STEX(++stats.errors);
+		} else {
+			STEX(++ops[syncop].result.missed);
+		}
+		return;
+	}
+	if (fsync(fd)) {
+		fprintf(stderr, "%s sync: %s(%i)\n",
+			fileName, strerror(errno), errno);
+		STEX(++stats.errors);
+		STEX(++ops[syncop].result.failure);
+		return;
+	}
+	STEX(++ops[syncop].result.ok);
+	if (verbose) {
+		printf("[%li] SYNC: %s\n", pthread_self(), fileName);
+	}
+	close(fd);
+}
+
+static void
+read_file(params_t *params)
+{
+	int fd;
+	char *buf;
+	int bufSize;
+	int offset;
+	const char *fileName;
+
+	fileName = params->filename;
+	fd = open(fileName, O_CREAT | O_APPEND | O_RDWR, 0700);
+	if (fd == -1) {
+		fprintf(stderr, "%s open/read: %s(%i)\n", fileName, strerror(errno),
+			errno);
+		STEX(++stats.errors);
+		STEX(++ops[readop].result.missed);
+		return;
+	}
+	STEX(++stats.opens);
+	nap(0, RND(max_sleep));
+	if (lseek(fd, RND(max_size), SEEK_SET) == -1) {
+		fprintf(stderr, "%s lseek: %s(%i)\n",
+			fileName, strerror(errno), errno);
+		STEX(++stats.errors);
+		close(fd);
+		return;
+	}
+	STEX(++stats.lseeks);
+	nap(0, RND(max_sleep));
+	bufSize = RND(max_buf_size / 3) + 30;
+	offset = RND(max_buf_size / 3);
+	buf = params->buffer;
+	if (read(fd, buf, bufSize + offset) == -1) {
+		fprintf(stderr, "%s read: %s(%i)\n", fileName, strerror(errno),
+			errno);
+		STEX(++stats.errors);
+		STEX(++ops[readop].result.failure);
+		close(fd);
+		return;
+	}
+	STEX(++ops[readop].result.ok);
+	if (verbose) {
+		printf("[%li] R: %s\n", pthread_self(), fileName);
+	}
+	close(fd);
+}
+
+static void
+write_file(params_t *params)
+{
+	int fd;
+	char *buf;
+	int bufSize;
+	int offset;
+	const char *fileName;
+	int osync;
+
+	fileName = params->filename;
+	osync = RND(2);
+	fd = open(fileName, O_CREAT | O_APPEND | O_RDWR | (osync ? O_SYNC : 0), 0700);
+	if (fd == -1) {
+		fprintf(stderr, "%s open/write: %s(%i)\n", fileName, strerror(errno),
+			errno);
+		STEX(++stats.errors);
+		STEX(++ops[writeop].result.missed);
+		return;
+	}
+	STEX(++stats.opens);
+	nap(0, RND(max_sleep));
+	if (lseek(fd, RND(max_size), SEEK_SET) == -1) {
+		fprintf(stderr, "%s lseek: %s(%i)\n",
+			fileName, strerror(errno), errno);
+		STEX(++stats.errors);
+		close(fd);
+		return;
+	}
+	STEX(++stats.lseeks);
+	nap(0, RND(max_sleep));
+	bufSize = RND(max_buf_size / 3) + 30;
+	offset = RND(max_buf_size / 3);
+	buf = params->buffer;
+	memset(buf, 0xfe + stats.opens, max_buf_size);
+	sprintf(buf + offset, "---%lx+++", time(NULL));
+	if (write(fd, buf, bufSize + offset) == -1) {
+		fprintf(stderr, "%s write: %s(%i)\n",
+			fileName, strerror(errno), errno);
+		STEX(++stats.errors);
+		STEX(++ops[writeop].result.failure);
+		close(fd);
+		return;
+	}
+	STEX(++ops[writeop].result.ok);
+	if (verbose) {
+		printf("[%li] W: %s\n", pthread_self(), fileName);
+	}
+	close(fd);
+}
+
+static void
+rename_file(params_t *params)
+{
+	char target[30];
+	const char *fileName;
+	int files;
+
+	fileName = params->filename;
+	files = params->files;
+	orderedname(params, target);
+	if (rename(fileName, target) == -1) {
+		switch (errno) {
+		case ENOENT:
+			STEX(++ops[renameop].result.missed);
+			break;
+		default:
+			{
+				fprintf(stderr, "rename( %s, %s ): %s(%i)\n",
+					fileName, target, strerror(errno),
+					errno);
+				STEX(++stats.errors);
+				STEX(++ops[renameop].result.failure);
+			}
+		}
+	} else {
+		if (verbose) {
+			printf("[%li] %s -> %s\n", pthread_self(), fileName,
+			       target);
+		}
+		STEX(++ops[renameop].result.ok);
+	}
+}
+
+static void
+unlink_file(params_t *params)
+{
+	const char *fileName;
+
+	fileName = params->filename;
+	if (unlink(fileName) == -1) {
+		switch (errno) {
+		case ENOENT:
+			STEX(++ops[unlinkop].result.missed);
+			break;
+		default:
+			{
+				fprintf(stderr, "%s unlink: %s(%i)\n",
+					fileName, strerror(errno), errno);
+				STEX(++stats.errors);
+				STEX(++ops[unlinkop].result.failure);
+			}
+		}
+	} else {
+		if (verbose) {
+			printf("[%li] U: %s\n", pthread_self(), fileName);
+		}
+		STEX(++ops[unlinkop].result.ok);
+	}
+}
+
+static void
+link_file(params_t *params)
+{
+	char target[30];
+	const char *fileName;
+	int files;
+
+	fileName = params->filename;
+	files = params->files;
+	orderedname(params, target);
+	if (link(fileName, target) == -1) {
+		switch (errno) {
+		case ENOENT:
+			STEX(++ops[linkop].result.missed);
+			break;
+		case EEXIST:
+			STEX(++ops[linkop].result.busy);
+			break;
+		default:
+			{
+				fprintf(stderr, "link( %s, %s ): %s(%i)\n",
+					fileName, target, strerror(errno),
+					errno);
+				STEX(++stats.errors);
+				STEX(++ops[linkop].result.failure);
+			}
+		}
+	} else {
+		if (verbose) {
+			printf("[%li] %s -> %s\n", pthread_self(), fileName,
+			       target);
+		}
+		STEX(++ops[linkop].result.ok);
+	}
+}
+
+static void
+sym_file(params_t *params)
+{
+	char target[30];
+	char source[30];
+	const char *fileName;
+	int files;
+
+	fileName = params->filename;
+	files = params->files;
+	orderedname(params, target);
+	sprintf(source, "../%s", fileName);
+	if (symlink(source, target) == -1) {
+		switch (errno) {
+		case ENOENT:
+			STEX(++ops[symop].result.missed);
+			break;
+		case EEXIST:
+			STEX(++ops[symop].result.busy);
+			break;
+		default:
+			{
+				fprintf(stderr, "link( %s, %s ): %s(%i)\n",
+					fileName, target, strerror(errno),
+					errno);
+				STEX(++stats.errors);
+				STEX(++ops[symop].result.failure);
+			}
+		}
+	} else {
+		if (verbose) {
+			printf("[%li] %s -> %s\n", pthread_self(), fileName,
+			       target);
+		}
+		STEX(++ops[symop].result.ok);
+	}
+}
+
+static void
+trunc_file(params_t *params)
+{
+	const char *fileName;
+
+	fileName = params->filename;
+	if (truncate(fileName, RND(max_size)) == -1) {
+		switch (errno) {
+		case ENOENT:
+			STEX(++ops[truncop].result.missed);
+			break;
+		default:
+			{
+				fprintf(stderr, "%s trunc: %s(%i)\n",
+					fileName, strerror(errno), errno);
+				STEX(++stats.errors);
+				STEX(++ops[truncop].result.failure);
+			}
+		}
+	} else {
+		if (verbose) {
+			printf("[%li] T: %s\n", pthread_self(), fileName);
+		}
+		STEX(++ops[truncop].result.ok);
+	}
+}
+
+static void
+pip_file(params_t *params)
+{
+	struct dirent  entry;
+	struct dirent *ptr;
+	int result;
+	int dirno;
+	int dogc;
+
+	dirno = RND(params->dirs);
+
+	if (params->cwd[dirno] == NULL) {
+		char dname[30];
+
+		sprintf(dname, "d%x", dirno);
+		params->cwd[dirno] = opendir(dname);
+		if (params->cwd[dirno] == NULL) {
+			perror("opendir");
+			exit(1);
+		}
+	}
+
+	dogc = (params->buffer[0] == 0x66);
+	errno = 0;
+	result = readdir_r(params->cwd[dirno], &entry, &ptr);
+	if (result == 0 && errno == 0 && ptr == &entry) {
+		char fname[100];
+
+		sprintf(fname, "d%x/%s", dirno, entry.d_name);
+		if (dogc) {
+			if (unlink(fname) == -1) {
+				switch (errno) {
+				case ENOENT:
+					STEX(++ops[gcop].result.missed);
+					break;
+				case EISDIR:
+					break;
+				default:
+					STEX(++stats.errors);
+					STEX(++ops[gcop].result.failure);
+				}
+			} else
+				STEX(++ops[gcop].result.ok);
+		} else {
+			STEX(++ops[pipop].result.ok);
+			if (verbose)
+				printf("[%li] P: %s\n", pthread_self(), fname);
+		}
+	} else if (errno == ENOENT || ptr == NULL)
+		rewinddir(params->cwd[dirno]);
+	else if (verbose) {
+		printf("[%li] P: %i, %i, %p, %s\n",
+		       pthread_self(), result, errno, ptr, entry.d_name);
+		STEX(++ops[dogc ? gcop : pipop].result.failure);
+	}
+}
+
+static void
+open_file(params_t *params)
+{
+	int fdno;
+
+	fdno = RND(fd_num);
+	if (params->fd[fdno] == 0) {
+		int fd;
+		const char *fileName;
+
+		fileName = params->filename;
+		fd = open(fileName, O_CREAT | O_APPEND | O_RDWR, 0700);
+		if (fd == -1) {
+			fprintf(stderr, "%s open/open: %s(%i)\n",
+				fileName, strerror(errno), errno);
+			STEX(++stats.errors);
+			STEX(++ops[openop].result.missed);
+			return;
+		}
+		params->fd[fdno] = fd;
+		STEX(++stats.opens);
+		STEX(++ops[openop].result.ok);
+	} else {
+		close(params->fd[fdno]);
+		params->fd[fdno] = 0;
+	}
+}
+
+static char *minp(char *p1, char *p2)
+{
+	if (p1 < p2)
+		return p1;
+	else
+		return p2;
+}
+
+static roundtopage(unsigned long val)
+{
+	return (val + pgsize - 1) / pgsize * pgsize;
+}
+
+static void
+mmap_file(params_t *params)
+{
+	int areano;
+
+	areano = RND(nr_mmapped);
+	if (params->mmapped[areano].start == NULL) {
+		int fd;
+
+		fd = params->fd[RND(fd_num)];
+		if (fd != 0) {
+			int result;
+			size_t length;
+			int flags;
+			off_t offset;
+			void *addr;
+
+			length = roundtopage(RND(max_buf_size) + 30);
+			offset = roundtopage(RND(max_size));
+			flags  = RND(1) == 0 ? MAP_SHARED : MAP_PRIVATE;
+			result = ftruncate(fd, offset + length + 1);
+			if (result == -1) {
+				fprintf(stderr,
+					"%i mmap/truncate: %s(%i)\n",
+					fd, strerror(errno), errno);
+				STEX(++stats.errors);
+				STEX(++ops[mmapop].result.missed);
+			} else {
+				addr = mmap(NULL, length, PROT_READ | PROT_WRITE,
+					    flags, fd, offset);
+				if (addr == MAP_FAILED) {
+					fprintf(stderr, "%i mmap: %s(%i)\n",
+						fd, strerror(errno), errno);
+					STEX(++stats.errors);
+					STEX(++ops[mmapop].result.missed);
+				} else {
+					params->mmapped[areano].start  = addr;
+					params->mmapped[areano].length = length;
+				}
+			}
+			STEX(++ops[mmapop].result.ok);
+		}
+	} else if (RND(100) == 0) {
+		munmap(params->mmapped[areano].start,
+		       params->mmapped[areano].length);
+		params->mmapped[areano].start = NULL;
+		STEX(++ops[mmapop].result.ok);
+	} else {
+		char *scan;
+		char *end;
+		int length;
+		int sigs0;
+
+		scan = params->mmapped[areano].start;
+		scan += RND(params->mmapped[areano].length);
+		end = minp(scan + RND(max_buf_size) + 30,
+			   params->mmapped[areano].start +
+			   params->mmapped[areano].length - 1);
+		sigs0 = sigs;
+		if (RND(1) == 0) {
+			char x;
+
+			x = 0;
+			for (;scan < end && sigs == sigs0; ++scan)
+				x += *scan;
+		} else {
+			for (;scan < end && sigs == sigs0; ++scan)
+				*scan = ((int)scan) ^ (*scan);
+		}
+		STEX(++ops[mmapop].result.ok);
+	}
+}
+
+static void
+gc_file(params_t *params)
+{
+	params->buffer[0] = 0x66;
+	pip_file(params);
+	params->buffer[0] = 0x00;
+}
+
+static void
+nap(int secs, int nanos)
+{
+	if (!benchmark)
+		_nap(secs, nanos);
+}
+
+static void
+_nap(int secs, int nanos)
+{
+	if ((secs > 0) || (nanos > 0)) {
+		struct timespec delay;
+
+		delay.tv_sec = secs;
+		delay.tv_nsec = nanos;
+
+		if (nanosleep(&delay, NULL) == -1) {
+			fprintf(stderr, "nanosleep: %s(%i)\n", strerror(errno),
+				errno);
+		}
+		STEX(++stats.naps);
+	}
+}
+
+/*
+ * When renaming or linking file (through link, rename, or symlink), maintain
+ * certain order, so that infinite loops of symlinks are avoided.
+ */
+static void orderedname(params_t *params, char *name)
+{
+	int targetno;
+	int dirno;
+
+	targetno = params->fileno +
+		RND(params->files - params->fileno - 1) + 1;
+
+	dirno = RND(params->dirs);
+	sprintf(name, "d%x/%x", dirno, targetno);
+}
+
+/*
+  Local variables:
+  c-indentation-style: "K&R"
+  mode-name: "LC"
+  c-basic-offset: 8
+  tab-width: 8
+  fill-column: 79
+  End:
+*/
diff -puN /dev/null not-for-inclusion/ulevel/puncher.sh
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/puncher.sh	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,23 @@
+#! /bin/sh
+
+OF=${1:-punched.file}
+SZ=${2:-1000}
+DD="dd if=/dev/zero of=$OF bs=4096 count=1 conv=notrunc"
+
+echo -n '->'
+
+rm -f $OF || exit 1
+$DD seek=$SZ 2>/dev/null || exit 2
+seq 0 2 $SZ | while read ;do
+        $DD seek=$REPLY 2>/dev/null || exit 3
+        echo -n .
+done
+
+echo
+echo -n '<-'
+
+rm -f $OF || exit 1
+seq $SZ -2 0 | while read ;do
+        $DD seek=$REPLY 2>/dev/null || exit 3
+        echo -n .
+done
diff -puN /dev/null not-for-inclusion/ulevel/readdir.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/readdir.c	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,43 @@
+#define _LARGEFILE64_SOURCE
+
+#include <sys/types.h>
+#include <dirent.h>
+#include <stdlib.h>
+
+#include <sys/stat.h>
+#include <unistd.h>
+
+#include <errno.h>
+
+int main( int argc, char **argv )
+{
+  DIR             *directory;
+  struct dirent64 *dentry;
+  int              do_stat;
+
+  directory = opendir( argv[ 1 ] );
+  do_stat   = atoi( argv[ 2 ] );
+  if( directory != NULL )
+	{
+	  while( ( dentry = readdir64( directory ) ) != NULL )
+		{
+		  puts( dentry -> d_name );
+		  if( do_stat ) {
+			struct stat buf;
+
+			if( stat( dentry -> d_name, &buf ) == -1 )
+			  {
+				perror( "stat" );
+				break;
+			  }
+		  }
+		}
+	  if( errno != 0 )
+		  perror( "readdir" );
+	  closedir( directory );
+    }
+  else
+	{
+	  perror( "cannot opendir" );
+	}
+}
diff -puN /dev/null not-for-inclusion/ulevel/seek-info.sh
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/seek-info.sh	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,3 @@
+#! /bin/sh
+
+awk 'BEGIN {prev=0} {cur = $2 ; print (cur - prev - 1) " " prev " " cur ; prev = cur}'
diff -puN /dev/null not-for-inclusion/ulevel/seeks.sh
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/seeks.sh	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,73 @@
+#! /bin/sh
+
+OPTVAL=`getopt -o d:e:s:o:t: -n 'seeks.sh' -- "$@"`
+
+# Note the quotes around `$TEMP': they are essential!
+eval set -- "$OPTVAL"
+
+XSTYLE=dots
+
+while true ;do
+	case "$1" in
+		-s)
+			START=$2
+			shift 2
+		;;
+		-e)
+			END=$2
+			shift 2
+		;;
+		-t)
+			TITLE=$2
+			shift 2
+		;;
+		-d)
+			XSTYLE=$2
+			shift 2
+		;;
+		-o)
+			OUTFILE=$2
+			shift 2
+		;;
+		--)
+			shift
+			break
+		;;
+		*)
+			echo "Internal error!"
+			exit 1
+		;;
+	esac
+done
+
+if [ $START ] ;then
+	XRANGE="[$START:$END]"
+else
+	XRANGE=""
+fi
+
+if [ $OUTFILE ] ;then
+	XOUT="set output '$OUTFILE';"
+else
+	XOUT=""
+fi
+
+FNAME=tmp.$$
+cat > $FNAME
+grep r $FNAME > $FNAME.r
+grep w $FNAME > $FNAME.w
+
+(
+	echo "set terminal postscript color;"
+	echo "set linestyle 1 lt 1;" # red line
+	echo "set linestyle 2 lt 3;" # blue line
+#	echo "clear;"
+	echo "set data style $XSTYLE;"
+	echo "set noborder;"
+	echo $XOUT
+#	echo "set offsets 0,0,0,1000;"
+	echo "set label \"$TITLE: `date +%Y-%m-%d` by `whoami` at `uname -a`\" at graph -0.1,-0.07"
+	echo "plot $XRANGE '$FNAME.r' title 'reads' lt 1, '$FNAME.w' title 'writes' lt 3;"
+) | gnuplot #| gv -landscape -
+
+rm -f $FNAME $FNAME.r $FNAME.w
diff -puN /dev/null not-for-inclusion/ulevel/shortlived
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/shortlived	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,72 @@
+#! /bin/sh
+
+#set -x
+
+OPTVAL=`getopt -o t:o:vd: -n 'shortlived' -- "$@"`
+
+# Note the quotes around `$OPTVAL': they are essential!
+eval set -- "$OPTVAL"
+
+verbose=0
+threads=10
+delay=1000
+limit=nolimit
+
+while true ;do
+	case "$1" in
+		-v)
+			verbose=$(($verbose + 1))
+			shift
+		;;
+		-t)
+			threads=$2
+			shift 2
+		;;
+		-d)
+			delay=$2
+			shift 2
+		;;
+		-o)
+			limit=$2
+			shift 2
+		;;
+		--)
+			shift
+			break
+		;;
+		*)
+			echo "Internal error!"
+			exit 1
+		;;
+	esac
+done
+
+function udelay()
+{
+	local ms
+	local i
+
+	ms=$1
+	i=$((35015 * ms / 1000))
+	while [ $i -gt 0 ] ;do i=$(($i - 1)) ;done
+}
+
+for thr in $(seq 1 $threads) ;do
+	while : ;do
+		fname=$thr.$RANDOM.$$
+		if [ $verbose -gt 0 ] ;then
+			echo $fname
+		fi
+		touch $fname
+		udelay $delay
+		rm $fname
+		if [ x$limit != xnolimit ] ;then
+			limit=$(($limit - 1))
+		fi
+		if [ x$limit = x0 ] ;then
+			break
+		fi
+	done &
+done
+
+wait
diff -puN /dev/null not-for-inclusion/ulevel/show-stats.sh
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/show-stats.sh	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,27 @@
+#! /bin/sh
+
+function print_files()
+{
+	local prefix
+
+	prefix=$1
+	for f in * ;do \
+		if [ -f $f ] ;then
+			echo -n $prefix$(basename $f) ": "
+			cat $f
+			echo
+		fi
+	done
+}
+
+print_files ""
+
+for l in level* ;do \
+	cd $l
+	hits=$(cat total_hits_at_level)
+	if [ $hits -gt 0 ] ;then
+		echo "Level $l"
+		print_files "...."
+	fi
+	cd ..
+done
\ No newline at end of file
diff -puN /dev/null not-for-inclusion/ulevel/sleep-info-parse
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/sleep-info-parse	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,4 @@
+BEGIN { filename=/dev/null; system("mkdir ./zzz") }
+/[0-9]+ [0-9]+ [0-9]+$/ { filename="./zzz/" sprintf("%0.15d", $2) }
+{ print $0 >filename }
+END { system("cat ./zzz/*; rm -fr zzz 0") }
diff -puN /dev/null not-for-inclusion/ulevel/stripspaces
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/stripspaces	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,14 @@
+#! /bin/sh
+
+#
+# strip trailing spaces
+#
+
+find . -type f -follow -name '*.[chS]' | egrep -v SCCS | \
+while read
+do
+    f=$REPLY
+    cat $f | sed 's/ *$//g' > /tmp/ttt && \
+    mv /tmp/ttt $f && \
+    echo $f
+done
\ No newline at end of file
diff -puN /dev/null not-for-inclusion/ulevel/syscalltest.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/ulevel/syscalltest.c	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,20 @@
+#include <stdio.h>
+#include <errno.h>
+#include <asm/unistd.h>
+
+static inline int reiser4(const char *command)
+{
+	long __res;
+	__asm__ volatile ("int $0x80"
+			  : "=a" (__res)
+			  : "0" (268),"b" ((long)command)); \
+	__syscall_return(int,__res); \
+}
+
+int main(int argc, char **argv)
+{
+	int result;
+
+	result = reiser4(argv[1]);
+	printf("%i\n", result);
+}
diff -puN /dev/null not-for-inclusion/yet_unneeded_abstractions/oid/oid40.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/yet_unneeded_abstractions/oid/oid40.c	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,170 @@
+/* Copyright 2001, 2002, 2003 by Hans Reiser, licensing governed by reiser4/README */
+
+#include "../../debug.h"
+#include "../../key.h"
+#include "oid40.h"
+#include "oid.h"
+
+#include <linux/types.h>	/* for __u??  */
+
+/* Object-id manipulations.
+   reiser 4.0 default objectid manager */
+
+/* Maximal possible object id. */
+static const oid_t ABSOLUTE_MAX_OID = (oid_t) ~ 0;
+
+/* Minimal possible object id. */
+static const oid_t ABSOLUTE_MIN_OID = (oid_t) 0;
+
+/* reserve 65k oids for internal use on both ends of oid-space.
+    There is no reason to be greedy here. */
+/* AUDIT how is it reserved on both ends of oid space, if oid40_read_allocator
+   is passed with pre-determined starting oid value (that is not checked against
+   being smaller then this value)? */
+#define OIDS_RESERVED  ( 1 << 16 )
+
+/* plugin->u.oid_allocator.read_oid_allocator
+   Initialise object id allocator */
+int
+oid40_read_allocator(reiser4_oid_allocator * map, __u64 nr_files, __u64 oids)
+{
+	assert("nikita-1977", map != NULL);
+
+	spin_lock_init(&map->u.oid40.oguard);
+	map->u.oid40.next_to_use = oids;
+	map->u.oid40.oids_in_use = nr_files;
+	return 0;
+}
+
+/* helper function: spin lock allocator */
+static void
+lock(reiser4_oid_allocator * map)
+{
+	assert("nikita-1978", map != NULL);
+	spin_lock(&map->u.oid40.oguard);
+}
+
+/* helper function: spin unlock allocator */
+static void
+unlock(reiser4_oid_allocator * map)
+{
+	assert("nikita-1979", map != NULL);
+	spin_unlock(&map->u.oid40.oguard);
+}
+
+/* plugin->u.oid_allocator.oids_free
+   number of oids available for use by users */
+__u64 oid40_free(reiser4_oid_allocator * map)
+{
+	__u64 result;
+
+	assert("nikita-1980", map != NULL);
+
+	lock(map);
+	result = ABSOLUTE_MAX_OID - OIDS_RESERVED - map->u.oid40.next_to_use;
+	unlock(map);
+	return result;
+}
+
+/* plugin->u.oid_allocator.next_oid */
+__u64 oid40_next_oid(reiser4_oid_allocator * map)
+{
+	__u64 result;
+
+	assert("zam-601", map != NULL);
+
+	lock(map);
+	result = map->u.oid40.next_to_use;
+	unlock(map);
+
+	return result;
+}
+
+/* plugin->u.oid_allocator.oids_used
+   return number of user-visible oids already allocated in this map */
+__u64 oid40_used(reiser4_oid_allocator * map)
+{
+	__u64 result;
+
+	assert("nikita-1981", map != NULL);
+
+	lock(map);
+	result = map->u.oid40.oids_in_use;
+	unlock(map);
+	return result;
+}
+
+/* plugin->u.oid_allocator.allocate_oid
+   allocate new objectid in "map" and store it in "result". Return 0
+   on success, negative error code on failure. */
+int
+oid40_allocate(reiser4_oid_allocator * map, oid_t * result)
+{
+	assert("nikita-1982", map != NULL);
+
+	lock(map);
+	*result = map->u.oid40.next_to_use;
+	++map->u.oid40.next_to_use;
+	++map->u.oid40.oids_in_use;
+	ON_TRACE(TRACE_OIDS, "[%i]: allocated: %llx\n", current->pid, *result);
+	assert("nikita-1983", map->u.oid40.next_to_use >= map->u.oid40.oids_in_use);
+	unlock(map);
+	return 0;
+}
+
+/* plugin->u.oid_allocator.allocate_oid
+   release object id back to "map". */
+/* This never actually marks oid as free, oid "map" is 64 bits and right now
+   there is assumption that counter would never overflow */
+int
+oid40_release(reiser4_oid_allocator * map, oid_t oid UNUSED_ARG)
+{
+	assert("nikita-1984", map != NULL);	/* BIG BROTHER IS WATCHING YOU */
+
+	ON_TRACE(TRACE_OIDS, "[%i]: released: %llx\n", current->pid, oid);
+	lock(map);
+	assert("nikita-1985", map->u.oid40.oids_in_use > 0);
+	--map->u.oid40.oids_in_use;
+	assert("nikita-1986", map->u.oid40.next_to_use >= map->u.oid40.oids_in_use);
+	unlock(map);
+	return 0;
+}
+
+/* plugin->u.oid_allocator.reserve_allocate
+   how many pages to reserve in transaction for allocation of new objectid */
+/* This currently assumes that PAGE_SIZE equals blocksize */
+int
+oid40_reserve_allocate(reiser4_oid_allocator * map UNUSED_ARG)
+{
+	return 1;
+}
+
+/* plugin->u.oid_allocator.reserve_release
+   how many pages to reserve in transaction for freeing of an objectid */
+/* This currently assumes that PAGE_SIZE equals blocksize */
+int
+oid40_reserve_release(reiser4_oid_allocator * map UNUSED_ARG)
+{
+	return 1;
+}
+
+/* plugin->u.oid_allocator.print_info */
+void
+oid40_print_info(const char *prefix, reiser4_oid_allocator * map)
+{
+	lock(map);
+	printk("%s: next free objectid %lli, "
+	       "oids in use %llu\n", prefix, map->u.oid40.next_to_use, map->u.oid40.oids_in_use);
+	unlock(map);
+}
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   scroll-step: 1
+   End:
+*/
diff -puN /dev/null not-for-inclusion/yet_unneeded_abstractions/oid/oid40.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/yet_unneeded_abstractions/oid/oid40.h	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,57 @@
+/* Copyright 2002, 2003 by Hans Reiser, licensing governed by reiser4/README */
+
+/* In reiser4 we use 64 bit object ids. One can easily check that
+   given exponential growth in hardware speed and disk capacity,
+   amount of time required to exhaust 64 bit oid space is enough to
+   relax, and forget about oid reuse.
+
+   reiser 4.0 oid allocator is then simple counter incremented on each
+   oid allocation. Also counter of used oids is maintained, mainly for
+   statfs(2) sake.
+*/
+#ifndef __REISER4_OID40_H__
+#define __REISER4_OID40_H__
+
+#include "../../forward.h"
+#include "../../key.h"
+
+#include <linux/types.h>	/* for __u??  */
+#include <linux/spinlock.h>
+
+typedef struct {
+	/* spinlock serializing accesses to this structure. */
+	spinlock_t oguard;
+	/* greatest oid ever allocated plus one. This is increased on each oid
+	   allocation. */
+	oid_t next_to_use;
+	/* oids actually used. This is increased on each oid allocation, and
+	   decreased on each oid release.
+	   number of files, in short
+	*/
+	oid_t oids_in_use;
+} oid40_allocator;
+
+extern int oid40_read_allocator(reiser4_oid_allocator *, __u64 nr_files, __u64 oids);
+extern __u64 oid40_free(reiser4_oid_allocator *);
+extern __u64 oid40_next_oid(reiser4_oid_allocator *);
+extern __u64 oid40_used(reiser4_oid_allocator *);
+extern int oid40_allocate(reiser4_oid_allocator *, oid_t * result);
+extern int oid40_release(reiser4_oid_allocator *, oid_t oid);
+extern int oid40_reserve_allocate(reiser4_oid_allocator *);
+extern int oid40_reserve_release(reiser4_oid_allocator *);
+
+extern void oid40_print_info(const char *, reiser4_oid_allocator *);
+
+/* __REISER4_OID40_H__ */
+#endif
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   scroll-step: 1
+   End:
+*/
diff -puN /dev/null not-for-inclusion/yet_unneeded_abstractions/oid/oid.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/yet_unneeded_abstractions/oid/oid.c	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,172 @@
+/* Copyright 2001, 2002, 2003 by Hans Reiser, licensing governed by reiser4/README */
+
+/* VS-FIXME-HANS: replace this code with a few macros that go something like
+
+oid = sb->next_oid++; sb->nr_used_oids++;
+
+wherever you need to create files, and similar simplicity elsewhere.  Note that this code as currently written contains
+function dereferences, which are much worse for compilers than datastructure dereferences (am I wrong?)
+
+Make a great big comment out of the rest of this until the day that somebody actually needs the abstraction present
+here.  That day may happen, but it is not today.
+
+Please create a directory named as_yet_unneeded_abstractions, and after discussing it on reiserfs-dev so that people can
+comment, find and put this, and other code like this, in it.  Let us hope that maybe we can put 5% of reiser4 in it.;-)
+
+The objectives of this code were laudable, but sometimes code needs to be written before we can see what part of its
+complexity we can get by without.
+
+ */
+
+#include "../plugin.h"
+#include "../plugin_header.h"
+#include "../../debug.h"
+
+#include "../../super.h"
+#include "../../key.h"
+#include "../../txnmgr.h"
+
+#include <linux/types.h>	/* for __u??  */
+#include <linux/fs.h>		/* for struct super_block  */
+
+/* a wrapper for allocate_oid method of oid_allocator plugin */
+int
+oid_allocate(oid_t * oid)
+{
+	struct super_block *s = reiser4_get_current_sb();
+
+	reiser4_super_info_data *sbinfo = get_super_private(s);
+	oid_allocator_plugin *oplug;
+
+	assert("vs-479", sbinfo != NULL);
+	oplug = sbinfo->oid_plug;
+	assert("vs-480", oplug && oplug->allocate_oid);
+	return oplug->allocate_oid(get_oid_allocator(s), oid);
+}
+
+/* a wrapper for release_oid method of oid_allocator plugin */
+int
+oid_release(oid_t oid)
+{
+	struct super_block *s = reiser4_get_current_sb();
+
+	reiser4_super_info_data *sbinfo = get_super_private(s);
+	oid_allocator_plugin *oplug;
+
+	assert("nikita-1902", sbinfo != NULL);
+	oplug = sbinfo->oid_plug;
+	assert("nikita-1903", (oplug != NULL) && (oplug->release_oid != NULL));
+	return oplug->release_oid(get_oid_allocator(s), oid);
+}
+
+/* FIXME-ZAM: it is enough ugly but each operation of OID allocating/releasing
+   are split into two parts, allocating/releasing itself and counting it (or
+   logging). At OID allocation time an atom could not be available yet, but it
+   should be available after we modify at least one block. So, new OID is
+   allocated _before_ actual transaction begins, and this operations is
+   counted _after_ it.  An allocation of empty atom can be a solution which
+   has inefficiency in case of further atom fusion on first captured
+   block. The OID releasing operation is spilt just for symmetry */
+
+/* count an object allocation in atom's nr_objects_created when current atom
+   is available */
+void
+oid_count_allocated(void)
+{
+	txn_atom *atom;
+
+	atom = get_current_atom_locked();
+	atom->nr_objects_created++;
+	UNLOCK_ATOM(atom);
+}
+
+/* count an object deletion in atom's nr_objects_deleted */
+void
+oid_count_released(void)
+{
+	txn_atom *atom;
+
+	atom = get_current_atom_locked();
+	atom->nr_objects_deleted++;
+	UNLOCK_ATOM(atom);
+}
+
+__u64 oid_used(void)
+{
+	reiser4_super_info_data *sbinfo = get_current_super_private();
+
+	assert("zam-636", sbinfo != NULL);
+	assert("zam-598", sbinfo->oid_plug != NULL);
+	assert("zam-599", sbinfo->oid_plug->oids_used != NULL);
+
+	return sbinfo->oid_plug->oids_used(&sbinfo->oid_allocator);
+}
+
+__u64 oid_next(void)
+{
+	reiser4_super_info_data *sbinfo = get_current_super_private();
+
+	assert("zam-637", sbinfo != NULL);
+	assert("zam-638", sbinfo->oid_plug != NULL);
+	assert("zam-639", sbinfo->oid_plug->next_oid != NULL);
+
+	return sbinfo->oid_plug->next_oid(&sbinfo->oid_allocator);
+}
+
+int
+oid_init_allocator(const struct super_block *s, __u64 nr_files, __u64 oids)
+{
+	reiser4_super_info_data *sbinfo = get_super_private(s);
+
+	assert("zam-640", sbinfo != NULL);
+	assert("zam-641", sbinfo->oid_plug != NULL);
+	assert("zam-642", sbinfo->oid_plug->init_oid_allocator != NULL);
+
+	return sbinfo->oid_plug->init_oid_allocator(&sbinfo->oid_allocator, nr_files, oids);
+}
+
+#if REISER4_DEBUG_OUTPUT
+void
+oid_print_allocator(const char *prefix, const struct super_block *s)
+{
+	reiser4_super_info_data *sbinfo = get_super_private(s);
+
+	if (sbinfo->oid_plug && sbinfo->oid_plug->print_info)
+		sbinfo->oid_plug->print_info(prefix, &sbinfo->oid_allocator);
+	return;
+}
+#endif
+
+/* initialization of objectid management plugins */
+oid_allocator_plugin oid_plugins[LAST_OID_ALLOCATOR_ID] = {
+	[OID40_ALLOCATOR_ID] = {
+				.h = {
+				      .type_id = REISER4_OID_ALLOCATOR_PLUGIN_TYPE,
+				      .id = OID40_ALLOCATOR_ID,
+				      .pops = NULL,
+				      .label = "reiser40 default oid manager",
+				      .desc = "no reusing objectids",
+				      .linkage = TYPE_SAFE_LIST_LINK_ZERO,
+				      }
+				,
+				.init_oid_allocator = oid40_read_allocator,
+				.oids_used = oid40_used,
+				.next_oid = oid40_next_oid,
+				.oids_free = oid40_free,
+				.allocate_oid = oid40_allocate,
+				.release_oid = oid40_release,
+				.oid_reserve_allocate = oid40_reserve_allocate,
+				.oid_reserve_release = oid40_reserve_release,
+				.print_info = oid40_print_info}
+};
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   scroll-step: 1
+   End:
+*/
diff -puN /dev/null not-for-inclusion/yet_unneeded_abstractions/oid/oid.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/not-for-inclusion/yet_unneeded_abstractions/oid/oid.h	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,54 @@
+/* Copyright 2002, 2003 by Hans Reiser, licensing governed by reiser4/README */
+
+#ifndef __REISER4_OID_H__
+#define __REISER4_OID_H__
+
+#include "../../forward.h"
+#include "../../key.h"
+#include "oid40.h"
+
+#include <linux/fs.h>		/* for struct super_block */
+
+extern __u64 oid_used(void);
+extern __u64 oid_next(void);
+
+extern int oid_allocate(oid_t *);
+extern int oid_release(oid_t);
+
+extern void oid_count_allocated(void);
+extern void oid_count_released(void);
+
+extern int oid_init_allocator(const struct super_block *, __u64, __u64);
+#if REISER4_DEBUG_OUTPUT
+extern void oid_print_allocator(const char *prefix, const struct super_block *);
+#else
+#define oid_print_allocator(p,s) noop
+#endif
+
+/* identifiers of available objectid managers */
+typedef enum {
+	/* default for reiser 4.0 oid manager id */
+	OID40_ALLOCATOR_ID,
+	LAST_OID_ALLOCATOR_ID
+} oid_allocator_id;
+
+/* this object is part of reiser4 private in-core super block */
+struct reiser4_oid_allocator {
+	union {
+		oid40_allocator oid40;
+	} u;
+};
+
+/* __REISER4_OID_H__ */
+#endif
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   scroll-step: 1
+   End:
+*/
diff -puN page_cache.c~profile-stat-trace-repacker page_cache.c
--- reiser4/page_cache.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/page_cache.c	2005-02-01 12:06:07.000000000 +0300
@@ -286,6 +286,15 @@ done_formatted_fake(struct super_block *
 	return 0;
 }
 
+#if REISER4_LOG
+int reiser4_submit_bio_helper(const char *moniker, int rw, struct bio *bio)
+{
+	write_io_log(moniker, rw, bio);
+	submit_bio(rw, bio);
+	return 0;
+}
+#endif
+
 reiser4_internal void reiser4_wait_page_writeback (struct page * page)
 {
 	assert ("zam-783", PageLocked(page));
@@ -305,6 +314,63 @@ tree_by_page(const struct page *page /* 
 	return &get_super_private(page->mapping->host->i_sb)->tree;
 }
 
+#if REISER4_DEBUG_MEMCPY
+
+/* Our own versions of memcpy, memmove, and memset used to profile shifts of
+   tree node content. Coded to avoid inlining. */
+
+struct mem_ops_table {
+	void *(*cpy) (void *dest, const void *src, size_t n);
+	void *(*move) (void *dest, const void *src, size_t n);
+	void *(*set) (void *s, int c, size_t n);
+};
+
+void *
+xxmemcpy(void *dest, const void *src, size_t n)
+{
+	return memcpy(dest, src, n);
+}
+
+void *
+xxmemmove(void *dest, const void *src, size_t n)
+{
+	return memmove(dest, src, n);
+}
+
+void *
+xxmemset(void *s, int c, size_t n)
+{
+	return memset(s, c, n);
+}
+
+struct mem_ops_table std_mem_ops = {
+	.cpy = xxmemcpy,
+	.move = xxmemmove,
+	.set = xxmemset
+};
+
+struct mem_ops_table *mem_ops = &std_mem_ops;
+
+void *
+xmemcpy(void *dest, const void *src, size_t n)
+{
+	return mem_ops->cpy(dest, src, n);
+}
+
+void *
+xmemmove(void *dest, const void *src, size_t n)
+{
+	return mem_ops->move(dest, src, n);
+}
+
+void *
+xmemset(void *s, int c, size_t n)
+{
+	return mem_ops->set(s, c, n);
+}
+
+#endif
+
 /* completion handler for single page bio-based read.
 
    mpage_end_io_read() would also do. But it's static.
@@ -464,6 +530,9 @@ int set_page_dirty_internal (struct page
 	mapping = page->mapping;
 	BUG_ON(mapping == NULL);
 
+ 	if (REISER4_STATS && !PageDirty(page))
+ 		reiser4_stat_inc(pages_dirty);
+ 
 	if (!TestSetPageDirty(page)) {
 		if (!mapping->backing_dev_info->memory_backed)
 			inc_page_state(nr_dirty);
@@ -504,6 +573,8 @@ reiser4_writepage(struct page *page /* p
 	s = page->mapping->host->i_sb;
 	init_context(&ctx, s);
 
+	reiser4_stat_inc(pcwb.calls);
+
 	assert("vs-828", PageLocked(page));
 
 #if REISER4_USE_ENTD
@@ -535,17 +606,29 @@ reiser4_writepage(struct page *page /* p
 			if (!(atom->flags & ATOM_FORCE_COMMIT)) {
 				atom->flags |= ATOM_FORCE_COMMIT;
 				ktxnmgrd_kick(&get_super_private(s)->tmgr);
+				reiser4_stat_inc(txnmgr.commit_from_writepage);
 			}
 			UNLOCK_ATOM(atom);
 		}
 		UNLOCK_JNODE(node);
 
 		result = emergency_flush(page);
-		if (result == 0)
+		if (result != 0) {
+			/*
+			 * cannot flush page right now, or some error
+			 */
+			reiser4_stat_inc(pcwb.not_written);
+		} else {
+			/*
+			 * page was successfully flushed
+			 */
+			reiser4_stat_inc(pcwb.written);
 			if (phantom && jnode_is_unformatted(node))
 				JF_SET(node, JNODE_KEEPME);
+		}
 		jput(node);
 	} else {
+		reiser4_stat_inc(pcwb.no_jnode);
 		result = PTR_ERR(node);
 	}
 	if (result != 0) {
@@ -729,7 +812,7 @@ reiser4_invalidate_pages(struct address_
 }
 
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 
 #define page_flag_name( page, flag )			\
 	( test_bit( ( flag ), &( page ) -> flags ) ? ((#flag "|")+3) : "" )
diff -puN page_cache.h~profile-stat-trace-repacker page_cache.h
--- reiser4/page_cache.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/page_cache.h	2005-02-01 11:51:12.000000000 +0300
@@ -20,7 +20,15 @@ extern reiser4_tree *tree_by_page(const 
 
 extern int set_page_dirty_internal (struct page * page, int tag_as_moved);
 
+#if REISER4_LOG
+extern char *jnode_short_info(const jnode *j, char *buf);
+extern int reiser4_submit_bio_helper(const char *moniker,
+				     int rw, struct bio *bio);
+#define reiser4_submit_bio(rw, bio)				\
+	reiser4_submit_bio_helper(__FUNCTION__, (rw), (bio))
+#else
 #define reiser4_submit_bio(rw, bio) submit_bio((rw), (bio))
+#endif
 
 extern void reiser4_wait_page_writeback (struct page * page);
 static inline void lock_and_wait_page_writeback (struct page * page)
@@ -40,7 +48,7 @@ extern void capture_reiser4_inodes (stru
 
 #define PAGECACHE_TAG_REISER4_MOVED PAGECACHE_TAG_DIRTY
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 extern void print_page(const char *prefix, struct page *page);
 #else
 #define print_page(prf, p) noop
diff -puN plugin/compress/compress.c~profile-stat-trace-repacker plugin/compress/compress.c
--- reiser4/plugin/compress/compress.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/compress/compress.c	2005-02-01 11:51:12.000000000 +0300
@@ -35,7 +35,7 @@ null_compress(coa_t coa, __u8 * src_firs
 	assert("edward-797", dst_len != NULL);
 
 	for (i = 0; i < NONE_NRCOPY; i++)
-		memcpy(dst_first, src_first, src_len);
+		xmemcpy(dst_first, src_first, src_len);
 	*dst_len = src_len;
 	return;
 }
@@ -253,7 +253,7 @@ lzo1_alloc(tfm_action act)
 			ret = -ENOMEM;
 			break;
 		}
-		memset(coa, 0, LZO_HEAP_SIZE(LZO1X_1_MEM_COMPRESS));
+		xmemset(coa, 0, LZO_HEAP_SIZE(LZO1X_1_MEM_COMPRESS));
 	case TFM_READ:	/* decompress */
 		break;
 	default:
diff -puN plugin/cryptcompress.c~profile-stat-trace-repacker plugin/cryptcompress.c
--- reiser4/plugin/cryptcompress.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/cryptcompress.c	2005-02-01 11:51:12.000000000 +0300
@@ -59,6 +59,7 @@ int cut_file_items(struct inode *inode, 
 int delete_object(struct inode *inode, int mode);
 __u8 cluster_shift_by_coord(const coord_t * coord);
 int ctail_make_unprepped_cluster(reiser4_cluster_t * clust, struct inode * inode);
+unsigned long clust_by_coord(const coord_t * coord);
 int hint_is_set(const hint_t *hint);
 reiser4_plugin * get_default_plugin(pset_member memb);
 
@@ -79,7 +80,7 @@ init_inode_data_cryptcompress(struct ino
 	data = cryptcompress_inode_data(inode);
 	assert("edward-685", data != NULL);
 
-	memset(data, 0, sizeof (*data));
+	xmemset(data, 0, sizeof (*data));
 	
 	init_rwsem(&data->lock);
 	init_inode_ordering(inode, crd, create);
@@ -107,7 +108,7 @@ crc_inode_ok(struct inode * inode)
 }
 #endif
 
-static crypto_stat_t * inode_crypto_stat (struct inode * inode)
+reiser4_internal crypto_stat_t * inode_crypto_stat (struct inode * inode)
 {
 	assert("edward-90", inode != NULL);
 	assert("edward-91", reiser4_inode_data(inode) != NULL);
@@ -184,7 +185,7 @@ attach_crypto_stat(struct inode * inode,
 		reiser4_kfree(stat);
 		return -ENOMEM;
 	}
-	memcpy(txt, data->keyid, data->keyid_size);
+	xmemcpy(txt, data->keyid, data->keyid_size);
 	sg.page = virt_to_page (txt);
 	sg.offset = offset_in_page (txt);
 	sg.length = data->keyid_size;
@@ -222,7 +223,7 @@ init_default_crypto(crypto_data_t * data
 {
 	assert("edward-692", data != NULL);
 
-	memset(data, 0, sizeof(*data));
+	xmemset(data, 0, sizeof(*data));
 
 	data->cra = get_default_plugin(PSET_CRYPTO)->h.id;
 	data->dia = get_default_plugin(PSET_DIGEST)->h.id;
@@ -234,7 +235,7 @@ init_default_compression(compression_dat
 {
 	assert("edward-693", data != NULL);
 
-	memset(data, 0, sizeof(*data));
+	xmemset(data, 0, sizeof(*data));
 
 	data->coa = get_default_plugin(PSET_COMPRESSION)->h.id;
 }
@@ -435,8 +436,8 @@ destroy_inode_cryptcompress(struct inode
 }
 
 /* returns translated offset */
-static loff_t inode_scaled_offset (struct inode * inode,
-				   const loff_t src_off /* input offset */)
+reiser4_internal loff_t inode_scaled_offset (struct inode * inode,
+					     const loff_t src_off /* input offset */)
 {
 	assert("edward-97", inode != NULL);
 
@@ -457,8 +458,7 @@ inode_scaled_cluster_size (struct inode 
 }
 
 /* return true if the cluster contains specified page */
-#if 0
-static int
+reiser4_internal int
 page_of_cluster(struct page * page, reiser4_cluster_t * clust, struct inode * inode)
 {
 	assert("edward-162", page != NULL);
@@ -468,7 +468,6 @@ page_of_cluster(struct page * page, reis
 
 	return (pg_to_clust(page->index, inode) == clust->index);
 }
-#endif
 
 reiser4_internal int
 new_cluster(reiser4_cluster_t * clust, struct inode * inode)
@@ -725,7 +724,7 @@ free_reserved4cluster(struct inode * ino
 
 /* Search a disk cluster item.
    If result is not cbk_errored current znode is locked */
-static int
+reiser4_internal int
 find_cluster_item(hint_t * hint,            
 		  const reiser4_key *key,   /* key of next cluster item to read */
 		  int check_key,            /* 1, if the caller read/write items */
@@ -924,7 +923,7 @@ crypto_overhead(size_t len /* advised le
 
 /* maximal aligning overhead which can be appended
    to the flow before encryption if any */
-static unsigned
+reiser4_internal unsigned
 max_crypto_overhead(struct inode * inode)
 {
 	if (!inode_get_crypto(inode) || !inode_crypto_plugin(inode)->align_cluster)
@@ -932,7 +931,7 @@ max_crypto_overhead(struct inode * inode
 	return crypto_blocksize(inode);
 }
 
-static unsigned
+reiser4_internal unsigned
 compress_overhead(struct inode * inode, int in_len)
 {
 	return inode_compression_plugin(inode)->overrun(in_len);
@@ -995,7 +994,7 @@ static void set_compression_magic(__u8 *
 {
 	/* FIXME-EDWARD: Use a checksum here */
 	assert("edward-279", magic != NULL); 
-	memset(magic, 0, DC_CHECKSUM_SIZE);
+	xmemset(magic, 0, DC_CHECKSUM_SIZE);
 }
 
 reiser4_internal int
@@ -1413,6 +1412,16 @@ try_capture_cluster(reiser4_cluster_t * 
 	return 0;
 }
 
+reiser4_internal jnode *
+jnode_of_page_cluster(reiser4_cluster_t * clust)
+{
+	assert("edward-916", clust != NULL);
+	assert("edward-917", clust->pages != NULL);
+	assert("edward-918", clust->nr_pages != 0);	
+
+	return jnode_of_page(clust->pages[0]);
+}
+
 /* Collect unlocked cluster pages and jnode */
 static int
 grab_cluster_pages_jnode(struct inode * inode, reiser4_cluster_t * clust)
@@ -1645,7 +1654,7 @@ update_sd_cryptcompress(struct inode *in
 	return result;
 }
 
-static void
+reiser4_internal void
 uncapture_cluster_jnode(jnode *node)
 {
 	txn_atom *atom;
@@ -1762,8 +1771,8 @@ struct inode * inode)
 		
 		assert("edward-986", off_to_pgcount(tc->len, i) != 0);
 
-		memcpy(tfm_stream_data(tc, INPUT_STREAM) + pg_to_off(i), 
-		       data, off_to_pgcount(tc->len, i));
+		xmemcpy(tfm_stream_data(tc, INPUT_STREAM) + pg_to_off(i), 
+			data, off_to_pgcount(tc->len, i));
 		kunmap(clust->pages[i]);
 		unlock_page(clust->pages[i]);
 		if (i)
@@ -1866,7 +1875,7 @@ write_hole(struct inode *inode, reiser4_
 		to_pg = min_count(PAGE_CACHE_SIZE - pg_off, cl_count);
 		lock_page(page);
 		data = kmap_atomic(page, KM_USER0);
-		memset(data + pg_off, 0, to_pg);
+		xmemset(data + pg_off, 0, to_pg);
 		flush_dcache_page(page);
 		kunmap_atomic(data, KM_USER0);
 		SetPageUptodate(page);
@@ -3234,6 +3243,10 @@ capture_anonymous_clusters(struct addres
 		if (to_capture == 0)
 			/* there may be left more pages */
 			redirty_inode(mapping->host);
+		
+		ON_TRACE(TRACE_CAPTURE_ANONYMOUS,
+			 "capture anonymous: oid %llu: end index %lu, captured %u\n",
+			 get_inode_oid(mapping->host), *index, CAPTURE_APAGE_BURST - to_capture);
 	}
  out:
 	done_lh(&lh);
@@ -3454,7 +3467,7 @@ save_len_cryptcompress_plugin(struct ino
 	return 0;
 }
 
-static int
+reiser4_internal int
 load_cryptcompress_plugin(struct inode * inode, reiser4_plugin * plugin, char **area, int *len)
 {
 	assert("edward-455", inode != NULL);
diff -puN plugin/cryptcompress.h~profile-stat-trace-repacker plugin/cryptcompress.h
--- reiser4/plugin/cryptcompress.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/cryptcompress.h	2005-02-01 11:51:12.000000000 +0300
@@ -71,7 +71,7 @@ alloc_ts(tfm_stream_t ** stm)
 	*stm = reiser4_kmalloc(sizeof ** stm, GFP_KERNEL);
 	if (*stm == NULL)
 		return -ENOMEM;
-	memset(*stm, 0, sizeof ** stm);
+	xmemset(*stm, 0, sizeof ** stm);
 	return 0;
 }
 
@@ -223,7 +223,7 @@ alloc_tfm_stream(tfm_cluster_t * tc, siz
 	tc->tun[id] = reiser4_kmalloc(sizeof(tfm_stream_t), GFP_KERNEL);
 	if (!tc->tun[id])
 		return -ENOMEM;
-	memset(tfm_stream(tc, id), 0, sizeof(tfm_stream_t));
+	xmemset(tfm_stream(tc, id), 0, sizeof(tfm_stream_t));
 	return alloc_ts_data(tfm_stream(tc, id), size);
 }
 
@@ -375,7 +375,7 @@ static inline void
 reset_cluster_pgset(reiser4_cluster_t * clust, int nrpages)
 {
 	assert("edward-1057", clust->pages != NULL);
-	memset(clust->pages, 0, sizeof(*clust->pages) * nrpages);
+	xmemset(clust->pages, 0, sizeof(*clust->pages) * nrpages);
 }
 
 static inline int
@@ -406,7 +406,7 @@ put_cluster_handle(reiser4_cluster_t * c
 	put_tfm_cluster(&clust->tc, act);
 	if (clust->pages)
 		free_cluster_pgset(clust);
-	memset(clust, 0, sizeof *clust);
+	xmemset(clust, 0, sizeof *clust);
 }
 
 /* security attributes supposed to be stored on disk
@@ -425,6 +425,7 @@ typedef struct cryptcompress_info {
 
 cryptcompress_info_t *cryptcompress_inode_data(const struct inode * inode);
 int equal_to_rdk(znode *, const reiser4_key *);
+int equal_to_ldk(znode *, const reiser4_key *);
 int goto_right_neighbor(coord_t *, lock_handle *);
 int load_file_hint(struct file *, hint_t *);
 void save_file_hint(struct file *, const hint_t *);
diff -puN plugin/dir/dir.c~profile-stat-trace-repacker plugin/dir/dir.c
--- reiser4/plugin/dir/dir.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/dir/dir.c	2005-02-01 11:51:12.000000000 +0300
@@ -120,7 +120,7 @@ link_common(struct inode *parent /* pare
 
 	parent_dplug = inode_dir_plugin(parent);
 
-	memset(&entry, 0, sizeof entry);
+	xmemset(&entry, 0, sizeof entry);
 	entry.obj = object;
 
 	data.mode = object->i_mode;
@@ -270,7 +270,7 @@ unlink_common(struct inode *parent /* pa
 		reiser4_dir_entry_desc entry;
 
 		parent_dplug = inode_dir_plugin(parent);
-		memset(&entry, 0, sizeof entry);
+		xmemset(&entry, 0, sizeof entry);
 
 		/* first, delete directory entry */
 		result = parent_dplug->rem_entry(parent, victim, &entry);
@@ -412,7 +412,7 @@ create_child_common(reiser4_object_creat
 		return RETERR(-EDQUOT);
 	}
 
-	memset(&entry, 0, sizeof entry);
+	xmemset(&entry, 0, sizeof entry);
 	entry.obj = object;
 
 	plugin_set_file(&reiser4_inode_data(object)->pset, obj_plug);
@@ -597,7 +597,7 @@ is_dir_empty(const struct inode *dir)
 }
 
 /* compare two logical positions within the same directory */
-static cmp_t dir_pos_cmp(const dir_pos * p1, const dir_pos * p2)
+reiser4_internal cmp_t dir_pos_cmp(const dir_pos * p1, const dir_pos * p2)
 {
 	cmp_t result;
 
@@ -654,6 +654,15 @@ adjust_dir_pos(struct file   * dir,
 	 * is currently positioned at @readdir_spot. Latter has to be updated
 	 * to maintain stable readdir.
 	 */
+
+	ON_TRACE(TRACE_DIR, "adjust: %s/%i",
+		 dir ? (char *)dir->f_dentry->d_name.name : "(anon)", adj);
+	ON_TRACE(TRACE_DIR, "\nf_pos: %llu, spot.fpos: %llu entry_no: %llu\n",
+		 dir ? dir->f_pos : 0, readdir_spot->fpos,
+		 readdir_spot->entry_no);
+
+	reiser4_stat_inc(dir.readdir.adjust_pos);
+
 	/* directory is positioned to the beginning. */
 	if (readdir_spot->entry_no == 0)
 		return;
@@ -679,9 +688,11 @@ adjust_dir_pos(struct file   * dir,
 			 */
 			pos->pos += adj;
 		}
+		reiser4_stat_inc(dir.readdir.adjust_lt);
 		break;
 	case GREATER_THAN:
 		/* directory is modified after @pos: nothing to do. */
+		reiser4_stat_inc(dir.readdir.adjust_gt);
 		break;
 	case EQUAL_TO:
 		/* cannot insert an entry readdir is looking at, because it
@@ -699,7 +710,8 @@ adjust_dir_pos(struct file   * dir,
 
 		   NOTE-NIKITA: now, semaphore is used, so...
 		*/
-		memset(readdir_spot, 0, sizeof *readdir_spot);
+		xmemset(readdir_spot, 0, sizeof *readdir_spot);
+		reiser4_stat_inc(dir.readdir.adjust_eq);
 	}
 }
 
@@ -850,7 +862,8 @@ dir_rewind(struct file *dir, readdir_pos
 		return RETERR(-EINVAL);
 	else if (destination == 0ll || dirpos == 0) {
 		/* rewind to the beginning of directory */
-		memset(pos, 0, sizeof *pos);
+		xmemset(pos, 0, sizeof *pos);
+		reiser4_stat_inc(dir.readdir.reset);
 		return dir_go_to(dir, pos, tap);
 	} else if (destination >= inode->i_size)
 		return RETERR(-ENOENT);
@@ -859,9 +872,11 @@ dir_rewind(struct file *dir, readdir_pos
 		/* I am afraid of negative numbers */
 		shift = -shift;
 		/* rewinding to the left */
+		reiser4_stat_inc(dir.readdir.rewind_left);
 		if (shift <= (int) pos->position.pos) {
 			/* destination is within sequence of entries with
 			   duplicate keys. */
+			reiser4_stat_inc(dir.readdir.left_non_uniq);
 			result = dir_go_to(dir, pos, tap);
 		} else {
 			shift -= pos->position.pos;
@@ -873,6 +888,7 @@ dir_rewind(struct file *dir, readdir_pos
 					result = rewind_left(tap, shift);
 					if (result == -E_DEADLOCK) {
 						tap_done(tap);
+						reiser4_stat_inc(dir.readdir.left_restart);
 						continue;
 					}
 				}
@@ -881,6 +897,7 @@ dir_rewind(struct file *dir, readdir_pos
 		}
 	} else {
 		/* rewinding to the right */
+		reiser4_stat_inc(dir.readdir.rewind_right);
 		result = dir_go_to(dir, pos, tap);
 		if (result == 0)
 			result = rewind_right(tap, shift);
@@ -953,6 +970,9 @@ feed_entry(struct file *f,
 
 	longterm_unlock_znode(tap->lh);
 
+	ON_TRACE(TRACE_DIR | TRACE_VFS_OPS, "readdir: %s, %llu, %llu, %llu\n",
+		 name, pos->fpos, pos->entry_no, get_key_objectid(&sd_key));
+
 	/*
 	 * send information about directory entry to the ->filldir() filler
 	 * supplied to us by caller (VFS).
@@ -1103,7 +1123,7 @@ static void kill_cursor(dir_cursor *curs
  * shrink d_cursors cache. Scan LRU list of unused cursors, freeing requested
  * number. Return number of still freeable cursors.
  */
-static int d_cursor_shrink(int nr, unsigned int gfp_mask)
+int d_cursor_shrink(int nr, unsigned int gfp_mask)
 {
 	if (nr != 0) {
 		dir_cursor *scan;
@@ -1178,7 +1198,7 @@ d_cursor_init_at(struct super_block *s)
 	p = &get_super_private(s)->d_info;
 
 	INIT_RADIX_TREE(&p->tree, GFP_KERNEL);
-	return d_cursor_hash_init(&p->table, D_CURSOR_TABLE_SIZE);
+	return d_cursor_hash_init(&p->table, D_CURSOR_TABLE_SIZE, NULL);
 }
 
 /*
@@ -1413,7 +1433,7 @@ insert_cursor(dir_cursor *cursor, struct
 	int                  result;
 	reiser4_file_fsdata *fsdata;
 
-	memset(cursor, 0, sizeof *cursor);
+	xmemset(cursor, 0, sizeof *cursor);
 
 	/* this is either first call to readdir, or rewind. Anyway, create new
 	 * cursor. */
@@ -1564,6 +1584,9 @@ dir_readdir_init(struct file *f, tap_t *
 	*pos = &fsdata->dir.readdir;
 	spin_unlock_inode(inode);
 
+	ON_TRACE(TRACE_DIR, " fpos: %llu entry_no: %llu\n",
+		 (*pos)->entry_no, (*pos)->fpos);
+
 	/* move @tap to the current position */
 	return dir_rewind(f, *pos, tap);
 }
@@ -1618,6 +1641,8 @@ readdir_common(struct file *f /* directo
 	inode = f->f_dentry->d_inode;
 	assert("nikita-1360", inode != NULL);
 
+	reiser4_stat_inc(dir.readdir.calls);
+
 	if (!S_ISDIR(inode->i_mode))
 		return RETERR(-ENOTDIR);
 
@@ -1627,6 +1652,10 @@ readdir_common(struct file *f /* directo
 
 	reiser4_readdir_readahead_init(inode, &tap);
 
+	ON_TRACE(TRACE_DIR | TRACE_VFS_OPS,
+		 "readdir: inode: %llu offset: %#llx\n",
+		 get_inode_oid(inode), f->f_pos);
+
  repeat:
 	result = dir_readdir_init(f, &tap, &pos);
 	if (result == 0) {
@@ -1640,6 +1669,8 @@ readdir_common(struct file *f /* directo
 			assert("nikita-3227", is_valid_dir_coord(inode, coord));
 
 			result = feed_entry(f, pos, &tap, filld, dirent);
+			ON_TRACE(TRACE_DIR | TRACE_VFS_OPS,
+				 "readdir: entry: offset: %#llx\n", f->f_pos);
 			if (result > 0) {
 				break;
 			} else if (result == 0) {
@@ -1672,6 +1703,8 @@ readdir_common(struct file *f /* directo
 	} else if (result == -E_NO_NEIGHBOR || result == -ENOENT)
 		result = 0;
 	tap_done(&tap);
+	ON_TRACE(TRACE_DIR | TRACE_VFS_OPS,
+		 "readdir_exit: offset: %#llx\n", f->f_pos);
 	detach_fsdata(f);
 	return (result <= 0) ? result : 0;
 }
@@ -1687,6 +1720,8 @@ seek_dir(struct file *file, loff_t off, 
 	struct inode *inode;
 
 	inode = file->f_dentry->d_inode;
+	ON_TRACE(TRACE_DIR | TRACE_VFS_OPS, "seek_dir: %s: %lli -> %lli/%i\n",
+		 file->f_dentry->d_name.name, file->f_pos, off, origin);
 	down(&inode->i_sem);
 
 	/* update ->f_pos */
diff -puN plugin/dir/hashed_dir.c~profile-stat-trace-repacker plugin/dir/hashed_dir.c
--- reiser4/plugin/dir/hashed_dir.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/dir/hashed_dir.c	2005-02-01 11:51:12.000000000 +0300
@@ -59,7 +59,7 @@ static int find_entry(struct inode *dir,
 static int check_item(const struct inode *dir,
 		      const coord_t * coord, const char *name);
 
-static reiser4_block_nr
+reiser4_internal reiser4_block_nr
 hashed_estimate_init(struct inode *parent, struct inode *object)
 {
 	reiser4_block_nr res = 0;
@@ -99,6 +99,7 @@ init_hashed(struct inode *object /* new 
 	assert("nikita-684", data != NULL);
 	assert("nikita-686", data->id == DIRECTORY_FILE_PLUGIN_ID);
 	assert("nikita-687", object->i_mode & S_IFDIR);
+	trace_stamp(TRACE_DIR);
 
 	reserve = hashed_estimate_init(parent, object);
 	if (reiser4_grab_space(reserve, BA_CAN_COMMIT))
@@ -150,7 +151,7 @@ done_hashed(struct inode *object /* obje
 
 	/* of course, this can be rewritten to sweep everything in one
 	   cut_tree(). */
-	memset(&entry, 0, sizeof entry);
+	xmemset(&entry, 0, sizeof entry);
 
 	/* FIXME: this done method is called from delete_directory_common which
 	 * reserved space already */
@@ -158,7 +159,7 @@ done_hashed(struct inode *object /* obje
 	if (reiser4_grab_space(reserve, BA_CAN_COMMIT | BA_RESERVED))
 		return RETERR(-ENOSPC);
 
-	memset(&goodby_dots, 0, sizeof goodby_dots);
+	xmemset(&goodby_dots, 0, sizeof goodby_dots);
 	entry.obj = goodby_dots.d_inode = object;
 	goodby_dots.d_name.name = ".";
 	goodby_dots.d_name.len = 1;
@@ -189,12 +190,12 @@ detach_hashed(struct inode *object, stru
 	assert("nikita-2885", object != NULL);
 	assert("nikita-2886", !inode_get_flag(object, REISER4_NO_SD));
 
-	memset(&entry, 0, sizeof entry);
+	xmemset(&entry, 0, sizeof entry);
 
 	/* NOTE-NIKITA this only works if @parent is -the- parent of
 	   @object, viz. object whose key is stored in dotdot
 	   entry. Wouldn't work with hard-links on directories. */
-	memset(&goodby_dots, 0, sizeof goodby_dots);
+	xmemset(&goodby_dots, 0, sizeof goodby_dots);
 	entry.obj = goodby_dots.d_inode = parent;
 	goodby_dots.d_name.name = "..";
 	goodby_dots.d_name.len = 2;
@@ -247,6 +248,7 @@ create_dot_dotdot(struct inode *object	/
 	assert("nikita-688", object != NULL);
 	assert("nikita-689", S_ISDIR(object->i_mode));
 	assert("nikita-691", parent != NULL);
+	trace_stamp(TRACE_DIR);
 
 	/* We store dot and dotdot as normal directory entries. This is
 	   not necessary, because almost all information stored in them
@@ -263,8 +265,8 @@ create_dot_dotdot(struct inode *object	/
 
 	*/
 
-	memset(&entry, 0, sizeof entry);
-	memset(&dots_entry, 0, sizeof dots_entry);
+	xmemset(&entry, 0, sizeof entry);
+	xmemset(&dots_entry, 0, sizeof dots_entry);
 	entry.obj = dots_entry.d_inode = object;
 	dots_entry.d_name.name = ".";
 	dots_entry.d_name.len = 1;
@@ -347,6 +349,8 @@ lookup_name_hashed(struct inode *parent 
 	coord_clear_iplug(coord);
 	init_lh(&lh);
 
+	ON_TRACE(TRACE_DIR | TRACE_VFS_OPS, "lookup inode: %lli \"%s\"\n", get_inode_oid(parent), dentry->d_name.name);
+
 	/* find entry in a directory. This is plugin method. */
 	result = find_entry(parent, dentry, &lh, ZNODE_READ_LOCK, &entry);
 	if (result == 0) {
@@ -540,6 +544,7 @@ replace_name(struct inode *to_inode	/* i
 		from_dir->i_mtime = CURRENT_TIME;
 	} else {
 		warning("nikita-2326", "Unexpected item type");
+		print_plugin("item", item_plugin_to_plugin(from_item));
 		result = RETERR(-EIO);
 	}
 	zrelse(node);
@@ -564,7 +569,7 @@ add_name(struct inode *inode	/* inode wh
 	assert("nikita-2333", lh->node == coord->node);
 	assert("nikita-2334", is_dir == S_ISDIR(inode->i_mode));
 
-	memset(&entry, 0, sizeof entry);
+	xmemset(&entry, 0, sizeof entry);
 	entry.obj = inode;
 	/* build key of directory entry description */
 	inode_dir_plugin(dir)->build_entry_key(dir, &name->d_name, &entry.key);
@@ -954,7 +959,7 @@ rename_hashed(struct inode *old_dir /* d
 		reiser4_mark_inode_dirty(new_inode);
 
 	if (result == 0) {
-		memset(&old_entry, 0, sizeof old_entry);
+		xmemset(&old_entry, 0, sizeof old_entry);
 		old_entry.obj = old_inode;
 
 		dplug->build_entry_key(old_dir,
@@ -989,10 +994,10 @@ rename_hashed(struct inode *old_dir /* d
 			reiser4_dentry_fsdata  dataonstack;
 			reiser4_dentry_fsdata *fsdata;
 
-			memset(&dataonstack, 0, sizeof dataonstack);
-			memset(&dotdot_entry, 0, sizeof dotdot_entry);
+			xmemset(&dataonstack, 0, sizeof dataonstack);
+			xmemset(&dotdot_entry, 0, sizeof dotdot_entry);
 			dotdot_entry.obj = old_dir;
-			memset(&dotdot_name, 0, sizeof dotdot_name);
+			xmemset(&dotdot_name, 0, sizeof dotdot_name);
 			dotdot_name.d_name.name = "..";
 			dotdot_name.d_name.len = 2;
 			/*
@@ -1070,6 +1075,7 @@ add_entry_hashed(struct inode *object	/*
 		return RETERR(-ENOSPC);
 
 	init_lh(&lh);
+	ON_TRACE(TRACE_DIR, "[%i]: creating \"%s\" in %llu\n", current->pid, where->d_name.name, get_inode_oid(object));
 	coord = &fsdata->dec.entry_coord;
 	coord_clear_iplug(coord);
 
@@ -1179,7 +1185,12 @@ rem_entry_hashed(struct inode *object	/*
 					(unsigned long long)get_inode_oid(object));
 				result = RETERR(-EIO);
 			}
-
+			write_current_logf(WRITE_TREE_LOG,
+					   "..de k %#llx %#llx %i %lli",
+					   get_inode_oid(where->d_inode),
+					   get_inode_oid(object),
+					   where->d_inode->i_nlink,
+					   where->d_inode->i_size);
 			assert("nikita-3405", where->d_inode->i_nlink != 1 ||
 			       where->d_inode->i_size != 2 ||
 			       inode_dir_plugin(where->d_inode) == NULL);
@@ -1436,10 +1447,14 @@ check_item(const struct inode *dir, cons
  		   directory is built of */
  		warning("nikita-1136", "Wrong item plugin");
  		print_coord("coord", coord, 1);
+ 		print_plugin("plugin", item_plugin_to_plugin(iplug));
  		return RETERR(-EIO);
  	}
 	assert("nikita-1137", iplug->s.dir.extract_name);
 
+	ON_TRACE(TRACE_DIR, "[%i]: check_item: \"%s\", \"%s\" in %lli (%lli)\n",
+		 current->pid, name, iplug->s.dir.extract_name(coord, buf),
+		 get_inode_oid(dir), *znode_get_block(coord->node));
 	/* Compare name stored in this entry with name we are looking for.
 
 	   NOTE-NIKITA Here should go code for support of something like
diff -puN plugin/disk_format/disk_format40.c~profile-stat-trace-repacker plugin/disk_format/disk_format40.c
--- reiser4/plugin/disk_format/disk_format40.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/disk_format/disk_format40.c	2005-02-01 11:51:12.000000000 +0300
@@ -12,6 +12,7 @@
 #include "../../tree.h"
 #include "../../super.h"
 #include "../../wander.h"
+#include "../../diskmap.h"
 #include "../../inode.h"
 #include "../../ktxnmgrd.h"
 #include "../../status_flags.h"
@@ -275,7 +276,7 @@ try_init_format40(struct super_block *s,
 		return PTR_ERR(super_bh);
 	*stage = READ_SUPER;
 
-	memcpy(sb_copy, ((format40_disk_super_block *) super_bh->b_data), sizeof (*sb_copy));
+	xmemcpy(sb_copy, ((format40_disk_super_block *) super_bh->b_data), sizeof (*sb_copy));
 	brelse(super_bh);
 
 	if (!equi(REISER4_LARGE_KEY,
@@ -458,6 +459,10 @@ release_format40(struct super_block *s)
 
 		all_grabbed2free();
 	}
+	if (reiser4_is_debugged(s, REISER4_STATS_ON_UMOUNT))
+		print_fs_info("umount ok", s);
+
+	/*done_tree(&sbinfo->tree);*/
 
 	sa_destroy_allocator(&sbinfo->space_allocator, s);
 	done_journal_info(s);
diff -puN plugin/file/file.c~profile-stat-trace-repacker plugin/file/file.c
--- reiser4/plugin/file/file.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/file/file.c	2005-02-01 12:02:08.000000000 +0300
@@ -8,6 +8,7 @@
 #include "../../page_cache.h"
 #include "../../ioctl.h"
 #include "../object.h"
+#include "../../prof.h"
 #include "../../safe_link.h"
 #include "funcs.h"
 
@@ -35,35 +36,31 @@ file_is_built_of_tails(const struct inod
 	return unix_file_inode_data(inode)->container == UF_CONTAINER_TAILS;
 }
 
-#if REISER4_DEBUG
-
-static int
+reiser4_internal int
 file_is_built_of_extents(const struct inode *inode)
 {
 	return unix_file_inode_data(inode)->container == UF_CONTAINER_EXTENTS;
 }
 
-static int
+reiser4_internal int
 file_is_empty(const struct inode *inode)
 {
 	return unix_file_inode_data(inode)->container == UF_CONTAINER_EMPTY;
 }
 
-#endif
-
-static int
+reiser4_internal int
 file_state_is_unknown(const struct inode *inode)
 {
 	return unix_file_inode_data(inode)->container == UF_CONTAINER_UNKNOWN;
 }
 
-static void
+reiser4_internal void
 set_file_state_extents(struct inode *inode)
 {
 	unix_file_inode_data(inode)->container = UF_CONTAINER_EXTENTS;
 }
 
-static void
+reiser4_internal void
 set_file_state_tails(struct inode *inode)
 {
 	unix_file_inode_data(inode)->container = UF_CONTAINER_TAILS;
@@ -80,7 +77,6 @@ set_file_state_unknown(struct inode *ino
 {
 	unix_file_inode_data(inode)->container = UF_CONTAINER_UNKNOWN;
 }
-
 static int
 less_than_ldk(znode *node, const reiser4_key *key)
 {
@@ -101,7 +97,7 @@ less_than_rdk(znode *node, const reiser4
 	return UNDER_RW(dk, current_tree, read, keylt(key, znode_get_rd_key(node)));
 }
 
-static int
+int
 equal_to_ldk(znode *node, const reiser4_key *key)
 {
 	return UNDER_RW(dk, current_tree, read, keyeq(key, znode_get_ld_key(node)));
@@ -151,8 +147,7 @@ check_coord(const coord_t *coord, const 
 
 #endif /* REISER4_DEBUG */
 
-static void
-init_uf_coord(uf_coord_t *uf_coord, lock_handle *lh)
+void init_uf_coord(uf_coord_t *uf_coord, lock_handle *lh)
 {
 	coord_init_zero(&uf_coord->base_coord);
         coord_clear_iplug(&uf_coord->base_coord);
@@ -163,6 +158,13 @@ init_uf_coord(uf_coord_t *uf_coord, lock
 }
 
 static inline void
+invalidate_extended_coord(uf_coord_t *uf_coord)
+{
+        coord_clear_iplug(&uf_coord->base_coord);
+	uf_coord->valid = 0;
+}
+
+static inline void
 validate_extended_coord(uf_coord_t *uf_coord, loff_t offset)
 {
 	assert("vs-1333", uf_coord->valid == 0);
@@ -332,6 +334,9 @@ find_file_item(hint_t *hint, /* coord, l
 	assert("nikita-3030", schedulable());
 	assert("vs-1707", hint != NULL);
 
+	/* collect statistics on the number of calls to this function */
+	reiser4_stat_inc(file.find_file_item);
+
 	coord = &hint->coord.base_coord;
 	lh = hint->coord.lh;
 	init_lh(lh);
@@ -348,12 +353,18 @@ find_file_item(hint_t *hint, /* coord, l
 			/* we moved to different node. Invalidate coord extension, zload is necessary to init it
 			   again */
 			hint->coord.valid = 0;
+			reiser4_stat_inc(file.find_file_item_via_right_neighbor);
+		} else {
+			reiser4_stat_inc(file.find_file_item_via_seal);
 		}
 		
 		set_file_state(inode, CBK_COORD_FOUND, znode_get_level(coord->node));
 		return CBK_COORD_FOUND;
 	}
 
+	/* collect statistics on the number of calls to this function which did not get optimized */
+	reiser4_stat_inc(file.find_file_item_via_cbk);
+
 	coord_init_zero(coord);
 	cbk_flags = (lock_mode == ZNODE_READ_LOCK) ? CBK_UNIQUE : (CBK_UNIQUE | CBK_FOR_INSERT);
 	if (inode != NULL) {
@@ -408,7 +419,7 @@ find_file_item_nohint(coord_t *coord, lo
 reiser4_internal void
 hint_init_zero(hint_t *hint)
 {
-	memset(hint, 0, sizeof (*hint));
+	xmemset(hint, 0, sizeof (*hint));
 }
 
 /* find position of last byte of last item of the file plus 1. This is used by truncate and mmap to find real file
@@ -733,7 +744,7 @@ load_file_hint(struct file *file, hint_t
 			hint->coord.valid = 0;
 			return 0;
 		}
-		memset(&fsdata->reg.hint, 0, sizeof(hint_t));
+		xmemset(&fsdata->reg.hint, 0, sizeof(hint_t));
 	}
 	hint_init_zero(hint);
 	return 0;
@@ -826,6 +837,8 @@ find_or_create_extent(struct page *page)
 	znode *loaded;
 	struct inode *inode;
 
+	reiser4_stat_inc(file.page_ops.writepage_calls);
+
 	assert("vs-1065", page->mapping && page->mapping->host);
 	inode = page->mapping->host;
 
@@ -1000,7 +1013,6 @@ capture_anonymous_page(struct page *pg, 
 	return result;
 }
 
-
 #define CAPTURE_APAGE_BURST      (1024l)
 
 /* look for pages tagged REISER4_MOVED starting from the index-th page, return
@@ -1017,12 +1029,20 @@ capture_anonymous_pages(struct address_s
 	int i;
 	int nr;
 
+	ON_TRACE(TRACE_CAPTURE_ANONYMOUS,
+		 "capture anonymous: oid %llu: start index %lu\n",
+		 get_inode_oid(mapping->host), *index);
+
 	pagevec_init(&pvec, 0);	
 	count = min(pagevec_space(&pvec), (unsigned)to_capture);
 	nr = 0;
 
 	found_pages = pagevec_lookup_tag(&pvec, mapping, index, PAGECACHE_TAG_REISER4_MOVED, count);
 	if (found_pages != 0) {
+		ON_TRACE(TRACE_CAPTURE_ANONYMOUS,
+			 "oid %llu: found %u moved pages\n",
+			 get_inode_oid(mapping->host), found_pages);
+		
 		for (i = 0; i < pagevec_count(&pvec); i ++) {
 			/* tag PAGECACHE_TAG_REISER4_MOVED will be cleared by
 			   set_page_dirty_internal which is called when jnode
@@ -1097,6 +1117,9 @@ capture_anonymous_jnodes(struct address_
 	}
        
 	/* there are anonymous jnodes from given range */
+	ON_TRACE(TRACE_CAPTURE_ANONYMOUS,
+		 "oid %llu: found %u anonymous jnodes in range (%lu %lu)\n",
+		 get_inode_oid(mapping->host), found_jnodes, *from, to - 1);
 	
 	/* start i/o for eflushed nodes */
 	for (i = 0; i < found_jnodes; i ++)
@@ -1471,11 +1494,18 @@ readpage_unix_file(void *vp, struct page
 	coord_t *coord;
 	struct file *file;
 
+	reiser4_stat_inc(file.page_ops.readpage_calls);
+
 	assert("vs-1062", PageLocked(page));
 	assert("vs-1061", page->mapping && page->mapping->host);
 	assert("vs-1078", (page->mapping->host->i_size > ((loff_t) page->index << PAGE_CACHE_SHIFT)));
 
 	inode = page->mapping->host;
+
+	ON_TRACE(TRACE_UNIX_FILE_OPS,
+		 "readpage: inode: %llu, page: %lu\n",
+		 get_inode_oid(inode), page->index);
+
 	file = vp;
 	result = load_file_hint(file, &hint);
 	if (result)
@@ -1974,7 +2004,16 @@ write_flow(hint_t *hint, struct file *fi
 	return append_and_or_overwrite(hint, file, inode, &flow, exclusive);
 }
 
-static struct page *
+reiser4_internal void
+drop_access(unix_file_info_t *uf_info)
+{
+	if (uf_info->exclusive_use)
+		drop_exclusive_access(uf_info);
+	else
+		drop_nonexclusive_access(uf_info);
+}
+
+reiser4_internal struct page *
 unix_file_filemap_nopage(struct vm_area_struct *area, unsigned long address, int * unused)
 {
 	struct page *page;
@@ -1984,6 +2023,10 @@ unix_file_filemap_nopage(struct vm_area_
 	inode = area->vm_file->f_dentry->d_inode;
 	init_context(&ctx, inode->i_sb);
 
+	ON_TRACE(TRACE_UNIX_FILE_OPS,
+		 "filemap_nopage: inode: %llu, address: %p\n",
+		 get_inode_oid(inode), (void *)address);
+
 	/* block filemap_nopage if copy on capture is processing with a node of this file */
 	down_read(&reiser4_inode_data(inode)->coc_sem);
 	/* second argument is to note that current atom may exist */
@@ -1996,6 +2039,11 @@ unix_file_filemap_nopage(struct vm_area_
 
 	/*txn_restart_current();*/
 
+	ON_TRACE(TRACE_UNIX_FILE_OPS,
+		 "filemap_nopage: inode: %llu, index: %lu\n",
+		 get_inode_oid(inode),
+		 (page != NULL && page != NOPAGE_OOM) ? page->index : 0);
+
 	reiser4_exit_context(&ctx);
 	return page;
 }
@@ -2129,6 +2177,9 @@ write_unix_file(struct file *file, /* fi
 	int user_space;
 	int try_free_space;
 
+	ON_TRACE(TRACE_UNIX_FILE_OPS, "UF_WRITE-start: i_ino %li, size %llu, off %llu, count %u\n",
+		 file->f_dentry->d_inode->i_ino, file->f_dentry->d_inode->i_size, *off, write_amount);
+
 	if (unlikely(write_amount == 0))
 		return 0;
 
@@ -2208,6 +2259,8 @@ write_unix_file(struct file *file, /* fi
 	nr_pages = 0;
 	try_free_space = 1;
 
+	ON_TRACE(TRACE_UNIX_FILE_OPS, "UF_WRITE-in loop: i_ino %li, size %llu, off %llu, left %u\n",
+		 inode->i_ino, inode->i_size, *off, left);
 	while (left > 0) {
 		unsigned long addr;
 		size_t to_write;
@@ -2253,12 +2306,18 @@ write_unix_file(struct file *file, /* fi
 		/* With no locks held we can commit atoms in attempt to recover
 		 * free space. */
 		if ((ssize_t)written == -ENOSPC && try_free_space) {
+			ON_TRACE(TRACE_UNIX_FILE_OPS,
+				 "UF_WRITE-try-to-free-space: i_ino %li, size %llu, off %llu, left %u\n",
+				 inode->i_ino, inode->i_size, *off, left);			
 			txnmgr_force_commit_all(inode->i_sb, 0);
 			try_free_space = 0;
 			continue;
 		}
 		if ((ssize_t)written < 0) {
 			result = written;
+			ON_TRACE(TRACE_UNIX_FILE_OPS,
+				 "UF_WRITE-error: %d. [i_ino %li, size %llu, off %llu, left %u]\n",
+				 result, inode->i_ino, inode->i_size, *off, left);			
 			break;
 		}
 		left -= written;
@@ -2266,6 +2325,9 @@ write_unix_file(struct file *file, /* fi
 
 		/* total number of written bytes */
 		count += written;
+		ON_TRACE(TRACE_UNIX_FILE_OPS,
+			 "UF_WRITE-written: %u bytes. i_ino %li, size %llu, off %llu, left %u\n",
+			 written, inode->i_ino, inode->i_size, *off, left);			
 	}
 
 	if ((file->f_flags & O_SYNC) || IS_SYNC(inode)) {
@@ -2280,6 +2342,8 @@ write_unix_file(struct file *file, /* fi
  	current->backing_dev_info = 0;
 	save_file_hint(file, &hint);
 
+	ON_TRACE(TRACE_UNIX_FILE_OPS, "UF_WRITE-end: i_ino %li, size %llu, off %llu, count %u, result %d\n",
+		 inode->i_ino, inode->i_size, *off, count, result);
 	return count ? count : result;
 }
 
@@ -2303,6 +2367,7 @@ release_unix_file(struct inode *object, 
 		if (result != 0) {
 			warning("nikita-3233", "Failed to convert in %s (%llu)",
 				__FUNCTION__, (unsigned long long)get_inode_oid(object));
+			print_inode("inode", object);
 		}
 	}
 	drop_exclusive_access(uf_info);
diff -puN plugin/file/funcs.h~profile-stat-trace-repacker plugin/file/funcs.h
--- reiser4/plugin/file/funcs.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/file/funcs.h	2005-02-01 11:51:12.000000000 +0300
@@ -5,6 +5,7 @@ void get_exclusive_access(unix_file_info
 void drop_exclusive_access(unix_file_info_t *);
 void get_nonexclusive_access(unix_file_info_t *, int);
 void drop_nonexclusive_access(unix_file_info_t *);
+void drop_access(unix_file_info_t *uf_info);
 
 int tail2extent(unix_file_info_t *);
 int extent2tail(unix_file_info_t *);
diff -puN plugin/file/pseudo.c~profile-stat-trace-repacker plugin/file/pseudo.c
--- reiser4/plugin/file/pseudo.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/file/pseudo.c	2005-02-01 11:51:12.000000000 +0300
@@ -12,6 +12,8 @@
 #include <linux/seq_file.h>
 #include <linux/fs.h>
 
+struct seq_operations pseudo_seq_op;
+
 /* extract pseudo file plugin, stored in @file */
 static pseudo_plugin *
 get_pplug(struct file * file)
diff -puN plugin/file/tail_conversion.c~profile-stat-trace-repacker plugin/file/tail_conversion.c
--- reiser4/plugin/file/tail_conversion.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/file/tail_conversion.c	2005-02-01 11:51:12.000000000 +0300
@@ -279,6 +279,9 @@ tail2extent(unix_file_info_t *uf_info)
 	int first_iteration;
 	int bytes;
 
+	/* collect statistics on the number of tail2extent conversions */
+	reiser4_stat_inc(file.tail2extent);
+
 	assert("nikita-3362", ea_obtained(uf_info));
 	inode = unix_file_info_to_inode(uf_info);
 	assert("nikita-3412", !IS_RDONLY(inode));
@@ -305,7 +308,7 @@ tail2extent(unix_file_info_t *uf_info)
 	result = 0;
 	first_iteration = 1;
 	while (done == 0) {
-		memset(pages, 0, sizeof (pages));
+		xmemset(pages, 0, sizeof (pages));
 		all_grabbed2free();
 		result = reserve_tail2extent_iteration(inode);
 		if (result != 0)
@@ -355,7 +358,7 @@ tail2extent(unix_file_info_t *uf_info)
 					done_lh(&lh);
 					done = 1;
 					p_data = kmap_atomic(page, KM_USER0);
-					memset(p_data + page_off, 0, PAGE_CACHE_SIZE - page_off);
+					xmemset(p_data + page_off, 0, PAGE_CACHE_SIZE - page_off);
 					kunmap_atomic(p_data, KM_USER0);
 					break;
 				}
@@ -427,6 +430,7 @@ tail2extent(unix_file_info_t *uf_info)
 		release_all_pages(pages, sizeof_array(pages));
 		warning("nikita-2282", "Partial conversion of %llu: %i",
 			(unsigned long long)get_inode_oid(inode), result);
+		print_inode("inode", inode);
 	}
 
  out:
@@ -499,6 +503,16 @@ write_page_by_tail(struct inode *inode, 
 	return result;
 }
 
+/* flow insertion is limited by CARRY_FLOW_NEW_NODES_LIMIT of new nodes. Therefore, minimal number of bytes of flow
+   which can be put into tree by one insert_flow is number of bytes contained in CARRY_FLOW_NEW_NODES_LIMIT nodes if
+   they all are filled completely by one tail item. Fortunately, there is a one to one mapping between bytes of tail
+   items and bytes of flow. If there were not, we would have to have special item plugin */
+reiser4_internal int min_bytes_per_flow(void)
+{
+	assert("vs-1103", current_tree->nplug && current_tree->nplug->max_item_size);
+	return CARRY_FLOW_NEW_NODES_LIMIT * current_tree->nplug->max_item_size();
+}
+
 static int
 reserve_extent2tail_iteration(struct inode *inode)
 {
@@ -540,6 +554,9 @@ extent2tail(unix_file_info_t *uf_info)
 	unsigned count;
 	__u64 offset;
 
+	/* collect statistics on the number of extent2tail conversions */
+	reiser4_stat_inc(file.extent2tail);
+
 	assert("nikita-3362", ea_obtained(uf_info));
 	inode = unix_file_info_to_inode(uf_info);
 	assert("nikita-3412", !IS_RDONLY(inode));
@@ -652,6 +669,7 @@ extent2tail(unix_file_info_t *uf_info)
 			"Partial conversion of %llu: %lu of %lu: %i",
 			(unsigned long long)get_inode_oid(inode), i,
 			num_pages, result);
+		print_inode("inode", inode);
 	}
 	all_grabbed2free();
 	return result;
diff -puN plugin/hash.c~profile-stat-trace-repacker plugin/hash.c
--- reiser4/plugin/hash.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/hash.c	2005-02-01 11:51:12.000000000 +0300
@@ -240,6 +240,7 @@ static __u64
 hash_deg(const unsigned char *name UNUSED_ARG /* name to hash */ ,
 	 int len UNUSED_ARG /* @name's length */ )
 {
+	ON_TRACE(TRACE_DIR, "Hashing %s\n", name);
 	return 0xc0c0c0c010101010ull;
 }
 
diff -puN plugin/item/blackbox.c~profile-stat-trace-repacker plugin/item/blackbox.c
--- reiser4/plugin/item/blackbox.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/blackbox.c	2005-02-01 11:51:12.000000000 +0300
@@ -25,7 +25,7 @@ store_black_box(reiser4_tree *tree,
 	coord_t coord;
 	lock_handle lh;
 
-	memset(&idata, 0, sizeof idata);
+	xmemset(&idata, 0, sizeof idata);
 
 	idata.data = data;
 	idata.user = 0;
@@ -65,7 +65,7 @@ load_black_box(reiser4_tree *tree,
 		if (result == 0) {
 			ilen = item_length_by_coord(&coord);
 			if (ilen <= length) {
-				memcpy(data, item_body_by_coord(&coord), ilen);
+				xmemcpy(data, item_body_by_coord(&coord), ilen);
 				unit_key_by_coord(&coord, key);
 			} else if (exact) {
 				/*
@@ -109,7 +109,7 @@ update_black_box(reiser4_tree *tree,
 		if (result == 0) {
 			ilen = item_length_by_coord(&coord);
 			if (length <= ilen) {
-				memcpy(item_body_by_coord(&coord), data, length);
+				xmemcpy(item_body_by_coord(&coord), data, length);
 			} else {
 				warning("nikita-3437",
 					"Wrong black box length: %i < %i",
diff -puN plugin/item/cde.c~profile-stat-trace-repacker plugin/item/cde.c
--- reiser4/plugin/item/cde.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/cde.c	2005-02-01 11:51:12.000000000 +0300
@@ -262,7 +262,7 @@ expand_item(const coord_t * coord /* coo
 	/* place where new header will be in */
 	header = header_at(coord, pos);
 	/* free space for new entry headers */
-	memmove(header + no, header, (unsigned) (address(coord, size) - (char *) header));
+	xmemmove(header + no, header, (unsigned) (address(coord, size) - (char *) header));
 	/* if adding to the end initialise first new header */
 	if (pos == entries) {
 		set_offset(coord, pos, (unsigned) size);
@@ -272,7 +272,7 @@ expand_item(const coord_t * coord /* coo
 	dent = dent + no * sizeof *header;
 	size += no * sizeof *header;
 	/* free space for new entries */
-	memmove(dent + data_size, dent, (unsigned) (address(coord, size) - dent));
+	xmemmove(dent + data_size, dent, (unsigned) (address(coord, size) - dent));
 
 	/* increase counter */
 	entries += no;
@@ -753,20 +753,26 @@ copy_units_cde(coord_t * target /* coord
 	int data_size;
 	int data_delta;
 	int i;
+#if REISER4_TRACE && REISER4_DEBUG_OUTPUT
+	reiser4_key debug_key;
+#endif
 
 	assert("nikita-1303", target != NULL);
 	assert("nikita-1304", source != NULL);
 	assert("nikita-1305", (int) from < units(source));
 	assert("nikita-1307", (int) (from + count) <= units(source));
 
+	IF_TRACE(TRACE_DIR | TRACE_NODES, print_key("cde_copy source", item_key_by_coord(source, &debug_key)));
+	IF_TRACE(TRACE_DIR | TRACE_NODES, print_key("cde_copy target", item_key_by_coord(target, &debug_key)));
+
 	if (where_is_free_space == SHIFT_LEFT) {
 		assert("nikita-1453", from == 0);
 		pos_in_target = units(target);
 	} else {
 		assert("nikita-1309", (int) (from + count) == units(source));
 		pos_in_target = 0;
-		memmove(item_body_by_coord(target),
-			(char *) item_body_by_coord(target) + free_space, item_length_by_coord(target) - free_space);
+		xmemmove(item_body_by_coord(target),
+			 (char *) item_body_by_coord(target) + free_space, item_length_by_coord(target) - free_space);
 	}
 
 	CHECKME(target);
@@ -787,12 +793,12 @@ copy_units_cde(coord_t * target /* coord
 	/* copy entries */
 	entry_from = (char *) entry_at(source, (int) from);
 	entry_to = (char *) entry_at(source, (int) (from + count));
-	memmove(entry_at(target, pos_in_target), entry_from, (unsigned) (entry_to - entry_from));
+	xmemmove(entry_at(target, pos_in_target), entry_from, (unsigned) (entry_to - entry_from));
 
 	/* copy headers */
 	header_from = (char *) header_at(source, (int) from);
 	header_to = (char *) header_at(source, (int) (from + count));
-	memmove(header_at(target, pos_in_target), header_from, (unsigned) (header_to - header_from));
+	xmemmove(header_at(target, pos_in_target), header_from, (unsigned) (header_to - header_from));
 
 	/* update offsets */
 	for (i = pos_in_target; i < (int) (pos_in_target + count); ++i)
@@ -856,7 +862,7 @@ cut_units_cde(coord_t * coord /* coord o
 	entry_to = (char *) entry_at(coord, (int) (from + count));
 
 	/* move headers */
-	memmove(header_from, header_to, (unsigned) (address(coord, size) - header_to));
+	xmemmove(header_from, header_to, (unsigned) (address(coord, size) - header_to));
 
 	header_delta = header_to - header_from;
 
@@ -865,7 +871,7 @@ cut_units_cde(coord_t * coord /* coord o
 	size -= header_delta;
 
 	/* copy entries */
-	memmove(entry_from, entry_to, (unsigned) (address(coord, size) - entry_to));
+	xmemmove(entry_from, entry_to, (unsigned) (address(coord, size) - entry_to));
 
 	entry_delta = entry_to - entry_from;
 	size -= entry_delta;
@@ -882,14 +888,14 @@ cut_units_cde(coord_t * coord /* coord o
 
 	if (from == 0) {
 		/* entries from head was removed - move remaining to right */
-		memmove((char *) item_body_by_coord(coord) +
+		xmemmove((char *) item_body_by_coord(coord) +
 			 header_delta + entry_delta, item_body_by_coord(coord), (unsigned) size);
 		if (REISER4_DEBUG)
-			memset(item_body_by_coord(coord), 0, (unsigned) header_delta + entry_delta);
+			xmemset(item_body_by_coord(coord), 0, (unsigned) header_delta + entry_delta);
 	} else {
 		/* freed space is already at the end of item */
 		if (REISER4_DEBUG)
-			memset((char *) item_body_by_coord(coord) + size, 0, (unsigned) header_delta + entry_delta);
+			xmemset((char *) item_body_by_coord(coord) + size, 0, (unsigned) header_delta + entry_delta);
 	}
 
 	return header_delta + entry_delta;
diff -puN plugin/item/ctail.c~profile-stat-trace-repacker plugin/item/ctail.c
--- reiser4/plugin/item/ctail.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/ctail.c	2005-02-01 11:51:12.000000000 +0300
@@ -69,7 +69,7 @@ pg_by_coord(const coord_t * coord)
 	return get_key_offset(item_key_by_coord(coord, &key)) >> PAGE_CACHE_SHIFT;
 }
 
-static unsigned long
+reiser4_internal unsigned long
 clust_by_coord(const coord_t * coord)
 {
 	return pg_by_coord(coord) >> cluster_shift_by_coord(coord);
@@ -251,7 +251,7 @@ paste_ctail(coord_t * coord, reiser4_ite
 	else
 		impossible("edward-453", "bad paste position");
 
-	memcpy(first_unit(coord) + coord->unit_pos, data->data, data->length);
+	xmemcpy(first_unit(coord) + coord->unit_pos, data->data, data->length);
 	
 	assert("edward-857", !check_ctail(coord, NULL));
 
@@ -298,13 +298,21 @@ copy_units_ctail(coord_t * target, coord
 
 	assert("edward-858", !check_ctail(source, NULL));
 	
+#if 0
+	if (item_length_by_coord(target) == count) {
+		/* new item has been created */
+		assert("edward-465", count > sizeof(ctail_item_format));
+		assert("edward-859", free_space == count + 1);
+		count--;
+	}
+#endif	
 	if (where_is_free_space == SHIFT_LEFT) {
 		/* append item @target with @count first bytes of @source:
 		   this restriction came from ordinary tails */
 		assert("edward-71", from == 0);
 		assert("edward-860", !check_ctail(target, NULL));
 		
-		memcpy(first_unit(target) + nr_units_ctail(target) - count, first_unit(source), count);
+		xmemcpy(first_unit(target) + nr_units_ctail(target) - count, first_unit(source), count);
 	} else {
 		/* target item is moved to right already */
 		reiser4_key key;
@@ -319,7 +327,7 @@ copy_units_ctail(coord_t * target, coord
 			/* new item has been created */
 			assert("edward-862", !check_ctail(target, NULL));
 		}
-		memcpy(first_unit(target), first_unit(source) + from, count);
+		xmemcpy(first_unit(target), first_unit(source) + from, count);
 		
 		assert("edward-863", !check_ctail(target, NULL));
 		
@@ -442,7 +450,7 @@ cut_or_kill_ctail_units(coord_t * coord,
 			/* part of item is removed, so move free space at the beginning
 			   of the item and update item key */
 			reiser4_key key;
-			memcpy(item + to + 1, item, sizeof(ctail_item_format));
+			xmemcpy(item + to + 1, item, sizeof(ctail_item_format));
 			item_key_by_coord(coord, &key);
 			set_key_offset(&key, get_key_offset(&key) + count);
 			node_plugin_by_node(coord->node)->update_item_key(coord, &key, 0 /*info */ );
@@ -455,10 +463,10 @@ cut_or_kill_ctail_units(coord_t * coord,
 			count += sizeof(ctail_item_format);
 		}
 		if (REISER4_DEBUG)
-			memset(item, 0, count);
+			xmemset(item, 0, count);
 	}
 	else if (REISER4_DEBUG)
-		memset(item + sizeof(ctail_item_format) + from, 0, count);
+		xmemset(item + sizeof(ctail_item_format) + from, 0, count);
 	return count;
 }
 
@@ -626,6 +634,8 @@ do_readpage_ctail(reiser4_cluster_t * cl
 		flush_dcache_page(page);
 		kunmap_atomic(data, KM_USER0);
 		SetPageUptodate(page);
+		
+		ON_TRACE(TRACE_CTAIL, " - hole, OK\n");
 		break;
 	case PREP_DISK_CLUSTER:
 		/* fill the page by transformed data */
@@ -641,6 +651,7 @@ do_readpage_ctail(reiser4_cluster_t * cl
 		flush_dcache_page(page);
 		kunmap(page);
 		SetPageUptodate(page);
+		ON_TRACE(TRACE_CTAIL, " - real data, OK\n");
 		break;
 	default:
 		impossible("edward-1169", "bad disk cluster state");
@@ -874,6 +885,7 @@ insert_crc_flow(coord_t * coord, lock_ha
 	lowest_level.track_type = CARRY_TRACK_CHANGE;
 	lowest_level.tracked = lh;
 
+	ON_STATS(lowest_level.level_no = znode_get_level(coord->node));
 	result = carry(&lowest_level, 0);
 	done_carry_pool(pool);
 
@@ -930,7 +942,7 @@ overwrite_ctail(coord_t * coord, flow_t 
 
 	if (count > f->length)
 		count = f->length;
-	memcpy(first_unit(coord), f->data, count);
+	xmemcpy(first_unit(coord), f->data, count);
 	move_flow_forward(f, count);
 	coord->unit_pos += count;
 	return 0;
@@ -978,7 +990,7 @@ int ctail_make_unprepped_cluster(reiser4
 	
 	assert("edward-1063", znode_is_write_locked(clust->hint->coord.lh->node));
 	
-	memset(buf, 0, UNPREPPED_DCLUSTER_LEN);
+	xmemset(buf, 0, UNPREPPED_DCLUSTER_LEN);
 	
 	flow_by_inode_cryptcompress(inode,
 				    buf,
@@ -1015,7 +1027,7 @@ int ctail_make_unprepped_cluster(reiser4
 
 /* the following functions are used by flush item methods */
 /* plugin->u.item.s.file.write ? */
-static int
+reiser4_internal int
 write_ctail(flush_pos_t * pos, crc_write_mode_t mode)
 {
 	int result;
@@ -1168,7 +1180,7 @@ alloc_convert_data(flush_pos_t * pos)
 	pos->sq = reiser4_kmalloc(sizeof(*pos->sq), GFP_KERNEL);
 	if (!pos->sq)
 		return RETERR(-ENOMEM);
-	memset(pos->sq, 0, sizeof(*pos->sq));
+	xmemset(pos->sq, 0, sizeof(*pos->sq));
 	return 0;
 }
 
@@ -1201,7 +1213,7 @@ init_item_convert_data(flush_pos_t * pos
 
 	sq = pos->sq;
 
-	memset(sq->itm, 0, sizeof(*sq->itm));
+	xmemset(sq->itm, 0, sizeof(*sq->itm));
 
 	/* iplug->init_convert_data() */
 	return init_convert_data_ctail(sq->itm, inode);
diff -puN plugin/item/ctail.h~profile-stat-trace-repacker plugin/item/ctail.h
--- reiser4/plugin/item/ctail.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/ctail.h	2005-02-01 11:51:12.000000000 +0300
@@ -68,6 +68,8 @@ int convert_ctail(flush_pos_t *);
 item_plugin * item_plugin_by_jnode(jnode *);
 
 size_t inode_scaled_cluster_size(struct inode *);
+loff_t inode_scaled_offset (struct inode *, const loff_t);
+unsigned max_crypto_overhead(struct inode *);
 
 #endif /* __FS_REISER4_CTAIL_H__ */
 
diff -puN plugin/item/extent.c~profile-stat-trace-repacker plugin/item/extent.c
--- reiser4/plugin/item/extent.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/extent.c	2005-02-01 11:51:12.000000000 +0300
@@ -7,6 +7,7 @@
 #include "../../inode.h"
 #include "../../page_cache.h"
 #include "../../emergency_flush.h"
+#include "../../prof.h"
 #include "../../flush.h"
 #include "../object.h"
 
@@ -16,6 +17,9 @@
 reiser4_internal reiser4_item_data *
 init_new_extent(reiser4_item_data *data, void *ext_unit, int nr_extents)
 {
+	if (REISER4_ZERO_NEW_NODE)
+		memset(data, 0, sizeof(reiser4_item_data));
+
 	data->data = ext_unit;
 	/* data->data is kernel space */
 	data->user = 0;
@@ -66,6 +70,14 @@ extent_is_unallocated(const coord_t *ite
 	return state_of_extent(extent_by_coord(item)) == UNALLOCATED_EXTENT;
 }
 
+reiser4_internal int
+extent_is_allocated(const coord_t *item)
+{
+	assert("jmacd-5133", item_is_extent(item));
+
+	return state_of_extent(extent_by_coord(item)) == ALLOCATED_EXTENT;
+}
+
 /* set extent's start and width */
 reiser4_internal void
 set_extent(reiser4_extent *ext, reiser4_block_nr start, reiser4_block_nr width)
@@ -113,6 +125,8 @@ replace_extent(coord_t *un_extent, lock_
 		assert("vs-1080", keyeq(&tmp, key));
 	}
 
+	DISABLE_NODE_CHECK;
+
 	/* set insert point after unit to be replaced */
 	un_extent->between = AFTER_UNIT;
 
@@ -157,6 +171,7 @@ replace_extent(coord_t *un_extent, lock_
 	}
 	tap_done(&watch);
 
+	ENABLE_NODE_CHECK;
 	return result;
 }
 
diff -puN plugin/item/extent_file_ops.c~profile-stat-trace-repacker plugin/item/extent_file_ops.c
--- reiser4/plugin/item/extent_file_ops.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/extent_file_ops.c	2005-02-01 11:51:12.000000000 +0300
@@ -474,6 +474,8 @@ make_extent(reiser4_key *key, uf_coord_t
 	assert("vs-960", znode_is_write_locked(uf_coord->base_coord.node));
 	assert("vs-1334", znode_is_loaded(uf_coord->base_coord.node));
 
+	DISABLE_NODE_CHECK;
+
 	*block = 0;
 	switch (mode) {
 	case FIRST_ITEM:
@@ -515,6 +517,8 @@ make_extent(reiser4_key *key, uf_coord_t
 		break;
 	}
 
+	ENABLE_NODE_CHECK;
+
 	ON_DEBUG(check_make_extent_result(result, mode, key, uf_coord->lh, *block));
 
 	return result;
@@ -698,6 +702,8 @@ extent_write_flow(struct inode *inode, f
 		if (count > flow->length)
 			count = flow->length;
 
+		write_page_log(inode->i_mapping, page_nr);
+
 		result = make_extent(&page_key, uf_coord, mode, &blocknr, &created, inode/* check quota */);
 		if (result) {
 			goto exit1;
@@ -709,6 +715,24 @@ extent_write_flow(struct inode *inode, f
 			result = PTR_ERR(j);
 			goto exit1;
 		}
+#if 0
+		LOCK_JNODE(j);
+		if (created) {
+			/* extent corresponding to this jnode was just created */
+			assert("vs-1504", *jnode_get_block(j) == 0);
+			JF_SET(j, JNODE_CREATED);
+			/* new block is added to file. Update inode->i_blocks and inode->i_bytes. FIXME:
+			   inode_set/get/add/sub_bytes is used to be called by quota macros */
+			/*inode_add_bytes(inode, PAGE_CACHE_SIZE);*/
+		}
+		if (*jnode_get_block(j) == 0) {
+			jnode_set_block(j, &blocknr);
+		} else {
+			assert("vs-1508", !blocknr_is_fake(&blocknr));
+			assert("vs-1507", ergo(blocknr, *jnode_get_block(j) == blocknr));
+		}
+		UNLOCK_JNODE(j);
+#endif
 
 		/* get page looked and attached to jnode */
 		page = jnode_get_page_locked(j, GFP_KERNEL);
@@ -814,6 +838,7 @@ extent_write_flow(struct inode *inode, f
 		if (!grabbed)
 			all_grabbed2free();
 		if (result) {
+			reiser4_stat_inc(extent.bdp_caused_repeats);
 			break;
 		}
 
@@ -936,7 +961,7 @@ zero_page(struct page *page)
 {
 	char *kaddr = kmap_atomic(page, KM_USER0);
 
-	memset(kaddr, 0, PAGE_CACHE_SIZE);
+	xmemset(kaddr, 0, PAGE_CACHE_SIZE);
 	flush_dcache_page(page);
 	kunmap_atomic(kaddr, KM_USER0);
 	SetPageUptodate(page);
@@ -1142,21 +1167,24 @@ read_extent(struct file *file, flow_t *f
 	extent_coord_extension_t *ext_coord;
 	unsigned long ra_pages;
 
-	assert("vs-1353", current_blocksize == PAGE_CACHE_SIZE);
-	assert("vs-572", flow->user == 1);
-	assert("vs-1351", flow->length > 0);
-
 	uf_coord = &hint->coord;
 	assert("vs-1318", coord_extension_is_ok(uf_coord));
 
+	inode = file->f_dentry->d_inode;
 	coord = &uf_coord->base_coord;
+	ext_coord = &uf_coord->extension.extent;
+
+	ON_TRACE(TRACE_EXTENTS, "read_extent start: ino %llu, size %llu, offset %llu, count %lld\n",
+		 get_inode_oid(inode), inode->i_size, get_key_offset(&flow->key), flow->length);
+	IF_TRACE(TRACE_EXTENTS, print_ext_coord("read_extent start", uf_coord));
+
+	assert("vs-1353", current_blocksize == PAGE_CACHE_SIZE);
+	assert("vs-572", flow->user == 1);
+	assert("vs-1351", flow->length > 0);
 	assert("vs-1119", znode_is_rlocked(coord->node));
 	assert("vs-1120", znode_is_loaded(coord->node));
 	assert("vs-1256", coord_matches_key_extent(coord, &flow->key));
 
-	inode = file->f_dentry->d_inode;
-	ext_coord = &uf_coord->extension.extent;
-
 	/* offset in a file to start read from */
 	file_off = get_key_offset(&flow->key);
 	/* index of page containing that offset */
@@ -1220,6 +1248,9 @@ read_extent(struct file *file, flow_t *f
 		count = PAGE_CACHE_SIZE;
 	} while (flow->length && uf_coord->valid == 1);
 
+	ON_TRACE(TRACE_EXTENTS, "read_extent done: left %lld\n", flow->length);
+	IF_TRACE(TRACE_EXTENTS, print_ext_coord("read_extent done", uf_coord));
+
 	return 0;
 }
 
@@ -1280,6 +1311,8 @@ capture_extent(reiser4_key *key, uf_coor
 	int created;
 	int check_quota;
 
+	ON_TRACE(TRACE_EXTENTS, "WP: index %lu, count %d..", page->index, page_count(page));
+
 	assert("vs-1051", page->mapping && page->mapping->host);
 	assert("nikita-3139", !inode_get_flag(page->mapping->host, REISER4_NO_SD));
 	assert("vs-864", znode_is_wlocked(uf_coord->base_coord.node));
@@ -1337,6 +1370,7 @@ capture_extent(reiser4_key *key, uf_coor
 		reiser4_update_sd(page->mapping->host);
 		/* warning about failure of this is issued already */
 
+	ON_TRACE(TRACE_EXTENTS, "OK\n");
 	return 0;
 }
 
diff -puN plugin/item/extent_flush_ops.c~profile-stat-trace-repacker plugin/item/extent_flush_ops.c
--- reiser4/plugin/item/extent_flush_ops.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/extent_flush_ops.c	2005-02-01 11:51:12.000000000 +0300
@@ -10,8 +10,6 @@
 
 #include <linux/pagemap.h>
 
-static reiser4_block_nr extent_unit_start(const coord_t *item);
-
 /* Return either first or last extent (depending on @side) of the item
    @coord is set to. Set @pos_in_unit either to first or to last block
    of extent. */
@@ -154,10 +152,16 @@ reiser4_internal int scan_extent(flush_s
 
 	assert("jmacd-7889", item_is_extent(&coord));
 
+	ON_TRACE(TRACE_FLUSH_VERB, "%s scan starts %lu: %s\n",
+		 (scanning_left(scan) ? "left" : "right"), scan_index, jnode_tostring(scan->node));
+
 repeat:
 	/* objectid of file */
 	oid = get_key_objectid(item_key_by_coord(&coord, &key));
 
+	ON_TRACE(TRACE_FLUSH_VERB, "%s scan index %lu: parent %p oid %llu\n",
+		 (scanning_left(scan) ? "left" : "right"), scan_index, coord.node, oid);
+
 	allocated = !extent_is_unallocated(&coord);
 	/* Get the values of this extent unit: */
 	unit_index = extent_unit_index(&coord);
@@ -192,6 +196,9 @@ repeat:
 			if (neighbor == NULL)
 				goto stop_same_parent;
 
+			ON_TRACE(TRACE_FLUSH_VERB, "alloc scan index %lu: %s\n",
+				 scan_index, jnode_tostring(neighbor));
+
 			if (scan->node != neighbor && !scan_goto(scan, neighbor)) {
 				/* @neighbor was jput() by scan_goto(). */
 				goto stop_same_parent;
@@ -220,6 +227,8 @@ repeat:
 
 		assert ("zam-1043", blocknr_is_fake(jnode_get_block(neighbor)));
 
+		ON_TRACE(TRACE_FLUSH_VERB, "unalloc scan index %lu: %s\n", scan_index, jnode_tostring(neighbor));
+
 		/* XXX commented assertion out, because it is inherently
 		 * racy */
 		/* assert("jmacd-3551", !jnode_check_flushprepped(neighbor)
@@ -338,7 +347,7 @@ extent_unit_width(const coord_t *item)
 }
 
 /* Starting block location of this unit */
-static reiser4_block_nr
+reiser4_internal reiser4_block_nr
 extent_unit_start(const coord_t *item)
 {
 	return extent_get_start(extent_by_coord(item));
@@ -367,6 +376,12 @@ split_allocated_extent(coord_t *coord, r
 	unit_key_by_coord(coord, &key);
 	set_key_offset(&key, (get_key_offset(&key) + pos_in_unit * current_blocksize));
 
+	ON_TRACE(TRACE_EXTENT_ALLOC,
+		 "split [%llu %llu] -> [%llu %llu][%llu %llu]\n",
+		 extent_get_start(ext), extent_get_width(ext),
+		 extent_get_start(&replace_ext), extent_get_width(&replace_ext),
+		 extent_get_start(&append_ext), extent_get_width(&append_ext));
+
 	grabbed = reserve_replace();
 	result = replace_extent(coord, znode_lh(coord->node), &key, init_new_extent(&item, &append_ext, 1),
 				&replace_ext, COPI_DONT_SHIFT_LEFT, 0/* return replaced position */);
@@ -545,25 +560,38 @@ try_to_merge_with_left(coord_t *coord, r
 		return 0;
 
 	/* we can glue, widen previous unit */
+	ON_TRACE(TRACE_EXTENT_ALLOC,
+		 "wide previous [%llu %llu] ->",
+		 extent_get_start(ext - 1), extent_get_width(ext - 1));
+
 	extent_set_width(ext - 1, extent_get_width(ext - 1) + extent_get_width(replace));
 
+	ON_TRACE(TRACE_EXTENT_ALLOC, " [%llu %llu] -> ", extent_get_start(ext - 1), extent_get_width(ext - 1));
+
 	if (extent_get_width(ext) != extent_get_width(replace)) {
 		/* make current extent narrower */
+		ON_TRACE(TRACE_EXTENT_ALLOC, "narrow [%llu %llu] -> ", extent_get_start(ext), extent_get_width(ext));
+
 		if (state_of_extent(ext) == ALLOCATED_EXTENT)
 			extent_set_start(ext, extent_get_start(ext) + extent_get_width(replace));
 		extent_set_width(ext, extent_get_width(ext) - extent_get_width(replace));
+
+		ON_TRACE(TRACE_EXTENT_ALLOC, "[%llu %llu]\n", extent_get_start(ext), extent_get_width(ext));
 	} else {
 		/* current extent completely glued with its left neighbor, remove it */
 		coord_t from, to;
 
+		ON_TRACE(TRACE_EXTENT_ALLOC, "delete [%llu %llu]\n", extent_get_start(ext), extent_get_width(ext));
+
 		coord_dup(&from, coord);
 		from.unit_pos = nr_units_extent(coord) - 1;
 		coord_dup(&to, &from);
 
 		/* currently cut from extent can cut either from the beginning or from the end. Move place which got
 		   freed after unit removal to end of item */
-		memmove(ext, ext + 1, (from.unit_pos - coord->unit_pos) * sizeof(reiser4_extent));
+		xmemmove(ext, ext + 1, (from.unit_pos - coord->unit_pos) * sizeof(reiser4_extent));
 		/* wipe part of item which is going to be cut, so that node_check will not be confused */
+		ON_DEBUG(xmemset(extent_item(coord) + from.unit_pos, 0, sizeof (reiser4_extent)));
 		cut_node_content(&from, &to, NULL, NULL, NULL);
 	}
 	znode_make_dirty(coord->node);
@@ -597,13 +625,19 @@ conv_extent(coord_t *coord, reiser4_exte
 
 	if (try_to_merge_with_left(coord, ext, replace)) {
 		/* merged @replace with left neighbor. Current unit is either removed or narrowed */
+		assert("nikita-3563", znode_at_read(coord->node));
 		return 0;
 	}
 
 	if (width == new_width) {
 		/* replace current extent with @replace */
+		ON_TRACE(TRACE_EXTENT_ALLOC, "replace: [%llu %llu]->[%llu %llu]\n",
+		       start, width,
+		       extent_get_start(replace), extent_get_width(replace));
+
 		*ext = *replace;
 		znode_make_dirty(coord->node);
+		assert("nikita-3563", znode_at_read(coord->node));
 		return 0;
 	}
 
@@ -615,10 +649,17 @@ conv_extent(coord_t *coord, reiser4_exte
 	unit_key_by_coord(coord, &key);
 	set_key_offset(&key, (get_key_offset(&key) + new_width * current_blocksize));
 
+	ON_TRACE(TRACE_EXTENT_ALLOC,
+		 "replace: [%llu %llu]->[%llu %llu][%llu %llu]\n",
+		 start, width,
+		 extent_get_start(replace), extent_get_width(replace),
+		 extent_get_start(&padd_ext), extent_get_width(&padd_ext));
+
 	grabbed = reserve_replace();
 	result = replace_extent(coord, znode_lh(coord->node), &key, init_new_extent(&item, &padd_ext, 1),
 				replace, COPI_DONT_SHIFT_LEFT, 0/* return replaced position */);
 
+	assert("nikita-3563", znode_at_read(coord->node));
 	free_replace_reserved(grabbed);
 	return result;
 }
@@ -702,11 +743,17 @@ mark_jnodes_overwrite(flush_pos_t *flush
 		node = jlookup(tree, oid, index);
 		if (!node) {
 			flush_pos->state = POS_INVALID;
+
+			ON_TRACE(TRACE_EXTENT_ALLOC, "node not found: (oid %llu, index %lu)\n", oid, index);
+
 			break;
 		}
 		if (jnode_check_flushprepped(node)) {
 			flush_pos->state = POS_INVALID;
 			atomic_dec(&node->x_count);
+
+			ON_TRACE(TRACE_EXTENT_ALLOC, "flushprepped: (oid %llu, index %lu)\n", oid, index);
+
 			break;
 		}
 		make_node_ovrwr(&jnodes, node);
@@ -743,6 +790,8 @@ alloc_extent(flush_pos_t *flush_pos)
 
 	coord = &flush_pos->coord;
 
+	check_pos(flush_pos);
+
 	ext = extent_by_coord(coord);
 	state = state_of_extent(ext);
 	if (state == HOLE_EXTENT) {
@@ -765,9 +814,13 @@ alloc_extent(flush_pos_t *flush_pos)
 		if (flush_pos->pos_in_unit) {
 			/* split extent unit into two */
 			result = split_allocated_extent(coord, flush_pos->pos_in_unit);
+			check_pos(flush_pos);
 			flush_pos->pos_in_unit = 0;
 			return result;
 		}
+		ON_TRACE(TRACE_EXTENT_ALLOC,
+			 "ALLOC: relocate: (oid %llu, index %llu) [%llu %llu] - ",
+			 oid, index, start, width);
 
 		/* Prevent nodes from e-flushing before allocating disk space for them. Nodes which were eflushed will be
 		   read from their temporary locations (but not more than certain limit: JNODES_TO_UNFLUSH) and that
@@ -776,12 +829,14 @@ alloc_extent(flush_pos_t *flush_pos)
 		protected_jnodes_init(&jnodes);
 
 		result = protect_extent_nodes(flush_pos, oid, index, width, &protected, ext, &jnodes.nodes);
+		check_pos(flush_pos);
 		if (result) {
   			warning("vs-1469", "Failed to protect extent. Should not happen\n");
 			protected_jnodes_done(&jnodes);
 			return result;
 		}
 		if (protected == 0) {
+			ON_TRACE(TRACE_EXTENT_ALLOC, "nothing todo\n");
 			flush_pos->state = POS_INVALID;
 			flush_pos->pos_in_unit = 0;
 			protected_jnodes_done(&jnodes);
@@ -797,37 +852,54 @@ alloc_extent(flush_pos_t *flush_pos)
 
 		/* allocate new block numbers for protected nodes */
 		extent_allocate_blocks(pos_hint(flush_pos), protected, &first_allocated, &allocated, block_stage);
+		check_pos(flush_pos);
+
+		ON_TRACE(TRACE_EXTENT_ALLOC, "allocated: (first %llu, cound %llu) - ", first_allocated, allocated);
 
 		if (allocated != protected)
 			/* unprotect nodes which will not be
 			 * allocated/relocated on this iteration */
 			unprotect_extent_nodes(flush_pos, protected - allocated,
 					       &jnodes.nodes);
+		check_pos(flush_pos);
 		if (state == ALLOCATED_EXTENT) {
 			/* on relocating - free nodes which are going to be
 			 * relocated */
 			reiser4_dealloc_blocks(&start, &allocated, BLOCK_ALLOCATED, BA_DEFER);
 		}
 
+		check_pos(flush_pos);
 		/* assign new block numbers to protected nodes */
 		assign_real_blocknrs(flush_pos, first_allocated, allocated, state, &jnodes.nodes);
 
+		check_pos(flush_pos);
 		protected_jnodes_done(&jnodes);
 
+		/* send to log information about which blocks were allocated for what */
+		write_current_logf(ALLOC_EXTENT_LOG,
+				   "alloc: oid: %llu, index: %llu, state %d, width: %llu. "
+				   "prot: %llu. got [%llu %llu]",
+				   oid, index, state, width, protected, first_allocated, allocated);
+
 		/* prepare extent which will replace current one */
 		set_extent(&replace_ext, first_allocated, allocated);
 
 		/* adjust extent item */
 		result = conv_extent(coord, &replace_ext);
+		check_pos(flush_pos);
 		if (result != 0 && result != -ENOMEM) {
   			warning("vs-1461", "Failed to allocate extent. Should not happen\n");
 			return result;
 		}
 	} else {
 		/* overwrite */
+		ON_TRACE(TRACE_EXTENT_ALLOC,
+			 "ALLOC: overwrite: (oid %llu, index %llu) [%llu %llu]\n",
+			 oid, index, start, width);
 		mark_jnodes_overwrite(flush_pos, oid, index, width);
 	}
 	flush_pos->pos_in_unit = 0;
+	check_pos(flush_pos);
 	return 0;
 }
 
@@ -913,6 +985,9 @@ squalloc_extent(znode *left, const coord
 	if (flush_pos->leaf_relocate || state == UNALLOCATED_EXTENT) {
 		protected_jnodes jnodes;
 
+		ON_TRACE(TRACE_EXTENT_ALLOC, "SQUALLOC: relocate: (oid %llu, index %llu) [%llu %llu] - ",
+			 oid, index, start, width);
+
 		/* relocate */
 		protected_jnodes_init(&jnodes);
 		result = protect_extent_nodes(flush_pos, oid, index, width, &protected, ext, &jnodes.nodes);
@@ -936,6 +1011,7 @@ squalloc_extent(znode *left, const coord
 
 		/* allocate new block numbers for protected nodes */
 		extent_allocate_blocks(pos_hint(flush_pos), protected, &first_allocated, &allocated, block_stage);
+		ON_TRACE(TRACE_EXTENT_ALLOC, "allocated: (first %llu, cound %llu) - ", first_allocated, allocated);
 		if (allocated != protected)
 			unprotect_extent_nodes(flush_pos, protected - allocated,
 					       &jnodes.nodes);
@@ -948,6 +1024,9 @@ squalloc_extent(znode *left, const coord
 			int target_block_stage;
 
 			/* free blocks which were just allocated */
+			ON_TRACE(TRACE_EXTENT_ALLOC,
+				 "left is full, free (first %llu, count %llu)\n",
+				 first_allocated, allocated);
 			target_block_stage = (state == ALLOCATED_EXTENT) ? BLOCK_FLUSH_RESERVED : BLOCK_UNALLOCATED;
 			reiser4_dealloc_blocks(&first_allocated, &allocated, target_block_stage, BA_PERMANENT);
 			unprotect_extent_nodes(flush_pos, allocated, &jnodes.nodes);
@@ -970,16 +1049,30 @@ squalloc_extent(znode *left, const coord
 		protected_jnodes_done(&jnodes);
 
 		set_key_offset(&key, get_key_offset(&key) + (allocated << current_blocksize_bits));
+		ON_TRACE(TRACE_EXTENT_ALLOC,
+			 "copied to left: [%llu %llu]\n", first_allocated, allocated);
+
+		/* send to log information about which blocks were allocated for what */
+		write_current_logf(ALLOC_EXTENT_LOG,
+				   "sqalloc: oid: %llu, index: %llu, state %d, width: %llu. "
+				   "prot: %llu. got [%llu %llu]",
+				   oid, index, state, width, protected, first_allocated, allocated);
 	} else {
-		/* overwrite: try to copy unit as it is to left neighbor and
-		   make all first not flushprepped nodes overwrite nodes */
+		/* overwrite */
+		ON_TRACE(TRACE_EXTENT_ALLOC,
+			 "SQUALLOC: overwrite: (oid %llu, index %llu) [%llu %llu] - ", oid, index, start, width);
+
+		/* overwrite: try to copy unit as it is to left neighbor and make all first not flushprepped nodes
+		   overwrite nodes */
 		set_extent(&copy_extent, start, width);
 		result = put_unit_to_end(left, &key, &copy_extent);
 		if (result == -E_NODE_FULL) {
+			ON_TRACE(TRACE_EXTENT_ALLOC, "left is full\n");
 			return SQUEEZE_TARGET_FULL;
 		}
 		mark_jnodes_overwrite(flush_pos, oid, index, width);
 		set_key_offset(&key, get_key_offset(&key) + (width << current_blocksize_bits));
+		ON_TRACE(TRACE_EXTENT_ALLOC, "copied to left\n");
 	}
 	*stop_key = key;
 	return SQUEEZE_CONTINUE;
diff -puN plugin/item/extent.h~profile-stat-trace-repacker plugin/item/extent.h
--- reiser4/plugin/item/extent.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/extent.h	2005-02-01 11:51:12.000000000 +0300
@@ -141,8 +141,10 @@ int allocate_extent_item_in_place(coord_
 int allocate_and_copy_extent(znode * left, coord_t * right, flush_pos_t * pos, reiser4_key * stop_key);
 
 int extent_is_unallocated(const coord_t * item);	/* True if this extent is unallocated (i.e., not a hole, not allocated). */
+int extent_is_allocated(const coord_t *);
 __u64 extent_unit_index(const coord_t * item);	/* Block offset of this unit. */
 __u64 extent_unit_width(const coord_t * item);	/* Number of blocks in this unit. */
+reiser4_block_nr extent_unit_start(const coord_t * item);	/* Starting block location of this unit. */
 
 /* plugin->u.item.f. */
 int scan_extent (flush_scan * scan);
diff -puN plugin/item/extent_item_ops.c~profile-stat-trace-repacker plugin/item/extent_item_ops.c
--- reiser4/plugin/item/extent_item_ops.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/extent_item_ops.c	2005-02-01 11:51:12.000000000 +0300
@@ -249,12 +249,12 @@ paste_extent(coord_t *coord, reiser4_ite
 	}
 
 	/* prepare space for new units */
-	memmove(ext + coord->unit_pos + data->length / sizeof (reiser4_extent),
-		ext + coord->unit_pos, (old_nr_units - coord->unit_pos) * sizeof (reiser4_extent));
+	xmemmove(ext + coord->unit_pos + data->length / sizeof (reiser4_extent),
+		 ext + coord->unit_pos, (old_nr_units - coord->unit_pos) * sizeof (reiser4_extent));
 
 	/* copy new data from kernel space */
 	assert("vs-556", data->user == 0);
-	memcpy(ext + coord->unit_pos, data->data, (unsigned) data->length);
+	xmemcpy(ext + coord->unit_pos, data->data, (unsigned) data->length);
 
 	/* after paste @coord is set to first of pasted units */
 	assert("vs-332", coord_is_existing_unit(coord));
@@ -320,7 +320,7 @@ copy_units_extent(coord_t *target, coord
 		node_plugin_by_node(target->node)->update_item_key(target, &key, 0/*info */);
 	}
 
-	memcpy(to_ext, from_ext, free_space);
+	xmemcpy(to_ext, from_ext, free_space);
 }
 
 /* item_plugin->b.create_hook
diff -puN /dev/null plugin/item/extent_repack_ops.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/plugin/item/extent_repack_ops.c	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,447 @@
+/* Copyright 2003 by Hans Reiser. */
+
+#include "item.h"
+#include "../../key.h"
+#include "../../super.h"
+#include "../../carry.h"
+#include "../../inode.h"
+#include "../../page_cache.h"
+#include "../../emergency_flush.h"
+#include "../../prof.h"
+#include "../../flush.h"
+#include "../../tap.h"
+#include "../object.h"
+
+#include "../../repacker.h"
+#include "extent.h"
+
+static int get_reiser4_inode_by_tap (struct inode ** result, tap_t * tap)
+{
+	reiser4_key ext_key;
+
+	unit_key_by_coord(tap->coord, &ext_key);
+	return get_reiser4_inode_by_key(result, &ext_key);
+}
+
+static jnode * get_jnode_by_mapping (struct inode * inode, long index)
+{
+	struct page * page;
+	jnode * node;
+
+	page = grab_cache_page(inode->i_mapping, index);
+	if (page == NULL)
+		return ERR_PTR(-ENOMEM);
+	node = jnode_of_page(page);
+	unlock_page(page);
+	page_cache_release(page);
+	return node;
+}
+
+static int mark_jnode_for_repacking (jnode * node)
+{
+	int ret = 0;
+
+	LOCK_JNODE(node);
+	ret = try_capture(node, ZNODE_WRITE_LOCK, 0, 0/* no can_coc */);
+	if (ret) {
+		UNLOCK_JNODE(node);
+		return ret;
+	}
+
+	jnode_make_dirty_locked(node);
+	UNLOCK_JNODE(node);
+	JF_SET(node, JNODE_REPACK);
+
+	ret = jload(node);
+	if (ret == 0) {
+		struct page * page;
+
+		page = jnode_page(node);
+		lock_page(page);
+		set_page_dirty_internal(page, 0);
+		unlock_page(page);
+		jrelse(node);
+	}
+
+	return ret;
+}
+
+/*
+   Mark jnodes of given extent for repacking.
+   @tap : lock, coord and load status for the tree traversal position,
+   @max_nr_marked: a maximum number of nodes which can be marked for repacking,
+   @return: error code if < 0, number of marked nodes otherwise.
+*/
+reiser4_internal int mark_extent_for_repacking (tap_t * tap, int max_nr_marked)
+{
+	coord_t * coord = tap->coord;
+	reiser4_extent *ext;
+	int nr_marked;
+	struct inode * inode;
+	unsigned long index, pos_in_extent;
+	reiser4_block_nr width, start;
+	int ret;
+
+	ext = extent_by_coord(coord);
+
+	if (state_of_extent(ext) == HOLE_EXTENT)
+		return 0;
+
+	width = extent_get_width(ext);
+	start = extent_get_start(ext);
+	index = extent_unit_index(coord);
+
+	ret = get_reiser4_inode_by_tap(&inode, tap);
+	if (ret)
+		return ret;
+
+	for (nr_marked = 0, pos_in_extent = 0;
+	     nr_marked < max_nr_marked && pos_in_extent < width; pos_in_extent ++)
+	{
+		jnode * node;
+
+		node = get_jnode_by_mapping(inode, index + pos_in_extent);
+		if (IS_ERR(node)) {
+			ret = PTR_ERR(node);
+			break;
+		}
+
+		/* Freshly created jnode has no block number set. */
+		if (node->blocknr == 0) {
+			reiser4_block_nr block;
+			block = start + pos_in_extent;
+			jnode_set_block(node, &block);
+
+			node->parent_item_id = EXTENT_POINTER_ID;
+		}
+
+		if (!JF_ISSET(node, JNODE_REPACK)) {
+			do {
+				/* Check whether the node is already read. */
+				if (!JF_ISSET(node, JNODE_PARSED)) {
+					ret = jstartio(node);
+					if (ret)
+						break;
+				}
+				ret = mark_jnode_for_repacking(node);
+				if (ret)
+					break;
+				nr_marked ++;
+			} while (0);
+		}
+		jput(node);
+		if (ret)
+			break;
+	}
+
+	iput(inode);
+	if (ret)
+		return ret;
+	return nr_marked;
+}
+
+/* Check should the repacker relocate this node. */
+static int relocatable (jnode * check)
+{
+	return !JF_ISSET(check, JNODE_OVRWR) && !JF_ISSET(check, JNODE_RELOC);
+}
+
+static int replace_end_of_extent (coord_t * coord, reiser4_block_nr end_part_start,
+				  reiser4_block_nr end_part_width, int * all_replaced)
+{
+	reiser4_extent * ext;
+	reiser4_block_nr ext_start;
+	reiser4_block_nr ext_width;
+
+	reiser4_item_data item;
+	reiser4_extent new_ext, replace_ext;
+	reiser4_block_nr replace_ext_width;
+	reiser4_key key;
+
+	int ret;
+
+	assert ("zam-959", item_is_extent(coord));
+
+	ext = extent_by_coord(coord);
+	ext_start = extent_get_start(ext);
+	ext_width = extent_get_width(ext);
+
+	assert ("zam-960", end_part_width <= ext_width);
+
+	replace_ext_width = ext_width - end_part_width;
+	if (replace_ext_width == 0) {
+		set_extent(ext, end_part_start, end_part_width);
+		znode_make_dirty(coord->node);
+		/* End part of extent is equal to the whole extent. */
+		* all_replaced = 1;
+		return 0;
+	}
+
+	set_extent(&replace_ext, ext_start, replace_ext_width);
+	set_extent(&new_ext, end_part_start, end_part_width);
+
+	unit_key_by_coord(coord, &key);
+	set_key_offset(&key, get_key_offset(&key) + replace_ext_width * current_blocksize);
+
+	{
+		reiser4_context * ctx = get_current_context();
+		reiser4_super_info_data * sinfo = get_super_private(ctx->super);
+		__u64 estimated;
+		__u64 were_grabbed;
+
+		were_grabbed = ctx->grabbed_blocks;
+		estimated = estimate_one_insert_item(&get_super_private(ctx->super)->tree);
+
+		/* grab space for operations on internal levels. */
+		ret = reiser4_grab_space(
+			estimated, BA_FORCE | BA_RESERVED | BA_PERMANENT | BA_FORMATTED);
+		if (ret)
+			return ret;
+
+		ret =  replace_extent(
+			coord, znode_lh(coord->node), &key,
+			init_new_extent(&item, &new_ext, 1), &replace_ext,
+			COPI_DONT_SHIFT_LEFT, 0);
+
+		/* release grabbed space if it was not used. */
+		assert ("zam-988", ctx->grabbed_blocks >= were_grabbed);
+		grabbed2free(ctx, sinfo, ctx->grabbed_blocks - were_grabbed);
+	}
+
+	return ret;
+}
+
+static int make_new_extent_at_end (coord_t * coord, reiser4_block_nr width, int * all_replaced)
+{
+	reiser4_extent * ext;
+	reiser4_block_nr ext_start;
+	reiser4_block_nr ext_width;
+	reiser4_block_nr new_ext_start;
+
+	assert ("zam-961", item_is_extent(coord));
+
+	ext = extent_by_coord(coord);
+	ext_start = extent_get_start(ext);
+	ext_width = extent_get_width(ext);
+
+	assert ("zam-962", width < ext_width);
+
+	if (state_of_extent(ext) == ALLOCATED_EXTENT)
+		new_ext_start = ext_start + ext_width - width;
+	else
+		new_ext_start = ext_start;
+
+	return replace_end_of_extent(coord, new_ext_start, width, all_replaced);
+}
+
+static void parse_extent(coord_t * coord, reiser4_block_nr * start, reiser4_block_nr * width, long * ind)
+{
+	reiser4_extent * ext;
+
+	ext   = extent_by_coord(coord);
+	*start = extent_get_start(ext);
+	*width = extent_get_width(ext);
+	*ind   = extent_unit_index(coord);
+}
+
+static int skip_not_relocatable_extent(struct inode * inode, coord_t * coord, int * done)
+{
+	reiser4_block_nr ext_width, ext_start;
+	long ext_index, reloc_start;
+	jnode * check = NULL;
+	int ret = 0;
+
+	assert("zam-985", state_of_extent(extent_by_coord(coord)));
+	parse_extent(coord, &ext_start, &ext_width, &ext_index);
+
+	for (reloc_start = ext_width - 1; reloc_start >= 0; reloc_start --) {
+		check = get_jnode_by_mapping(inode, reloc_start + ext_index);
+		if (IS_ERR(check))
+			return PTR_ERR(check);
+
+		if (check->blocknr == 0) {
+			reiser4_block_nr block;
+			block = ext_start + reloc_start;
+			jnode_set_block(check, &block);
+
+			check->parent_item_id = EXTENT_POINTER_ID;
+		}
+
+		if (relocatable(check)) {
+			jput(check);
+			if (reloc_start < ext_width - 1)
+				ret = make_new_extent_at_end(coord, ext_width - reloc_start - 1, done);
+			return ret;
+		}
+		jput(check);
+	}
+	*done = 1;
+	return 0;
+}
+
+
+static int relocate_extent (struct inode * inode, coord_t * coord, reiser4_blocknr_hint * hint,
+			    int *done, reiser4_block_nr * len)
+{
+	reiser4_block_nr ext_width, ext_start;
+	long ext_index, reloc_ind;
+	reiser4_block_nr new_ext_width, new_ext_start, new_block;
+	int unallocated_flg;
+	int ret = 0;
+
+	parse_extent(coord, &ext_start, &ext_width, &ext_index);
+	assert("zam-974", *len != 0);
+
+	unallocated_flg = (state_of_extent(extent_by_coord(coord)) == UNALLOCATED_EXTENT);
+	hint->block_stage = unallocated_flg ? BLOCK_UNALLOCATED : BLOCK_FLUSH_RESERVED;
+
+	new_ext_width = *len;
+	ret = reiser4_alloc_blocks(hint, &new_ext_start, &new_ext_width, BA_PERMANENT);
+	if (ret)
+		return ret;
+
+	hint->blk = new_ext_start;
+	if (!unallocated_flg) {
+		reiser4_block_nr dealloc_ext_start;
+
+		dealloc_ext_start = ext_start + ext_width - new_ext_width;
+		ret = reiser4_dealloc_blocks(&dealloc_ext_start, &new_ext_width, 0,
+					     BA_DEFER | BA_PERMANENT);
+		if (ret)
+			return ret;
+	}
+
+	new_block = new_ext_start;
+	for (reloc_ind = ext_width - new_ext_width; reloc_ind < ext_width; reloc_ind ++)
+	{
+		jnode * check;
+
+		check = get_jnode_by_mapping(inode, ext_index + reloc_ind);
+		if (IS_ERR(check))
+			return PTR_ERR(check);
+
+		assert("zam-975", relocatable(check));
+		assert("zam-986", check->blocknr != 0);
+
+		jnode_set_block(check, &new_block);
+		check->parent_item_id = EXTENT_POINTER_ID;
+		new_block ++;
+
+		JF_SET(check, JNODE_RELOC);
+		JF_SET(check, JNODE_REPACK);
+
+		jput(check);
+	}
+
+	ret = replace_end_of_extent(coord, new_ext_start, new_ext_width, done);
+	*len = new_ext_width;
+	return ret;
+}
+
+static int find_relocatable_extent (struct inode * inode, coord_t * coord,
+				    int * nr_reserved, reiser4_block_nr * len)
+{
+	reiser4_block_nr ext_width, ext_start;
+	long ext_index, reloc_end;
+	jnode * check = NULL;
+	int ret = 0;
+
+	*len = 0;
+	parse_extent(coord, &ext_start, &ext_width, &ext_index);
+
+	for (reloc_end = ext_width - 1;
+	     reloc_end >= 0 && *nr_reserved > 0; reloc_end --)
+	{
+		assert("zam-980", get_current_context()->grabbed_blocks >= *nr_reserved);
+
+		check = get_jnode_by_mapping(inode, reloc_end + ext_index);
+		if (IS_ERR(check))
+			return PTR_ERR(check);
+
+		if (check->blocknr == 0) {
+			reiser4_block_nr block;
+			block = ext_start + reloc_end;
+			jnode_set_block(check, &block);
+			check->parent_item_id = EXTENT_POINTER_ID;
+		}
+
+		if (!relocatable(check)) {
+			assert("zam-973", reloc_end < ext_width - 1);
+			goto out;
+		}
+		/* add node to transaction. */
+		ret = mark_jnode_for_repacking(check);
+		if (ret)
+			goto out;		;
+		jput(check);
+
+		(*len) ++;
+		(*nr_reserved) --;
+	}
+	if (0) {
+	out:
+		jput(check);
+	}
+	return ret;
+}
+
+static int find_and_relocate_end_of_extent (
+	struct inode * inode, coord_t * coord,
+	struct repacker_cursor * cursor, int * done)
+{
+	reiser4_block_nr len;
+	int ret;
+
+	ret = skip_not_relocatable_extent(inode, coord, done);
+	if (ret || (*done))
+		return ret;
+
+	ret = find_relocatable_extent(inode, coord, &cursor->count, &len);
+	if (ret)
+		return ret;
+	if (len == 0) {
+		*done = 1;
+		return 0;
+	}
+
+	ret = relocate_extent(inode, coord, &cursor->hint, done, &len);
+	if (ret)
+		return ret;
+	cursor->stats.jnodes_dirtied += (long)len;
+	return 0;
+}
+
+/* process (relocate) unformatted nodes in backward direction: from the end of extent to the its start.  */
+reiser4_internal int
+process_extent_backward_for_repacking (tap_t * tap, struct repacker_cursor * cursor)
+{
+	coord_t * coord = tap->coord;
+	reiser4_extent *ext;
+	struct inode * inode = NULL;
+	int done = 0;
+	int ret;
+
+	assert("zam-985", cursor->count > 0);
+	ext = extent_by_coord(coord);
+	if (state_of_extent(ext) == HOLE_EXTENT)
+		return 0;
+
+	ret = get_reiser4_inode_by_tap(&inode, tap);
+
+	while (!ret && !done)
+		ret = find_and_relocate_end_of_extent(inode, coord, cursor, &done);
+
+	iput(inode);
+	return ret;
+}
+
+/*
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   scroll-step: 1
+   End:
+*/
diff -puN plugin/item/internal.c~profile-stat-trace-repacker plugin/item/internal.c
--- reiser4/plugin/item/internal.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/internal.c	2005-02-01 11:51:12.000000000 +0300
@@ -274,6 +274,10 @@ create_hook_internal(const coord_t * ite
 		assert("nikita-3297", ZF_ISSET(child, JNODE_ORPHAN));
 		ZF_CLR(child, JNODE_ORPHAN);
 
+		ON_TRACE(TRACE_ZWEB, "create: %llx: %i [%llx]\n",
+			 *znode_get_block(item->node), item->node->c_count,
+			 *znode_get_block(child));
+
 		WUNLOCK_TREE(tree);
 		if ((left != NULL) && !keyeq(znode_get_rd_key(left),
 					     znode_get_rd_key(child))) {
@@ -329,6 +333,10 @@ kill_hook_internal(const coord_t * item 
 		init_parent_coord(&child->in_parent, NULL);
 		-- item->node->c_count;
 		WUNLOCK_TREE(tree);
+		ON_TRACE(TRACE_ZWEB, "kill: %llx: %i [%llx]\n",
+			 *znode_get_block(item->node), item->node->c_count,
+			 *znode_get_block(child));
+
 		zput(child);
 		return 0;
 	} else {
@@ -368,6 +376,7 @@ shift_hook_internal(const coord_t * item
 	if (child == NULL)
 		return 0;
 	if (!IS_ERR(child)) {
+		reiser4_stat_inc(tree.reparenting);
 		WLOCK_TREE(tree);
 		++ new_node->c_count;
 		assert("nikita-1395", znode_parent(child) == old_node);
@@ -378,6 +387,10 @@ shift_hook_internal(const coord_t * item
 		-- old_node->c_count;
 		WUNLOCK_TREE(tree);
 		zput(child);
+		ON_TRACE(TRACE_ZWEB, "shift: %llx: %i -> %lli: %i [%llx]\n",
+			 *znode_get_block(old_node),
+			 old_node->c_count, *znode_get_block(new_node),
+			 new_node->c_count, *znode_get_block(child));
 		return 0;
 	} else
 		return PTR_ERR(child);
diff -puN plugin/item/item.c~profile-stat-trace-repacker plugin/item/item.c
--- reiser4/plugin/item/item.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/item.c	2005-02-01 11:51:12.000000000 +0300
@@ -26,6 +26,7 @@ item_body_by_coord_hard(coord_t * coord 
 	assert("nikita-325", coord->node != NULL);
 	assert("nikita-326", znode_is_loaded(coord->node));
 	assert("nikita-3200", coord->offset == INVALID_OFFSET);
+	trace_stamp(TRACE_TREE);
 
 	coord->offset = node_plugin_by_node(coord->node)->item_by_coord(coord) - zdata(coord->node);
 	ON_DEBUG(coord->body_v = coord->node->times_locked);
@@ -58,8 +59,10 @@ item_length_by_coord(const coord_t * coo
 	assert("nikita-327", coord != NULL);
 	assert("nikita-328", coord->node != NULL);
 	assert("nikita-329", znode_is_loaded(coord->node));
+	trace_stamp(TRACE_TREE);
 
 	len = node_plugin_by_node(coord->node)->length_by_coord(coord);
+	check_contexts();
 	return len;
 }
 
@@ -69,6 +72,7 @@ obtain_item_plugin(const coord_t * coord
 	assert("nikita-330", coord != NULL);
 	assert("nikita-331", coord->node != NULL);
 	assert("nikita-332", znode_is_loaded(coord->node));
+	trace_stamp(TRACE_TREE);
 
 	coord_set_iplug((coord_t *) coord,
 			node_plugin_by_node(coord->node)->plugin_by_coord(coord));
@@ -85,6 +89,8 @@ item_type_by_coord(const coord_t * coord
 	assert("nikita-335", znode_is_loaded(coord->node));
 	assert("nikita-336", item_plugin_by_coord(coord) != NULL);
 
+	trace_stamp(TRACE_TREE);
+
 	return item_plugin_by_coord(coord)->b.item_type;
 }
 
@@ -97,8 +103,10 @@ item_id_by_coord(const coord_t * coord /
 	assert("vs-538", coord->node != NULL);
 	assert("vs-537", znode_is_loaded(coord->node));
 	assert("vs-536", item_plugin_by_coord(coord) != NULL);
-	assert("vs-540", item_id_by_plugin(item_plugin_by_coord(coord)) < LAST_ITEM_ID);
 
+	trace_stamp(TRACE_TREE);
+
+	assert("vs-540", item_id_by_plugin(item_plugin_by_coord(coord)) < LAST_ITEM_ID);
 	return item_id_by_plugin(item_plugin_by_coord(coord));
 }
 
@@ -111,6 +119,7 @@ item_key_by_coord(const coord_t * coord 
 	assert("nikita-338", coord != NULL);
 	assert("nikita-339", coord->node != NULL);
 	assert("nikita-340", znode_is_loaded(coord->node));
+	trace_stamp(TRACE_TREE);
 
 	return node_plugin_by_node(coord->node)->key_at(coord, key);
 }
@@ -125,6 +134,7 @@ max_item_key_by_coord(const coord_t *coo
 	assert("nikita-338", coord != NULL);
 	assert("nikita-339", coord->node != NULL);
 	assert("nikita-340", znode_is_loaded(coord->node));
+	trace_stamp(TRACE_TREE);
 
 	/* make coord pointing to last item's unit */
 	coord_dup(&last, coord);
@@ -143,6 +153,7 @@ unit_key_by_coord(const coord_t * coord 
 	assert("nikita-772", coord != NULL);
 	assert("nikita-774", coord->node != NULL);
 	assert("nikita-775", znode_is_loaded(coord->node));
+	trace_stamp(TRACE_TREE);
 
 	if (item_plugin_by_coord(coord)->b.unit_key != NULL)
 		return item_plugin_by_coord(coord)->b.unit_key(coord, key);
@@ -158,6 +169,7 @@ max_unit_key_by_coord(const coord_t * co
 	assert("nikita-772", coord != NULL);
 	assert("nikita-774", coord->node != NULL);
 	assert("nikita-775", znode_is_loaded(coord->node));
+	trace_stamp(TRACE_TREE);
 
 	if (item_plugin_by_coord(coord)->b.max_unit_key != NULL)
 		return item_plugin_by_coord(coord)->b.max_unit_key(coord, key);
@@ -195,7 +207,7 @@ paste_no_paste(coord_t * coord UNUSED_AR
 }
 
 /* default ->fast_paste() method */
-static int
+reiser4_internal int
 agree_to_fast_op(const coord_t * coord UNUSED_ARG /* coord of item */ )
 {
 	return 1;
@@ -253,6 +265,9 @@ are_items_mergeable(const coord_t * i1 /
 	iplug = item_plugin_by_coord(i1);
 	assert("nikita-1338", iplug != NULL);
 
+	IF_TRACE(TRACE_NODES, print_key("k1", item_key_by_coord(i1, &k1)));
+	IF_TRACE(TRACE_NODES, print_key("k2", item_key_by_coord(i2, &k2)));
+
 	/* NOTE-NIKITA are_items_mergeable() is also called by assertions in
 	   shifting code when nodes are in "suspended" state. */
 	assert("nikita-1663", keyle(item_key_by_coord(i1, &k1), item_key_by_coord(i2, &k2)));
@@ -569,6 +584,11 @@ item_plugin item_plugins[LAST_ITEM_ID] =
 			.max_unit_key      = max_unit_key_extent,
 			.estimate          = NULL,
 			.item_data_by_flow = NULL,
+			.show              = show_extent,
+#if REISER4_DEBUG_OUTPUT
+			.print             = print_extent,
+			.item_stat         = item_stat_extent,
+#endif
 #if REISER4_DEBUG
 			.check = check_extent
 #endif
@@ -624,6 +644,11 @@ item_plugin item_plugins[LAST_ITEM_ID] =
 			.max_unit_key      = unit_key_tail,
 			.estimate          = NULL,
 			.item_data_by_flow = NULL,
+			.show              = show_tail,
+#if REISER4_DEBUG_OUTPUT
+			.print             = NULL,
+			.item_stat         = NULL,
+#endif
 #if REISER4_DEBUG
 			.check             = NULL
 #endif
diff -puN plugin/item/item.h~profile-stat-trace-repacker plugin/item/item.h
--- reiser4/plugin/item/item.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/item.h	2005-02-01 11:51:12.000000000 +0300
@@ -167,7 +167,15 @@ typedef struct {
 	/* converts flow @f to item data. @coord == 0 on insert */
 	int (*item_data_by_flow) (const coord_t *, const flow_t *, reiser4_item_data *);
 
-	/*void (*show) (struct seq_file *, coord_t *);*/
+	void (*show) (struct seq_file *, coord_t *);
+
+#if REISER4_DEBUG_OUTPUT
+	/* used for debugging only, prints an ascii description of the
+	   item contents */
+	void (*print) (const char *, coord_t *);
+	/* gather statistics */
+	void (*item_stat) (const coord_t *, void *);
+#endif
 
 #if REISER4_DEBUG
 	/* used for debugging, every item should have here the most
@@ -338,6 +346,7 @@ item_plugin_by_coord(const coord_t * coo
 	assert("nikita-330", coord != NULL);
 	assert("nikita-331", coord->node != NULL);
 	assert("nikita-332", znode_is_loaded(coord->node));
+	trace_stamp(TRACE_TREE);
 
 	if (unlikely(!coord_is_iplug_set(coord)))
 		obtain_item_plugin(coord);
@@ -365,6 +374,7 @@ item_body_by_coord(const coord_t * coord
 	assert("nikita-324", coord != NULL);
 	assert("nikita-325", coord->node != NULL);
 	assert("nikita-326", znode_is_loaded(coord->node));
+	trace_stamp(TRACE_TREE);
 
 	if (coord->offset == INVALID_OFFSET)
 		item_body_by_coord_hard((coord_t *)coord);
diff -puN plugin/item/sde.c~profile-stat-trace-repacker plugin/item/sde.c
--- reiser4/plugin/item/sde.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/sde.c	2005-02-01 11:51:12.000000000 +0300
@@ -156,7 +156,7 @@ add_entry_de(struct inode *dir /* direct
 	dent = (directory_entry_format *) item_body_by_coord(coord);
 	build_inode_key_id(entry->obj, &dent->id);
 	if (longname) {
-		memcpy(dent->name, name, len);
+		xmemcpy(dent->name, name, len);
 		cputod8(0, &dent->name[len]);
 	}
 	return 0;
diff -puN plugin/item/static_stat.c~profile-stat-trace-repacker plugin/item/static_stat.c
--- reiser4/plugin/item/static_stat.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/static_stat.c	2005-02-01 11:51:12.000000000 +0300
@@ -598,7 +598,7 @@ symlink_target_to_inode(struct inode *in
 	if (!inode->u.generic_ip)
 		return RETERR(-ENOMEM);
 
-	memcpy((char *) (inode->u.generic_ip), target, (size_t) len);
+	xmemcpy((char *) (inode->u.generic_ip), target, (size_t) len);
 	((char *) (inode->u.generic_ip))[len] = 0;
 	inode_set_flag(inode, REISER4_GENERIC_PTR_USED);
 	return 0;
@@ -663,7 +663,7 @@ save_symlink_sd(struct inode *inode, cha
 		result = symlink_target_to_inode(inode, target, length);
 
 		/* copy symlink to stat data */
-		memcpy(sd->body, target, (size_t) length);
+		xmemcpy(sd->body, target, (size_t) length);
 		(*area)[length] = 0;
 	} else {
 		/* there is nothing to do in update but move area */
@@ -791,6 +791,7 @@ present_plugin_sd(struct inode *inode /*
 		} else {
 			warning("nikita-658", "duplicate plugin for %llu",
 				(unsigned long long)get_inode_oid(inode));
+			print_plugin("plugin", plugin);
 			return RETERR(-EINVAL);
 		}
 		move_on(len, area, sizeof *slot);
@@ -970,7 +971,7 @@ static int crypto_stat_to_inode (struct 
 	}
 	/* load inode crypto-stat */
 	stat->keysize = tmp->keysize;
-	memcpy(stat->keyid, tmp->keyid, (size_t)size);
+	xmemcpy(stat->keyid, tmp->keyid, (size_t)size);
 	reiser4_inode_data(inode)->crypt = stat;
 
 	inode_set_flag(inode, REISER4_CRYPTO_STAT_LOADED);
@@ -1042,7 +1043,7 @@ static int save_crypto_sd(struct inode *
 
 		/* copy inode crypto-stat to the disk stat-data */
 		cputod16(stat->keysize, &sd->keysize);
-		memcpy(sd->keyid, stat->keyid, (size_t)dplug->dsize);
+		xmemcpy(sd->keyid, stat->keyid, (size_t)dplug->dsize);
 		inode_set_flag(inode, REISER4_CRYPTO_STAT_LOADED);
 	} else {
 		/* do nothing */
diff -puN plugin/item/tail.c~profile-stat-trace-repacker plugin/item/tail.c
--- reiser4/plugin/item/tail.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/item/tail.c	2005-02-01 11:51:12.000000000 +0300
@@ -133,7 +133,7 @@ paste_tail(coord_t *coord, reiser4_item_
 	if (coord->unit_pos == 0)
 		/* make space for pasted data when pasting at the beginning of
 		   the item */
-		memmove(item + data->length, item, old_item_length);
+		xmemmove(item + data->length, item, old_item_length);
 
 	if (coord->between == AFTER_UNIT)
 		coord->unit_pos++;
@@ -147,9 +147,9 @@ paste_tail(coord_t *coord, reiser4_item_
 			__copy_from_user(item + coord->unit_pos, data->data, (unsigned) data->length);
 		} else
 			/* copy from kernel space */
-			memcpy(item + coord->unit_pos, data->data, (unsigned) data->length);
+			xmemcpy(item + coord->unit_pos, data->data, (unsigned) data->length);
 	} else {
-		memset(item + coord->unit_pos, 0, (unsigned) data->length);
+		xmemset(item + coord->unit_pos, 0, (unsigned) data->length);
 	}
 	return 0;
 }
@@ -183,16 +183,16 @@ copy_units_tail(coord_t *target, coord_t
 		/* append item @target with @count first bytes of @source */
 		assert("vs-365", from == 0);
 
-		memcpy((char *) item_body_by_coord(target) +
-		       item_length_by_coord(target) - count, (char *) item_body_by_coord(source), count);
+		xmemcpy((char *) item_body_by_coord(target) +
+			item_length_by_coord(target) - count, (char *) item_body_by_coord(source), count);
 	} else {
 		/* target item is moved to right already */
 		reiser4_key key;
 
 		assert("vs-367", (unsigned) item_length_by_coord(source) == from + count);
 
-		memcpy((char *) item_body_by_coord(target), (char *) item_body_by_coord(source) + from, count);
-		
+		xmemcpy((char *) item_body_by_coord(target), (char *) item_body_by_coord(source) + from, count);
+
 		/* new units are inserted before first unit in an item,
 		   therefore, we have to update item key */
 		item_key_by_coord(source, &key);
@@ -256,7 +256,7 @@ do_cut_or_kill(coord_t *coord, pos_in_no
 	}
 
 	if (REISER4_DEBUG)
-		memset((char *) item_body_by_coord(coord) + from, 0, count);
+		xmemset((char *) item_body_by_coord(coord) + from, 0, count);
 	return count;
 }
 
@@ -318,9 +318,7 @@ overwrite_tail(coord_t *coord, flow_t *f
 }
 
 /* tail redpage function. It is called from readpage_tail(). */
-static int
-do_readpage_tail(uf_coord_t *uf_coord, struct page *page)
-{
+reiser4_internal int do_readpage_tail(uf_coord_t *uf_coord, struct page *page) {
 	tap_t tap;
 	int result;
 	coord_t coord;
@@ -354,8 +352,8 @@ do_readpage_tail(uf_coord_t *uf_coord, s
 		pagedata = kmap_atomic(page, KM_USER0);
 
 		/* copying tail body to page. */
-		memcpy(pagedata + mapped,
-		       ((char *)item_body_by_coord(&coord) + coord.unit_pos), count);
+		xmemcpy(pagedata + mapped,
+			((char *)item_body_by_coord(&coord) + coord.unit_pos), count);
 
 		flush_dcache_page(page);
 
diff -puN plugin/node/node40.c~profile-stat-trace-repacker plugin/node/node40.c
--- reiser4/plugin/node/node40.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/node/node40.c	2005-02-01 11:51:12.000000000 +0300
@@ -1,5 +1,6 @@
 /* Copyright 2001, 2002, 2003 by Hans Reiser, licensing governed by reiser4/README */
 
+/*#include "../../forward.h"*/
 #include "../../debug.h"
 #include "../../key.h"
 #include "../../coord.h"
@@ -34,7 +35,7 @@
 */
 /* NIKITA-FIXME-HANS: I told you guys not less than 10 times to not call it r4fs.  Change to "ReIs". */
 /* magic number that is stored in ->magic field of node header */
-static const __u32 REISER4_NODE_MAGIC = 0x52344653;	/* (*(__u32 *)"R4FS"); */
+const __u32 REISER4_NODE_MAGIC = 0x52344653;	/* (*(__u32 *)"R4FS"); */
 
 static int prepare_for_update(znode * left, znode * right, carry_plugin_info * info);
 
@@ -118,6 +119,20 @@ nh40_set_mkfs_id(node40_header * nh, __u
 	cputod32(id, &nh->mkfs_id);
 }
 
+static inline __u32
+nh40_get_mkfs_id(node40_header * nh)
+{
+	return d32tocpu(&nh->mkfs_id);
+}
+
+#if 0
+static void
+nh40_set_flush_id(node40_header * nh, __u64 id)
+{
+	cputod64(id, &nh->flush.flush_id);
+}
+#endif
+
 static inline __u64
 nh40_get_flush_id(node40_header * nh)
 {
@@ -175,6 +190,7 @@ reiser4_internal size_t free_space_node4
 	assert("nikita-577", node != NULL);
 	assert("nikita-578", znode_is_loaded(node));
 	assert("nikita-579", zdata(node) != NULL);
+	trace_stamp(TRACE_NODES);
 
 	return nh40_get_free_space(node40_node_header(node));
 }
@@ -185,6 +201,7 @@ reiser4_internal size_t free_space_node4
 static inline short
 node40_num_of_items_internal(const znode * node)
 {
+	trace_stamp(TRACE_NODES);
 	return nh40_get_num_items(node40_node_header(node));
 }
 
@@ -204,6 +221,7 @@ static inline void check_num_items(const
 reiser4_internal int
 num_of_items_node40(const znode * node)
 {
+	trace_stamp(TRACE_NODES);
 	return node40_num_of_items_internal(node);
 }
 
@@ -305,7 +323,7 @@ key_at_node40(const coord_t * coord, rei
 
 	/* @coord is set to existing item */
 	ih = node40_ih_at_coord(coord);
-	memcpy(key, &ih->key, sizeof (reiser4_key));
+	xmemcpy(key, &ih->key, sizeof (reiser4_key));
 	return key;
 }
 
@@ -344,7 +362,13 @@ lookup_node40(znode * node /* node to qu
 	assert("nikita-2693", znode_is_any_locked(node));
 	cassert(REISER4_SEQ_SEARCH_BREAK > 2);
 
+	trace_stamp(TRACE_NODES);
+
 	items = node_num_items(node);
+	NODE_INCSTAT(node, calls);
+	NODE_ADDSTAT(node, items, items);
+
+	node_check(node, REISER4_NODE_DKEYS);
 
 	if (unlikely(items == 0)) {
 		coord_init_first_unit(coord, node);
@@ -388,6 +412,7 @@ lookup_node40(znode * node /* node to qu
 
 		assert("nikita-1084", median >= 0);
 		assert("nikita-1085", median < items);
+		NODE_INCSTAT(node, binary);
 		switch (keycmp(key, &medianh->key)) {
 		case LESS_THAN:
 			right = median;
@@ -420,6 +445,7 @@ lookup_node40(znode * node /* node to qu
 		for (left = right, ih = righth; left >= 0; ++ ih, -- left) {
 			cmp_t comparison;
 
+			NODE_INCSTAT(node, seq);
 			prefetchkey(&(ih + 1)->key);
 			comparison = keycmp(&ih->key, key);
 			if (comparison == GREATER_THAN)
@@ -561,6 +587,8 @@ check_node40(const znode * node /* node 
 	assert("nikita-580", node != NULL);
 	assert("nikita-581", error != NULL);
 	assert("nikita-2948", znode_is_loaded(node));
+	trace_stamp(TRACE_NODES);
+
 
 	if (ZF_ISSET(node, JNODE_HEARD_BANSHEE))
 		return 0;
@@ -688,6 +716,7 @@ check_node40(const znode * node /* node 
 		flags |= REISER4_NODE_TREE_STABLE;
 
 		if (keygt(&prev, znode_get_rd_key((znode *)node))) {
+			reiser4_stat_inc(tree.rd_key_skew);
 			if (flags & REISER4_NODE_TREE_STABLE) {
 				*error = "Last key is greater than rdkey";
 				return -1;
@@ -760,7 +789,10 @@ init_node40(znode * node /* node to init
 	assert("nikita-572", zdata(node) != NULL);
 
 	header = node40_node_header(node);
-	memset(header, 0, sizeof (node40_header));
+	if (REISER4_ZERO_NEW_NODE)
+		xmemset(zdata(node), 0, (unsigned int) znode_size(node));
+	else
+		xmemset(header, 0, sizeof (node40_header));
 	nh40_set_free_space(header, znode_size(node) - sizeof (node40_header));
 	nh40_set_free_space_start(header, sizeof (node40_header));
 	/* sane hypothesis: 0 in CPU format is 0 in disk format */
@@ -775,7 +807,6 @@ init_node40(znode * node /* node to init
 	return 0;
 }
 
-#ifdef GUESS_EXISTS
 reiser4_internal int
 guess_node40(const znode * node /* node to guess plugin of */ )
 {
@@ -788,6 +819,19 @@ guess_node40(const znode * node /* node 
 	    (plugin_by_disk_id(znode_get_tree(node),
 			       REISER4_NODE_PLUGIN_TYPE, &nethack->common_header.plugin_id)->h.id == NODE40_ID);
 }
+
+#if REISER4_DEBUG_OUTPUT
+reiser4_internal void
+print_node40(const char *prefix, const znode * node /* node to print */ ,
+	     __u32 flags UNUSED_ARG /* print flags */ )
+{
+	node40_header *header;
+
+	header = node40_node_header(node);
+	printk("%s: BLOCKNR %Lu FREE_SPACE %u, LEVEL %u, ITEM_NUMBER %u\n",
+	       prefix,
+	       *znode_get_block(node), nh40_get_free_space(header), nh40_get_level(header), nh40_get_num_items(header));
+}
 #endif
 
 /* plugin->u.node.chage_item_size
@@ -801,6 +845,8 @@ change_item_size_node40(coord_t * coord,
 	int item_length;
 	unsigned i;
 
+	node_check(coord->node, 0);
+
 	/* make sure that @item is coord of existing item */
 	assert("vs-210", coord_is_existing_item(coord));
 
@@ -811,8 +857,8 @@ change_item_size_node40(coord_t * coord,
 
 	/* move item bodies */
 	ih = node40_ih_at_coord(coord);
-	memmove(item_data + item_length + by, item_data + item_length,
-		nh40_get_free_space_start(node40_node_header(coord->node)) - (ih40_get_offset(ih) + item_length));
+	xmemmove(item_data + item_length + by, item_data + item_length,
+		 nh40_get_free_space_start(node40_node_header(coord->node)) - (ih40_get_offset(ih) + item_length));
 
 	/* update offsets of moved items */
 	for (i = coord->item_pos + 1; i < nh40_get_num_items(nh); i++) {
@@ -842,6 +888,8 @@ create_item_node40(coord_t * target, con
 	unsigned offset;
 	unsigned i;
 
+	node_check(target->node, 0);
+
 	nh = node40_node_header(target->node);
 
 	assert("vs-212", coord_is_between_items(target));
@@ -861,7 +909,7 @@ create_item_node40(coord_t * target, con
 		/* new item will start at this offset */
 		offset = ih40_get_offset(ih);
 
-		memmove(zdata(target->node) + offset + data->length,
+		xmemmove(zdata(target->node) + offset + data->length,
 			 zdata(target->node) + offset, nh40_get_free_space_start(nh) - offset);
 		/* update headers of moved items */
 		for (i = target->item_pos; i < nh40_get_num_items(nh); i++) {
@@ -870,7 +918,7 @@ create_item_node40(coord_t * target, con
 		}
 
 		/* @ih is set to item header of the last item, move item headers */
-		memmove(ih - 1, ih, sizeof (item_header40) * (nh40_get_num_items(nh) - target->item_pos));
+		xmemmove(ih - 1, ih, sizeof (item_header40) * (nh40_get_num_items(nh) - target->item_pos));
 	} else {
 		/* new item will start at this offset */
 		offset = nh40_get_free_space_start(nh);
@@ -878,7 +926,7 @@ create_item_node40(coord_t * target, con
 
 	/* make item header for the new item */
 	ih = node40_ih_at_coord(target);
-	memcpy(&ih->key, key, sizeof (reiser4_key));
+	xmemcpy(&ih->key, key, sizeof (reiser4_key));
 	ih40_set_offset(ih, offset);
 	save_plugin_id(item_plugin_to_plugin(data->iplug), &ih->plugin_id);
 
@@ -910,7 +958,7 @@ create_item_node40(coord_t * target, con
 			__copy_from_user(zdata(target->node) + offset, data->data, (unsigned) data->length);
 		} else
 			/* copy from kernel space */
-			memcpy(zdata(target->node) + offset, data->data, (unsigned) data->length);
+			xmemcpy(zdata(target->node) + offset, data->data, (unsigned) data->length);
 	}
 
 	if (target->item_pos == 0) {
@@ -922,6 +970,7 @@ create_item_node40(coord_t * target, con
 		item_plugin_by_coord(target)->b.create_hook(target, data->arg);
 	}
 
+	node_check(target->node, 0);
 	return 0;
 }
 
@@ -933,7 +982,7 @@ update_item_key_node40(coord_t * target,
 	item_header40 *ih;
 
 	ih = node40_ih_at_coord(target);
-	memcpy(&ih->key, key, sizeof (reiser4_key));
+	xmemcpy(&ih->key, key, sizeof (reiser4_key));
 
 	if (target->item_pos == 0) {
 		prepare_for_update(NULL, target->node, info);
@@ -990,8 +1039,8 @@ compact(znode *node, struct cut40_info *
 	nr_items = nh40_get_num_items(nh);
 
 	/* remove gap made up by removal */
-	memmove(zdata(node) + cinfo->freed_space_start, zdata(node) + cinfo->freed_space_end,
-		nh40_get_free_space_start(nh) - cinfo->freed_space_end);
+	xmemmove(zdata(node) + cinfo->freed_space_start, zdata(node) + cinfo->freed_space_end,
+		 nh40_get_free_space_start(nh) - cinfo->freed_space_end);
 
 	/* update item headers of moved items - change their locations */
 	pos = cinfo->first_moved;
@@ -1015,8 +1064,8 @@ compact(znode *node, struct cut40_info *
 	if (cinfo->removed_count != MAX_POS_IN_NODE) {
 		/* number of items changed. Remove item headers of those items */
 		ih = node40_ih_at(node, nr_items - 1);
-		memmove(ih + cinfo->removed_count, ih,
-			sizeof (item_header40) * (nr_items - cinfo->removed_count - cinfo->first_removed));
+		xmemmove(ih + cinfo->removed_count, ih,
+			 sizeof (item_header40) * (nr_items - cinfo->removed_count - cinfo->first_removed));
 		freed += sizeof (item_header40) * cinfo->removed_count;
 		node40_set_num_items(node, nh, nr_items - cinfo->removed_count);
 	}
@@ -1039,6 +1088,7 @@ shrink_item_node40(coord_t *coord, int d
 	assert("nikita-3488", delta >= 0);
 
 	node = coord->node;
+	node_check(node, 0);
 	nh = node40_node_header(node);
 	nr_items = nh40_get_num_items(nh);
 
@@ -1047,7 +1097,7 @@ shrink_item_node40(coord_t *coord, int d
 	end = zdata(node) + ih40_get_offset(ih) + length_by_coord_node40(coord);
 
 	/* remove gap made up by removal */
-	memmove(end - delta, end, nh40_get_free_space_start(nh) - delta);
+	xmemmove(end - delta, end, nh40_get_free_space_start(nh) - delta);
 
 	/* update item headers of moved items - change their locations */
 	pos = coord->item_pos + 1;
@@ -1307,7 +1357,7 @@ prepare_for_compact(struct cut40_info *c
 			ih = node40_ih_at(node, item_pos);
 
 			if (params->smallest_removed)
-				memcpy(params->smallest_removed, &ih->key, sizeof (reiser4_key));
+				xmemcpy(params->smallest_removed, &ih->key, sizeof (reiser4_key));
 
 			cinfo->freed_space_start = ih40_get_offset(ih);
 
@@ -1379,7 +1429,7 @@ prepare_for_compact(struct cut40_info *c
 			ih = node40_ih_at(node, item_pos);
 
 			if (params->smallest_removed)
-				memcpy(params->smallest_removed, &ih->key, sizeof (reiser4_key));
+				xmemcpy(params->smallest_removed, &ih->key, sizeof (reiser4_key));
 
 			freed = kill_head_f(params->to, data, 0, &new_first_key);
 
@@ -1431,6 +1481,7 @@ kill_node40(struct carry_kill_data *kdat
 	int first_key_changed;
 
 	node = kdata->params.from->node;
+	node_check(node, 0);
 
 	first_key_changed = prepare_for_compact(&cinfo, &kdata->params, 0/* not cut */, kdata, info);
 	compact(node, &cinfo);
@@ -1449,6 +1500,7 @@ kill_node40(struct carry_kill_data *kdat
 	coord_clear_iplug(kdata->params.from);
 	coord_clear_iplug(kdata->params.to);
 
+	node_check(node, 0);
 	znode_make_dirty(node);
 	return cinfo.removed_count == MAX_POS_IN_NODE ? 0 : cinfo.removed_count;
 }
@@ -1463,6 +1515,7 @@ cut_node40(struct carry_cut_data *cdata,
 	int first_key_changed;
 
 	node = cdata->params.from->node;
+	node_check(node, 0);
 
 	first_key_changed = prepare_for_compact(&cinfo, &cdata->params, 1/* not cut */, cdata, info);
 	compact(node, &cinfo);
@@ -1481,6 +1534,7 @@ cut_node40(struct carry_cut_data *cdata,
 	coord_clear_iplug(cdata->params.from);
 	coord_clear_iplug(cdata->params.to);
 
+	node_check(node, 0);
 	znode_make_dirty(node);
 	return cinfo.removed_count == MAX_POS_IN_NODE ? 0 : cinfo.removed_count ;
 }
@@ -1720,6 +1774,8 @@ copy_units(coord_t * target, coord_t * s
 	assert("nikita-1464", source != NULL);
 	assert("nikita-1465", from + count <= coord_num_units(source));
 
+	IF_TRACE(TRACE_COORDS, print_coord("copy_units source:", source, 0));
+
 	iplug = item_plugin_by_coord(source);
 	assert("nikita-1468", iplug == item_plugin_by_coord(target));
 	iplug->b.copy_units(target, source, from, count, dir, free_space);
@@ -1760,6 +1816,8 @@ copy(struct shift_params *shift)
 
 	from = shift->wish_stop;
 
+	IF_TRACE(TRACE_COORDS, print_coord("node40_copy from:", &from, 0));
+
 	coord_init_first_unit(&to, shift->target);
 
 	/* NOTE:NIKITA->VS not sure what I am doing: shift->target is empty,
@@ -1785,8 +1843,11 @@ copy(struct shift_params *shift)
 			nh40_set_free_space_start(nh, (unsigned) free_space_start);
 			nh40_set_free_space(nh, nh40_get_free_space(nh) - shift->merging_bytes);
 
+			IF_TRACE(TRACE_COORDS, print_coord("before copy_units from:", &from, 0));
+			IF_TRACE(TRACE_COORDS, print_coord("before copy_units to:", &to, 0));
+
 			/* appending last item of @target */
-			copy_units(&to, &from, 0, /* starting from 0-th unit */
+			copy_units(&to, &from, 0,	/* starting from 0-th unit */
 				   shift->merging_units, SHIFT_LEFT, shift->merging_bytes);
 			coord_inc_item_pos(&from);
 			from_ih--;
@@ -1798,8 +1859,8 @@ copy(struct shift_params *shift)
 			/* copy @entire items entirely */
 
 			/* copy item headers */
-			memcpy(to_ih - shift->entire + 1,
-			       from_ih - shift->entire + 1, shift->entire * sizeof (item_header40));
+			xmemcpy(to_ih - shift->entire + 1,
+				from_ih - shift->entire + 1, shift->entire * sizeof (item_header40));
 			/* update item header offset */
 			old_offset = ih40_get_offset(from_ih);
 			/* AUDIT: Looks like if we calculate old_offset + free_space_start here instead of just old_offset, we can perform one "add" operation less per each iteration */
@@ -1807,8 +1868,8 @@ copy(struct shift_params *shift)
 				ih40_set_offset(to_ih, ih40_get_offset(from_ih) - old_offset + free_space_start);
 
 			/* copy item bodies */
-			memcpy(zdata(shift->target) + free_space_start, zdata(from.node) + old_offset,	/*ih40_get_offset (from_ih), */
-			       shift->entire_bytes);
+			xmemcpy(zdata(shift->target) + free_space_start, zdata(from.node) + old_offset,	/*ih40_get_offset (from_ih), */
+				shift->entire_bytes);
 
 			coord_add_item_pos(&from, (int) shift->entire);
 			coord_add_item_pos(&to, (int) shift->entire);
@@ -1830,7 +1891,7 @@ copy(struct shift_params *shift)
 			/* copy item header of partially copied item */
 			coord_set_item_pos(&to, node40_num_of_items_internal(to.node)
 					   - 1);
-			memcpy(to_ih, from_ih, sizeof (item_header40));
+			xmemcpy(to_ih, from_ih, sizeof (item_header40));
 			ih40_set_offset(to_ih, nh40_get_free_space_start(nh) - shift->part_bytes);
 			if (item_plugin_by_coord(&to)->b.init)
 				item_plugin_by_coord(&to)->b.init(&to, &from, 0);
@@ -1846,9 +1907,9 @@ copy(struct shift_params *shift)
 		coord_set_item_pos(&to, 0);
 
 		/* prepare space for new items */
-		memmove(zdata(to.node) + sizeof (node40_header) +
-			shift->shift_bytes,
-			zdata(to.node) + sizeof (node40_header), free_space_start - sizeof (node40_header));
+		xmemmove(zdata(to.node) + sizeof (node40_header) +
+			 shift->shift_bytes,
+			 zdata(to.node) + sizeof (node40_header), free_space_start - sizeof (node40_header));
 		/* update item headers of moved items */
 		to_ih = node40_ih_at(to.node, 0);
 		/* first item gets @merging_bytes longer. free space appears
@@ -1860,7 +1921,7 @@ copy(struct shift_params *shift)
 			ih40_set_offset(to_ih - i, ih40_get_offset(to_ih - i) + shift->shift_bytes);
 
 		/* move item headers to make space for new items */
-		memmove(to_ih - old_items + 1 - new_items, to_ih - old_items + 1, sizeof (item_header40) * old_items);
+		xmemmove(to_ih - old_items + 1 - new_items, to_ih - old_items + 1, sizeof (item_header40) * old_items);
 		to_ih -= (new_items - 1);
 
 		nh40_set_free_space_start(nh, free_space_start + shift->shift_bytes);
@@ -1888,7 +1949,7 @@ copy(struct shift_params *shift)
 			/* copy @entire items entirely */
 
 			/* copy item headers */
-			memcpy(to_ih, from_ih, shift->entire * sizeof (item_header40));
+			xmemcpy(to_ih, from_ih, shift->entire * sizeof (item_header40));
 
 			/* update item header offset */
 			old_offset = ih40_get_offset(from_ih + shift->entire - 1);
@@ -1899,9 +1960,9 @@ copy(struct shift_params *shift)
 						old_offset + sizeof (node40_header) + shift->part_bytes);
 			/* copy item bodies */
 			coord_add_item_pos(&from, -(int) (shift->entire - 1));
-			memcpy(zdata(to.node) + sizeof (node40_header) +
-			       shift->part_bytes, item_by_coord_node40(&from),
-			       shift->entire_bytes);
+			xmemcpy(zdata(to.node) + sizeof (node40_header) +
+				shift->part_bytes, item_by_coord_node40(&from),
+				shift->entire_bytes);
 			coord_dec_item_pos(&from);
 		}
 
@@ -1913,7 +1974,7 @@ copy(struct shift_params *shift)
 			   a new item into @target->node */
 
 			/* copy item header of partially copied item */
-			memcpy(to_ih, from_ih, sizeof (item_header40));
+			xmemcpy(to_ih, from_ih, sizeof (item_header40));
 			ih40_set_offset(to_ih, sizeof (node40_header));
 			if (item_plugin_by_coord(&to)->b.init)
 				item_plugin_by_coord(&to)->b.init(&to, &from, 0);
@@ -2591,13 +2652,15 @@ shift_check(void *vp, const znode *left,
 
 #endif
 
+ON_DEBUG_MODIFY(extern __u32 znode_checksum(const znode * node);)
+
 /* plugin->u.node.shift
    look for description of this method in plugin/node/node.h */
 reiser4_internal int
 shift_node40(coord_t *from, znode *to, shift_direction pend,
-	     int delete_child,	/* if @from->node becomes empty - it will be
-				   deleted from the tree if this is set to 1 */
-	     int including_stop_coord,
+	     int delete_child,	/* if @from->node becomes empty - it will be deleted from the tree if this is set to
+				   1 */
+	     int including_stop_coord /* */ ,
 	     carry_plugin_info *info)
 {
 	struct shift_params shift;
@@ -2605,16 +2668,23 @@ shift_node40(coord_t *from, znode *to, s
 	znode *left, *right;
 	znode *source;
 	int target_empty;
+#if REISER4_DEBUG
+	struct shift_check *check_data;
+#endif
 
 	assert("nikita-2161", coord_check(from));
 
-	memset(&shift, 0, sizeof (shift));
+	ON_DEBUG_MODIFY(znode_set_checksum(ZJNODE(to), 0));
+
+	xmemset(&shift, 0, sizeof (shift));
 	shift.pend = pend;
 	shift.wish_stop = *from;
 	shift.target = to;
 
 	assert("nikita-1473", znode_is_write_locked(from->node));
 	assert("nikita-1474", znode_is_write_locked(to));
+	node_check(from->node, 0);
+	node_check(to, 0);
 
 	source = from->node;
 
@@ -2654,6 +2724,8 @@ shift_node40(coord_t *from, znode *to, s
 
 	target_empty = node_is_empty(to);
 
+	ON_DEBUG_MODIFY(assert("nikita-3427", to->cksum == znode_checksum(to)));
+
 	/* when first node plugin with item body compression is implemented,
 	   this must be changed to call node specific plugin */
 
@@ -2663,9 +2735,15 @@ shift_node40(coord_t *from, znode *to, s
 	if (!shift.shift_bytes) {
 		/* we could not shift anything */
 		assert("nikita-2079", coord_check(from));
+		ON_DEBUG_MODIFY(assert("nikita-3433",
+				       to->cksum == znode_checksum(to)));
 		return 0;
 	}
 
+	ON_DEBUG(check_data = shift_check_prepare(left, right));
+
+	IF_TRACE(TRACE_COORDS, print_coord("shift->wish_stop before copy:", &shift.wish_stop, 0));
+
 	copy(&shift);
 
 	/* result value of this is important. It is used by adjust_coord below */
@@ -2704,7 +2782,23 @@ shift_node40(coord_t *from, znode *to, s
 		   will be removing the pointer to node @from->node */
 		result = prepare_removal_node40(source, info);
 	}
+
+#ifdef DEBUGGING_SHIFT
+	dinfo("SHIFT TO %s: merging %d, entire %d, part %d, size %d\n",
+	      shift.pend == SHIFT_LEFT ? "LEFT" : "RIGHT",
+	      shift.merging_units, shift.entire, shift.part_units, shift.shift_bytes);
+#endif
+	ON_TRACE(TRACE_SHIFT, "shift: [%Li] %s--%s [%Li]: %i\n",
+		 *znode_get_block(left),
+		 (shift.pend == SHIFT_LEFT) ? "<" : "",
+		 (shift.pend == SHIFT_LEFT) ? "" : ">", *znode_get_block(right), shift.shift_bytes);
+
+	node_check(source, 0);
+	node_check(to, 0);
 	assert("nikita-2080", coord_check(from));
+
+	ON_DEBUG(shift_check(check_data, left, right));
+
 	return result ? result : (int) shift.shift_bytes;
 }
 
diff -puN plugin/node/node40.h~profile-stat-trace-repacker plugin/node/node40.h
--- reiser4/plugin/node/node40.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/node/node40.h	2005-02-01 11:51:12.000000000 +0300
@@ -79,10 +79,11 @@ reiser4_key *key_at_node40(const coord_t
 size_t estimate_node40(znode * node);
 int check_node40(const znode * node, __u32 flags, const char **error);
 int parse_node40(znode * node);
+#if REISER4_DEBUG_OUTPUT
+void print_node40(const char *prefix, const znode * node, __u32 flags);
+#endif
 int init_node40(znode * node);
-#if GUESS_EXISTS
 int guess_node40(const znode * node);
-#endif
 void change_item_size_node40(coord_t * coord, int by);
 int create_item_node40(coord_t * target, const reiser4_key * key, reiser4_item_data * data, carry_plugin_info * info);
 void update_item_key_node40(coord_t * target, const reiser4_key * key, carry_plugin_info * info);
diff -puN plugin/node/node.c~profile-stat-trace-repacker plugin/node/node.c
--- reiser4/plugin/node/node.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/node/node.c	2005-02-01 11:51:12.000000000 +0300
@@ -74,6 +74,251 @@ leftmost_key_in_node(const znode * node 
 	return key;
 }
 
+#if REISER4_DEBUG_OUTPUT
+/* helper function: convert 4 bit integer to its hex representation */
+/* Audited by: green(2002.06.12) */
+static char
+hex_to_ascii(const int hex /* hex digit */ )
+{
+	assert("nikita-1081", (0 <= hex) && (hex < 0x10));
+
+	if (hex < 10)
+		return '0' + hex;
+	else
+		return 'a' + hex - 10;
+}
+
+/* helper function used to indent output during recursive tree printing */
+/* Audited by: green(2002.06.12) */
+reiser4_internal void
+indent(unsigned indentation)
+{
+	unsigned i;
+
+	for (i = 0; i < indentation; ++i)
+		printk("%.1i........", indentation - i);
+}
+
+/* helper function used to indent output for @node during recursive tree
+   printing */
+reiser4_internal void
+indent_znode(const znode * node /* current node */ )
+{
+	if (znode_get_tree(node)->height < znode_get_level(node))
+		indent(0);
+	else
+		indent(znode_get_tree(node)->height - znode_get_level(node));
+}
+
+/* debugging aid: output human readable information about @node */
+reiser4_internal void
+print_node_content(const char *prefix /* output prefix */ ,
+		   const znode * node /* node to print */ ,
+		   __u32 flags /* print flags */ )
+{
+	unsigned short i;
+	coord_t coord;
+	item_plugin *iplug;
+	reiser4_key key;
+
+	if (!znode_is_loaded(node)) {
+		print_znode("znode is not loaded\n", node);
+		return;
+	}
+	if (node_plugin_by_node(node)->print != NULL) {
+		indent_znode(node);
+		node_plugin_by_node(node)->print(prefix, node, flags);
+
+		indent_znode(node);
+		print_key("LDKEY", &node->ld_key);
+
+		indent_znode(node);
+		print_key("RDKEY", &node->rd_key);
+	}
+
+	/*if( flags & REISER4_NODE_SILENT ) {return;} */
+
+	coord.node = (znode *) node;
+	coord.unit_pos = 0;
+	coord.between = AT_UNIT;
+	/*indent_znode (node); */
+	for (i = 0; i < node_num_items(node); i++) {
+		int j;
+		int length;
+		char *data;
+
+		indent_znode(node);
+		printk("%d: ", i);
+
+		coord_set_item_pos(&coord, i);
+
+		iplug = item_plugin_by_coord(&coord);
+		print_plugin("\titem plugin", item_plugin_to_plugin(iplug));
+		indent_znode(node);
+		item_key_by_coord(&coord, &key);
+		print_key("\titem key", &key);
+
+		indent_znode(node);
+		printk("\tlength %d\n", item_length_by_coord(&coord));
+		indent_znode(node);
+		iplug->b.print("\titem", &coord);
+
+		data = item_body_by_coord(&coord);
+		length = item_length_by_coord(&coord);
+		indent_znode(node);
+		printk("\titem length: %i, offset: %i\n", length, data - zdata(node));
+		for (j = 0; j < length; ++j) {
+			char datum;
+
+			if ((j % 16) == 0) {
+				/* next 16 bytes */
+				if (j == 0) {
+					indent_znode(node);
+					printk("\tdata % .2i: ", j);
+				} else {
+					printk("\n");
+					indent_znode(node);
+					printk("\t     % .2i: ", j);
+				}
+			}
+			datum = data[j];
+			printk("%c", hex_to_ascii((datum & 0xf0) >> 4));
+			printk("%c ", hex_to_ascii(datum & 0xf));
+		}
+		printk("\n");
+		indent_znode(node);
+		printk("======================\n");
+	}
+	printk("\n");
+}
+
+/* debugging aid: output human readable information about @node
+   the same as the above, but items to be printed must be specified */
+reiser4_internal void
+print_node_items(const char *prefix /* output prefix */ ,
+		 const znode * node /* node to print */ ,
+		 __u32 flags /* print flags */ ,
+		 unsigned from, unsigned count)
+{
+	unsigned i;
+	coord_t coord;
+	item_plugin *iplug;
+	reiser4_key key;
+
+	if (!znode_is_loaded(node)) {
+		print_znode("znode is not loaded\n", node);
+		return;
+	}
+	if (node_plugin_by_node(node)->print != NULL) {
+		indent_znode(node);
+		node_plugin_by_node(node)->print(prefix, node, flags);
+
+		indent_znode(node);
+		print_key("LDKEY", &node->ld_key);
+
+		indent_znode(node);
+		print_key("RDKEY", &node->rd_key);
+	}
+
+	/*if( flags & REISER4_NODE_SILENT ) {return;} */
+
+	coord.node = (znode *) node;
+	coord.unit_pos = 0;
+	coord.between = AT_UNIT;
+	/*indent_znode (node); */
+	if (from >= node_num_items(node) || from + count > node_num_items(node)) {
+		printk("there are no those items (%u-%u) in the node (%u)\n",
+		       from, from + count - 1, node_num_items(node));
+		return;
+	}
+
+	for (i = from; i < from + count; i++) {
+		int j;
+		int length;
+		char *data;
+
+		indent_znode(node);
+		printk("%d: ", i);
+
+		coord_set_item_pos(&coord, i);
+
+		iplug = item_plugin_by_coord(&coord);
+		print_plugin("\titem plugin", item_plugin_to_plugin(iplug));
+		indent_znode(node);
+		item_key_by_coord(&coord, &key);
+		print_key("\titem key", &key);
+
+		if (iplug->b.print) {
+			indent_znode(node);
+			printk("\tlength %d\n", item_length_by_coord(&coord));
+			indent_znode(node);
+			iplug->b.print("\titem", &coord);
+		}
+		data = item_body_by_coord(&coord);
+		length = item_length_by_coord(&coord);
+		indent_znode(node);
+		printk("\titem length: %i, offset: %i\n", length, data - zdata(node));
+		for (j = 0; j < length; ++j) {
+			char datum;
+
+			if ((j % 16) == 0) {
+				/* next 16 bytes */
+				if (j == 0) {
+					indent_znode(node);
+					printk("\tdata % .2i: ", j);
+				} else {
+					printk("\n");
+					indent_znode(node);
+					printk("\t     % .2i: ", j);
+				}
+			}
+			datum = data[j];
+			printk("%c", hex_to_ascii((datum & 0xf0) >> 4));
+			printk("%c ", hex_to_ascii(datum & 0xf));
+		}
+		printk("\n");
+		indent_znode(node);
+		printk("======================\n");
+	}
+	printk("\n");
+}
+#endif
+
+#if REISER4_DEBUG_NODE
+/* debugging aid: check consistency of @node content */
+void
+node_check(znode * node /* node to check */ ,
+	   __u32 flags /* check flags */ )
+{
+	const char *mes;
+	int result;
+	reiser4_tree *tree;
+
+	assert("nikita-3534", schedulable());
+
+	if (!reiser4_is_debugged(reiser4_get_current_sb(), REISER4_CHECK_NODE))
+		return;
+
+	if (get_current_context()->disable_node_check)
+		return;
+	tree = znode_get_tree(node);
+
+	if (znode_above_root(node))
+		return;
+	if (znode_just_created(node))
+		return;
+
+	zload(node);
+	result = node_plugin_by_node(node)->check(node, flags, &mes);
+	if (result != 0) {
+		printk("%s\n", mes);
+		print_node_content("check", node, ~0u);
+		reiser4_panic("vs-273", "node corrupted");
+	}
+	zrelse(node);
+}
+#endif
+
 node_plugin node_plugins[LAST_NODE_ID] = {
 	[NODE40_ID] = {
 		.h = {
@@ -99,6 +344,9 @@ node_plugin node_plugins[LAST_NODE_ID] =
 #ifdef GUESS_EXISTS
 		.guess = guess_node40,
 #endif
+#if REISER4_DEBUG_OUTPUT
+		.print = print_node40,
+#endif
 		.change_item_size = change_item_size_node40,
 		.create_item = create_item_node40,
 		.update_item_key = update_item_key_node40,
diff -puN plugin/node/node.h~profile-stat-trace-repacker plugin/node/node.h
--- reiser4/plugin/node/node.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/node/node.h	2005-02-01 11:51:12.000000000 +0300
@@ -179,7 +179,7 @@ typedef struct node_plugin {
 	   Uncomment after 4.0 only.
 	*/
 	/*      int ( *guess )( const znode *node ); */
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 	void (*print) (const char *prefix, const znode * node, __u32 flags);
 #endif
 	/* change size of @item by @by bytes. @item->node has enough free
@@ -240,8 +240,35 @@ typedef enum {
 } reiser4_node_id;
 
 extern reiser4_key *leftmost_key_in_node(const znode * node, reiser4_key * key);
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 extern void print_node_content(const char *prefix, const znode * node, __u32 flags);
+extern void print_node_items(const char *prefix /* output prefix */ ,
+			     const znode * node /* node to print */ ,
+			     __u32 flags /* print flags */ ,
+			     unsigned from, unsigned count);
+#else
+#define print_node_content(p,n,f) noop
+#endif
+
+extern void indent(unsigned indentation);
+extern void indent_znode(const znode * node);
+
+#if REISER4_DEBUG_NODE
+extern void node_check(znode * node, __u32 flags);
+#define DISABLE_NODE_CHECK				\
+({							\
+	++ get_current_context() -> disable_node_check;	\
+})
+
+#define ENABLE_NODE_CHECK				\
+({							\
+	-- get_current_context() -> disable_node_check;	\
+})
+
+#else
+#define node_check( n, f ) noop
+#define DISABLE_NODE_CHECK noop
+#define ENABLE_NODE_CHECK noop
 #endif
 
 extern void indent_znode(const znode * node);
@@ -251,7 +278,6 @@ typedef struct common_node_header {
 	   of a node. */
 	d16 plugin_id;
 } common_node_header;
-
 /* __REISER4_NODE_H__ */
 #endif
 /*
diff -puN plugin/object.c~profile-stat-trace-repacker plugin/object.c
--- reiser4/plugin/object.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/object.c	2005-02-01 11:51:12.000000000 +0300
@@ -72,6 +72,7 @@ NIKITA-FIXME-HANS: period?
 #include "../inode.h"
 #include "../super.h"
 #include "../reiser4.h"
+#include "../prof.h"
 #include "../safe_link.h"
 
 #include <linux/types.h>
@@ -95,6 +96,7 @@ key_warning(const reiser4_key * key /* k
 		warning("nikita-717", "Error for inode %llu (%i)",
 			(unsigned long long)get_key_objectid(key), code);
 		print_key("for key", key);
+		print_inode("inode", inode);
 	}
 }
 
@@ -253,6 +255,9 @@ insert_new_sd(struct inode *inode /* ino
 	*/
 
 	if (result == IBK_INSERT_OK) {
+		write_current_logf(WRITE_TREE_LOG, "..sd i %#llx %#llx",
+				   get_inode_oid(inode), ref->locality_id);
+
 		coord_clear_iplug(&coord);
 		result = zload(coord.node);
 		if (result == 0) {
@@ -477,7 +482,7 @@ write_sd_by_inode_common(struct inode *i
 }
 
 /* checks whether yet another hard links to this object can be added */
-static int
+reiser4_internal int
 can_add_link_common(const struct inode *object /* object to check */ )
 {
 	assert("nikita-732", object != NULL);
@@ -488,7 +493,7 @@ can_add_link_common(const struct inode *
 }
 
 /* remove object stat data. Space for it must be reserved by caller before */
-static int
+reiser4_internal int
 common_object_delete_no_reserve(struct inode *inode /* object to remove */)
 {
 	int result;
@@ -502,6 +507,7 @@ common_object_delete_no_reserve(struct i
 		DQUOT_DROP(inode);
 
 		build_sd_key(inode, &sd_key);
+		write_current_logf(WRITE_TREE_LOG, "..sd k %#llx", get_inode_oid(inode));
 		result = cut_tree(tree_by_inode(inode), &sd_key, &sd_key, NULL);
 		if (result == 0) {
 			inode_set_flag(inode, REISER4_NO_SD);
@@ -1100,7 +1106,7 @@ process_truncate(struct inode *inode, __
 	return result;
 }
 
-static int
+reiser4_internal int
 safelink_common(struct inode *object, reiser4_safe_link_t link, __u64 value)
 {
 	int result;
diff -puN plugin/object.h~profile-stat-trace-repacker plugin/object.h
--- reiser4/plugin/object.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/object.h	2005-02-01 11:51:12.000000000 +0300
@@ -22,6 +22,8 @@ extern int write_sd_by_inode_common(stru
 extern int owns_item_common(const struct inode *inode,
 			    const coord_t * coord);
 extern reiser4_block_nr estimate_update_common(const struct inode *inode);
+extern int safelink_common(struct inode *object,
+			   reiser4_safe_link_t link, __u64 value);
 extern int prepare_write_common (struct file *, struct page *, unsigned, unsigned);
 extern int key_by_inode_and_offset_common(struct inode *, loff_t, reiser4_key *);
 extern int setattr_reserve_common(reiser4_tree *);
diff -puN plugin/plugin.c~profile-stat-trace-repacker plugin/plugin.c
--- reiser4/plugin/plugin.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/plugin.c	2005-02-01 11:51:12.000000000 +0300
@@ -187,6 +187,7 @@ NIKTIA-FIXME-HANS: Do the line above.  I
 int init_plugins(void);
 int setup_plugins(struct super_block *super, reiser4_plugin ** area);
 reiser4_plugin *lookup_plugin(const char *type_label, const char *plug_label);
+reiser4_plugin *lookup_plugin_name(char *plug_label);
 int locate_plugin(struct inode *inode, plugin_locator * loc);
 
 /* internal functions. */
@@ -200,6 +201,7 @@ init_plugins(void)
 {
 	reiser4_plugin_type type_id;
 
+	ON_TRACE(TRACE_PLUGINS, "Builtin plugins:\n");
 	for (type_id = 0; type_id < REISER4_PLUGIN_TYPES; ++type_id) {
 		reiser4_plugin_type_data *ptype;
 		int i;
@@ -209,6 +211,8 @@ init_plugins(void)
 		assert("nikita-3509", ptype->type_id == type_id);
 
 		plugin_list_init(&ptype->plugins_list);
+		ON_TRACE(TRACE_PLUGINS,
+			 "Of type %s (%s):\n", ptype->label, ptype->desc);
 /* NIKITA-FIXME-HANS: change builtin_num to some other name lacking the term builtin. */
 		for (i = 0; i < ptype->builtin_num; ++i) {
 			reiser4_plugin *plugin;
@@ -220,6 +224,7 @@ init_plugins(void)
 				continue;
 			assert("nikita-3445", plugin->h.type_id == type_id);
 			plugin->h.id = i;
+			IF_TRACE(TRACE_PLUGINS, print_plugin("\t", plugin));
 			if (plugin->h.pops != NULL &&
 			    plugin->h.pops->init != NULL) {
 				int result;
@@ -235,6 +240,28 @@ init_plugins(void)
 	return 0;
 }
 
+/* lookup plugin name by scanning tables */
+reiser4_internal reiser4_plugin *
+lookup_plugin_name(char *plug_label /* label to search for */ )
+{
+	reiser4_plugin_type type_id;
+	reiser4_plugin *plugin;
+
+/* DEMIDOV-FIXME-HANS: did you get Saveliev to agree that his name is not Vova?  If not, change to DEMIDOV-001 */
+	assert("vova-001", plug_label != NULL);
+
+	plugin = NULL;
+
+	dinfo("lookup_plugin_name: %s\n", plug_label);
+
+	for (type_id = 0; type_id < REISER4_PLUGIN_TYPES; ++type_id) {
+		plugin = find_plugin(&plugins[type_id], plug_label);
+		if (plugin != NULL)
+			break;
+	}
+	return plugin;
+}
+
 /* true if plugin type id is valid */
 reiser4_internal int
 is_type_id_valid(reiser4_plugin_type type_id /* plugin type id */)
diff -puN plugin/plugin.h~profile-stat-trace-repacker plugin/plugin.h
--- reiser4/plugin/plugin.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/plugin.h	2005-02-01 11:51:12.000000000 +0300
@@ -474,6 +474,9 @@ typedef struct sd_ext_plugin {
 	int (*absent) (struct inode * inode);
 	int (*save_len) (struct inode * inode);
 	int (*save) (struct inode * inode, char **area);
+#if REISER4_DEBUG_OUTPUT
+	void (*print) (const char *prefix, char **area, int *len);
+#endif
 	/* alignment requirement for this stat-data part */
 	int alignment;
 } sd_ext_plugin;
@@ -787,6 +790,11 @@ PLUGIN_BY_ID(pseudo_plugin, REISER4_PSEU
 
 extern int save_plugin_id(reiser4_plugin * plugin, d16 * area);
 
+#if REISER4_DEBUG_OUTPUT
+extern void print_plugin(const char *prefix, reiser4_plugin * plugin);
+#else
+#define print_plugin( pr, pl ) noop
+#endif
 
 TYPE_SAFE_LIST_DEFINE(plugin, reiser4_plugin, h.linkage);
 
diff -puN plugin/plugin_set.c~profile-stat-trace-repacker plugin/plugin_set.c
--- reiser4/plugin/plugin_set.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/plugin_set.c	2005-02-01 11:51:12.000000000 +0300
@@ -150,6 +150,11 @@ reiser4_internal void plugin_set_put(plu
 {
 }
 
+reiser4_internal plugin_set *plugin_set_clone(plugin_set *set)
+{
+	return set;
+}
+
 static inline unsigned long *
 pset_field(plugin_set *set, int offset)
 {
@@ -251,24 +256,6 @@ static struct {
 	}
 };
 
-#if REISER4_DEBUG
-static reiser4_plugin_type
-pset_member_to_type(pset_member memb)
-{
-	assert("nikita-3501", 0 <= memb && memb < PSET_LAST);
-	return pset_descr[memb].type;
-}
-#endif
-
-reiser4_plugin_type
-pset_member_to_type_unsafe(pset_member memb)
-{
-	if (0 <= memb && memb < PSET_LAST)
-		return pset_descr[memb].type;
-	else
-		return REISER4_PLUGIN_TYPES;
-}
-
 int pset_set(plugin_set **set, pset_member memb, reiser4_plugin *plugin)
 {
 	assert("nikita-3492", set != NULL);
@@ -289,6 +276,20 @@ reiser4_plugin *pset_get(plugin_set *set
 	return *(reiser4_plugin **)(((char *)set) + pset_descr[memb].offset);
 }
 
+reiser4_plugin_type pset_member_to_type(pset_member memb)
+{
+	assert("nikita-3501", 0 <= memb && memb < PSET_LAST);
+	return pset_descr[memb].type;
+}
+
+reiser4_plugin_type pset_member_to_type_unsafe(pset_member memb)
+{
+	if (0 <= memb && memb < PSET_LAST)
+		return pset_descr[memb].type;
+	else
+		return REISER4_PLUGIN_TYPES;
+}
+
 #define DEFINE_PLUGIN_SET(type, field)					\
 reiser4_internal int plugin_set_ ## field(plugin_set **set, type *val)	\
 {									\
@@ -299,10 +300,12 @@ reiser4_internal int plugin_set_ ## fiel
 
 DEFINE_PLUGIN_SET(file_plugin, file)
 DEFINE_PLUGIN_SET(dir_plugin, dir)
+DEFINE_PLUGIN_SET(perm_plugin, perm)
 DEFINE_PLUGIN_SET(formatting_plugin, formatting)
 DEFINE_PLUGIN_SET(hash_plugin, hash)
 DEFINE_PLUGIN_SET(fibration_plugin, fibration)
 DEFINE_PLUGIN_SET(item_plugin, sd)
+DEFINE_PLUGIN_SET(item_plugin, dir_item)
 DEFINE_PLUGIN_SET(crypto_plugin, crypto)
 DEFINE_PLUGIN_SET(digest_plugin, digest)
 DEFINE_PLUGIN_SET(compression_plugin, compression)
@@ -311,7 +314,7 @@ reiser4_internal int plugin_set_init(voi
 {
 	int result;
 
-	result = ps_hash_init(&ps_table, PS_TABLE_SIZE);
+	result = ps_hash_init(&ps_table, PS_TABLE_SIZE, NULL);
 	if (result == 0) {
 		plugin_set_slab = kmem_cache_create("plugin_set",
 						    sizeof (plugin_set), 0,
diff -puN plugin/plugin_set.h~profile-stat-trace-repacker plugin/plugin_set.h
--- reiser4/plugin/plugin_set.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/plugin_set.h	2005-02-01 11:51:12.000000000 +0300
@@ -43,14 +43,17 @@ struct plugin_set {
 };
 
 extern plugin_set *plugin_set_get_empty(void);
+extern plugin_set *plugin_set_clone(plugin_set *set);
 extern void        plugin_set_put(plugin_set *set);
 
 extern int plugin_set_file       (plugin_set **set, file_plugin *file);
 extern int plugin_set_dir        (plugin_set **set, dir_plugin *file);
+extern int plugin_set_perm       (plugin_set **set, perm_plugin *file);
 extern int plugin_set_formatting (plugin_set **set, formatting_plugin *file);
 extern int plugin_set_hash       (plugin_set **set, hash_plugin *file);
 extern int plugin_set_fibration  (plugin_set **set, fibration_plugin *file);
 extern int plugin_set_sd         (plugin_set **set, item_plugin *file);
+extern int plugin_set_dir_item   (plugin_set **set, item_plugin *file);
 extern int plugin_set_crypto     (plugin_set **set, crypto_plugin *file);
 extern int plugin_set_digest     (plugin_set **set, digest_plugin *file);
 extern int plugin_set_compression(plugin_set **set, compression_plugin *file);
@@ -61,6 +64,7 @@ extern void plugin_set_done(void);
 extern int pset_set(plugin_set **set, pset_member memb, reiser4_plugin *plugin);
 extern reiser4_plugin *pset_get(plugin_set *set, pset_member memb);
 
+extern reiser4_plugin_type pset_member_to_type(pset_member memb);
 extern reiser4_plugin_type pset_member_to_type_unsafe(pset_member memb);
 
 /* __PLUGIN_SET_H__ */
diff -puN plugin/pseudo/pseudo.c~profile-stat-trace-repacker plugin/pseudo/pseudo.c
--- reiser4/plugin/pseudo/pseudo.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/pseudo/pseudo.c	2005-02-01 11:51:12.000000000 +0300
@@ -359,6 +359,7 @@ init_pseudo(struct inode *parent, struct
 							      parent, &data);
 	if (result != 0) {
 		warning("nikita-3203", "Cannot install pseudo plugin");
+		print_plugin("plugin", pseudo_plugin_to_plugin(pplug));
 		return result;
 	}
 
@@ -1341,7 +1342,12 @@ static int items_show(struct seq_file *m
 	/* output key... */
 	sprintf_key(buf, unit_key_by_coord(&c->coord, &key));
 	/* ... and item plugin label... */
-	seq_printf(m, "%s %s\n", buf, iplug->h.label);
+	seq_printf(m, "%s %s ", buf, iplug->h.label);
+	if (iplug->b.show != NULL)
+		/* ... and call ->b.show() method of item plugin, if any, to
+		 * do the rest */
+		iplug->b.show(m, &c->coord);
+	seq_printf(m, "\n");
 	return 0;
 }
 
@@ -1366,7 +1372,7 @@ static int get_new(struct file *file, co
 		unsigned long hash;
 
 		reiser4_object_create_data data;
-		memset(&data, 0, sizeof data);
+		xmemset(&data, 0, sizeof data);
 
 		data.mode = S_IFREG | 0 /* mode */;
 		data.id = UNIX_FILE_PLUGIN_ID;
diff -puN plugin/space/bitmap.c~profile-stat-trace-repacker plugin/space/bitmap.c
--- reiser4/plugin/space/bitmap.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/space/bitmap.c	2005-02-01 11:51:12.000000000 +0300
@@ -8,7 +8,10 @@
 #include "../../tree.h"
 #include "../../super.h"
 #include "../../lib.h"
+
 #include "../plugin.h"
+#include "../../diskmap.h"
+
 #include "space_allocator.h"
 #include "bitmap.h"
 
@@ -344,7 +347,7 @@ reiser4_clear_bits(char *addr, bmap_off_
 	last_byte = (end - 1) >> 3;
 
 	if (last_byte > first_byte + 1)
-		memset(addr + first_byte + 1, 0, (size_t) (last_byte - first_byte - 1));
+		xmemset(addr + first_byte + 1, 0, (size_t) (last_byte - first_byte - 1));
 
 	first_byte_mask >>= 8 - (start & 0x7);
 	last_byte_mask <<= ((end - 1) & 0x7) + 1;
@@ -374,7 +377,7 @@ reiser4_set_bits(char *addr, bmap_off_t 
 	last_byte = (end - 1) >> 3;
 
 	if (last_byte > first_byte + 1)
-		memset(addr + first_byte + 1, 0xFF, (size_t) (last_byte - first_byte - 1));
+		xmemset(addr + first_byte + 1, 0xFF, (size_t) (last_byte - first_byte - 1));
 
 	first_byte_mask <<= start & 0x7;
 	last_byte_mask >>= 7 - ((end - 1) & 0x7);
@@ -594,7 +597,7 @@ adjust_first_zero_bit(struct bitmap_node
 	((REISER4_MASTER_OFFSET / PAGE_CACHE_SIZE) + 2)
 
 /* Audited by: green(2002.06.12) */
-static void
+reiser4_internal void
 get_bitmap_blocknr(struct super_block *super, bmap_nr_t bmap, reiser4_block_nr * bnr)
 {
 
@@ -618,7 +621,7 @@ get_bitmap_blocknr(struct super_block *s
 
 /* construct a fake block number for shadow bitmap (WORKING BITMAP) block */
 /* Audited by: green(2002.06.12) */
-static void
+reiser4_internal void
 get_working_bitmap_blocknr(bmap_nr_t bmap, reiser4_block_nr * bnr)
 {
 	*bnr = (reiser4_block_nr) ((bmap & ~REISER4_BLOCKNR_STATUS_BIT_MASK) | REISER4_BITMAP_BLOCKS_STATUS_VALUE);
@@ -629,7 +632,7 @@ static void
 init_bnode(struct bitmap_node *bnode,
 	   struct super_block *super UNUSED_ARG, bmap_nr_t bmap UNUSED_ARG)
 {
-	memset(bnode, 0, sizeof (struct bitmap_node));
+	xmemset(bnode, 0, sizeof (struct bitmap_node));
 
 	sema_init(&bnode->sema, 1);
 	atomic_set(&bnode->loaded, 0);
@@ -779,9 +782,9 @@ load_and_lock_bnode(struct bitmap_node *
 				/* working bitmap is initialized by on-disk
 				 * commit bitmap. This should be performed
 				 * under semaphore. */
-				memcpy(bnode_working_data(bnode),
-				       bnode_commit_data(bnode),
-				       bmap_size(current_blocksize));
+				xmemcpy(bnode_working_data(bnode),
+					bnode_commit_data(bnode),
+					bmap_size(current_blocksize));
 			} else {
 				up(&bnode->sema);
 			}
@@ -1013,9 +1016,9 @@ static int bitmap_alloc_backward(reiser4
 }
 
 /* plugin->u.space_allocator.alloc_blocks() */
-static int
+reiser4_internal int
 alloc_blocks_forward(reiser4_blocknr_hint * hint, int needed,
-		     reiser4_block_nr * start, reiser4_block_nr * len)
+			 reiser4_block_nr * start, reiser4_block_nr * len)
 {
 	struct super_block *super = get_current_context()->super;
 	int actual_len;
diff -puN plugin/space/bitmap.h~profile-stat-trace-repacker plugin/space/bitmap.h
--- reiser4/plugin/space/bitmap.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/plugin/space/bitmap.h	2005-02-01 11:51:12.000000000 +0300
@@ -27,6 +27,9 @@ extern int pre_commit_hook_bitmap(void);
 typedef __u64 bmap_nr_t;
 typedef __u32 bmap_off_t;
 
+/* exported for user-level simulator */
+extern void get_bitmap_blocknr(struct super_block *, bmap_nr_t, reiser4_block_nr *);
+
 #endif				/* __REISER4_PLUGIN_SPACE_BITMAP_H__ */
 
 /* Make Linus happy.
diff -puN pool.c~profile-stat-trace-repacker pool.c
--- reiser4/pool.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/pool.c	2005-02-01 11:51:12.000000000 +0300
@@ -76,13 +76,13 @@ reiser4_init_pool(reiser4_pool * pool /*
 	assert("nikita-956", num_of_objs >= 0);
 	assert("nikita-957", data != NULL);
 
-	memset(pool, 0, sizeof *pool);
+	xmemset(pool, 0, sizeof *pool);
 	pool->obj_size = obj_size;
 	pool->data = data;
 	pool_usage_list_init(&pool->free);
 	pool_usage_list_init(&pool->used);
 	pool_extra_list_init(&pool->extra);
-	memset(data, 0, obj_size * num_of_objs);
+	xmemset(data, 0, obj_size * num_of_objs);
 	for (i = 0; i < num_of_objs; ++i) {
 		h = (reiser4_pool_header *) (data + i * obj_size);
 		reiser4_init_pool_obj(h);
@@ -107,19 +107,22 @@ reiser4_done_pool(reiser4_pool * pool UN
    allocation.
 
 */
-static void *
+reiser4_internal void *
 reiser4_pool_alloc(reiser4_pool * pool	/* pool to allocate object
 					 * from */ )
 {
 	reiser4_pool_header *result;
 
 	assert("nikita-959", pool != NULL);
+	trace_stamp(TRACE_CARRY);
+	reiser4_stat_inc(pool.alloc);
 
 	if (!pool_usage_list_empty(&pool->free)) {
 		result = pool_usage_list_pop_front(&pool->free);
 		pool_usage_list_clean(result);
 		assert("nikita-965", pool_extra_list_is_clean(result));
 	} else {
+		reiser4_stat_inc(pool.kmalloc);
 		/* pool is empty. Extra allocations don't deserve dedicated
 		   slab to be served from, as they are expected to be rare. */
 		result = reiser4_kmalloc(pool->obj_size, GFP_KERNEL);
@@ -132,7 +135,7 @@ reiser4_pool_alloc(reiser4_pool * pool	/
 	++pool->objs;
 	pool_level_list_clean(result);
 	pool_usage_list_push_front(&pool->used, result);
-	memset(result + 1, 0, pool->obj_size - sizeof *result);
+	xmemset(result + 1, 0, pool->obj_size - sizeof *result);
 	return result;
 }
 
@@ -144,6 +147,7 @@ reiser4_pool_free(reiser4_pool * pool,
 {
 	assert("nikita-961", h != NULL);
 	assert("nikita-962", pool != NULL);
+	trace_stamp(TRACE_CARRY);
 
 	-- pool->objs;
 	assert("nikita-963", pool->objs >= 0);
@@ -190,6 +194,8 @@ add_obj(reiser4_pool * pool	/* pool from
 
 	assert("nikita-972", pool != NULL);
 
+	trace_stamp(TRACE_CARRY);
+
 	result = reiser4_pool_alloc(pool);
 	if (IS_ERR(result))
 		return result;
diff -puN pool.h~profile-stat-trace-repacker pool.h
--- reiser4/pool.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/pool.h	2005-02-01 11:51:12.000000000 +0300
@@ -51,6 +51,7 @@ TYPE_SAFE_LIST_DEFINE(pool_level, reiser
 
 extern void reiser4_init_pool(reiser4_pool * pool, size_t obj_size, int num_of_objs, char *data);
 extern void reiser4_done_pool(reiser4_pool * pool);
+extern void *reiser4_pool_alloc(reiser4_pool * pool);
 extern void reiser4_pool_free(reiser4_pool * pool, reiser4_pool_header * h);
 reiser4_pool_header *add_obj(reiser4_pool * pool, pool_level_list_head * list,
 			     pool_ordering order, reiser4_pool_header * reference);
diff -puN /dev/null prof.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/prof.c	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,273 @@
+/* Copyright 2001, 2002, 2003 by Hans Reiser, licensing governed by
+ * reiser4/README */
+
+/* profiling facilities. */
+
+/*
+ * This code is used to collect statistics about how many times particular
+ * function (or part of function) was called, and how long average call
+ * took. In addition (or, in the first place, depending on one's needs), it
+ * also keep track of through what call-chain profiled piece of code was
+ * entered. Latter is done by having a list of call-chains. Call-chains are
+ * obtained by series of calls to __builtin_return_address() (hence, this
+ * functionality requires kernel to be compiled with frame pointers). Whenever
+ * profiled region is just about to be left, call-chain is constructed and
+ * then compared against all chains already in the list. If match is found
+ * (cache hit!), its statistics are updated, otherwise (cache miss), entry
+ * with smallest hit count is selected and re-used to new call-chain.
+ *
+ * NOTE: this replacement policy has obvious deficiencies: after some time
+ * entries in the list accumulate high hit counts and will effectively prevent
+ * any new call-chain from finding a place in the list, even is this
+ * call-chain is frequently activated. Probably LRU should be used instead
+ * (this is not that hard, /proc/<pid>/sleep patch does this), but nobody
+ * complained so far.
+ *
+ */
+
+
+#include "kattr.h"
+#include "reiser4.h"
+#include "context.h"
+#include "super.h"
+#include "prof.h"
+
+#include <linux/sysfs.h>
+#include <linux/slab.h>
+#include <linux/types.h>
+#include <linux/fs.h>
+#include <linux/spinlock.h>
+#include <linux/kallsyms.h>
+
+#if REISER4_PROF
+
+#ifdef CONFIG_FRAME_POINTER
+static void
+update_prof_trace(reiser4_prof_cnt *cnt, int depth, int shift)
+{
+	int i;
+	int minind;
+	__u64 minhit;
+	unsigned long hash;
+	backtrace_path bt;
+
+	fill_backtrace(&bt, depth, shift);
+
+	for (i = 0, hash = 0 ; i < REISER4_BACKTRACE_DEPTH ; ++ i) {
+		hash += (unsigned long)bt.trace[i];
+	}
+	minhit = ~0ull;
+	minind = 0;
+	for (i = 0 ; i < REISER4_PROF_TRACE_NUM ; ++ i) {
+		if (hash == cnt->bt[i].hash) {
+			++ cnt->bt[i].hits;
+			return;
+		}
+		if (cnt->bt[i].hits < minhit) {
+			minhit = cnt->bt[i].hits;
+			minind = i;
+		}
+	}
+	cnt->bt[minind].path = bt;
+	cnt->bt[minind].hash = hash;
+	cnt->bt[minind].hits = 1;
+}
+#else
+#define update_prof_trace(cnt, depth, shift) noop
+#endif
+
+void update_prof_cnt(reiser4_prof_cnt *cnt, __u64 then, __u64 now,
+		     unsigned long swtch_mark, __u64 start_jif,
+		     int depth, int shift)
+{
+	__u64 delta;
+
+	delta = now - then;
+	cnt->nr ++;
+	cnt->total += delta;
+	cnt->max = max(cnt->max, delta);
+	if (swtch_mark == nr_context_switches()) {
+		cnt->noswtch_nr ++;
+		cnt->noswtch_total += delta;
+		cnt->noswtch_max = max(cnt->noswtch_max, delta);
+	}
+	update_prof_trace(cnt, depth, shift);
+}
+
+struct prof_attr_entry {
+	struct attribute attr;
+	char name[10];
+};
+
+static struct prof_attr_entry prof_attr[REISER4_PROF_TRACE_NUM];
+
+static ssize_t
+show_prof_attr(struct kobject *kobj, struct attribute *attr, char *buf)
+{
+	char *p;
+	reiser4_prof_entry *entry;
+	reiser4_prof_cnt   *val;
+#ifdef CONFIG_FRAME_POINTER
+	int pos;
+	int j;
+
+	pos = ((struct prof_attr_entry *)attr) - prof_attr;
+#endif
+	entry = container_of(kobj, reiser4_prof_entry, kobj);
+	val = &entry->cnt;
+	p = buf;
+	KATTR_PRINT(p, buf, "%llu %llu %llu %llu %llu %llu\n",
+		    val->nr, val->total, val->max,
+		    val->noswtch_nr, val->noswtch_total, val->noswtch_max);
+#ifdef CONFIG_FRAME_POINTER
+	if (val->bt[pos].hash != 0) {
+		KATTR_PRINT(p, buf, "\t%llu: ", val->bt[pos].hits);
+		for (j = 0 ; j < REISER4_BACKTRACE_DEPTH ; ++ j) {
+			char         *module;
+			const char   *name;
+			char          namebuf[128];
+			unsigned long address;
+			unsigned long offset;
+			unsigned long size;
+
+			address = (unsigned long) val->bt[pos].path.trace[j];
+			name = kallsyms_lookup(address, &size,
+					       &offset, &module, namebuf);
+			KATTR_PRINT(p, buf, "\n\t\t%#lx ", address);
+			if (name != NULL)
+				KATTR_PRINT(p, buf, "%s+%#lx/%#lx",
+					    name, offset, size);
+		}
+		KATTR_PRINT(p, buf, "\n");
+	}
+#endif
+	return (p - buf);
+}
+
+/* zero a prof entry corresponding to @attr */
+static ssize_t
+store_prof_attr(struct kobject *kobj, struct attribute *attr, const char *buf, size_t size)
+{
+	reiser4_prof_entry *entry;
+
+	entry = container_of(kobj, reiser4_prof_entry, kobj);
+	memset(&entry->cnt, 0, sizeof(reiser4_prof_cnt));
+	return sizeof(reiser4_prof_cnt);
+}
+
+static struct sysfs_ops prof_attr_ops = {
+	.show = show_prof_attr,
+	.store = store_prof_attr
+};
+
+static struct kobj_type ktype_reiser4_prof = {
+	.sysfs_ops	= &prof_attr_ops,
+	.default_attrs	= NULL
+};
+
+static decl_subsys(prof, &ktype_reiser4_prof, NULL);
+
+static struct kobject cpu_prof;
+
+#define DEFINE_PROF_ENTRY_0(attr_name,field_name)	\
+	.field_name = {					\
+		.kobj = {	       			\
+			.name = attr_name	\
+		}					\
+	}
+
+
+#define DEFINE_PROF_ENTRY(name)				\
+ 	DEFINE_PROF_ENTRY_0(#name,name)
+
+reiser4_prof reiser4_prof_defs = {
+	DEFINE_PROF_ENTRY(fuse_wait),
+#if 0
+	DEFINE_PROF_ENTRY(cbk),
+	DEFINE_PROF_ENTRY(init_context),
+	DEFINE_PROF_ENTRY(jlook),
+	DEFINE_PROF_ENTRY(writepage),
+	DEFINE_PROF_ENTRY(jload),
+	DEFINE_PROF_ENTRY(jrelse),
+	DEFINE_PROF_ENTRY(flush_alloc),
+	DEFINE_PROF_ENTRY(forward_squalloc),
+	DEFINE_PROF_ENTRY(atom_wait_event),
+	DEFINE_PROF_ENTRY(zget),
+	/* write profiling */
+	DEFINE_PROF_ENTRY(extent_write),
+	/* read profiling */
+	DEFINE_PROF_ENTRY(file_read)
+#endif
+};
+
+void calibrate_prof(void)
+{
+	__u64 start;
+	__u64 end;
+
+	rdtscll(start);
+	schedule_timeout(HZ/100);
+	rdtscll(end);
+	warning("nikita-2923", "1 sec. == %llu rdtsc.", (end - start) * 100);
+}
+
+
+int init_prof_kobject(void)
+{
+	int result;
+	int i;
+	reiser4_prof_entry *array;
+
+	for (i = 0; i < REISER4_PROF_TRACE_NUM; ++ i) {
+		sprintf(prof_attr[i].name, "%i", i);
+		prof_attr[i].attr.name = prof_attr[i].name;
+		prof_attr[i].attr.mode = 0644;
+	}
+
+	result = subsystem_register(&prof_subsys);
+	if (result != 0)
+		return result;
+
+	cpu_prof.kset = &prof_subsys.kset;
+	snprintf(cpu_prof.name, KOBJ_NAME_LEN, "cpu_prof");
+	result = kobject_register(&cpu_prof);
+	if (result != 0)
+		return result;
+
+	/* populate */
+	array = (reiser4_prof_entry *)&reiser4_prof_defs;
+	for(i = 0 ; i < sizeof(reiser4_prof_defs)/sizeof(reiser4_prof_entry);
+	    ++ i) {
+		struct kobject *kobj;
+		int j;
+
+		kobj = &array[i].kobj;
+		kobj->ktype = &ktype_reiser4_prof;
+		kobj->parent = kobject_get(&cpu_prof);
+
+		result = kobject_register(kobj);
+		if (result != 0)
+			break;
+
+		for (j = 0; j < REISER4_PROF_TRACE_NUM; ++ j) {
+			result = sysfs_create_file(kobj, &prof_attr[j].attr);
+			if (result != 0)
+				break;
+		}
+	}
+	if (result != 0)
+		kobject_unregister(&cpu_prof);
+	return result;
+}
+
+void done_prof_kobject(void)
+{
+	kobject_unregister(&cpu_prof);
+	subsystem_unregister(&prof_subsys);
+}
+
+/* REISER4_PROF */
+#else
+
+/* REISER4_PROF */
+#endif
diff -puN /dev/null prof.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/prof.h	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,130 @@
+/* Copyright 2001, 2002, 2003 by Hans Reiser, licensing governed by
+ * reiser4/README */
+
+/* profiling. This is i386, rdtsc-based profiling. See prof.c for comments. */
+
+#if !defined( __REISER4_PROF_H__ )
+#define __REISER4_PROF_H__
+
+#include "kattr.h"
+
+#if (defined(__i386__) || defined(CONFIG_USERMODE)) && defined(CONFIG_REISER4_PROF)
+#define REISER4_PROF (1)
+#else
+#define REISER4_PROF (0)
+#endif
+
+#if REISER4_PROF
+
+#include <asm-i386/msr.h>
+
+#define REISER4_PROF_TRACE_NUM (30)
+
+/* data structure to keep call trace */
+typedef struct {
+	/* hash of trace---used for fast comparison */
+	unsigned long hash;
+	/* call trace proper---return addresses collected by
+	 * __builtin_return_address() */
+	backtrace_path path;
+	/* number of times profiled code was entered through this call
+	 * chain */
+	__u64 hits;
+} reiser4_trace;
+
+/* statistics for profiled region of code */
+typedef struct {
+	/* number of times region was entered */
+	__u64 nr;
+	/* total time spent in this region */
+	__u64 total;
+	/* maximal time per enter */
+	__u64 max;
+	/* number of times region was executed without context switch */
+	__u64 noswtch_nr;
+	/* total time spent in executions without context switch */
+	__u64 noswtch_total;
+	/* maximal time of execution without context switch */
+	__u64 noswtch_max;
+	/* array of back traces */
+	reiser4_trace bt[REISER4_PROF_TRACE_NUM];
+} reiser4_prof_cnt;
+
+/* profiler entry. */
+typedef struct {
+	/* sysfs placeholder */
+	struct kobject kobj;
+	/* statistics, see above */
+	reiser4_prof_cnt cnt;
+} reiser4_prof_entry;
+
+typedef struct {
+	reiser4_prof_entry fuse_wait;
+#if 0
+	reiser4_prof_entry cbk;
+	reiser4_prof_entry init_context;
+	reiser4_prof_entry jlook;
+	reiser4_prof_entry writepage;
+	reiser4_prof_entry jload;
+	reiser4_prof_entry jrelse;
+	reiser4_prof_entry flush_alloc;
+	reiser4_prof_entry forward_squalloc;
+	reiser4_prof_entry atom_wait_event;
+	reiser4_prof_entry zget;
+	/* write profiling */
+	reiser4_prof_entry extent_write;
+	/* read profiling */
+	reiser4_prof_entry file_read;
+#endif
+} reiser4_prof;
+
+extern reiser4_prof reiser4_prof_defs;
+
+extern unsigned long nr_context_switches(void);
+void update_prof_cnt(reiser4_prof_cnt *cnt, __u64 then, __u64 now,
+		     unsigned long swtch_mark, __u64 start_jif,
+		     int delta, int shift);
+void calibrate_prof(void);
+
+#define PROF_BEGIN(aname)							\
+	unsigned long __swtch_mark__ ## aname = nr_context_switches();		\
+        __u64 __prof_jiffies ## aname = jiffies;				\
+	__u64 __prof_cnt__ ## aname = ({ __u64 __tmp_prof ;			\
+			      		rdtscll(__tmp_prof) ; __tmp_prof; })
+
+#define PROF_END(aname) __PROF_END(aname, REISER4_BACKTRACE_DEPTH, 0)
+
+#define __PROF_END(aname, depth, shift)			\
+({							\
+	__u64 __prof_end;				\
+							\
+	rdtscll(__prof_end);				\
+	update_prof_cnt(&reiser4_prof_defs.aname.cnt, 	\
+			__prof_cnt__ ## aname,		\
+			__prof_end,			\
+			__swtch_mark__ ## aname, 	\
+			__prof_jiffies ## aname, 	\
+			depth, shift );			\
+})
+
+extern int init_prof_kobject(void);
+extern void done_prof_kobject(void);
+
+/* REISER4_PROF */
+#else
+
+typedef struct reiser4_prof_cnt {} reiser4_prof_cnt;
+typedef struct reiser4_prof {} reiser4_prof;
+
+#define PROF_BEGIN(aname) noop
+#define PROF_END(aname) noop
+#define __PROF_END(aname, depth, shift) noop
+#define calibrate_prof() noop
+
+#define init_prof_kobject() (0)
+#define done_prof_kobject() noop
+
+#endif
+
+/* __REISER4_PROF_H__ */
+#endif
diff -puN readahead.c~profile-stat-trace-repacker readahead.c
--- reiser4/readahead.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/readahead.c	2005-02-01 11:51:12.000000000 +0300
@@ -68,6 +68,8 @@ formatted_readahead(znode *node, ra_info
 	if (low_on_memory())
 		return;
 
+	write_current_logf(READAHEAD_LOG, "...readahead\n");
+
 	/* We can have locked nodes on upper tree levels, in this situation lock
 	   priorities do not help to resolve deadlocks, we have to use TRY_LOCK
 	   here. */
@@ -111,6 +113,8 @@ formatted_readahead(znode *node, ra_info
 	}
 	zput(cur);
 	done_lh(&next_lh);
+
+	write_current_logf(READAHEAD_LOG, "...readahead exits\n");
 }
 
 static inline loff_t get_max_readahead(struct reiser4_file_ra_state *ra)
diff -puN reiser4.h~profile-stat-trace-repacker reiser4.h
--- reiser4/reiser4.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/reiser4.h	2005-02-01 13:26:10.000000000 +0300
@@ -25,6 +25,133 @@
 #define REISER4_DEBUG (0)
 #endif
 
+#if defined(CONFIG_REISER4_DEBUG_MODIFY)
+/*
+ * Turn on "znode modification checks". In this mode znode check-sum is
+ * maintained in special field added to znode. Check-sum is updated during
+ * znode_make_dirty() (or, during zload()). It is checked that check-sum is
+ * only if ever updated between acquiring write lock on znode and calling
+ * znode_make_dirty(). This significantly slows down testing, but we should
+ * run our test-suite through with this every once in a while.  */
+#define REISER4_DEBUG_MODIFY (1)
+#else
+#define REISER4_DEBUG_MODIFY (0)
+#endif
+
+#if defined(CONFIG_REISER4_DEBUG_MEMCPY)
+/* Provide our own memcpy/memmove to profile shifts. Reiser4 code uses
+ * xmem{cpy,move,set}() functions in stead of mem{cpy,move,set}(). When
+ * REISER4_DEBUG_MEMCPY is on, care is taken to uninline xmem* functions so
+ * that they show up in CPU profiling (/proc/profile, for example) separately
+ * from calling functions. This is done to estimate CPU consumption of memory
+ * shifts. When this mode is off, xmem* functions are preprocessed into their
+ * mem* analogs. */
+#define REISER4_DEBUG_MEMCPY (1)
+#else
+#define REISER4_DEBUG_MEMCPY (0)
+#endif
+
+#if defined(CONFIG_REISER4_DEBUG_NODE)
+/*
+ * Check consistency of internal node structures. When this mode is on, node
+ * consistency check (implemented by plugin/node/node.c:node_check() function)
+ * are invoked in many places (including start and end of most node plugin
+ * methods). node_check() includes a lot of checks, see it for details.
+ *
+ * Node consistency checking (which is off by default) has to be activated by
+ * setting REISER4_CHECK_NODE bit in ->debug_flags field of
+ * reiser4_super_info_data. This can be done with debug_flags mount option.
+ */
+#define REISER4_DEBUG_NODE (1)
+#else
+#define REISER4_DEBUG_NODE (0)
+#endif
+
+#if defined(CONFIG_REISER4_ZERO_NEW_NODE)
+/* If this is non-zero, clear content of new node, otherwise leave whatever
+   may happen to be here */
+#define REISER4_ZERO_NEW_NODE (1)
+#else
+#define REISER4_ZERO_NEW_NODE (0)
+#endif
+
+#if defined(CONFIG_REISER4_TRACE)
+/* tracing facility. When this is on, {ON,IF}_TRACE statements are
+ * activated. Thy print (through printk()) information about control flow
+ * (what function is called, with what arguments, etc.). {ON,IF}_TRACE
+ * statements contain "trace mask" and output is done only when this mask
+ * matches current trace mask, calculated by get_current_trace_flags()
+ * function. Current trace mask is combined from per-thread context mask
+ * (stored in reiser4_context), and per-super-block mask (stored in
+ * ->trace_flags field of reiser4_super_info_data). Per-super-block trace mask
+ * can be adjusted through:
+ *
+ *     1. mount option "trace_flags"
+ *
+ *     2. /sys/fs/reiser4/<dev>/trace_flags file.
+ *
+ */
+#define REISER4_TRACE (1)
+#else
+#define REISER4_TRACE (0)
+#endif
+
+#if defined(CONFIG_REISER4_EVENT_LOG)
+/*
+ * Collect event logs. When this is on, logging macros/functions declared in
+ * fs/reiser4/log.h are activated. Event-logging facility is designed to cope
+ * with large amount of output data. To this end, event descriptions are
+ * buffered in the internal buffer (of REISER4_TRACE_BUF_SIZE bytes) and then
+ * written into user-visible log file. Log file is specified through log_file
+ * mount option.
+ *
+ * Events which are logged are specified through log_flags mount option (or
+ * /sys/fs/reiser4/<dev>/log_flags file). See
+ * fs/reiser4/debug.h:reiser4_log_flags for possible values.
+ *
+ * Note that event-logging is for gathering statistics (as opposed to tracing,
+ * which is for debugging).
+ *
+ * When running experiments with event-logging on, it's important to minimize
+ * an impact of event-logging to the system. It was found that one of the most
+ * disturbing effects of event-logging is continuous generation of dirty
+ * memory that triggers premature write-back and, generally, affects system
+ * behavior in various ways. To work around this set log file to named pipe,
+ * and use netcat(1) to dump log through over network.
+ *
+ */
+#define REISER4_LOG (1)
+#else
+#define REISER4_LOG (0)
+#endif
+
+#if defined(CONFIG_REISER4_STATS)
+/*
+ * Collect statistics. In this mode reiser4 collects a lot of statistical
+ * information in the form if "stat-counters". There are global counters
+ * (per-super-block) and per-level counters collected separately for each
+ * level of the internal reiser4 tree. See fs/reiser4/stats.[ch] for the list
+ * of counters. Counters are exported under /sys/fs/reiser4/<dev>/stats/
+ *
+ * Note: this option consumes quite a bit of kernel memory.
+ */
+/* to turn this on reiser4-kobject-umount-race.patch is needed */
+#define REISER4_STATS (1)
+#else
+#define REISER4_STATS (0)
+#endif
+
+#if defined(CONFIG_REISER4_DEBUG_OUTPUT)
+/*
+ * In this mode various "debugging output" functions are compiled in. These
+ * functions output human readable representation of various reiser4 kernel
+ * data-structures (keys, tree nodes, items, etc.), which are used in error
+ * messages.
+ */
+#define REISER4_DEBUG_OUTPUT (1)
+#else
+#define REISER4_DEBUG_OUTPUT (0)
+#endif
 
 #if defined(CONFIG_REISER4_COPY_ON_CAPTURE)
 /*
@@ -36,6 +163,19 @@
 #define REISER4_COPY_ON_CAPTURE (0)
 #endif
 
+#if defined(CONFIG_REISER4_LOCKPROF)
+/*
+ * Turns on lock profiling mode. In this mode reiser4 spin-locks are
+ * instrumented to collect information about their contention and
+ * utilization. See fs/reiser4/spinprof.[ch] for details.
+ *
+ * Lock profiling results are exported as /sys/profregion/
+ */
+#define REISER4_LOCKPROF (1)
+#else
+#define REISER4_LOCKPROF (0)
+#endif
+
 /*
  * Turn on large keys mode. In his mode (which is default), reiser4 key has 4
  * 8-byte components. In the old "small key" mode, it's 3 8-byte
@@ -57,10 +197,106 @@
 #define REISER4_LARGE_KEY (1)
 /*#define REISER4_LARGE_KEY (0)*/
 
+#if defined(CONFIG_REISER4_ALL_IN_ONE)
+/*
+ * Turn on all-on-one compilation mode. In this mode reiser4 is compiled as
+ * one single source file all-in-one.c that includes all other sources. This
+ * is supposed to result in better code, because compiler is free to perform
+ * all optimizations within the same compilation unit. To achieve this,
+ * (almost) all reiser4 functions are prefixed with reiser4_internal
+ * specifier. In normal compilation mode it expands to nothing, in all-in-one
+ * mode, it expands to "static", thus telling compiler that function is only
+ * used in this compilation unit (that is, in whole reiser4).
+ *
+ * Note-1: compilation in this mode would result in large number of warnings,
+ * because header files weren't updated.
+ *
+ * Note-2: in addition to generating better code this mode can be used to
+ * detect declared but not used functions, or declarations without definition.
+ *
+ * Note-3: this should be tried with -funit-at-a-time option of gcc 3.4
+ */
+#define REISER4_ALL_IN_ONE (1)
+#else
+#define REISER4_ALL_IN_ONE (0)
+#endif
+
+#if defined (CONFIG_REISER4_DEBUG_NODE_INVARIANT)
+/*
+ * In this mode [zj]node invariants are checked. This mode is not usually on,
+ * because it consumes a lot of CPU. See [zj]node_invariant() and
+ * doc/lock-ordering for description of invariants checked.
+ */
+#define REISER4_DEBUG_NODE_INVARIANT (1)
+#else
+#define REISER4_DEBUG_NODE_INVARIANT (0)
+#endif
+
+#if defined(CONFIG_REISER4_DEBUG_SPIN_LOCKS) && defined(CONFIG_REISER4_DEBUG)
+/*
+ * Turns on spin-lock debugging. Many (but not all) spin-locks used by reiser4
+ * are accessed through special wrapper macros defined in spin_macros.h. These
+ * macros allow, among other things, to specify for a given spin-lock type its
+ * "lock ordering predicate" that specifies what other locks may or may not be
+ * held simultaneously with this one. Spin-lock debugging checks for these
+ * ordering constraints along with trivial checks for proper lock/unlock
+ * nesting, etc. Note, that spin_macros.h also support spin-lock profiling
+ * described above (CONFIG_REISER4_LOCKPROF).
+ *
+ * Note: this is not available through fs/Kconfig. Adjust manually.
+ */
+#define REISER4_DEBUG_SPIN_LOCKS (1)
+#else
+#define REISER4_DEBUG_SPIN_LOCKS (0)
+#endif
+
+#define CONFIG_REISER4_DEBUG_CONTEXTS y
+#if defined(CONFIG_REISER4_DEBUG_CONTEXTS) && defined(CONFIG_REISER4_DEBUG)
+/*
+ * In this mode reiser4_context debugging is activated. reiser4_context is a
+ * data-structure created on stack at the beginning of reiser4 entry. In this
+ * mode, list of all "active" contexts is maintained, and periodically
+ * checked. This is to catch various hard-to-debug bugs like exiting without
+ * destroying context, or stack overflowing.
+ *
+ * Note: this is not available through fs/Kconfig. Adjust manually.
+ */
+#define REISER4_DEBUG_CONTEXTS (1)
+#else
+#define REISER4_DEBUG_CONTEXTS (0)
+#endif
+
+#if defined(CONFIG_REISER4_DEBUG_SIBLING_LIST) && defined(CONFIG_REISER4_DEBUG)
+/*
+ * Turn on sibling-list debugging. In this mode consistency of sibling lists
+ * of reiser4 internal tree is checked.
+ *
+ * Note: this is not available through fs/Kconfig. Adjust manually.
+ */
+#define REISER4_DEBUG_SIBLING_LIST (1)
+#else
+#define REISER4_DEBUG_SIBLING_LIST (0)
+#endif
+
+/* defining this makes reiser4_create to create both unix and crc files */
+/*#define CONFIG_TEST_CRC*/
+#if defined(CONFIG_TEST_CRC)
+#define TEST_CRC (1)
+#else
+#define TEST_CRC (0)
+#endif
+
+#if defined(CONFIG_CRYPTO_DEFLATE)
+#define REISER4_GZIP_TFM (1)
+#else
+#define REISER4_GZIP_TFM (0)
+#endif
+
 /*
  * This will be turned on automatically when viewmasks are for
  * obvious reasons.
  */
+
 #define ENABLE_REISER4_PSEUDO (0)
 
 /*
diff -puN /dev/null repacker.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/repacker.c	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,661 @@
+/* Copyright 2003 by Hans Reiser */
+
+/*
+   The reiser4 repacker.
+
+   It walks the reiser4 tree and marks all nodes (reads them if it is
+   necessary) for repacking by setting JNODE_REPACK bit. Also, all nodes which
+   have no JNODE_REPACK bit set nodes added to a transaction and marked dirty.
+*/
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/kobject.h>
+#include <linux/sched.h>
+#include <linux/writeback.h>
+#include <linux/suspend.h>
+
+#include <asm/atomic.h>
+
+#include "reiser4.h"
+#include "kattr.h"
+#include "super.h"
+#include "tree.h"
+#include "tree_walk.h"
+#include "jnode.h"
+#include "znode.h"
+#include "block_alloc.h"
+
+#include "plugin/item/extent.h"
+
+#include <linux/spinlock.h>
+#include "kcond.h"
+
+#include "repacker.h"
+
+/* The reiser4 repacker process nodes by chunks of REPACKER_CHUNK_SIZE
+ * size. */
+#define REPACKER_DEFAULT_CHUNK_SIZE 512
+
+enum repacker_state_bits {
+	REPACKER_RUNNING       = 0x1,
+	REPACKER_STOP          = 0x2,
+	REPACKER_DESTROY       = 0x4,
+	REPACKER_GOES_BACKWARD = 0x8
+};
+
+/* Per super block repacker structure for  */
+struct repacker {
+	/* Back reference to a super block. */
+	struct super_block * super;
+	/* Repacker thread state */
+	enum repacker_state_bits  state;
+	/* A spin lock to protect state */
+	spinlock_t guard;
+	/* A conditional variable to wait repacker state change. */
+	kcond_t    cond;
+#if REISER4_USE_SYSFS
+	/* An object (kobject), externally visible through SysFS. */
+	struct kobject kobj;
+#endif
+	struct {
+		reiser4_key start_key;
+		reiser4_block_nr chunk_size;
+		reiser4_block_nr count;
+	} params;
+};
+
+/* A thread-safe repacker check state bit routine.  */
+static inline int check_repacker_state_bit(struct repacker *repacker, enum repacker_state_bits bits)
+{
+	int result;
+
+	spin_lock(&repacker->guard);
+	result = !!(repacker->state & bits);
+	spin_unlock(&repacker->guard);
+
+	return result;
+}
+
+static int check_repacker_state (struct repacker * repacker)
+{
+	if (check_repacker_state_bit(
+		    get_current_super_private()->repacker, REPACKER_STOP))
+		return -EINTR;
+	if (current->flags & PF_FREEZE)
+		return -E_REPEAT;
+	if (current_atom_should_commit())
+		return -E_REPEAT;
+	return 0;
+}
+
+static void repacker_cursor_init (struct repacker_cursor * cursor, struct repacker * repacker)
+{
+	int backward = check_repacker_state_bit(repacker, REPACKER_GOES_BACKWARD);
+
+	xmemset(cursor, 0, sizeof (struct repacker_cursor));
+
+	blocknr_hint_init(&cursor->hint);
+	cursor->hint.backward = backward;
+
+	if (backward)
+		cursor->hint.blk = get_current_super_private()->block_count - 1;
+	else
+		cursor->hint.blk = 0;
+}
+
+static void repacker_cursor_done (struct repacker_cursor * cursor)
+{
+	blocknr_hint_done(&cursor->hint);
+}
+
+/* routines for closing current transaction and beginning new one */
+
+static int end_work (void)
+{
+	reiser4_context * ctx = get_current_context();
+
+	txn_end(ctx);
+	return 0;
+}
+static void begin_work (void)
+{
+	reiser4_context * ctx = get_current_context();
+	preempt_point();
+	txn_begin(ctx);
+}
+
+/* Processing of a formatted node when the repacker goes forward. */
+static int process_znode_forward (tap_t * tap, void * arg)
+{
+	struct repacker_cursor * cursor = arg;
+	znode * node = tap->lh->node;
+	int ret;
+
+	assert("zam-954", cursor->count > 0);
+
+	ret = check_repacker_state(get_current_super_private()->repacker);
+	if (ret)
+		return ret;
+
+	if (ZF_ISSET(node, JNODE_REPACK))
+		return 0;
+
+	if (current_atom_should_commit())
+		return -E_REPEAT;
+
+	znode_make_dirty(node);
+	ZF_SET(node, JNODE_REPACK);
+
+	cursor->stats.znodes_dirtied ++;
+
+	if (-- cursor->count <= 0)
+		return -E_REPEAT;
+	return 0;
+}
+
+/* Processing of unformatted nodes (of one extent unit) when the repacker goes
+ * forward. */
+static int process_extent_forward (tap_t *tap, void * arg)
+{
+	int ret;
+	struct repacker_cursor * cursor = arg;
+
+	ret = check_repacker_state(get_current_super_private()->repacker);
+	if (ret)
+		return ret;
+
+	ret = mark_extent_for_repacking(tap, cursor->count);
+	if (ret > 0) {
+		cursor->stats.jnodes_dirtied += ret;
+		cursor->count -= ret;
+		if (cursor->count <= 0)
+			     return -E_REPEAT;
+		return 0;
+	}
+
+	return ret;
+}
+
+
+/* It is for calling by tree walker before taking any locks. */
+static int prepare_repacking_session (void * arg)
+{
+	struct repacker_cursor * cursor = arg;
+	int ret;
+
+	assert("zam-951", schedulable());
+
+	all_grabbed2free();
+	ret = end_work();
+	if (ret)
+		return ret;
+
+	if (current->flags & PF_FREEZE)
+		refrigerator(PF_FREEZE);
+
+	begin_work();
+	balance_dirty_pages_ratelimited(get_current_super_private()->fake->i_mapping);
+	cursor->count = get_current_super_private()->repacker->params.chunk_size;
+	return  reiser4_grab_space((__u64)cursor->count,
+				   BA_CAN_COMMIT | BA_FORCE);
+}
+
+/* When the repacker goes backward (from the rightmost key to the leftmost
+ * one), it does relocation of all processed nodes to the end of disk.  Thus
+ * repacker does what usually the reiser4 flush does but in backward direction
+ * and node converting is not supported. */
+static int process_znode_backward (tap_t * tap, void * arg)
+{
+	lock_handle parent_lock;
+	load_count parent_load;
+	znode * child = tap->lh->node;
+	struct repacker_cursor * cursor = arg;
+	__u64 new_blocknr;
+	int ret;
+
+	assert("zam-977", (unsigned)(cursor->count) <= get_current_context()->grabbed_blocks);
+
+	/* Add node to current transaction like in processing forward. */
+	ret = process_znode_forward(tap, arg);
+	if (ret)
+		return ret;
+
+	init_lh(&parent_lock);
+	ret = reiser4_get_parent(&parent_lock, child, ZNODE_WRITE_LOCK, 0);
+	if (ret)
+		goto out;
+
+	init_load_count(&parent_load);
+
+	/* Do not relocate nodes which were processed by flush already. */
+	if (ZF_ISSET(child, JNODE_RELOC) || ZF_ISSET(child, JNODE_OVRWR))
+		goto out;
+
+	if (ZF_ISSET(child, JNODE_CREATED)) {
+		assert("zam-962", blocknr_is_fake(znode_get_block(child)));
+		cursor->hint.block_stage = BLOCK_UNALLOCATED;
+	} else {
+		if (znode_get_level(child) == LEAF_LEVEL)
+			cursor->hint.block_stage = BLOCK_FLUSH_RESERVED;
+		else {
+			ret = reiser4_grab_space((__u64)1,
+						 BA_FORCE |
+						 BA_RESERVED |
+						 BA_PERMANENT |
+						 BA_FORMATTED);
+			if (ret)
+				goto out;
+
+			cursor->hint.block_stage = BLOCK_GRABBED;
+		}
+	}
+
+	{
+		__u64 len = 1UL;
+
+		ret = reiser4_alloc_blocks(&cursor->hint, &new_blocknr, &len,
+					   BA_PERMANENT | BA_FORMATTED);
+		if (ret)
+			goto out;
+
+		cursor->hint.blk = new_blocknr;
+	}
+
+	if (!ZF_ISSET(child, JNODE_CREATED)) {
+		ret = reiser4_dealloc_block(znode_get_block(child), 0,
+				    BA_DEFER | BA_PERMANENT | BA_FORMATTED);
+		if (ret)
+			goto out;
+	}
+
+	/* Flush doesn't process nodes twice, it will not discard this block
+	 * relocation. */
+	ZF_SET(child, JNODE_RELOC);
+
+	/* Update parent reference. */
+	if (unlikely(znode_above_root(parent_lock.node))) {
+		reiser4_tree * tree = current_tree;
+		UNDER_RW_VOID(tree, tree, write, tree->root_block = new_blocknr);
+	} else {
+		coord_t parent_coord;
+		item_plugin *iplug;
+
+		ret = incr_load_count_znode(&parent_load, parent_lock.node);
+		if (ret)
+			goto out;
+
+		ret = find_child_ptr(parent_lock.node, child, &parent_coord);
+		if (ret)
+			goto out;
+
+		assert ("zam-960", item_is_internal(&parent_coord));
+		assert ("zam-961", znode_is_loaded(child));
+		iplug = item_plugin_by_coord(&parent_coord);
+		assert("zam-964", iplug->f.update != NULL);
+		iplug->f.update(&parent_coord, &new_blocknr);
+	}
+
+	znode_make_dirty(parent_lock.node);
+	ret = znode_rehash(child, &new_blocknr);
+
+ out:
+	done_load_count(&parent_load);
+	done_lh(&parent_lock);
+	assert("zam-982", (unsigned)(cursor->count) <= get_current_context()->grabbed_blocks);
+	return ret;
+}
+
+/* Processing of unformatted nodes when the repacker goes backward. */
+static int process_extent_backward (tap_t * tap, void * arg)
+{
+	struct repacker_cursor * cursor = arg;
+	int ret;
+
+	assert("zam-978", (unsigned)(cursor->count) <= get_current_context()->grabbed_blocks);
+
+	ret = check_repacker_state(get_current_super_private()->repacker);
+	if (ret)
+		return ret;
+
+	ret = process_extent_backward_for_repacking(tap, cursor);
+	if (ret)
+		return ret;
+	if (cursor->count <= 0)
+		return -E_REPEAT;
+
+	return 0;
+}
+/* A set of functions to be called by tree_walk in repacker forward pass. */
+static struct tree_walk_actor forward_actor = {
+	.process_znode  = process_znode_forward,
+	.process_extent = process_extent_forward,
+	.before         = prepare_repacking_session
+};
+
+/* A set of functions to be called by tree_walk in repacker backward pass. */
+static struct tree_walk_actor backward_actor = {
+	.process_znode  = process_znode_backward,
+	.process_extent = process_extent_backward,
+	.before         = prepare_repacking_session
+};
+
+
+reiser4_internal int reiser4_repacker (struct repacker * repacker)
+{
+	struct repacker_cursor cursor;
+	int backward;
+	struct tree_walk_actor * actor;
+	int ret;
+
+	repacker_cursor_init(&cursor, repacker);
+
+	backward = check_repacker_state_bit(repacker, REPACKER_GOES_BACKWARD);
+	actor = backward ? &backward_actor : &forward_actor;
+	ret = tree_walk(NULL, backward, actor, &cursor);
+	printk(KERN_INFO "reiser4 repacker: "
+	       "%lu formatted node(s) processed, %lu unformatted node(s) processed, ret = %d\n",
+	       cursor.stats.znodes_dirtied, cursor.stats.jnodes_dirtied, ret);
+
+	repacker_cursor_done(&cursor);
+	return ret;
+}
+
+/* The repacker kernel thread code. */
+reiser4_internal int repacker_d(void *arg)
+{
+	struct repacker * repacker = arg;
+	struct task_struct * me = current;
+	int ret;
+
+	reiser4_context ctx;
+
+	daemonize("k_reiser4_repacker_d");
+
+	/* block all signals */
+	spin_lock_irq(&me->sighand->siglock);
+	siginitsetinv(&me->blocked, 0);
+	recalc_sigpending();
+	spin_unlock_irq(&me->sighand->siglock);
+
+	/* zeroing the fs_context copied form parent process' task struct. */
+	me->journal_info = NULL;
+
+	printk(KERN_INFO "Repacker: I am alive, pid = %u\n", me->pid);
+	ret = init_context(&ctx, repacker->super);
+	if (!ret) {
+		ret = reiser4_repacker(repacker);
+		reiser4_exit_context(&ctx);
+	}
+
+	spin_lock(&repacker->guard);
+	repacker->state &= ~REPACKER_RUNNING;
+	kcond_broadcast(&repacker->cond);
+	spin_unlock(&repacker->guard);
+
+	return ret;
+}
+
+static void wait_repacker_completion(struct repacker * repacker)
+{
+	if (repacker->state & REPACKER_RUNNING) {
+		kcond_wait(&repacker->cond, &repacker->guard, 0);
+		assert("zam-956", !(repacker->state & REPACKER_RUNNING));
+	}
+}
+
+#if REISER4_USE_SYSFS
+
+static int start_repacker(struct repacker * repacker)
+{
+	spin_lock(&repacker->guard);
+	if (!(repacker->state & REPACKER_DESTROY)) {
+		repacker->state &= ~REPACKER_STOP;
+		if (!(repacker->state & REPACKER_RUNNING)) {
+			repacker->state |= REPACKER_RUNNING;
+			spin_unlock(&repacker->guard);
+			kernel_thread(repacker_d, repacker, CLONE_VM | CLONE_FS | CLONE_FILES);
+			return 0;
+		}
+	}
+	spin_unlock(&repacker->guard);
+	return 0;
+}
+
+static void stop_repacker(struct repacker * repacker)
+{
+	spin_lock(&repacker->guard);
+	repacker->state |= REPACKER_STOP;
+	spin_unlock(&repacker->guard);
+}
+
+struct repacker_attr {
+	struct attribute attr;
+	ssize_t (*show)(struct repacker *, char * buf);
+	ssize_t (*store)(struct repacker *, const char * buf, size_t size);
+};
+
+static ssize_t start_attr_show (struct repacker * repacker, char * buf)
+{
+	return snprintf(buf, PAGE_SIZE , "%d", check_repacker_state_bit(repacker, REPACKER_RUNNING));
+}
+
+static ssize_t start_attr_store (struct repacker * repacker,  const char *buf, size_t size)
+{
+	int start_stop = 0;
+
+	sscanf(buf, "%d", &start_stop);
+	if (start_stop)
+		start_repacker(repacker);
+	else
+		stop_repacker(repacker);
+
+	return size;
+}
+
+static ssize_t direction_attr_show (struct repacker * repacker, char * buf)
+{
+	return snprintf(buf, PAGE_SIZE , "%d", check_repacker_state_bit(repacker, REPACKER_GOES_BACKWARD));
+}
+
+static ssize_t direction_attr_store (struct repacker * repacker,  const char *buf, size_t size)
+{
+	int go_left = 0;
+
+	sscanf(buf, "%d", &go_left);
+
+	spin_lock(&repacker->guard);
+	if (!(repacker->state & REPACKER_RUNNING)) {
+		if (go_left)
+			repacker->state |= REPACKER_GOES_BACKWARD;
+		else
+			repacker->state &= ~REPACKER_GOES_BACKWARD;
+	}
+	spin_unlock(&repacker->guard);
+	return size;
+}
+
+static ssize_t start_key_attr_show (struct repacker * repacker, char * buf)
+{
+	spin_lock(&repacker->guard);
+	spin_unlock(&repacker->guard);
+
+	return 0;
+}
+
+static ssize_t start_key_attr_store (struct repacker * repacker,  const char *buf, size_t size)
+{
+	spin_lock(&repacker->guard);
+	spin_unlock(&repacker->guard);
+
+	return (ssize_t)size;
+}
+
+static ssize_t count_attr_show (struct repacker * repacker, char * buf)
+{
+	__u64 count;
+
+	spin_lock(&repacker->guard);
+	count = repacker->params.count;
+	spin_unlock(&repacker->guard);
+
+	return snprintf(buf, PAGE_SIZE, "%llu", (unsigned long long)count);
+}
+
+static ssize_t count_attr_store (struct repacker * repacker,  const char *buf, size_t size)
+{
+	unsigned long long count;
+
+	sscanf(buf, "%Lu", &count);
+
+	spin_lock(&repacker->guard);
+	repacker->params.count = (__u64)count;
+	spin_unlock(&repacker->guard);
+
+	return (ssize_t)size;
+}
+
+static ssize_t chunk_size_attr_show (struct repacker * repacker, char * buf)
+{
+	__u64 chunk_size;
+
+	spin_lock(&repacker->guard);
+	chunk_size = repacker->params.chunk_size;
+	spin_unlock(&repacker->guard);
+
+	return snprintf(buf, PAGE_SIZE, "%Lu", (unsigned long long)chunk_size);
+}
+
+static ssize_t chunk_size_attr_store (struct repacker * repacker,  const char *buf, size_t size)
+{
+	unsigned long long chunk_size;
+
+	sscanf(buf, "%Lu", &chunk_size);
+
+	spin_lock(&repacker->guard);
+	repacker->params.chunk_size = (__u64)chunk_size;
+	spin_unlock(&repacker->guard);
+
+	return (ssize_t)size;
+}
+
+#define REPACKER_ATTR(attr_name, perm)			\
+static struct repacker_attr attr_name ## _attr = {	\
+	.attr = {					\
+		.name = # attr_name,			\
+		.mode = perm				\
+	},						\
+	.show = attr_name ## _attr_show,		\
+	.store = attr_name ## _attr_store,		\
+}
+
+REPACKER_ATTR(start, 0644);
+REPACKER_ATTR(direction, 0644);
+REPACKER_ATTR(start_key, 0644);
+REPACKER_ATTR(count, 0644);
+REPACKER_ATTR(chunk_size, 0644);
+
+static struct attribute * repacker_def_attrs[] = {
+	&start_attr.attr,
+	&direction_attr.attr,
+	&start_key_attr.attr,
+	&count_attr.attr,
+	&chunk_size_attr.attr,
+	NULL
+};
+
+static ssize_t repacker_attr_show (struct kobject *kobj, struct attribute *attr,  char *buf)
+{
+	struct repacker_attr * r_attr = container_of(attr, struct repacker_attr, attr);
+	struct repacker * repacker = container_of(kobj, struct repacker, kobj);
+
+	return r_attr->show(repacker, buf);
+}
+
+static ssize_t repacker_attr_store (struct kobject *kobj, struct attribute *attr, const char *buf, size_t size)
+{
+	struct repacker_attr * r_attr = container_of(attr, struct repacker_attr, attr);
+	struct repacker * repacker = container_of(kobj, struct repacker, kobj);
+
+	return r_attr->store(repacker, buf, size);
+}
+
+static struct sysfs_ops repacker_sysfs_ops = {
+	.show  = repacker_attr_show,
+	.store = repacker_attr_store
+};
+
+static struct kobj_type repacker_ktype = {
+	.sysfs_ops     = &repacker_sysfs_ops,
+	.default_attrs = repacker_def_attrs,
+	.release       = NULL
+};
+
+static int init_repacker_sysfs_interface (struct super_block * s)
+{
+	int ret = 0;
+	reiser4_super_info_data * sinfo = get_super_private(s);
+	struct kobject * root = &sinfo->kobj.kobj;
+	struct repacker * repacker = sinfo->repacker;
+
+	assert("zam-947", repacker != NULL);
+
+	snprintf(repacker->kobj.name, KOBJ_NAME_LEN, "repacker");
+	repacker->kobj.parent = kobject_get(root);
+	repacker->kobj.ktype = &repacker_ktype;
+	ret = kobject_register(&repacker->kobj);
+
+	return ret;
+}
+
+static void done_repacker_sysfs_interface (struct super_block * s)
+{
+	reiser4_super_info_data * sinfo = get_super_private(s);
+
+	kobject_unregister(&sinfo->repacker->kobj);
+}
+
+#else  /* REISER4_USE_SYSFS */
+
+#define init_repacker_sysfs_interface(s) (0)
+#define done_repacker_sysfs_interface(s) do{}while(0)
+
+#endif /* REISER4_USE_SYSFS */
+
+reiser4_internal int init_reiser4_repacker (struct super_block *super)
+{
+	reiser4_super_info_data * sinfo = get_super_private(super);
+
+	assert ("zam-946", sinfo->repacker == NULL);
+	sinfo->repacker = kmalloc(sizeof (struct repacker), GFP_KERNEL);
+	if (sinfo->repacker == NULL)
+		return -ENOMEM;
+	xmemset(sinfo->repacker, 0, sizeof(struct repacker));
+	sinfo->repacker->super = super;
+
+	/* set repacker parameters by default values */
+	sinfo->repacker->params.chunk_size = REPACKER_DEFAULT_CHUNK_SIZE;
+
+	spin_lock_init(&sinfo->repacker->guard);
+	kcond_init(&sinfo->repacker->cond);
+
+	return init_repacker_sysfs_interface(super);
+}
+
+reiser4_internal void done_reiser4_repacker (struct super_block *super)
+{
+	reiser4_super_info_data * sinfo = get_super_private(super);
+	struct repacker * repacker;
+
+	repacker = sinfo->repacker;
+	assert("zam-945", repacker != NULL);
+	done_repacker_sysfs_interface(super);
+
+	spin_lock(&repacker->guard);
+	repacker->state |= (REPACKER_STOP | REPACKER_DESTROY);
+	wait_repacker_completion(repacker);
+	spin_unlock(&repacker->guard);
+
+	kfree(repacker);
+	sinfo->repacker = NULL;
+}
diff -puN /dev/null repacker.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/repacker.h	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,22 @@
+/* Copyright 2003 by Hans Reiser */
+
+#ifndef __FS_REISER4_REPACKER_H__
+#define __FS_REISER4_REPACKER_H__
+
+/* Repacker per tread state and statistics. */
+struct repacker_cursor {
+	reiser4_blocknr_hint hint;
+	int count;
+	struct  {
+		long znodes_dirtied;
+		long jnodes_dirtied;
+	} stats;
+};
+
+extern int  init_reiser4_repacker(struct super_block *);
+extern void done_reiser4_repacker(struct super_block *);
+
+extern int reiser4_repacker (struct repacker * repacker);
+extern int repacker_d(void *arg);
+
+#endif /* __FS_REISER4_REPACKER_H__ */
diff -puN safe_link.c~profile-stat-trace-repacker safe_link.c
--- reiser4/safe_link.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/safe_link.c	2005-02-01 11:51:12.000000000 +0300
@@ -104,8 +104,7 @@ build_link_key(struct inode *inode, reis
  * how much disk space is necessary to insert and remove (in the
  * error-handling path) safe-link.
  */
-static __u64
-safe_link_tograb(reiser4_tree *tree)
+reiser4_internal __u64 safe_link_tograb(reiser4_tree *tree)
 {
 	return
 		/* insert safe link */
@@ -285,6 +284,7 @@ static int process_safelink(struct super
 				"Cannot handle safelink for %lli",
 				(unsigned long long)oid);
 			print_key("key", sdkey);
+			print_inode("inode", inode);
 			result = 0;
 		}
 		if (result != 0) {
diff -puN safe_link.h~profile-stat-trace-repacker safe_link.h
diff -puN seal.c~profile-stat-trace-repacker seal.c
--- reiser4/seal.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/seal.c	2005-02-01 11:51:12.000000000 +0300
@@ -55,7 +55,7 @@ seal_init(seal_t * seal /* seal to initi
 						 * attached to */ )
 {
 	assert("nikita-1886", seal != NULL);
-	memset(seal, 0, sizeof *seal);
+	xmemset(seal, 0, sizeof *seal);
 	if (coord != NULL) {
 		znode *node;
 
@@ -167,6 +167,7 @@ seal_validate(seal_t * seal /* seal to v
 				ON_DEBUG(coord_update_v(coord));
 				assert("nikita-1990", node == seal->coord.node);
 				assert("nikita-1898", WITH_DATA_RET(coord->node, 1, check_seal_match(coord, key)));
+				reiser4_stat_inc(seal.perfect_match);
 			} else
 				result = RETERR(-E_REPEAT);
 		}
@@ -178,6 +179,7 @@ seal_validate(seal_t * seal /* seal to v
 		}
 	} else {
 		/* znode wasn't in cache */
+		reiser4_stat_inc(seal.out_of_cache);
 		result = RETERR(-E_REPEAT);
 	}
 	return result;
diff -puN seal.h~profile-stat-trace-repacker seal.h
--- reiser4/seal.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/seal.h	2005-02-01 11:58:02.000000000 +0300
@@ -39,6 +39,12 @@ extern int seal_validate(seal_t * seal,
 			 tree_level level,
 			 lock_handle * lh, lookup_bias bias, znode_lock_mode mode, znode_lock_request request);
 
+#if REISER4_DEBUG_OUTPUT
+extern void print_seal(const char *prefix, const seal_t * seal);
+#else
+#define print_seal( prefix, seal ) noop
+#endif
+
 /* __SEAL_H__ */
 #endif
 
diff -puN search.c~profile-stat-trace-repacker search.c
--- reiser4/search.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/search.c	2005-02-01 11:51:12.000000000 +0300
@@ -15,14 +15,14 @@
 #include "block_alloc.h"
 #include "tree_walk.h"
 #include "tree.h"
+#include "log.h"
 #include "reiser4.h"
 #include "super.h"
+#include "prof.h"
 #include "inode.h"
 
 #include <linux/slab.h>
 
-static const char * bias_name(lookup_bias bias);
-
 /* tree searching algorithm, intranode searching algorithms are in
    plugin/node/ */
 
@@ -86,6 +86,35 @@ cbk_cache_done(cbk_cache * cache /* cach
 	     !cbk_cache_list_end( &( cache ) -> lru, ( slot ) ) ; 	\
 	     ( slot ) = cbk_cache_list_next( slot ) )
 
+#if REISER4_DEBUG_OUTPUT
+/* Debugging aid: print human readable information about @slot */
+reiser4_internal void
+print_cbk_slot(const char *prefix /* prefix to print */ ,
+	       const cbk_cache_slot * slot /* slot to print */ )
+{
+	if (slot == NULL)
+		printk("%s: null slot\n", prefix);
+	else
+		print_znode("node", slot->node);
+}
+
+/* Debugging aid: print human readable information about @cache */
+reiser4_internal void
+print_cbk_cache(const char *prefix /* prefix to print */ ,
+		const cbk_cache * cache /* cache to print */ )
+{
+	if (cache == NULL)
+		printk("%s: null cache\n", prefix);
+	else {
+		cbk_cache_slot *scan;
+
+		printk("%s: cache: %p\n", prefix, cache);
+		for_all_slots(cache, scan)
+		    print_cbk_slot("slot", scan);
+	}
+}
+#endif
+
 #if REISER4_DEBUG
 /* this function assures that [cbk-cache-invariant] invariant holds */
 static int
@@ -160,7 +189,7 @@ cbk_cache_invalidate(const znode * node 
 
 /* add to the cbk-cache in the "tree" information about "node". This
     can actually be update of existing slot in a cache. */
-static void
+reiser4_internal void
 cbk_cache_add(const znode * node /* node to add to the cache */ )
 {
 	cbk_cache *cache;
@@ -216,21 +245,20 @@ static level_lookup_result search_to_lef
 
 /* pack numerous (numberous I should say) arguments of coord_by_key() into
  * cbk_handle */
-static cbk_handle *
-cbk_pack(cbk_handle *handle,
-	 reiser4_tree * tree,
-	 const reiser4_key * key,
-	 coord_t * coord,
-	 lock_handle * active_lh,
-	 lock_handle * parent_lh,
-	 znode_lock_mode lock_mode,
-	 lookup_bias bias,
-	 tree_level lock_level,
-	 tree_level stop_level,
-	 __u32 flags,
-	 ra_info_t *info)
+reiser4_internal cbk_handle *cbk_pack(cbk_handle *handle,
+		     reiser4_tree * tree,
+		     const reiser4_key * key,
+		     coord_t * coord,
+		     lock_handle * active_lh,
+		     lock_handle * parent_lh,
+		     znode_lock_mode lock_mode,
+		     lookup_bias bias,
+		     tree_level lock_level,
+		     tree_level stop_level,
+		     __u32 flags,
+		     ra_info_t *info)
 {
-	memset(handle, 0, sizeof *handle);
+	xmemset(handle, 0, sizeof *handle);
 
 	handle->tree = tree;
 	handle->key = key;
@@ -308,8 +336,13 @@ coord_by_key(reiser4_tree * tree	/* tree
 	assert("nikita-355", coord != NULL);
 	assert("nikita-356", (bias == FIND_EXACT) || (bias == FIND_MAX_NOT_MORE_THAN));
 	assert("nikita-357", stop_level >= LEAF_LEVEL);
+
+	if (!lock_stack_isclean(get_current_lock_stack()))
+		print_clog();
+
 	/* no locks can be held during tree traversal */
 	assert("nikita-2104", lock_stack_isclean(get_current_lock_stack()));
+	trace_stamp(TRACE_TREE);
 
 	cbk_pack(&handle,
 		 tree,
@@ -356,8 +389,13 @@ object_lookup(struct inode *object,
 	assert("nikita-355", coord != NULL);
 	assert("nikita-356", (bias == FIND_EXACT) || (bias == FIND_MAX_NOT_MORE_THAN));
 	assert("nikita-357", stop_level >= LEAF_LEVEL);
+
+	if (!lock_stack_isclean(get_current_lock_stack()))
+		print_clog();
+
 	/* no locks can be held during tree search by key */
 	assert("nikita-2104", lock_stack_isclean(get_current_lock_stack()));
+	trace_stamp(TRACE_TREE);
 
 	cbk_pack(&handle,
 		 object != NULL ? tree_by_inode(object) : current_tree,
@@ -386,6 +424,9 @@ coord_by_handle(cbk_handle * handle)
 	 * first check cbk_cache (which is look-aside cache for our tree) and
 	 * of this fails, start traversal.
 	 */
+
+	write_tree_log(handle->tree, tree_lookup, handle->key);
+
 	/* first check whether "key" is in cache of recent lookups. */
 	if (cbk_cache_search(handle) == 0)
 		return handle->result;
@@ -594,6 +635,7 @@ prepare_object_lookup(cbk_handle * h)
 		/*
 		 * object doesn't have known vroot, start from real tree root.
 		 */
+		reiser4_stat_inc(tree.object_lookup_novroot);
 		return LOOKUP_CONT;
 	}
 
@@ -623,20 +665,25 @@ prepare_object_lookup(cbk_handle * h)
 				zrelse(vroot);/*h->active_lh->node);*/
 				if (h->active_lh->node != vroot) {
 					result = LOOKUP_REST;
+					reiser4_stat_inc(tree.object_lookup_moved);
 				} else if (result == LOOKUP_CONT) {
 					move_lh(h->parent_lh, h->active_lh);
 					h->flags &= ~CBK_DKSET;
 				}
 			}
-		}
+		} else
+			/* vroot is not up-to-date. Restart. */
+			reiser4_stat_inc(tree.object_lookup_outside);
 	} else
 		/* long-term locking failed. Restart. */
-		;
+		reiser4_stat_inc(tree.object_lookup_cannotlock);
 
 	zput(vroot);
 
 	if (IS_CBKERR(h->result) || result == LOOKUP_REST)
 		hput(h);
+	if (result != LOOKUP_REST)
+		reiser4_stat_inc_at_level(h->level, object_lookup_start);
 	return result;
 }
 
@@ -658,6 +705,9 @@ traverse_tree(cbk_handle * h /* search h
 	assert("nikita-2949", !(h->flags & CBK_DKSET));
 	assert("zam-355", lock_stack_isclean(get_current_lock_stack()));
 
+	trace_stamp(TRACE_TREE);
+	reiser4_stat_inc(tree.cbk);
+
 	done = 0;
 	iterations = 0;
 	vroot_used = 0;
@@ -678,6 +728,7 @@ restart:
 		vroot_used = 1;
 		done = prepare_object_lookup(h);
 		if (done == LOOKUP_REST) {
+			reiser4_stat_inc(tree.object_lookup_restart);
 			goto restart;
 		} else if (done == LOOKUP_DONE)
 			return h->result;
@@ -720,6 +771,7 @@ restart:
 			done = 1;
 			break;
 		case LOOKUP_REST:
+			reiser4_stat_inc(tree.cbk_restart);
 			hput(h);
 			/* deadlock avoidance is normal case. */
 			if (h->result != -E_DEADLOCK)
@@ -752,6 +804,7 @@ restart:
 			     (h->bias == FIND_EXACT) &&
 			     (!node_is_empty(h->coord->node)), coord_is_existing_item(h->coord))));
 	}
+	write_tree_log(h->tree, tree_exit);
 	return h->result;
 }
 
@@ -951,6 +1004,12 @@ cbk_level_lookup(cbk_handle * h /* searc
 		   2. or, node itself is going to be removed from the
 		   tree. Release lock and restart.
 		*/
+		if (REISER4_STATS) {
+			if (znode_contains_key_lock(active, h->key))
+				reiser4_stat_inc_at_level(h->level, cbk_met_ghost);
+			else
+				reiser4_stat_inc_at_level(h->level, cbk_key_moved);
+		}
 		h->result = -E_REPEAT;
 	}
 	if (h->result == -E_REPEAT)
@@ -972,6 +1031,7 @@ cbk_level_lookup(cbk_handle * h /* searc
 	if (ldkeyset && !node_is_empty(active) &&
 	    !keyeq(leftmost_key_in_node(active, &key), &ldkey)) {
 		warning("vs-3533", "Keys are inconsistent. Fsck?");
+		print_node_content("child", active, ~0);
 		print_key("inparent", &ldkey);
 		print_key("inchild", &key);
 		h->result = RETERR(-EIO);
@@ -1095,8 +1155,10 @@ cbk_node_lookup(cbk_handle * h /* search
 				return search_to_left(h);
 			} else
 				h->result = CBK_COORD_FOUND;
+			reiser4_stat_inc(tree.cbk_found);
 		} else {
 			h->result = CBK_COORD_NOTFOUND;
+			reiser4_stat_inc(tree.cbk_notfound);
 		}
 		if (!(h->flags & CBK_IN_CACHE))
 			cbk_cache_add(active);
@@ -1246,6 +1308,7 @@ cbk_cache_scan_slots(cbk_handle * h /* c
 
 		if (llr != LOOKUP_DONE) {
 			/* restart or continue on the next level */
+			reiser4_stat_inc(tree.cbk_cache_wrong_node);
 			result = RETERR(-ENOENT);
 		} else if (IS_CBKERR(h->result))
 			/* io or oom */
@@ -1275,6 +1338,7 @@ cbk_cache_scan_slots(cbk_handle * h /* c
 		   so that cbk() will be performed. This is not that
 		   important, because such races should be rare. Are they?
 		*/
+		reiser4_stat_inc(tree.cbk_cache_race);
 		result = RETERR(-ENOENT);	/* -ERAUGHT */
 	}
 	zrelse(node);
@@ -1311,8 +1375,11 @@ cbk_cache_search(cbk_handle * h /* cbk h
 		if (result != 0) {
 			done_lh(h->active_lh);
 			done_lh(h->parent_lh);
+			reiser4_stat_inc(tree.cbk_cache_miss);
 		} else {
 			assert("nikita-1319", !IS_CBKERR(h->result));
+			reiser4_stat_inc(tree.cbk_cache_hit);
+			write_tree_log(h->tree, tree_cached);
 			break;
 		}
 	}
@@ -1408,6 +1475,7 @@ search_to_left(cbk_handle * h /* search 
 	node = h->active_lh->node;
 	assert("nikita-1763", coord_is_leftmost_unit(coord));
 
+	reiser4_stat_inc(tree.check_left_nonuniq);
 	h->result = reiser4_get_left_neighbor(
 		&lh, node, (int) h->lock_mode, GN_CAN_USE_UPPER_LEVELS);
 	neighbor = NULL;
@@ -1438,11 +1506,14 @@ search_to_left(cbk_handle * h /* search 
 			if (h->result == NS_NOT_FOUND) {
 	case -E_NO_NEIGHBOR:
 				h->result = CBK_COORD_FOUND;
+				reiser4_stat_inc(tree.cbk_found);
 				if (!(h->flags & CBK_IN_CACHE))
 					cbk_cache_add(node);
 	default:		/* some other error */
 				result = LOOKUP_DONE;
 			} else if (h->result == NS_FOUND) {
+				reiser4_stat_inc(tree.left_nonuniq_found);
+
 				RLOCK_DK(znode_get_tree(neighbor));
 				h->rd_key = *znode_get_ld_key(node);
 				leftmost_key_in_node(neighbor, &h->ld_key);
@@ -1471,7 +1542,7 @@ search_to_left(cbk_handle * h /* search 
 }
 
 /* debugging aid: return symbolic name of search bias */
-static const char *
+reiser4_internal const char *
 bias_name(lookup_bias bias /* bias to get name of */ )
 {
 	if (bias == FIND_EXACT)
@@ -1488,7 +1559,7 @@ bias_name(lookup_bias bias /* bias to ge
 	}
 }
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 /* debugging aid: print human readable information about @p */
 reiser4_internal void
 print_coord_content(const char *prefix /* prefix to print */ ,
@@ -1506,6 +1577,7 @@ print_coord_content(const char *prefix /
 	if (znode_is_loaded(p->node)) {
 		item_key_by_coord(p, &key);
 		print_key(prefix, &key);
+		print_plugin(prefix, item_plugin_to_plugin(item_plugin_by_coord(p)));
 	}
 }
 
diff -puN spin_macros.h~profile-stat-trace-repacker spin_macros.h
--- reiser4/spin_macros.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/spin_macros.h	2005-02-01 11:51:12.000000000 +0300
@@ -35,6 +35,7 @@
 #include <linux/profile.h>
 
 #include "debug.h"
+#include "spinprof.h"
 
 /* Checks that read write lock @s is locked (or not) by the -current-
  * thread. not yet implemented */
@@ -52,12 +53,212 @@
 #    define check_spin_is_locked(s)     ((void)(s), 1)
 #endif
 
+#if REISER4_DEBUG_SPIN_LOCKS
+#define __ODCA(l, e) ON_DEBUG_CONTEXT(assert(l, e))
+#else
+#define __ODCA(l, e) noop
+#endif
+
+#define REISER4_LOCKPROF_OBJECTS (0)
+
+#if REISER4_LOCKPROF
+
+/*
+ * If spin lock profiling is on, define profregions (see spinprof.[ch])
+ * exporting through sysfs information about spin lock contention. With each
+ * spin lock type two profregions are associated: "held" region (exported as
+ * /sys/profregion/foo_h), and "trying" region (exported as
+ * /sys/profregion/foo_t).
+ */
+
+/*
+ * This macro, given spin lock type, defines corresponding profregions and
+ * functions to register and unregister them.
+ */
+#define DEFINE_SPIN_PROFREGIONS(aname)						\
+struct profregion pregion_spin_ ## aname ## _held = {   			\
+	.kobj = {								\
+		.name = #aname  "_h"						\
+	}									\
+};										\
+										\
+struct profregion pregion_spin_ ## aname ## _trying = { 			\
+	.kobj = {								\
+		.name = #aname  "_t"						\
+	}									\
+};										\
+										\
+static inline int register_ ## aname ## _profregion(void)			\
+{										\
+	int result;								\
+										\
+	result = profregion_register(&pregion_spin_ ## aname ## _held);		\
+	if (result != 0)							\
+		return result;							\
+	result = profregion_register(&pregion_spin_ ## aname ## _trying);	\
+	return result;								\
+}										\
+										\
+static inline void unregister_ ## aname ## _profregion(void)			\
+{										\
+	profregion_unregister(&pregion_spin_ ## aname ## _held);		\
+	profregion_unregister(&pregion_spin_ ## aname ## _trying);		\
+}										\
+										\
+typedef struct { int foo; } aname ## _spin_dummy_profregion
+
+#define DECLARE_SPIN_PROFREGIONS(NAME)				\
+extern struct profregion pregion_spin_ ## NAME ## _held;	\
+extern struct profregion pregion_spin_ ## NAME ## _trying;
+
+/*
+ * If spin lock profiling is on, define profregions (see spinprof.[ch])
+ * exporting through sysfs information about read write lock contention. With
+ * each read write lock type four profregions are associated: "read held" and
+ * "write held" regions, and "read trying" and "write trying" regions,
+ * exported as /sys/profregion/foo_{r,w}_{t,h}.
+ */
+
+
+/*
+ * This macro, given read write lock type, defines corresponding profregions
+ * and functions to register and unregister them.
+ */
+#define DEFINE_RW_PROFREGIONS(aname)						\
+struct profregion pregion_rw_ ## aname ## _r_held = {   			\
+	.kobj = {								\
+		.name = #aname  "_r_h"						\
+	}									\
+};										\
+										\
+struct profregion pregion_rw_ ## aname ## _w_held = {   			\
+	.kobj = {								\
+		.name = #aname  "_w_h"						\
+	}									\
+};										\
+										\
+struct profregion pregion_rw_ ## aname ## _r_trying = {   			\
+	.kobj = {								\
+		.name = #aname  "_r_t"						\
+	}									\
+};										\
+										\
+struct profregion pregion_rw_ ## aname ## _w_trying = {   			\
+	.kobj = {								\
+		.name = #aname  "_w_t"						\
+	}									\
+};										\
+										\
+static inline int register_ ## aname ## _profregion(void)			\
+{										\
+	int result;								\
+										\
+	result = profregion_register(&pregion_rw_ ## aname ## _r_held);		\
+	if (result != 0)							\
+		return result;							\
+	result = profregion_register(&pregion_rw_ ## aname ## _w_held);		\
+	if (result != 0)							\
+		return result;							\
+	result = profregion_register(&pregion_rw_ ## aname ## _r_trying);	\
+	if (result != 0)							\
+		return result;							\
+	result = profregion_register(&pregion_rw_ ## aname ## _w_trying);	\
+	return result;								\
+}										\
+										\
+static inline void unregister_ ## aname ## _profregion(void)			\
+{										\
+	profregion_unregister(&pregion_rw_ ## aname ## _r_held);		\
+	profregion_unregister(&pregion_rw_ ## aname ## _w_held);		\
+	profregion_unregister(&pregion_rw_ ## aname ## _r_trying);		\
+	profregion_unregister(&pregion_rw_ ## aname ## _w_trying);		\
+}										\
+										\
+typedef struct { int foo; } aname ## _rw_dummy_profregion
+
+#define DECLARE_RW_PROFREGIONS(NAME)				\
+extern struct profregion pregion_rw_ ## NAME ## _r_held;	\
+extern struct profregion pregion_rw_ ## NAME ## _w_held;	\
+extern struct profregion pregion_rw_ ## NAME ## _r_trying;	\
+extern struct profregion pregion_rw_ ## NAME ## _w_trying;
+
+#if REISER4_LOCKPROF_OBJECTS
+#define OBJCNT(field) field
+#else
+#define OBJCNT(field) (NULL)
+#endif
+
+/*
+ * Helper macros to enter and leave profiling regions.
+ */
+
+#define GETCPU(cpu)				\
+	int cpu = get_cpu()
+
+#define PUTCPU(cpu) put_cpu()
+
+#define PREG_IN(cpu, preg, objloc, codeloc)				\
+	profregion_in(cpu, preg, OBJCNT(objloc), codeloc)
+
+#define PREG_REPLACE(cpu, preg, objloc, codeloc)			\
+	profregion_replace(cpu, preg, OBJCNT(objloc), codeloc)
+
+#define PREG_EX(cpu, preg) profregion_ex(cpu, preg)
+
+/* REISER4_LOCKPROF */
+#else
+
+/*
+ * If spin lock profiling is disabled, declare everything to noops.
+ */
+
+#define DEFINE_SPIN_PROFREGIONS(aname)				\
+static inline int register_ ## aname ## _profregion(void)	\
+{								\
+	return 0;						\
+}								\
+								\
+static inline void unregister_ ## aname ## _profregion(void)	\
+{								\
+}
+
+#define DECLARE_SPIN_PROFREGIONS(NAME)
+
+#define DEFINE_RW_PROFREGIONS(aname)				\
+static inline int register_ ## aname ## _profregion(void)	\
+{								\
+	return 0;						\
+}								\
+								\
+static inline void unregister_ ## aname ## _profregion(void)	\
+{								\
+}
+
+#define DECLARE_RW_PROFREGIONS(NAME)
+
+#define GETCPU(cpu)
+#define PUTCPU(cpu)
+#define PREG_IN(cpu, preg, objloc, codeloc)
+#define PREG_REPLACE(cpu, preg, objloc, codeloc)
+#define PREG_EX(cpu, preg)
+
+/* REISER4_LOCKPROF */
+#endif
+
 /*
  * Data structure embedded into kernel objects together with spin lock.
  */
 typedef struct reiser4_spin_data {
 	/* spin lock proper */
 	spinlock_t lock;
+#if REISER4_LOCKPROF && REISER4_LOCKPROF_OBJECTS
+	/* number of times clock interrupt found spin lock of this objects to
+	 * be held */
+	int        held;
+	/* number of times clock interrupt found that current thread is trying
+	 * to acquire this spin lock */
+	int        trying;
+#endif
 } reiser4_spin_data;
 
 /*
@@ -66,18 +267,28 @@ typedef struct reiser4_spin_data {
 typedef struct reiser4_rw_data {
 	/* read write lock proper */
 	rwlock_t lock;
-} reiser4_rw_data;
-
-#if REISER4_DEBUG
-#define __ODCA(l, e) ON_DEBUG_CONTEXT(assert(l, e))
-#else
-#define __ODCA(l, e) noop
+#if REISER4_LOCKPROF && REISER4_LOCKPROF_OBJECTS
+	/* number of times clock interrupt found read write lock of this
+	 * objects to be read held */
+	int      r_held;
+	/* number of times clock interrupt found that current thread is trying
+	 * to acquire this lock for read */
+	int      r_trying;
+	/* number of times clock interrupt found read write lock of this
+	 * objects to be write held */
+	int      w_held;
+	/* number of times clock interrupt found that current thread is trying
+	 * to acquire this lock for write */
+	int      w_trying;
 #endif
+} reiser4_rw_data;
 
 /* Define several inline functions for each type of spinlock. This is long
  * monster macro definition. */
 #define SPIN_LOCK_FUNCTIONS(NAME,TYPE,FIELD)					\
 										\
+DECLARE_SPIN_PROFREGIONS(NAME)							\
+										\
 /* Initialize spin lock embedded in @x			*/			\
 static inline void spin_ ## NAME ## _init(TYPE *x)				\
 {										\
@@ -121,17 +332,26 @@ static inline int  spin_ ## NAME ## _is_
 										\
 /* Acquire spin lock embedded in @x without checking lock ordering.       */	\
 /* This is useful when, for example, locking just created object.         */	\
-static inline void spin_lock_ ## NAME ## _no_ord (TYPE *x) 			\
+static inline void spin_lock_ ## NAME ## _no_ord (TYPE *x, 			\
+						  locksite *t, locksite *h)	\
 {										\
+	GETCPU(cpu);								\
 	__ODCA("nikita-2703", spin_ ## NAME ## _is_not_locked(x));		\
+	PREG_IN(cpu, &pregion_spin_ ## NAME ## _trying, &x->FIELD.trying, t);	\
 	spin_lock(&x->FIELD.lock);						\
+	PREG_REPLACE(cpu,							\
+		     &pregion_spin_ ## NAME ## _held, &x->FIELD.held, h);	\
+	PUTCPU(cpu);								\
 	spin_ ## NAME ## _inc();						\
 }										\
 										\
 /* Account for spin lock acquired by some other means. For example        */	\
 /* through atomic_dec_and_lock() or similar.                              */	\
-static inline void spin_lock_ ## NAME ## _acc (TYPE *x)				\
+static inline void spin_lock_ ## NAME ## _acc (TYPE *x, locksite *h)		\
 {										\
+	GETCPU(cpu);								\
+	PREG_IN(cpu, &pregion_spin_ ## NAME ## _held, &x->FIELD.held, h);	\
+	PUTCPU(cpu);								\
 	spin_ ## NAME ## _inc();						\
 }										\
 										\
@@ -145,17 +365,18 @@ static inline void spin_lock_ ## NAME ##
 /* If clock interrupt finds that current thread holds the lock on @x,     */	\
 /* counters in @h will be incremented.                                    */	\
 /*                                                                        */	\
-static inline void spin_lock_ ## NAME ## _at (TYPE *x) 				\
+static inline void spin_lock_ ## NAME ## _at (TYPE *x, 				\
+					      locksite *t, locksite *h)		\
 {										\
 	__ODCA("nikita-1383", spin_ordering_pred_ ## NAME(x));			\
-	spin_lock_ ## NAME ## _no_ord(x);					\
+	spin_lock_ ## NAME ## _no_ord(x, t, h);					\
 }										\
 										\
 /* Lock @x.                                                               */	\
 static inline void spin_lock_ ## NAME (TYPE *x)					\
 {										\
 	__ODCA("nikita-1383", spin_ordering_pred_ ## NAME(x));			\
-	spin_lock_ ## NAME ## _no_ord(x);					\
+	spin_lock_ ## NAME ## _no_ord(x, 0, 0);					\
 }										\
 										\
 /* Try to obtain lock @x. On success, returns 1 with @x locked.           */	\
@@ -163,7 +384,11 @@ static inline void spin_lock_ ## NAME (T
 static inline int  spin_trylock_ ## NAME (TYPE *x)				\
 {										\
 	if (spin_trylock (& x->FIELD.lock)) {					\
+		GETCPU(cpu);							\
 		spin_ ## NAME ## _inc();					\
+		PREG_IN(cpu,							\
+			&pregion_spin_ ## NAME ## _held, &x->FIELD.held, 0);	\
+		PUTCPU(cpu);							\
 		return 1;							\
 	}									\
 	return 0;								\
@@ -178,6 +403,7 @@ static inline void spin_unlock_ ## NAME 
 										\
 	spin_ ## NAME ## _dec();						\
 	spin_unlock (& x->FIELD.lock);						\
+	PREG_EX(get_cpu(), &pregion_spin_ ## NAME ## _held);			\
 }										\
 										\
 typedef struct { int foo; } NAME ## _spin_dummy
@@ -203,10 +429,12 @@ typedef struct { int foo; } NAME ## _spi
 ({										\
 	typeof (obj) __obj;							\
 	typeof (exp) __result;							\
+	LOCKSITE_INIT(__hits_trying);						\
+	LOCKSITE_INIT(__hits_held);						\
 										\
 	__obj = (obj);								\
 	__ODCA("nikita-2492", __obj != NULL);					\
-	spin_lock_ ## obj_type ## _at (__obj);					\
+	spin_lock_ ## obj_type ## _at (__obj, &__hits_trying, &__hits_held);	\
 	__result = exp;								\
 	spin_unlock_ ## obj_type (__obj);					\
 	__result;								\
@@ -218,10 +446,12 @@ typedef struct { int foo; } NAME ## _spi
 #define UNDER_SPIN_VOID(obj_type, obj, exp)					\
 ({										\
 	typeof (obj) __obj;							\
+	LOCKSITE_INIT(__hits_trying);						\
+	LOCKSITE_INIT(__hits_held);						\
 										\
 	__obj = (obj);								\
 	__ODCA("nikita-2492", __obj != NULL);					\
-	spin_lock_ ## obj_type ## _at (__obj);					\
+	spin_lock_ ## obj_type ## _at (__obj, &__hits_trying, &__hits_held);	\
 	exp;									\
 	spin_unlock_ ## obj_type (__obj);					\
 })
@@ -231,6 +461,7 @@ typedef struct { int foo; } NAME ## _spi
  * insanely long macro definition. */
 #define RW_LOCK_FUNCTIONS(NAME,TYPE,FIELD)					\
 										\
+DECLARE_RW_PROFREGIONS(NAME)							\
 										\
 /* Initialize read write lock embedded into @x.                           */	\
 static inline void rw_ ## NAME ## _init(TYPE *x)				\
@@ -312,50 +543,64 @@ static inline void write_ ## NAME ## _de
 										\
 /* Acquire read lock on @x without checking lock ordering predicates.     */	\
 /* This is useful when, for example, locking just created object.         */	\
-static inline void read_lock_ ## NAME ## _no_ord (TYPE *x)			\
+static inline void read_lock_ ## NAME ## _no_ord (TYPE *x,			\
+						  locksite *t, locksite *h)	\
 {										\
+	GETCPU(cpu);								\
 	__ODCA("nikita-2976", rw_ ## NAME ## _is_not_read_locked(x));		\
+	PREG_IN(cpu, &pregion_rw_ ## NAME ## _r_trying, &x->FIELD.r_trying, t);	\
 	read_lock(&x->FIELD.lock);						\
+	PREG_REPLACE(cpu, &pregion_rw_ ## NAME ## _r_held,			\
+		     &x->FIELD.r_held, h);					\
+	PUTCPU(cpu);								\
 	read_ ## NAME ## _inc();						\
 }										\
 										\
 /* Acquire write lock on @x without checking lock ordering predicates.    */	\
 /* This is useful when, for example, locking just created object.         */	\
-static inline void write_lock_ ## NAME ## _no_ord (TYPE *x)			\
+static inline void write_lock_ ## NAME ## _no_ord (TYPE *x,			\
+						   locksite *t, locksite *h)	\
 {										\
+	GETCPU(cpu);								\
 	__ODCA("nikita-2977", rw_ ## NAME ## _is_not_write_locked(x));		\
+	PREG_IN(cpu, &pregion_rw_ ## NAME ## _w_trying, &x->FIELD.w_trying, t);	\
 	write_lock(&x->FIELD.lock);						\
+	PREG_REPLACE(cpu, &pregion_rw_ ## NAME ## _w_held,			\
+		     &x->FIELD.w_held, h);					\
+	PUTCPU(cpu);								\
 	write_ ## NAME ## _inc();						\
 }										\
 										\
 /* Read lock @x with explicit indication of spin lock profiling "sites".  */	\
 /* See spin_lock_foo_at() above for more information.                     */	\
-static inline void read_lock_ ## NAME ## _at (TYPE *x) 				\
+static inline void read_lock_ ## NAME ## _at (TYPE *x, 				\
+					      locksite *t, locksite *h)		\
 {										\
 	__ODCA("nikita-2975", rw_ordering_pred_ ## NAME(x));			\
-	read_lock_ ## NAME ## _no_ord(x);					\
+	read_lock_ ## NAME ## _no_ord(x, t, h);					\
 }										\
 										\
 /* Write lock @x with explicit indication of spin lock profiling "sites". */	\
 /* See spin_lock_foo_at() above for more information.                     */	\
-static inline void write_lock_ ## NAME ## _at (TYPE *x)				\
+static inline void write_lock_ ## NAME ## _at (TYPE *x,				\
+					       locksite *t, locksite *h)	\
 {										\
 	__ODCA("nikita-2978", rw_ordering_pred_ ## NAME(x));			\
-	write_lock_ ## NAME ## _no_ord(x);					\
+	write_lock_ ## NAME ## _no_ord(x, t, h);				\
 }										\
 										\
 /* Read lock @x.                                                          */	\
 static inline void read_lock_ ## NAME (TYPE *x)					\
 {										\
 	__ODCA("nikita-2975", rw_ordering_pred_ ## NAME(x));			\
-	read_lock_ ## NAME ## _no_ord(x);					\
+	read_lock_ ## NAME ## _no_ord(x, 0, 0);					\
 }										\
 										\
 /* Write lock @x.                                                         */	\
 static inline void write_lock_ ## NAME (TYPE *x)				\
 {										\
 	__ODCA("nikita-2978", rw_ordering_pred_ ## NAME(x));			\
-	write_lock_ ## NAME ## _no_ord(x);					\
+	write_lock_ ## NAME ## _no_ord(x, 0, 0);				\
 }										\
 										\
 /* Release read lock on @x.                                               */	\
@@ -367,6 +612,7 @@ static inline void read_unlock_ ## NAME 
 	read_ ## NAME ## _dec();						\
 	__ODCA("nikita-2703", rw_ ## NAME ## _is_read_locked(x));		\
 	read_unlock (& x->FIELD.lock);						\
+	PREG_EX(get_cpu(), &pregion_rw_ ## NAME ## _r_held);			\
 }										\
 										\
 /* Release write lock on @x.                                              */	\
@@ -378,6 +624,7 @@ static inline void write_unlock_ ## NAME
 	write_ ## NAME ## _dec();						\
 	__ODCA("nikita-2703", rw_ ## NAME ## _is_write_locked(x));		\
 	write_unlock (& x->FIELD.lock);						\
+	PREG_EX(get_cpu(), &pregion_rw_ ## NAME ## _w_held);			\
 }										\
 										\
 /* Try to obtain write lock on @x. On success, returns 1 with @x locked.  */	\
@@ -385,6 +632,10 @@ static inline void write_unlock_ ## NAME
 static inline int  write_trylock_ ## NAME (TYPE *x)				\
 {										\
 	if (write_trylock (& x->FIELD.lock)) {					\
+		GETCPU(cpu);							\
+		PREG_IN(cpu, &pregion_rw_ ## NAME ## _w_held,			\
+			&x->FIELD.w_held, 0);					\
+		PUTCPU(cpu);							\
 		write_ ## NAME ## _inc();					\
 		return 1;							\
 	}									\
@@ -415,10 +666,12 @@ typedef struct { int foo; } NAME ## _rw_
 ({									\
 	typeof (obj) __obj;						\
 	typeof (exp) __result;						\
+	LOCKSITE_INIT(__hits_t);					\
+	LOCKSITE_INIT(__hits_h);					\
 									\
 	__obj = (obj);							\
 	__ODCA("nikita-2981", __obj != NULL);				\
-	rw ## _lock_ ## obj_type ## _at (__obj);			\
+	rw ## _lock_ ## obj_type ## _at (__obj, &__hits_t, &__hits_h);	\
 	__result = exp;							\
 	rw ## _unlock_ ## obj_type (__obj);				\
 	__result;							\
@@ -430,14 +683,114 @@ typedef struct { int foo; } NAME ## _rw_
 #define UNDER_RW_VOID(obj_type, obj, rw, exp)				\
 ({									\
 	typeof (obj) __obj;						\
+	LOCKSITE_INIT(__hits_t);					\
+	LOCKSITE_INIT(__hits_h);					\
 									\
 	__obj = (obj);							\
 	__ODCA("nikita-2982", __obj != NULL);				\
-	rw ## _lock_ ## obj_type ## _at (__obj);			\
+	rw ## _lock_ ## obj_type ## _at (__obj, &__hits_t, &__hits_h);	\
 	exp;								\
 	rw ## _unlock_ ## obj_type (__obj);				\
 })
 
+#if REISER4_LOCKPROF
+
+/*
+ * Wrapper function to work with locks of certain reiser4 objects. These
+ * functions allows to track where in code locks are held (or tried) for the
+ * longest time.
+ */
+
+#define LOCK_JNODE(node)				\
+({							\
+	LOCKSITE_INIT(__hits_t);			\
+	LOCKSITE_INIT(__hits_h);			\
+							\
+	spin_lock_jnode_at(node, &__hits_t, &__hits_h);	\
+})
+
+#define LOCK_JLOAD(node)				\
+({							\
+	LOCKSITE_INIT(__hits_t);			\
+	LOCKSITE_INIT(__hits_h);			\
+							\
+	spin_lock_jload_at(node, &__hits_t, &__hits_h);	\
+})
+
+#define LOCK_ATOM(atom)					\
+({							\
+	LOCKSITE_INIT(__hits_t);			\
+	LOCKSITE_INIT(__hits_h);			\
+							\
+	spin_lock_atom_at(atom, &__hits_t, &__hits_h);	\
+})
+
+#define LOCK_TXNH(txnh)					\
+({							\
+	LOCKSITE_INIT(__hits_t);			\
+	LOCKSITE_INIT(__hits_h);			\
+							\
+	spin_lock_txnh_at(txnh, &__hits_t, &__hits_h);	\
+})
+
+#define LOCK_INODE(inode)					\
+({								\
+	LOCKSITE_INIT(__hits_t);				\
+	LOCKSITE_INIT(__hits_h);				\
+								\
+	spin_lock_inode_object_at(inode, &__hits_t, &__hits_h);	\
+})
+
+#define RLOCK_TREE(tree)				\
+({							\
+	LOCKSITE_INIT(__hits_t);			\
+	LOCKSITE_INIT(__hits_h);			\
+							\
+	read_lock_tree_at(tree, &__hits_t, &__hits_h);	\
+})
+
+#define WLOCK_TREE(tree)				\
+({							\
+	LOCKSITE_INIT(__hits_t);			\
+	LOCKSITE_INIT(__hits_h);			\
+							\
+	write_lock_tree_at(tree, &__hits_t, &__hits_h);	\
+})
+
+#define RLOCK_DK(tree)  				\
+({							\
+	LOCKSITE_INIT(__hits_t);			\
+	LOCKSITE_INIT(__hits_h);			\
+							\
+	read_lock_dk_at(tree, &__hits_t, &__hits_h);	\
+})
+
+#define WLOCK_DK(tree)  				\
+({							\
+	LOCKSITE_INIT(__hits_t);			\
+	LOCKSITE_INIT(__hits_h);			\
+							\
+	write_lock_dk_at(tree, &__hits_t, &__hits_h);	\
+})
+
+#define RLOCK_ZLOCK(lock)				\
+({							\
+	LOCKSITE_INIT(__hits_t);			\
+	LOCKSITE_INIT(__hits_h);			\
+							\
+	read_lock_zlock_at(lock, &__hits_t, &__hits_h);	\
+})
+
+#define WLOCK_ZLOCK(lock)				\
+({							\
+	LOCKSITE_INIT(__hits_t);			\
+	LOCKSITE_INIT(__hits_h);			\
+							\
+	write_lock_zlock_at(lock, &__hits_t, &__hits_h);	\
+})
+
+
+#else
 #define LOCK_JNODE(node) spin_lock_jnode(node)
 #define LOCK_JLOAD(node) spin_lock_jload(node)
 #define LOCK_ATOM(atom) spin_lock_atom(atom)
@@ -449,6 +802,7 @@ typedef struct { int foo; } NAME ## _rw_
 #define WLOCK_DK(tree) write_lock_dk(tree)
 #define RLOCK_ZLOCK(lock) read_lock_zlock(lock)
 #define WLOCK_ZLOCK(lock) write_lock_zlock(lock)
+#endif
 
 #define UNLOCK_JNODE(node) spin_unlock_jnode(node)
 #define UNLOCK_JLOAD(node) spin_unlock_jload(node)
diff -puN /dev/null spinprof.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/spinprof.c	2005-02-01 12:30:31.000000000 +0300
@@ -0,0 +1,553 @@
+/* Copyright 2001, 2002, 2003 by Hans Reiser, licensing governed by
+ * reiser4/README */
+
+/* spin lock profiling */
+
+/*
+ * Spin-lock profiling code.
+ *
+ * Basic notion in our profiling code is "profiling region" (struct
+ * profregion). Profiling region is entered and left by calling
+ * profregion_in() and profregion_ex() function correspondingly. It is invalid
+ * to be preempted (voluntary or not) while inside profiling region. Profiling
+ * regions can be entered recursively, and it is not necessary nest then
+ * properly, that is
+ *
+ *     profregion_in(&A);
+ *     profregion_in(&B);
+ *     profregion_ex(&A);
+ *     profregion_ex(&B))
+ *
+ * is valid sequence of operations. Each CPU maintains an array of currently
+ * active profiling regions. This array is consulted by clock interrupt
+ * handler, and counters in the profiling regions found active by handler are
+ * incremented. This allows one to estimate for how long region has been
+ * active on average. Spin-locking code in spin_macros.h uses this to measure
+ * spin-lock contention. Specifically two profiling regions are defined for
+ * each spin-lock type: one is activate while thread is trying to acquire
+ * lock, and another when it holds the lock.
+ *
+ * Profiling regions export their statistics in the sysfs, under special
+ * directory /sys/profregion.
+ *
+ * Each profregion is represented as a child directory
+ * /sys/profregion/foo. Internally it's represented as a struct kobject (viz
+ * one embedded into struct profregion, see spinprof.h).
+ *
+ * Each /sys/profregion/foo directory contains files representing fields in
+ * profregion:
+ *
+ *     hits
+ *     busy
+ *     obj
+ *     objhit
+ *     code
+ *     codehit
+ *
+ * See spinprof.h for details.
+ *
+ *
+ */
+
+#include "kattr.h"
+#include "spinprof.h"
+#include "debug.h"
+
+#include <linux/percpu.h>
+#include <linux/notifier.h>
+#include <linux/kallsyms.h>
+
+#include <asm/irq.h>
+#include <asm/ptrace.h> /* for instruction_pointer() */
+
+#if REISER4_LOCKPROF
+
+/*
+ * helper macro: how many bytes left in the PAGE_SIZE buffer, starting at @buf
+ * and used up to and including @p.
+ */
+#define LEFT(p, buf) (PAGE_SIZE - ((p) - (buf)) - 1)
+
+void profregion_functions_start_here(void);
+void profregion_functions_end_here(void);
+
+static locksite none = {
+	.hits = STATCNT_INIT,
+	.func = "",
+	.line = 0
+};
+
+/*
+ * sysfs holder.
+ */
+struct profregion_attr {
+	struct attribute attr;
+	ssize_t (*show)(struct profregion *pregion, char *buf);
+};
+
+/*
+ * macro to define profregion_attr for the given profregion
+ */
+#define PROFREGION_ATTR(aname)			\
+static struct profregion_attr aname = {		\
+	.attr = {				\
+		.name = (char *)#aname,		\
+		.mode = 0666			\
+	},					\
+	.show = aname ## _show			\
+}
+
+/*
+ * ->show() method for the "hits" attribute.
+ */
+static ssize_t hits_show(struct profregion *pregion, char *buf)
+{
+	char *p = buf;
+	KATTR_PRINT(p, buf, "%li\n", statcnt_get(&pregion->hits));
+	return (p - buf);
+}
+
+/*
+ * ->show() method for the "busy" attribute.
+ */
+static ssize_t busy_show(struct profregion *pregion, char *buf)
+{
+	char *p = buf;
+	KATTR_PRINT(p, buf, "%li\n", statcnt_get(&pregion->busy));
+	return (p - buf);
+}
+
+/*
+ * ->show() method for the "obj" attribute.
+ */
+static ssize_t obj_show(struct profregion *pregion, char *buf)
+{
+	char *p = buf;
+	KATTR_PRINT(p, buf, "%p\n", pregion->obj);
+	return (p - buf);
+}
+
+/*
+ * ->show() method for the "objhit" attribute.
+ */
+static ssize_t objhit_show(struct profregion *pregion, char *buf)
+{
+	char *p = buf;
+	KATTR_PRINT(p, buf, "%i\n", pregion->objhit);
+	return (p - buf);
+}
+
+/*
+ * ->show() method for the "code" attribute.
+ */
+static ssize_t code_show(struct profregion *pregion, char *buf)
+{
+	char *p = buf;
+	locksite *site;
+
+	site = pregion->code ? : &none;
+	KATTR_PRINT(p, buf, "%s:%i\n", site->func, site->line);
+	return (p - buf);
+}
+
+/*
+ * ->show() method for the "codehit" attribute.
+ */
+static ssize_t codehit_show(struct profregion *pregion, char *buf)
+{
+	char *p = buf;
+	KATTR_PRINT(p, buf, "%i\n", pregion->codehit);
+	return (p - buf);
+}
+
+PROFREGION_ATTR(hits);
+PROFREGION_ATTR(busy);
+PROFREGION_ATTR(obj);
+PROFREGION_ATTR(objhit);
+PROFREGION_ATTR(code);
+PROFREGION_ATTR(codehit);
+
+/*
+ * wrapper to call attribute ->show() methods (defined above). This is called
+ * by sysfs.
+ */
+static ssize_t
+profregion_show(struct kobject * kobj, struct attribute *attr, char *buf)
+{
+	struct profregion *pregion;
+	struct profregion_attr *pattr;
+
+	pregion = container_of(kobj, struct profregion, kobj);
+	pattr   = container_of(attr, struct profregion_attr, attr);
+
+	return pattr->show(pregion, buf);
+}
+
+/*
+ * ->store() method for profregion sysfs object. Any write to this object,
+ * just resets profregion stats.
+ */
+static ssize_t profregion_store(struct kobject * kobj,
+				struct attribute * attr UNUSED_ARG,
+				const char * buf UNUSED_ARG,
+				size_t size)
+{
+	struct profregion *pregion;
+
+	pregion = container_of(kobj, struct profregion, kobj);
+	statcnt_reset(&pregion->hits);
+	statcnt_reset(&pregion->busy);
+	pregion->obj     = 0;
+	pregion->objhit  = 0;
+	pregion->code    = 0;
+	pregion->codehit = 0;
+	return size;
+}
+
+/*
+ * sysfs attribute operations vector...
+ */
+static struct sysfs_ops profregion_attr_ops = {
+	.show  = profregion_show,
+	.store = profregion_store
+};
+
+/*
+ * ...and attributes themselves.
+ */
+static struct attribute * def_attrs[] = {
+	&hits.attr,
+	&busy.attr,
+	&obj.attr,
+	&objhit.attr,
+	&code.attr,
+	&codehit.attr,
+	NULL
+};
+
+/*
+ * ktype for kobjects representing profregions.
+ */
+static struct kobj_type ktype_profregion = {
+	.sysfs_ops	= &profregion_attr_ops,
+	.default_attrs	= def_attrs,
+};
+
+/*
+ * sysfs object for /sys/profregion
+ */
+static decl_subsys(profregion, &ktype_profregion, NULL);
+
+/*
+ * profregionstack for each CPU
+ */
+DEFINE_PER_CPU(struct profregionstack, inregion) = {0};
+
+/*
+ * profregion meaning "no other profregion is active"
+ */
+struct profregion outside = {
+	.hits = STATCNT_INIT,
+	.kobj = {
+		.name = "outside"
+	}
+};
+
+/*
+ * profregion meaning "we are in reiser4 context, but no locks are held"
+ */
+struct profregion incontext = {
+	.hits = STATCNT_INIT,
+	.kobj = {
+		.name = "incontext"
+	}
+};
+
+/*
+ * profregion meaning "we are profregion handling code". This is to estimate
+ * profregion overhead.
+ */
+struct profregion overhead = {
+	.hits = STATCNT_INIT,
+	.kobj = {
+		.name = "overhead"
+	}
+};
+
+extern struct profregion pregion_spin_jnode_held;
+extern struct profregion pregion_spin_jnode_trying;
+
+/*
+ * This is main profregion handling function. It is called from clock
+ * interrupt handler on each tick (HZ times per second).
+ *
+ * It determines what profregions are active at the moment of call, and
+ * updates their fields correspondingly.
+ */
+static int callback(struct pt_regs *regs)
+{
+	struct profregionstack *stack;
+	unsigned long pc;
+	int ntop;
+
+	/* instruction pointer at which interrupt happened */
+	pc = instruction_pointer(regs);
+
+	if (pc > (unsigned long)profregion_functions_start_here &&
+	    pc < (unsigned long)profregion_functions_end_here) {
+		/* if @pc lies in this file---count it as overhead */
+		statcnt_inc(&overhead.hits);
+		return 0;
+	}
+
+	stack = &get_cpu_var(inregion);
+	ntop = stack->top;
+	if (unlikely(ntop != 0)) {
+		struct pregactivation *act;
+		struct profregion *preg;
+		int hits;
+
+		act = &stack->stack[ntop - 1];
+		preg = act->preg;
+		statcnt_inc(&preg->hits);
+
+		hits = 0;
+		if (act->objloc != NULL) {
+			BUG_ON(*act->objloc == 0x6b6b6b6b);
+			BUG_ON(*act->objloc == 0x5a5a5a5a);
+			hits = ++ (*act->objloc);
+		}
+		if (unlikely(hits > preg->objhit)) {
+			if (preg->obj != act->objloc) {
+				preg->objhit = hits;
+				preg->obj    = act->objloc;
+				if (preg->champion != NULL)
+					preg->champion(preg);
+			}
+		}
+
+		hits = 0;
+		if (act->codeloc != NULL) {
+			statcnt_inc(&act->codeloc->hits);
+			hits = statcnt_get(&act->codeloc->hits);
+		}
+		if (unlikely(hits > preg->codehit)) {
+			preg->codehit = hits;
+			preg->code    = act->codeloc;
+		}
+		for (; ntop > 0 ; --ntop) {
+			preg = stack->stack[ntop - 1].preg;
+			if (preg != NULL)
+				statcnt_inc(&preg->busy);
+		}
+	} else if (is_in_reiser4_context())
+		statcnt_inc(&incontext.hits);
+	else
+		statcnt_inc(&outside.hits);
+	put_cpu_var(inregion);
+	return 0;
+}
+
+/*
+ * profregion initialization: setup sysfs things.
+ */
+int __init
+profregion_init(void)
+{
+	int result;
+
+	/* register /sys/profregion */
+	result = subsystem_register(&profregion_subsys);
+	if (result != 0)
+		return result;
+
+	/* register /sys/profregion/outside */
+	result = profregion_register(&outside);
+	if (result != 0)
+		return result;
+
+	/* register /sys/profregion/incontext */
+	result = profregion_register(&incontext);
+	if (result != 0)
+		return result;
+
+	/* register /sys/profregion/overhead */
+	result = profregion_register(&overhead);
+	if (result != 0)
+		return result;
+
+	/* register our callback function to be called on each clock tick */
+	return register_timer_hook(callback);
+}
+subsys_initcall(profregion_init);
+
+/*
+ * undo profregion_init() actions.
+ */
+static void __exit
+profregion_exit(void)
+{
+	profregion_unregister(&overhead);
+	profregion_unregister(&incontext);
+	profregion_unregister(&outside);
+	subsystem_unregister(&profregion_subsys);
+}
+__exitcall(profregion_exit);
+
+/*
+ * register profregion
+ */
+int profregion_register(struct profregion *pregion)
+{
+	/* tell sysfs that @pregion is part of /sys/profregion "subsystem" */
+	kobj_set_kset_s(pregion, profregion_subsys);
+	/* and register /sys/profregion/<pregion> */
+	return kobject_register(&pregion->kobj);
+}
+
+/*
+ * dual to profregion_register(): unregister profregion
+ */
+void profregion_unregister(struct profregion *pregion)
+{
+	kobject_register(&pregion->kobj);
+}
+
+void profregion_functions_start_here(void) { }
+
+/*
+ * search for @pregion in the stack of currently active profregions on this
+ * cpu. Return its index if found, 0 otherwise.
+ */
+int profregion_find(struct profregionstack *stack, struct profregion *pregion)
+{
+	int i;
+
+	for (i = stack->top - 2 ; i >= 0 ; -- i) {
+		if (stack->stack[i].preg == pregion) {
+			return i;
+		}
+	}
+	BUG();
+	return 0;
+}
+
+/*
+ * Fill @act slot with information
+ */
+void profregfill(struct pregactivation *act,
+		 struct profregion *pregion,
+		 void *objloc, locksite *codeloc)
+{
+	act->objloc  = NULL;
+	act->codeloc = NULL;
+	/* barrier is needed here, because clock interrupt can come at any
+	 * point, and we want our callback to see consistent data */
+	barrier();
+	act->preg    = pregion;
+	act->objloc  = objloc;
+	act->codeloc = codeloc;
+}
+
+/*
+ * activate profregion @pregion on processor @cpu.
+ */
+void profregion_in(int cpu, struct profregion *pregion,
+		   void *objloc, locksite *codeloc)
+{
+	struct profregionstack *stack;
+	int ntop;
+
+	preempt_disable();
+	stack = &per_cpu(inregion, cpu);
+	ntop = stack->top;
+	/* check for stack overflow */
+	BUG_ON(ntop == PROFREGION_MAX_DEPTH);
+	/* store information about @pregion in the next free slot on the
+	 * stack */
+	profregfill(&stack->stack[ntop], pregion, objloc, codeloc);
+	/* put optimization barrier here */
+	/* barrier is needed here, because clock interrupt can come at any
+	 * point, and we want our callback to see consistent data */
+	barrier();
+	++ stack->top;
+}
+
+/*
+ * deactivate (leave) @pregion at processor @cpu.
+ */
+void profregion_ex(int cpu, struct profregion *pregion)
+{
+	struct profregionstack *stack;
+	int ntop;
+
+	stack = &per_cpu(inregion, cpu);
+	ntop = stack->top;
+	BUG_ON(ntop == 0);
+	/*
+	 * in the usual case (when locks nest properly), @pregion uses top
+	 * slot of the stack. Free it.
+	 */
+	if(likely(stack->stack[ntop - 1].preg == pregion)) {
+		do {
+			-- ntop;
+		} while (ntop > 0 &&
+			 stack->stack[ntop - 1].preg == NULL);
+		/* put optimization barrier here */
+		barrier();
+		stack->top = ntop;
+	} else
+		/*
+		 * Otherwise (locks are not nested), find slot used by
+		 * @prefion and free it.
+		 */
+		stack->stack[profregion_find(stack, pregion)].preg = NULL;
+	preempt_enable();
+	put_cpu();
+}
+
+/*
+ * simultaneously deactivate top-level profregion in the stack, and activate
+ * @pregion. This is optimization to serve common case, when profregion
+ * covering "trying to take lock X" is immediately followed by profregion
+ * covering "holding lock X".
+ */
+void profregion_replace(int cpu, struct profregion *pregion,
+			void *objloc, void *codeloc)
+{
+	struct profregionstack *stack;
+	int ntop;
+
+	stack = &per_cpu(inregion, cpu);
+	ntop = stack->top;
+	BUG_ON(ntop == 0);
+	profregfill(&stack->stack[ntop - 1], pregion, objloc, codeloc);
+}
+
+void profregion_functions_end_here(void) { }
+
+/* REISER4_LOCKPROF */
+#else
+
+#if defined(CONFIG_REISER4_NOOPT) || defined(CONFIG_KGDB)
+
+locksite __hits;
+locksite __hits_h;
+locksite __hits_t;
+locksite __hits_held;
+locksite __hits_trying;
+
+#endif /* CONFIG_REISER4_NOOPT */
+
+/* REISER4_LOCKPROF */
+#endif
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   End:
+*/
diff -puN /dev/null spinprof.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/spinprof.h	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,131 @@
+/* Copyright 2002, 2003, 2004 by Hans Reiser, licensing governed by
+ * reiser4/README */
+
+/* spin lock profiling. See spinprof.c for comments. */
+
+#ifndef __SPINPROF_H__
+#define __SPINPROF_H__
+
+#include "debug.h"
+#include "spin_macros.h"
+#include "statcnt.h"
+
+#include <linux/config.h>
+#include <linux/profile.h>
+#include <linux/kobject.h>
+
+#if REISER4_LOCKPROF
+
+/* maximal number of profiling regions that can be active at the same time */
+#define PROFREGION_MAX_DEPTH (12)
+
+typedef struct percpu_counter scnt_t;
+
+/* spin-locking code uses this to identify place in the code, where particular
+ * call to locking function is made. */
+typedef struct locksite {
+	statcnt_t   hits;   /* number of times profiling region that is
+			     * entered at this place of code was found active
+			     * my clock interrupt handler. */
+	const char *func;   /* function */
+	int         line;   /* line in the source file */
+} locksite;
+
+/* macro to initialize locksite */
+#define LOCKSITE_INIT(name)			\
+	static locksite name = {		\
+		.hits = STATCNT_INIT,		\
+		.func = __FUNCTION__,		\
+		.line = __LINE__		\
+	}
+
+/* profiling region */
+struct profregion {
+	/* how many times clock interrupt handler found this profiling region
+	 * to be at the top of array of active regions. */
+	statcnt_t      hits;
+	/* how many times clock interrupt handler found this profiling region
+	 * in active array */
+	statcnt_t      busy;
+	/* sysfs handle */
+	struct kobject kobj;
+	/* object that (so far) was observed to be locked/contended most
+	 * through this region */
+	void          *obj;
+	/* number of times ->obj's lock was requested/held while in this
+	 * region */
+	int            objhit;
+	/* place in code that (so far) was most active user of this
+	 * profregion */
+	locksite      *code;
+	/* number of times clock interrupt handler observed that ->code was in
+	 * this profregion */
+	int            codehit;
+	/*
+	 * optional method called when ->obj is changed. Can be used to output
+	 * information about most contended objects.
+	 */
+	void (*champion)(struct profregion * preg);
+};
+
+/*
+ * slot in profregionstack used when profregion is activated (that is,
+ * entered).
+ */
+struct pregactivation {
+	/* profiling region */
+	struct profregion *preg;
+	/* pointer to hits counter, embedded into object */
+	int               *objloc;
+	/* current lock site */
+	locksite          *codeloc;
+};
+
+/*
+ * Stack recording currently active profregion activations. Strictly speaking
+ * this is not a stack at all, because locks (and profregions) do not
+ * necessary nest properly.
+ */
+struct profregionstack {
+	/* index of next free slot */
+	int top;
+	/* array of slots for profregion activations */
+	struct pregactivation stack[PROFREGION_MAX_DEPTH];
+};
+
+DECLARE_PER_CPU(struct profregionstack, inregion);
+
+extern int  profregion_register(struct profregion *pregion);
+extern void profregion_unregister(struct profregion *pregion);
+
+extern void profregion_in(int cpu, struct profregion *pregion,
+			  void *objloc, locksite *codeloc);
+extern void profregion_ex(int cpu, struct profregion *pregion);
+extern void profregion_replace(int cpu, struct profregion *pregion,
+			       void *objloc, void *codeloc);
+
+/* REISER4_LOCKPROF */
+#else
+
+struct profregionstack {};
+#define profregion_register(pregion) (0)
+#define profregion_unregister(pregion) noop
+
+typedef struct locksite {} locksite;
+#define LOCKSITE_INIT(name) extern locksite name
+
+/* REISER4_LOCKPROF */
+#endif
+
+/* __SPINPROF_H__ */
+#endif
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   scroll-step: 1
+   End:
+*/
diff -puN /dev/null statcnt.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/statcnt.h	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,113 @@
+/* Copyright 2002, 2003 by Hans Reiser, licensing governed by reiser4/README */
+
+/* Efficient counter for statistics collection. */
+
+/*
+ * This is write-optimized statistical counter. There is stock counter of such
+ * kind (include/linux/percpu_counter.h), but it is read-optimized, that is
+ * reads are cheap, updates are relatively expensive. We need data-structure
+ * for our statistical counters (stats.[ch]) that are write-mostly, that is,
+ * they are updated much more frequently than read.
+ */
+
+#ifndef __STATCNT_H__
+#define __STATCNT_H__
+
+#include <linux/types.h>
+#include <linux/config.h>
+#include <linux/spinlock.h>
+#include <linux/smp.h>
+#include <linux/threads.h>
+
+#ifdef CONFIG_SMP
+
+struct __statcnt_slot {
+	long count;
+} ____cacheline_aligned;
+
+/*
+ * counter.
+ *
+ * This is an array of integer counters, one per each processor. Each
+ * individual counter is cacheline aligned, so that processor don't fight for
+ * cache-lines when accessing this. Such alignment makes this counter _huge_.
+ *
+ * To update counter, thread just modifies an element in array corresponding
+ * to its current processor.
+ *
+ * To read value of counter array is scanned and all elements are summed
+ * up. This means that read value can be slightly inaccurate, because scan is
+ * not protected by any lock, but that is it.
+ */
+typedef struct statcnt {
+	struct __statcnt_slot counters[NR_CPUS];
+} statcnt_t;
+
+#define STATCNT_INIT						\
+{								\
+	.counters = { [ 0 ... NR_CPUS - 1 ] = { .count = 0 } }	\
+}
+
+static inline void statcnt_add(statcnt_t *cnt, int val)
+{
+	int cpu;
+
+	cpu = get_cpu();
+	cnt->counters[cpu].count += val;
+	put_cpu();
+}
+
+static inline long statcnt_get(statcnt_t *cnt)
+{
+	long result;
+	int  i;
+
+	for (i = 0, result = 0; i < NR_CPUS; ++i)
+		result += cnt->counters[i].count;
+	return result;
+}
+
+/* CONFIG_SMP */
+#else
+
+typedef struct statcnt {
+	long count;
+} statcnt_t;
+
+#define STATCNT_INIT { .count = 0 }
+
+static inline void statcnt_add(statcnt_t *cnt, int val)
+{
+	cnt->count += val;
+}
+
+static inline long statcnt_get(statcnt_t *cnt)
+{
+	return cnt->count;
+}
+
+/* CONFIG_SMP */
+#endif
+
+static inline void statcnt_init(statcnt_t *cnt)
+{
+	xmemset(cnt, 0, sizeof *cnt);
+}
+
+#define statcnt_reset(cnt) statcnt_init(cnt)
+
+#define statcnt_inc(cnt) statcnt_add((cnt), +1)
+#define statcnt_dec(cnt) statcnt_add((cnt), -1)
+
+/* __STATCNT_H__ */
+#endif
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   End:
+*/
diff -puN /dev/null stats.c
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/stats.c	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,639 @@
+/* Copyright 2001, 2002, 2003 by Hans Reiser, licensing governed by
+ * reiser4/README */
+
+/* Statistical facilities. */
+
+/*
+ * Reiser4 has special REISER4_STATS compilation option (flippable through
+ * kernel configuration process). When it is on, code to collect statistics is
+ * compiled in. When option is off, code is preprocessed to zilch.
+ *
+ * Statistics are ["statistics" as singular is a name of a science, used as
+ * plural it refers to "classified facts respecting ... any particular class
+ * or interest" (Webster)] collected in the form of "statistical
+ * counters". Each counter has type statcnt_t (see statcnt.h). Counters are
+ * organized into per-super block reiser4_statistics structure. This structure
+ * contains sub-structures used to group counters. This grouping is only for
+ * cleanness, it has no effect on execution.
+ *
+ * In addition to sub-structures reiser4_statistics also contains array of
+ * reiser4_level_stat structures used to collect statistics attributable to
+ * particular level in reiser4 internal tree.
+ *
+ * As explained in statcnt.h, statcnt_t is large, hence, reiser4_statistics,
+ * containing fewscores of counters is _huge_. It is so huge, that it cannot
+ * be allocated with kmalloc() and vmalloc() is used for this.
+ *
+ * reiser4_stat_inc() and reiser4_stat_add() macros defined in stats.h are
+ * main means of updating statistical counters. Note, that due to the
+ * construction of statcnt_t counters said macros are completely lock-less
+ * and, no than less, almost accurate.
+ *
+ * Each statistical counter is exported through sysfs (see kattr.c for more
+ * details).
+ *
+ * If you adding new stat-counter, you should add it into appropriate struct
+ * definition in stats.h (reiser4_level_statistics or reiser4_statistics), and
+ * add initialization of counter to the reiser4_stat_defs[] or
+ * reiser4_stat_level_defs[] arrays in this file.
+ *
+ * Note: it is probably possible to avoid this duplication by placing some
+ * description of counters into third file and using preprocessor to generate
+ * definitions of structs and arrays.
+ *
+ */
+
+#include "kattr.h"
+#include "reiser4.h"
+#include "stats.h"
+#include "statcnt.h"
+#include "super.h"
+#include "debug.h"
+
+#include <linux/sysfs.h>
+#include <linux/vmalloc.h>
+
+/*
+ * Data-type describing how to export stat-counter through sysfs.
+ */
+typedef struct reiser4_stats_cnt {
+	/* standard object to interact with sysfs */
+	reiser4_kattr  kattr;
+	/* offset to the counter from the beginning of embedding data-type
+	 * (reiser4_level_statistics or reiser4_statistics) */
+	ptrdiff_t      offset;
+	/* counter size in bytes */
+	size_t         size;
+	/* printf(3) format to output counter value */
+	const char    *format;
+} reiser4_stats_cnt;
+
+/*
+ * helper macro: return value of counter (of type @type) located at the offset
+ * @offset (in bytes) from the data-structure located at @ptr.
+ */
+#define getptrat(type, ptr, offset) ((type *)(((char *)(ptr)) + (offset)))
+
+/*
+ * helper macro to define reiser4_stats_cnt describing particular
+ * stat-counter.
+ */
+#define DEFINE_STATCNT_0(aname,   /* name under which counter will be exported \
+				   * in sysfs */			\
+			 afield,  /* name of field in the embedding type */ \
+	  		 atype,   /* data-type of counter */		\
+		         afmt,    /* output printf(3) format */		\
+	  		 ashow,   /* show method */			\
+			 astore   /* store method */)			\
+{									\
+	.kattr = {							\
+		.attr = {						\
+			.kattr = {					\
+				.name = (char *)aname,			\
+				.mode = 0666 /* rw-rw-rw- */		\
+			},						\
+			.show   = ashow,				\
+			.store  = astore				\
+		},							\
+		.cookie = 0,						\
+	},								\
+	.format = afmt "\n",						\
+	.offset = offsetof(atype, afield),				\
+	.size   = sizeof(((atype *)0)->afield)				\
+}
+
+#if REISER4_STATS
+
+/*
+ * return counter corresponding to the @fskattr. struct fs_kattr is embedded
+ * into reiser4_kattr, and reiser4_kattr is embedded into reiser4_stats_cnt.
+ */
+static inline reiser4_stats_cnt *getcnt(struct fs_kattr * fskattr)
+{
+	return container_of(fskattr, reiser4_stats_cnt, kattr.attr);
+}
+
+/*
+ * ->show() method for "global" --that is, not per-level-- stat-counter.
+ */
+static ssize_t
+show_stat_attr(struct super_block * s, struct fs_kobject * fskobj,
+	       struct fs_kattr * fskattr, char * buf)
+{
+	char *p;
+	reiser4_stats_cnt *cnt;
+	statcnt_t *val;
+
+	/* obtain counter description */
+	cnt = getcnt(fskattr);
+	/* use byte offset stored in description to obtain counter value */
+	val = getptrat(statcnt_t, get_super_private(s)->stats, cnt->offset);
+	p = buf;
+	KATTR_PRINT(p, buf, cnt->format, statcnt_get(val));
+	return (p - buf);
+}
+
+/*
+ * ->store() method for "global" --that is, not per-level-- stat-counter.
+ */
+static ssize_t
+store_stat_attr(struct super_block * s, struct fs_kobject * fskobj,
+		struct fs_kattr * fskattr, const char * buf, size_t size)
+{
+	reiser4_stats_cnt *cnt;
+	statcnt_t *val;
+
+	/*
+	 * any write into file representing stat-counter in sysfs, resets
+	 * counter to zero
+	 */
+
+	cnt = getcnt(fskattr);
+	val = getptrat(statcnt_t, get_super_private(s)->stats, cnt->offset);
+	statcnt_reset(val);
+	return size;
+}
+
+/*
+ * ->show() method for per-level stat-counter
+ */
+static ssize_t
+show_stat_level_attr(struct super_block * s, struct fs_kobject * fskobj,
+		     struct fs_kattr * fskattr, char * buf)
+{
+	char *p;
+	reiser4_stats_cnt *cnt;
+	statcnt_t *val;
+	int level;
+
+	/* obtain level from reiser4_level_stats_kobj */
+	level = container_of(fskobj, reiser4_level_stats_kobj, kobj)->level;
+	/* obtain counter description */
+	cnt = getcnt(fskattr);
+	/* obtain counter value, using level and byte-offset from the
+	 * beginning of per-level counter struct */
+	val = getptrat(statcnt_t, &get_super_private(s)->stats->level[level],
+		       cnt->offset);
+	p = buf;
+	KATTR_PRINT(p, buf, cnt->format, statcnt_get(val));
+	return (p - buf);
+}
+
+/*
+ * ->store() method for per-level stat-counter
+ */
+static ssize_t
+store_stat_level_attr(struct super_block * s, struct fs_kobject * fskobj,
+		      struct fs_kattr * fskattr, const char * buf, size_t size)
+{
+	reiser4_stats_cnt *cnt;
+	statcnt_t *val;
+	int level;
+
+	/*
+	 * any write into file representing stat-counter in sysfs, resets
+	 * counter to zero
+	 */
+
+	level = container_of(fskobj, reiser4_level_stats_kobj, kobj)->level;
+	cnt = getcnt(fskattr);
+	val = getptrat(statcnt_t, &get_super_private(s)->stats->level[level],
+		       cnt->offset);
+	statcnt_reset(val);
+	return size;
+}
+
+/*
+ * macro defining reiser4_stats_cnt instance describing particular global
+ * stat-counter
+ */
+#define DEFINE_STATCNT(field)					\
+	DEFINE_STATCNT_0(#field, field, reiser4_stat, "%lu", 	\
+			 show_stat_attr, store_stat_attr)
+
+reiser4_stats_cnt reiser4_stat_defs[] = {
+	DEFINE_STATCNT(tree.cbk),
+	DEFINE_STATCNT(tree.cbk_found),
+	DEFINE_STATCNT(tree.cbk_notfound),
+	DEFINE_STATCNT(tree.cbk_restart),
+	DEFINE_STATCNT(tree.cbk_cache_hit),
+	DEFINE_STATCNT(tree.cbk_cache_miss),
+	DEFINE_STATCNT(tree.cbk_cache_wrong_node),
+	DEFINE_STATCNT(tree.cbk_cache_race),
+	DEFINE_STATCNT(tree.object_lookup_novroot),
+	DEFINE_STATCNT(tree.object_lookup_moved),
+	DEFINE_STATCNT(tree.object_lookup_outside),
+	DEFINE_STATCNT(tree.object_lookup_cannotlock),
+	DEFINE_STATCNT(tree.object_lookup_restart),
+	DEFINE_STATCNT(tree.pos_in_parent_hit),
+	DEFINE_STATCNT(tree.pos_in_parent_miss),
+	DEFINE_STATCNT(tree.pos_in_parent_set),
+	DEFINE_STATCNT(tree.fast_insert),
+	DEFINE_STATCNT(tree.fast_paste),
+	DEFINE_STATCNT(tree.fast_cut),
+	DEFINE_STATCNT(tree.reparenting),
+	DEFINE_STATCNT(tree.rd_key_skew),
+	DEFINE_STATCNT(tree.check_left_nonuniq),
+	DEFINE_STATCNT(tree.left_nonuniq_found),
+
+	DEFINE_STATCNT(vfs_calls.open),
+	DEFINE_STATCNT(vfs_calls.lookup),
+	DEFINE_STATCNT(vfs_calls.create),
+	DEFINE_STATCNT(vfs_calls.mkdir),
+	DEFINE_STATCNT(vfs_calls.symlink),
+	DEFINE_STATCNT(vfs_calls.mknod),
+	DEFINE_STATCNT(vfs_calls.rename),
+	DEFINE_STATCNT(vfs_calls.readlink),
+	DEFINE_STATCNT(vfs_calls.follow_link),
+	DEFINE_STATCNT(vfs_calls.setattr),
+	DEFINE_STATCNT(vfs_calls.getattr),
+	DEFINE_STATCNT(vfs_calls.read),
+	DEFINE_STATCNT(vfs_calls.write),
+	DEFINE_STATCNT(vfs_calls.truncate),
+	DEFINE_STATCNT(vfs_calls.statfs),
+	DEFINE_STATCNT(vfs_calls.bmap),
+	DEFINE_STATCNT(vfs_calls.link),
+	DEFINE_STATCNT(vfs_calls.llseek),
+	DEFINE_STATCNT(vfs_calls.readdir),
+	DEFINE_STATCNT(vfs_calls.ioctl),
+	DEFINE_STATCNT(vfs_calls.mmap),
+	DEFINE_STATCNT(vfs_calls.unlink),
+	DEFINE_STATCNT(vfs_calls.rmdir),
+	DEFINE_STATCNT(vfs_calls.alloc_inode),
+	DEFINE_STATCNT(vfs_calls.destroy_inode),
+	DEFINE_STATCNT(vfs_calls.delete_inode),
+	DEFINE_STATCNT(vfs_calls.write_super),
+	DEFINE_STATCNT(vfs_calls.private_data_alloc),
+
+	DEFINE_STATCNT(dir.readdir.calls),
+	DEFINE_STATCNT(dir.readdir.reset),
+	DEFINE_STATCNT(dir.readdir.rewind_left),
+	DEFINE_STATCNT(dir.readdir.left_non_uniq),
+	DEFINE_STATCNT(dir.readdir.left_restart),
+	DEFINE_STATCNT(dir.readdir.rewind_right),
+	DEFINE_STATCNT(dir.readdir.adjust_pos),
+	DEFINE_STATCNT(dir.readdir.adjust_lt),
+	DEFINE_STATCNT(dir.readdir.adjust_gt),
+	DEFINE_STATCNT(dir.readdir.adjust_eq),
+
+	DEFINE_STATCNT(file.page_ops.readpage_calls),
+	DEFINE_STATCNT(file.page_ops.writepage_calls),
+	DEFINE_STATCNT(file.tail2extent),
+	DEFINE_STATCNT(file.extent2tail),
+	DEFINE_STATCNT(file.find_file_item),
+	DEFINE_STATCNT(file.find_file_item_via_seal),
+	DEFINE_STATCNT(file.find_file_item_via_right_neighbor),
+	DEFINE_STATCNT(file.find_file_item_via_cbk),
+
+	DEFINE_STATCNT(extent.unfm_block_reads),
+	DEFINE_STATCNT(extent.broken_seals),
+	DEFINE_STATCNT(extent.bdp_caused_repeats),
+
+	DEFINE_STATCNT(tail.bdp_caused_repeats),
+
+	DEFINE_STATCNT(txnmgr.slept_in_wait_atom),
+	DEFINE_STATCNT(txnmgr.slept_in_wait_event),
+	DEFINE_STATCNT(txnmgr.commits),
+	DEFINE_STATCNT(txnmgr.post_commit_writes),
+	DEFINE_STATCNT(txnmgr.time_spent_in_commits),
+	DEFINE_STATCNT(txnmgr.empty_bio),
+	DEFINE_STATCNT(txnmgr.commit_from_writepage),
+	DEFINE_STATCNT(txnmgr.capture_equal),
+	DEFINE_STATCNT(txnmgr.capture_both),
+	DEFINE_STATCNT(txnmgr.capture_block),
+	DEFINE_STATCNT(txnmgr.capture_txnh),
+	DEFINE_STATCNT(txnmgr.capture_none),
+	DEFINE_STATCNT(txnmgr.restart.atom_begin),
+	DEFINE_STATCNT(txnmgr.restart.cannot_commit),
+	DEFINE_STATCNT(txnmgr.restart.should_wait),
+	DEFINE_STATCNT(txnmgr.restart.flush),
+	DEFINE_STATCNT(txnmgr.restart.fuse_lock_owners_fused),
+	DEFINE_STATCNT(txnmgr.restart.fuse_lock_owners),
+	DEFINE_STATCNT(txnmgr.restart.trylock_throttle),
+	DEFINE_STATCNT(txnmgr.restart.assign_block),
+	DEFINE_STATCNT(txnmgr.restart.assign_txnh),
+	DEFINE_STATCNT(txnmgr.restart.fuse_wait_nonblock),
+	DEFINE_STATCNT(txnmgr.restart.fuse_wait_slept),
+	DEFINE_STATCNT(txnmgr.restart.init_fusion_atomf),
+	DEFINE_STATCNT(txnmgr.restart.init_fusion_atomh),
+	DEFINE_STATCNT(txnmgr.restart.init_fusion_fused),
+
+	DEFINE_STATCNT(flush.squeezed_completely),
+	DEFINE_STATCNT(flush.flushed_with_unallocated),
+	DEFINE_STATCNT(flush.squeezed_leaves),
+	DEFINE_STATCNT(flush.squeezed_leaf_items),
+	DEFINE_STATCNT(flush.squeezed_leaf_bytes),
+	DEFINE_STATCNT(flush.flush),
+	DEFINE_STATCNT(flush.left),
+	DEFINE_STATCNT(flush.right),
+	DEFINE_STATCNT(flush.slept_in_mtflush_sem),
+
+	DEFINE_STATCNT(pool.alloc),
+	DEFINE_STATCNT(pool.kmalloc),
+
+	DEFINE_STATCNT(seal.perfect_match),
+	DEFINE_STATCNT(seal.out_of_cache),
+
+	DEFINE_STATCNT(hashes.znode.lookup),
+	DEFINE_STATCNT(hashes.znode.insert),
+	DEFINE_STATCNT(hashes.znode.remove),
+	DEFINE_STATCNT(hashes.znode.scanned),
+	DEFINE_STATCNT(hashes.zfake.lookup),
+	DEFINE_STATCNT(hashes.zfake.insert),
+	DEFINE_STATCNT(hashes.zfake.remove),
+	DEFINE_STATCNT(hashes.zfake.scanned),
+	DEFINE_STATCNT(hashes.jnode.lookup),
+	DEFINE_STATCNT(hashes.jnode.insert),
+	DEFINE_STATCNT(hashes.jnode.remove),
+	DEFINE_STATCNT(hashes.jnode.scanned),
+	DEFINE_STATCNT(hashes.lnode.lookup),
+	DEFINE_STATCNT(hashes.lnode.insert),
+	DEFINE_STATCNT(hashes.lnode.remove),
+	DEFINE_STATCNT(hashes.lnode.scanned),
+	DEFINE_STATCNT(hashes.eflush.lookup),
+	DEFINE_STATCNT(hashes.eflush.insert),
+	DEFINE_STATCNT(hashes.eflush.remove),
+	DEFINE_STATCNT(hashes.eflush.scanned),
+
+	DEFINE_STATCNT(block_alloc.nohint),
+
+	DEFINE_STATCNT(non_uniq),
+
+	/* pcwb - page common write back */
+	DEFINE_STATCNT(pcwb.calls),
+	DEFINE_STATCNT(pcwb.no_jnode),
+	DEFINE_STATCNT(pcwb.written),
+	DEFINE_STATCNT(pcwb.not_written),
+
+	/* cop on capture stats */
+	DEFINE_STATCNT(coc.calls),
+	/* satisfied requests */
+ 	DEFINE_STATCNT(coc.ok_uber),
+ 	DEFINE_STATCNT(coc.ok_nopage),
+ 	DEFINE_STATCNT(coc.ok_clean),
+	DEFINE_STATCNT(coc.ok_ovrwr),
+ 	DEFINE_STATCNT(coc.ok_reloc),
+	/* refused copy on capture requests */
+	DEFINE_STATCNT(coc.forbidden),
+	DEFINE_STATCNT(coc.writeback),
+	DEFINE_STATCNT(coc.flush_queued),
+	DEFINE_STATCNT(coc.dirty),
+	DEFINE_STATCNT(coc.eflush),
+	DEFINE_STATCNT(coc.scan_race),
+	DEFINE_STATCNT(coc.atom_changed),
+	DEFINE_STATCNT(coc.coc_race),
+	DEFINE_STATCNT(coc.coc_wait),
+};
+
+/*
+ * macro defining reiser4_stats_cnt instance describing particular per-level
+ * stat-counter
+ */
+#define DEFINE_STAT_LEVEL_CNT(field)					\
+	DEFINE_STATCNT_0(#field, field,					\
+			 reiser4_level_stat, "%lu", 			\
+			 show_stat_level_attr, store_stat_level_attr)
+
+reiser4_stats_cnt reiser4_stat_level_defs[] = {
+	DEFINE_STAT_LEVEL_CNT(carry_restart),
+	DEFINE_STAT_LEVEL_CNT(carry_done),
+	DEFINE_STAT_LEVEL_CNT(carry_left_in_carry),
+	DEFINE_STAT_LEVEL_CNT(carry_left_in_cache),
+	DEFINE_STAT_LEVEL_CNT(carry_left_missed),
+	DEFINE_STAT_LEVEL_CNT(carry_left_not_avail),
+	DEFINE_STAT_LEVEL_CNT(carry_left_refuse),
+	DEFINE_STAT_LEVEL_CNT(carry_right_in_carry),
+	DEFINE_STAT_LEVEL_CNT(carry_right_in_cache),
+	DEFINE_STAT_LEVEL_CNT(carry_right_missed),
+	DEFINE_STAT_LEVEL_CNT(carry_right_not_avail),
+	DEFINE_STAT_LEVEL_CNT(insert_looking_left),
+	DEFINE_STAT_LEVEL_CNT(insert_looking_right),
+	DEFINE_STAT_LEVEL_CNT(insert_alloc_new),
+	DEFINE_STAT_LEVEL_CNT(insert_alloc_many),
+	DEFINE_STAT_LEVEL_CNT(insert),
+	DEFINE_STAT_LEVEL_CNT(delete),
+	DEFINE_STAT_LEVEL_CNT(cut),
+	DEFINE_STAT_LEVEL_CNT(paste),
+	DEFINE_STAT_LEVEL_CNT(extent),
+	DEFINE_STAT_LEVEL_CNT(paste_restarted),
+	DEFINE_STAT_LEVEL_CNT(update),
+	DEFINE_STAT_LEVEL_CNT(modify),
+	DEFINE_STAT_LEVEL_CNT(half_split_race),
+	DEFINE_STAT_LEVEL_CNT(dk_vs_create_race),
+	DEFINE_STAT_LEVEL_CNT(track_lh),
+	DEFINE_STAT_LEVEL_CNT(sibling_search),
+	DEFINE_STAT_LEVEL_CNT(cbk_key_moved),
+	DEFINE_STAT_LEVEL_CNT(cbk_met_ghost),
+	DEFINE_STAT_LEVEL_CNT(object_lookup_start),
+
+	DEFINE_STAT_LEVEL_CNT(jnode.jload),
+	DEFINE_STAT_LEVEL_CNT(jnode.jload_already),
+	DEFINE_STAT_LEVEL_CNT(jnode.jload_page),
+	DEFINE_STAT_LEVEL_CNT(jnode.jload_async),
+	DEFINE_STAT_LEVEL_CNT(jnode.jload_read),
+	DEFINE_STAT_LEVEL_CNT(jnode.jput),
+	DEFINE_STAT_LEVEL_CNT(jnode.jputlast),
+
+	DEFINE_STAT_LEVEL_CNT(znode.lock),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_iteration),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_neighbor),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_neighbor_iteration),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_read),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_write),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_lopri),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_hipri),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_contented),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_uncontented),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_dying),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_cannot_lock),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_can_lock),
+	DEFINE_STAT_LEVEL_CNT(znode.lock_no_capture),
+	DEFINE_STAT_LEVEL_CNT(znode.unlock),
+	DEFINE_STAT_LEVEL_CNT(znode.wakeup),
+	DEFINE_STAT_LEVEL_CNT(znode.wakeup_found),
+	DEFINE_STAT_LEVEL_CNT(znode.wakeup_found_read),
+	DEFINE_STAT_LEVEL_CNT(znode.wakeup_scan),
+	DEFINE_STAT_LEVEL_CNT(znode.wakeup_convoy),
+	DEFINE_STAT_LEVEL_CNT(node.lookup.calls),
+	DEFINE_STAT_LEVEL_CNT(node.lookup.items),
+	DEFINE_STAT_LEVEL_CNT(node.lookup.binary),
+	DEFINE_STAT_LEVEL_CNT(node.lookup.seq),
+	DEFINE_STAT_LEVEL_CNT(node.lookup.found),
+	DEFINE_STAT_LEVEL_CNT(node.lookup.pos),
+	DEFINE_STAT_LEVEL_CNT(node.lookup.posrelative),
+	DEFINE_STAT_LEVEL_CNT(node.lookup.samepos),
+	DEFINE_STAT_LEVEL_CNT(node.lookup.nextpos),
+
+	DEFINE_STAT_LEVEL_CNT(vm.release.try),
+	DEFINE_STAT_LEVEL_CNT(vm.release.ok),
+	DEFINE_STAT_LEVEL_CNT(vm.release.loaded),
+	DEFINE_STAT_LEVEL_CNT(vm.release.copy),
+	DEFINE_STAT_LEVEL_CNT(vm.release.eflushed),
+	DEFINE_STAT_LEVEL_CNT(vm.release.fake),
+	DEFINE_STAT_LEVEL_CNT(vm.release.dirty),
+	DEFINE_STAT_LEVEL_CNT(vm.release.ovrwr),
+	DEFINE_STAT_LEVEL_CNT(vm.release.writeback),
+	DEFINE_STAT_LEVEL_CNT(vm.release.keepme),
+	DEFINE_STAT_LEVEL_CNT(vm.release.bitmap),
+
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.called),
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.ok),
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.nolonger),
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.needs_block),
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.loaded),
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.queued),
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.protected),
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.heard_banshee),
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.nopage),
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.writeback),
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.bitmap),
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.clustered),
+	DEFINE_STAT_LEVEL_CNT(vm.eflush.eflushed),
+
+	DEFINE_STAT_LEVEL_CNT(time_slept),
+	DEFINE_STAT_LEVEL_CNT(total_hits_at_level)
+};
+
+/*
+ * print single stat-counter.
+ */
+static void
+print_cnt(reiser4_stats_cnt * cnt, const char * prefix, void * base)
+{
+	printk("%s%s:\t ", prefix, cnt->kattr.attr.kattr.name);
+	printk(cnt->format,
+	       statcnt_get(getptrat(statcnt_t, base, cnt->offset)));
+}
+
+/*
+ * Print statistical data accumulated so far.
+ *
+ * This is done during umount if REISER4_STATS_ON_UMOUNT flag is set in
+ * ->debug_flags.
+ */
+reiser4_internal void
+reiser4_print_stats(void)
+{
+	reiser4_stat *s;
+	int i;
+
+	s = get_current_super_private()->stats;
+	for(i = 0 ; i < sizeof_array(reiser4_stat_defs) ; ++ i)
+		print_cnt(&reiser4_stat_defs[i], "", s);
+
+	for (i = 0; i < REAL_MAX_ZTREE_HEIGHT; ++i) {
+		int j;
+
+		if (statcnt_get(&s->level[i].total_hits_at_level) <= 0)
+			continue;
+		printk("tree: at level: %i\n", i +  LEAF_LEVEL);
+		for(j = 0 ; j < sizeof_array(reiser4_stat_level_defs) ; ++ j)
+			print_cnt(&reiser4_stat_level_defs[j], "\t", &s->level[i]);
+	}
+}
+
+/*
+ * add all defined per-level stat-counters as attributes to the @kobj. This is
+ * the way stat-counters are exported through sysfs.
+ */
+int
+reiser4_populate_kattr_level_dir(struct kobject * kobj)
+{
+	int result;
+	int i;
+
+	result = 0;
+	for(i = 0 ; i < sizeof_array(reiser4_stat_level_defs) && !result ; ++ i){
+		struct attribute *a;
+
+		a = &reiser4_stat_level_defs[i].kattr.attr.kattr;
+		result = sysfs_create_file(kobj, a);
+	}
+	if (result != 0)
+		warning("nikita-2921", "Failed to add sysfs level attr: %i, %i",
+			result, i);
+	return result;
+}
+
+/*
+ * initialize stat-counters for a super block. Called during mount.
+ */
+int reiser4_stat_init(reiser4_stat ** storehere)
+{
+	reiser4_stat *stats;
+	statcnt_t *cnt;
+	int num, i;
+
+	/* sanity check: @stats size is multiple of statcnt_t size */
+	cassert((sizeof *stats) / (sizeof *cnt) * (sizeof *cnt) == (sizeof *stats));
+
+	/*
+	 * allocate @stats via vmalloc_32: it's too large for kmalloc.
+	 */
+	stats = vmalloc_32(sizeof *stats);
+	if (stats == NULL)
+		return -ENOMEM;
+
+	*storehere = stats;
+
+	num = (sizeof *stats) / (sizeof *cnt);
+	cnt = (statcnt_t *)stats;
+	/*
+	 * initialize all counters
+	 */
+	for (i = 0; i < num ; ++i, ++cnt)
+		statcnt_init(cnt);
+	return 0;
+}
+
+/*
+ * release resources used by stat-counters. Called during umount. Dual to
+ * reiser4_stat_init.
+ */
+void reiser4_stat_done(reiser4_stat ** stats)
+{
+	vfree(*stats);
+	*stats = NULL;
+}
+
+#else
+void
+reiser4_print_stats()
+{
+}
+#endif
+
+/*
+ * populate /sys/fs/reiser4/<dev>/stats with sub-objects.
+ */
+reiser4_internal int
+reiser4_populate_kattr_dir(struct kobject * kobj UNUSED_ARG)
+{
+	int result;
+	ON_STATS(int i);
+
+	result = 0;
+#if REISER4_STATS
+	for(i = 0 ; i < sizeof_array(reiser4_stat_defs) && !result ; ++ i) {
+		struct attribute *a;
+
+		a = &reiser4_stat_defs[i].kattr.attr.kattr;
+		result = sysfs_create_file(kobj, a);
+	}
+	if (result != 0)
+		warning("nikita-2920", "Failed to add sysfs attr: %i, %i",
+			result, i);
+#endif
+	return result;
+}
+
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   End:
+*/
diff -puN /dev/null stats.h
--- /dev/null	2004-10-02 12:38:03.000000000 +0400
+++ reiser4-vs/stats.h	2005-02-01 11:51:12.000000000 +0300
@@ -0,0 +1,769 @@
+/* Copyright 2001, 2002, 2003, 2004 by Hans Reiser, licensing governed by
+ * reiser4/README */
+
+/* Statistics gathering. See stats.c for comments. */
+
+#if !defined( __FS_REISER4_STATS_H__ )
+#define __FS_REISER4_STATS_H__
+
+#include "forward.h"
+#include "reiser4.h"
+#include "debug.h"
+#include "statcnt.h"
+
+/* for __u?? types */
+#include <linux/types.h>
+/* for struct super_block, etc */
+#include <linux/fs.h>
+/* for in_interrupt() */
+#include <asm/hardirq.h>
+
+#include <linux/sched.h>
+
+#if REISER4_STATS
+
+/* following macros update counters from &reiser4_stat below, which
+   see */
+
+#define ON_STATS(e) e
+/* statistics gathering features. */
+
+#define REISER4_STATS_STRICT (0)
+
+/* statistical counters collected on each level of internal tree */
+typedef struct reiser4_level_statistics {
+	/* carries restarted due to deadlock avoidance algorithm */
+	statcnt_t carry_restart;
+	/* carries performed */
+	statcnt_t carry_done;
+	/* how many times carry, trying to find left neighbor of a given node,
+	   found it already in a carry set. */
+	statcnt_t carry_left_in_carry;
+	/* how many times carry, trying to find left neighbor of a given node,
+	   found it already in a memory. */
+	statcnt_t carry_left_in_cache;
+	/* how many times carry, trying to find left neighbor of a given node,
+	   found it is not in a memory. */
+	statcnt_t carry_left_missed;
+	/* how many times carry, trying to find left neighbor of a given node,
+	   found that left neighbor either doesn't exist (we are at the left
+	   border of the tree already), or that there is extent on the left.
+	*/
+	statcnt_t carry_left_not_avail;
+	/* how many times carry, trying to find left neighbor of a given node,
+	   gave this up to avoid deadlock */
+	statcnt_t carry_left_refuse;
+	/* how many times carry, trying to find right neighbor of a given
+	   node, found it already in a carry set. */
+	statcnt_t carry_right_in_carry;
+	/* how many times carry, trying to find right neighbor of a given
+	   node, found it already in a memory. */
+	statcnt_t carry_right_in_cache;
+	/* how many times carry, trying to find right neighbor of a given
+	   node, found it is not in a memory. */
+	statcnt_t carry_right_missed;
+	/* how many times carry, trying to find right neighbor of a given
+	   node, found that right neighbor either doesn't exist (we are at the
+	   right border of the tree already), or that there is extent on the
+	   right.
+	*/
+	statcnt_t carry_right_not_avail;
+	/* how many times insertion has to look into the left neighbor,
+	   searching for the free space. */
+	statcnt_t insert_looking_left;
+	/* how many times insertion has to look into the right neighbor,
+	   searching for the free space. */
+	statcnt_t insert_looking_right;
+	/* how many times insertion has to allocate new node, searching for
+	   the free space. */
+	statcnt_t insert_alloc_new;
+	/* how many times insertion has to allocate several new nodes in a
+	   row, searching for the free space. */
+	statcnt_t insert_alloc_many;
+	/* how many insertions were performed by carry. */
+	statcnt_t insert;
+	/* how many deletions were performed by carry. */
+	statcnt_t delete;
+	/* how many cuts were performed by carry. */
+	statcnt_t cut;
+	/* how many pastes (insertions into existing items) were performed by
+	   carry. */
+	statcnt_t paste;
+	/* how many extent insertions were done by carry. */
+	statcnt_t extent;
+	/* how many paste operations were restarted as insert. */
+	statcnt_t paste_restarted;
+	/* how many updates of delimiting keys were performed by carry. */
+	statcnt_t update;
+	/* how many times carry notified parent node about updates in its
+	   child. */
+	statcnt_t modify;
+	/* how many times node was found reparented at the time when its
+	   parent has to be updated. */
+	statcnt_t half_split_race;
+	/* how many times new node was inserted into sibling list after
+	   concurrent balancing modified right delimiting key if its left
+	   neighbor.
+	*/
+	statcnt_t dk_vs_create_race;
+	/* how many times insert or paste ultimately went into node different
+	   from original target */
+	statcnt_t track_lh;
+	/* how many times sibling lookup required getting that high in a
+	   tree */
+	statcnt_t sibling_search;
+	/* key was moved out of node while thread was waiting for the lock */
+	statcnt_t cbk_key_moved;
+	/* node was moved out of tree while thread was waiting for the lock */
+	statcnt_t cbk_met_ghost;
+	/* how many times vroot ("virtual root") optimization was used during
+	 * tree lookup */
+	statcnt_t object_lookup_start;
+	struct {
+		/* calls to jload() */
+		statcnt_t jload;
+		/* calls to jload() that found jnode already loaded */
+		statcnt_t jload_already;
+		/* calls to jload() that found page already in memory */
+		statcnt_t jload_page;
+		/* calls to jload() that found jnode with asynchronous io
+		 * started */
+		statcnt_t jload_async;
+		/* calls to jload() that actually had to read data */
+		statcnt_t jload_read;
+		/* calls to jput() */
+		statcnt_t jput;
+		/* calls to jput() that released last reference */
+		statcnt_t jputlast;
+	} jnode;
+	struct {
+		/* calls to lock_znode() */
+		statcnt_t lock;
+		/* number of times loop inside lock_znode() was executed */
+		statcnt_t lock_iteration;
+		/* calls to lock_neighbor() */
+		statcnt_t lock_neighbor;
+		/* number of times loop inside lock_neighbor() was executed */
+		statcnt_t lock_neighbor_iteration;
+		/* read locks taken */
+		statcnt_t lock_read;
+		/* write locks taken */
+		statcnt_t lock_write;
+		/* low priority locks taken */
+		statcnt_t lock_lopri;
+		/* high priority locks taken */
+		statcnt_t lock_hipri;
+		/* how many requests for znode long term lock couldn't succeed
+		 * immediately. */
+		statcnt_t lock_contented;
+		/* how many requests for znode long term lock managed to
+		 * succeed immediately. */
+		statcnt_t lock_uncontented;
+		/* attempt to acquire a lock failed, because target node was
+		 * dying */
+		statcnt_t lock_dying;
+		/* lock wasn't immediately available, due to incompatible lock
+		 * mode */
+		statcnt_t lock_cannot_lock;
+		/* lock was immediately available (i.e., without wait) */
+		statcnt_t lock_can_lock;
+		/* no node capture was necessary when acquiring a lock */
+		statcnt_t lock_no_capture;
+		/* number of unlocks */
+		statcnt_t unlock;
+		/* number of times unlock decided to wake up sleeping
+		 * requestors */
+		statcnt_t wakeup;
+		/* number of times requestors were actually found during wake
+		 * up */
+		statcnt_t wakeup_found;
+		/* number of read-mode requestors found */
+		statcnt_t wakeup_found_read;
+		/* number of requestor queue items scanned during wake-up
+		 * processing */
+		statcnt_t wakeup_scan;
+		/* number of requestors bundled into convoys */
+		statcnt_t wakeup_convoy;
+	} znode;
+	struct {
+		/* node lookup stats */
+		struct {
+			/* ->lookup() calls */
+			statcnt_t calls;
+			/* items in all nodes */
+			statcnt_t items;
+			/* "hops" of binary search */
+			statcnt_t binary;
+			/* iterations of sequential search */
+			statcnt_t seq;
+			/* how many times key sought for was found */
+			statcnt_t found;
+			/* average position where key was found */
+			statcnt_t pos;
+			/* average position where key was found relative to
+			 * total number of items */
+			statcnt_t posrelative;
+			/* number of times key was found in the same position
+			 * as in the previous lookup in this node */
+			statcnt_t samepos;
+			/* number of times key was found in the next position
+			 * relative to the previous lookup in this node */
+			statcnt_t nextpos;
+		} lookup;
+	} node;
+	struct {
+		/* reiser4_releasepage() stats */
+		struct {
+			/* for how many pages on this level ->releasepage()
+			 * was called. */
+			statcnt_t try;
+			/* how many pages were released on this level */
+			statcnt_t ok;
+			/*
+			 * how many times we failed to release a page,
+			 * because...
+			 */
+			/* jnode pinned it in memory */
+			statcnt_t loaded;
+			/* it's coced page */
+			statcnt_t copy;
+			/* it has fake block number */
+			statcnt_t fake;
+			/* it is dirty */
+			statcnt_t dirty;
+			/* it is in the overwrite set */
+			statcnt_t ovrwr;
+			/* it is under writeback */
+			statcnt_t writeback;
+			/* it's anonymous page, and jnode is not yet captured
+			 * into atom. */
+			statcnt_t keepme;
+			/* it's bitmap */
+			statcnt_t bitmap;
+
+			/* emergency flush was performed on this page/jnode,
+			 * so it's ok to release */
+			statcnt_t eflushed;
+		} release;
+		/* emergency flush statistics */
+		struct {
+			/* how many times emergency flush was invoked on this
+			 * level */
+			statcnt_t called;
+			/* eflush was successful */
+			statcnt_t ok;
+			/* jnode ceased to be flushable after lock release */
+			statcnt_t nolonger;
+			/* new block number was needed for eflush */
+			statcnt_t needs_block;
+			/*
+			 * eflush failed, because...
+			 */
+			/* jnode is loaded */
+			statcnt_t loaded;
+			/* jnode is in the flush queue */
+			statcnt_t queued;
+			/* jnode is protected (JNODE_PROTECTED bit is on) */
+			statcnt_t protected;
+			/* jnode heard banshee already */
+			statcnt_t heard_banshee;
+			/* jnode has no page */
+			statcnt_t nopage;
+			/* jnode is under writeback */
+			statcnt_t writeback;
+			/* jnode is bitmap */
+			statcnt_t bitmap;
+			/* jnode is crypto-compress cluster */
+			statcnt_t clustered;
+			/* jnode is already eflushed */
+			statcnt_t eflushed;
+		} eflush;
+	} vm;
+	/*
+	 * non zero, if there is some other non-zero counter at this tree
+	 * level. Used to suppress processing of higher tree levels, that
+	 * don't exist on the underlying file system.
+	 */
+	statcnt_t total_hits_at_level;
+	/* total time (in jiffies) threads sleep for the longterm locks on
+	 * this level */
+	statcnt_t time_slept;
+} reiser4_level_stat;
+
+/*
+ * hash table statistics. Such object is added to each type safe hash table
+ * instance (see fs/reiser4/type_safe_hash.h).
+ */
+typedef struct tshash_stat {
+	statcnt_t lookup;  /* number of lookup calls */
+	statcnt_t insert;  /* number of insert calls */
+	statcnt_t remove;  /* number of remove calls */
+	statcnt_t scanned; /* total number of items inspected during all
+			    * operations. This can be used to estimate average
+			    * hash-chain depth. */
+} tshash_stat;
+
+#define TSHASH_LOOKUP(stat) ({ if(stat) statcnt_inc(&stat->lookup); })
+#define TSHASH_INSERT(stat) ({ if(stat) statcnt_inc(&stat->insert); })
+#define TSHASH_REMOVE(stat) ({ if(stat) statcnt_inc(&stat->remove); })
+#define TSHASH_SCANNED(stat) ({ if(stat) statcnt_inc(&stat->scanned); })
+
+/* set of statistics counter. This is embedded into super-block when
+   REISER4_STATS is on. */
+typedef struct reiser4_statistics {
+	struct {
+		/* calls to coord_by_key */
+		statcnt_t cbk;
+		/* calls to coord_by_key that found requested key */
+		statcnt_t cbk_found;
+		/* calls to coord_by_key that didn't find requested key */
+		statcnt_t cbk_notfound;
+		/* number of times calls to coord_by_key restarted */
+		statcnt_t cbk_restart;
+		/* calls to coord_by_key that found key in coord cache */
+		statcnt_t cbk_cache_hit;
+		/* calls to coord_by_key that didn't find key in coord
+		   cache */
+		statcnt_t cbk_cache_miss;
+		/* cbk cache search found wrong node */
+		statcnt_t cbk_cache_wrong_node;
+		/* search for key in coord cache raced against parallel
+		   balancing and lose. This should be rare. If not,
+		   update cbk_cache_search() according to comment
+		   therewithin.
+		*/
+		statcnt_t cbk_cache_race;
+		/*
+		 * statistics for vroot ("virtual root") optimization of tree
+		 * lookup.
+		 */
+		/*
+		 * vroot usage failed, because...
+		 */
+		/* given object has no vroot set */
+		statcnt_t object_lookup_novroot;
+		/* vroot changed due to race with balancing */
+		statcnt_t object_lookup_moved;
+		/* object is not fitted into its vroot any longer */
+		statcnt_t object_lookup_outside;
+		/* failed to lock vroot */
+		statcnt_t object_lookup_cannotlock;
+
+		/* tree traversal had to be re-started due to vroot failure */
+		statcnt_t object_lookup_restart;
+
+		/* number of times coord of child in its parent, cached
+		   in a former, was reused. */
+		statcnt_t pos_in_parent_hit;
+		/* number of time binary search for child position in
+		   its parent had to be redone. */
+		statcnt_t pos_in_parent_miss;
+		/* number of times position of child in its parent was
+		   cached in the former */
+		statcnt_t pos_in_parent_set;
+		/* how many times carry() was skipped by doing "fast
+		   insertion path". See
+		   fs/reiser4/plugin/node/node.h:->fast_insert() method.
+		*/
+		statcnt_t fast_insert;
+		/* how many times carry() was skipped by doing "fast
+		   paste path". See
+		   fs/reiser4/plugin/node/node.h:->fast_paste() method.
+		*/
+		statcnt_t fast_paste;
+		/* how many times carry() was skipped by doing "fast
+		   cut path". See
+		   fs/reiser4/plugin/node/node.h:->cut_insert() method.
+		*/
+		statcnt_t fast_cut;
+		/* children reparented due to shifts at the parent level */
+		statcnt_t reparenting;
+		/* right delimiting key is not exact */
+		statcnt_t rd_key_skew;
+		statcnt_t check_left_nonuniq;
+		statcnt_t left_nonuniq_found;
+	} tree;
+	reiser4_level_stat level[REISER4_MAX_ZTREE_HEIGHT];
+	/* system call statistics. Indicates how many times given system (or,
+	 * sometimes, internal kernel function) was
+	 * invoked. Self-explanatory. */
+	struct {
+		statcnt_t open;
+		statcnt_t lookup;
+		statcnt_t create;
+		statcnt_t mkdir;
+		statcnt_t symlink;
+		statcnt_t mknod;
+		statcnt_t rename;
+		statcnt_t readlink;
+		statcnt_t follow_link;
+		statcnt_t setattr;
+		statcnt_t getattr;
+		statcnt_t read;
+		statcnt_t write;
+		statcnt_t truncate;
+		statcnt_t statfs;
+		statcnt_t bmap;
+		statcnt_t link;
+		statcnt_t llseek;
+		statcnt_t readdir;
+		statcnt_t ioctl;
+		statcnt_t mmap;
+		statcnt_t unlink;
+		statcnt_t rmdir;
+		statcnt_t alloc_inode;
+		statcnt_t destroy_inode;
+		statcnt_t delete_inode;
+		statcnt_t write_super;
+		statcnt_t private_data_alloc; /* allocations of either per
+					       * struct dentry or per struct
+					       * file data */
+	} vfs_calls;
+	struct {
+		/* readdir stats */
+		struct {
+			/* calls to readdir */
+			statcnt_t calls;
+			/* rewinds to the beginning of directory */
+			statcnt_t reset;
+			/* partial rewinds to the left */
+			statcnt_t rewind_left;
+			/* rewind to left that was completely within sequence
+			 * of duplicate keys */
+			statcnt_t left_non_uniq;
+			/* restarts of rewinds to the left due to hi/lo
+			 * priority locking */
+			statcnt_t left_restart;
+			/* rewinds to the right */
+			statcnt_t rewind_right;
+			/* how many times readdir position has to be adjusted
+			 * due to directory modification. Large readdir
+			 * comment in plugin/dir/dir.c */
+			statcnt_t adjust_pos;
+			/* how many times adjustment was on the left of
+			 * current readdir position */
+			statcnt_t adjust_lt;
+			/* how many times adjustment was on the right of
+			 * current readdir position */
+			statcnt_t adjust_gt;
+			/* how many times adjustment was exactly on the
+			 * current readdir position */
+			statcnt_t adjust_eq;
+		} readdir;
+	} dir;
+
+	/* statistics of unix file plugin */
+	struct {
+
+		struct {
+			statcnt_t readpage_calls;
+			statcnt_t writepage_calls;
+		} page_ops;
+
+		/* number of tail conversions */
+		statcnt_t tail2extent;
+		statcnt_t extent2tail;
+
+		/* find_next_item statistic */
+		statcnt_t find_file_item;
+		statcnt_t find_file_item_via_seal;
+		statcnt_t find_file_item_via_right_neighbor;
+		statcnt_t find_file_item_via_cbk;
+
+	} file;
+	struct {
+		/* how many unformatted nodes were read */
+		statcnt_t unfm_block_reads;
+
+		/* extent_write seals and unlock znode before locking/capturing
+		   page which is to be modified. After page is locked/captured
+		   it validates a seal. Number of found broken seals is stored
+		   here
+		*/
+		statcnt_t broken_seals;
+
+		/* extent_write calls balance_dirty_pages after it modifies
+		   every page. Before that it seals node it currently holds
+		   and uses seal_validate to lock it again. This field stores
+		   how many times balance_dirty_pages broke that seal and
+		   caused to repease search tree traversal
+		*/
+		statcnt_t bdp_caused_repeats;
+		/* how many times extent_write could not write a coord and had
+		 * to ask for research */
+		statcnt_t repeats;
+	} extent;
+	struct { /* stats on tail items */
+		/* tail_write calls balance_dirty_pages after every call to
+		   insert_flow. Before that it seals node it currently holds
+		   and uses seal_validate to lock it again. This field stores
+		   how many times balance_dirty_pages broke that seal and
+		   caused to repease search tree traversal
+		*/
+		statcnt_t bdp_caused_repeats;
+	} tail;
+	/* transaction manager stats */
+	struct {
+		/* jiffies, spent in atom_wait_event() */
+		statcnt_t slept_in_wait_event;
+		/* jiffies, spent in capture_fuse_wait (wait for atom state
+		 * change) */
+		statcnt_t slept_in_wait_atom;
+		/* number of commits */
+		statcnt_t commits;
+		/*number of post commit writes */
+		statcnt_t post_commit_writes;
+		/* jiffies, spent in commits and post commit writes */
+		statcnt_t time_spent_in_commits;
+		/* how many times attempt to write a flush queue ended up with
+		 * an empty bio */
+		statcnt_t empty_bio;
+		/* how many times ->writepage kicked ktxnmged to start commit
+		 * of an atom */
+		statcnt_t commit_from_writepage;
+
+		/*
+		 * fs/txnmgrd.c:try_capture_block() stats
+		 */
+
+		/* atoms of node and transaction handle are the same
+		 * already */
+		statcnt_t capture_equal;
+		/* node and handle both belong to atoms */
+		statcnt_t capture_both;
+		/* only node belongs to atom */
+		statcnt_t capture_block;
+		/* only handle belongs to atom */
+		statcnt_t capture_txnh;
+		/* neither node nor handle belong to atom */
+		statcnt_t capture_none;
+
+		/*
+		 * how many times some transaction manager activity had to be
+		 * re-started, because...
+		 */
+		struct {
+			/* new atom was created */
+			statcnt_t atom_begin;
+			/* commit_current_atom() found atom in use */
+			statcnt_t cannot_commit;
+			/* committer had to wait */
+			statcnt_t should_wait;
+			/* jnode_flush was invoked several times in a row */
+			statcnt_t flush;
+			/* fuse_not_fused_lock_owners() fused atoms */
+			statcnt_t fuse_lock_owners_fused;
+			/* fuse_not_fused_lock_owners() has to restart */
+			statcnt_t fuse_lock_owners;
+			/* trylock failed on atom */
+			statcnt_t trylock_throttle;
+			/* atom trylock failed in capture_assign_block() */
+			statcnt_t assign_block;
+			/* atom trylock failed in capture_assign_txnh() */
+			statcnt_t assign_txnh;
+			/* capture_fuse_wait() was called in non-blocking
+			 * mode */
+			statcnt_t fuse_wait_nonblock;
+			/* capture_fuse_wait() had to sleep */
+			statcnt_t fuse_wait_slept;
+			/* capture_init_fusion() failed to try-lock node
+			 * atom */
+			statcnt_t init_fusion_atomf;
+			/* capture_init_fusion() failed to try-lock handle
+			 * atom */
+			statcnt_t init_fusion_atomh;
+			/* capture_init_fusion_locked() slept during fusion */
+			statcnt_t init_fusion_fused;
+		} restart;
+	} txnmgr;
+	struct {
+		/* how many nodes were squeezed to left neighbor completely */
+		statcnt_t squeezed_completely;
+		/* how many times nodes with unallocated children are written */
+		statcnt_t flushed_with_unallocated;
+		/* how many leaves were squeezed to left */
+		statcnt_t squeezed_leaves;
+		/* how many items were squeezed on leaf level */
+		statcnt_t squeezed_leaf_items;
+		/* how mnay bytes were squeezed on leaf level */
+		statcnt_t squeezed_leaf_bytes;
+		/* how many times jnode_flush was called */
+		statcnt_t flush;
+		/* how many nodes were scanned by scan_left() */
+		statcnt_t left;
+		/* how many nodes were scanned by scan_right() */
+		statcnt_t right;
+		/* an overhead of MTFLUSH semaphore */
+		statcnt_t slept_in_mtflush_sem;
+	} flush;
+	struct {
+		/* how many carry objects were allocated */
+		statcnt_t alloc;
+		/* how many "extra" carry objects were allocated by
+		   kmalloc. */
+		statcnt_t kmalloc;
+	} pool;
+	struct {
+		/* seals that were found pristine */
+		statcnt_t perfect_match;
+		/* how many times node under seal was out of cache */
+		statcnt_t out_of_cache;
+	} seal;
+	/* hash tables stats. See tshash_stat above. */
+	struct {
+		/* for the hash table of znodes with real block numbers */
+		tshash_stat znode;
+		/* for the hash table of znodes with fake block numbers */
+		tshash_stat zfake;
+		/* for the hash table of jnodes */
+		tshash_stat jnode;
+		/* for the hash table of lnodes */
+		tshash_stat lnode;
+		/* for the hash table of eflush_node_t's */
+		tshash_stat eflush;
+	} hashes;
+	struct {
+		/* how many times block was allocated without having valid
+		 * preceder. */
+		statcnt_t nohint;
+	} block_alloc;
+	/* how many non-unique keys were scanned into tree */
+	statcnt_t non_uniq;
+
+	/* page_common_writeback stats */
+	struct {
+		/* calls to ->writepage() */
+		statcnt_t calls;
+		/* ->writepage() failed to allocate jnode for the page */
+		statcnt_t no_jnode;
+		/* emergency flush succeed */
+		statcnt_t written;
+		/* emergency flush failed */
+		statcnt_t not_written;
+	} pcwb;
+
+	/* stat of copy on capture requests */
+	struct {
+		statcnt_t calls;
+		/* satisfied requests */
+		statcnt_t ok_uber;
+		statcnt_t ok_nopage;
+		statcnt_t ok_clean;
+		statcnt_t ok_ovrwr;
+		statcnt_t ok_reloc;
+		/* refused copy on capture requests */
+		statcnt_t forbidden;
+		statcnt_t writeback;
+		statcnt_t flush_queued;
+		statcnt_t dirty;
+		statcnt_t eflush;
+		statcnt_t scan_race;
+		statcnt_t atom_changed;
+		statcnt_t coc_race;
+		statcnt_t coc_wait;
+	} coc;
+
+	statcnt_t pages_dirty;
+	statcnt_t pages_clean;
+} reiser4_stat;
+
+
+#define get_current_stat() 					\
+	(get_super_private_nocheck(reiser4_get_current_sb())->stats)
+
+/* Macros to gather statistical data. If REISER4_STATS is disabled, they
+   are preprocessed to nothing.
+*/
+
+#define	reiser4_stat(sb, cnt) (&get_super_private_nocheck(sb)->stats->cnt)
+
+#define	reiser4_stat_inc_at(sb, counter)					\
+	statcnt_inc(&get_super_private_nocheck(sb)->stats->counter)
+
+#define	reiser4_stat_inc(counter)				\
+	ON_CONTEXT(statcnt_inc(&get_current_stat()->counter))
+
+#define reiser4_stat_add(counter, delta) 			\
+	ON_CONTEXT(statcnt_add(&get_current_stat()->counter, delta))
+
+#define	reiser4_stat_inc_at_level(lev, stat)					\
+({										\
+	int __level;								\
+										\
+	__level = (lev);        						\
+	if (__level >= 0) {							\
+		if(__level < REISER4_MAX_ZTREE_HEIGHT) {			\
+			reiser4_stat_inc(level[__level]. stat);			\
+			reiser4_stat_inc(level[__level]. total_hits_at_level);	\
+		}								\
+	}									\
+})
+
+#define	reiser4_stat_add_at_level(lev, stat, value)				\
+({										\
+	int level;								\
+										\
+	level = (lev);          						\
+	if (level >= 0) {							\
+		if(level < REISER4_MAX_ZTREE_HEIGHT) {				\
+			reiser4_stat_add(level[level]. stat , value );		\
+			reiser4_stat_inc(level[level]. total_hits_at_level);	\
+		}								\
+	}									\
+})
+
+#define	reiser4_stat_level_inc(l, stat)			\
+	reiser4_stat_inc_at_level((l)->level_no, stat)
+
+
+struct kobject;
+extern int reiser4_populate_kattr_level_dir(struct kobject * kobj);
+extern int reiser4_stat_init(reiser4_stat ** stats);
+extern void reiser4_stat_done(reiser4_stat ** stats);
+
+/* REISER4_STATS */
+#else
+
+#define ON_STATS(e) noop
+
+#define	reiser4_stat(sb, cnt) ((void *)NULL)
+#define	reiser4_stat_inc(counter)  noop
+#define reiser4_stat_add(counter, delta) noop
+
+#define	reiser4_stat_inc_at(sb, counter) noop
+#define	reiser4_stat_inc_at_level(lev, stat) noop
+#define reiser4_stat_add_at_level(lev, stat, cnt) noop
+#define	reiser4_stat_level_inc(l, stat) noop
+
+typedef struct {
+} reiser4_stat;
+
+typedef struct tshash_stat {
+} tshash_stat;
+
+#define TSHASH_LOOKUP(stat) noop
+#define TSHASH_INSERT(stat) noop
+#define TSHASH_REMOVE(stat) noop
+#define TSHASH_SCANNED(stat) noop
+
+#define reiser4_populate_kattr_level_dir(kobj, i) (0)
+#define reiser4_stat_init(s) (0)
+#define reiser4_stat_done(s) noop
+
+#endif
+
+extern int reiser4_populate_kattr_dir(struct kobject * kobj);
+
+
+/* __FS_REISER4_STATS_H__ */
+#endif
+
+/* Make Linus happy.
+   Local variables:
+   c-indentation-style: "K&R"
+   mode-name: "LC"
+   c-basic-offset: 8
+   tab-width: 8
+   fill-column: 120
+   End:
+*/
diff -puN super.c~profile-stat-trace-repacker super.c
--- reiser4/super.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/super.c	2005-02-01 11:51:12.000000000 +0300
@@ -42,6 +42,17 @@ statfs_type(const struct super_block *su
 	return (long) REISER4_SUPER_MAGIC;
 }
 
+/* block size used by file system corresponding to @super */
+reiser4_internal int
+reiser4_blksize(const struct super_block *super /* super block queried */ )
+{
+	assert("nikita-450", super != NULL);
+	assert("nikita-451", is_reiser4_super(super));
+	/* FIXME-VS: blocksize has to be 512, 1024, 2048, etc */
+	assert("zam-391", super->s_blocksize > 0);
+	return super->s_blocksize;
+}
+
 /* functions to read/modify fields of reiser4_super_info_data */
 
 /* get number of blocks in file system */
@@ -120,6 +131,14 @@ reiser4_set_free_blocks(const struct sup
 	get_super_private(super)->blocks_free = nr;
 }
 
+/* increment reiser4_super_info_data's counter of free blocks */
+reiser4_internal void
+reiser4_inc_free_blocks(const struct super_block *super)
+{
+	assert("vs-496", reiser4_free_blocks(super) < reiser4_block_count(super));
+	get_super_private(super)->blocks_free++;
+}
+
 /* get mkfs unique identifier */
 reiser4_internal __u32
 reiser4_mkfs_id(const struct super_block *super	/* super block
@@ -148,6 +167,16 @@ reiser4_free_committed_blocks(const stru
 	return get_super_private(super)->blocks_free_committed;
 }
 
+/* this is only used once on mount time to number of free blocks in
+   filesystem */
+reiser4_internal void
+reiser4_set_free_committed_blocks(const struct super_block *super, __u64 nr)
+{
+	assert("vs-507", super != NULL);
+	assert("vs-508", is_reiser4_super(super));
+	get_super_private(super)->blocks_free_committed = nr;
+}
+
 /* amount of blocks in the file system reserved for @uid and @gid */
 reiser4_internal long
 reiser4_reserved_blocks(const struct super_block *super	/* super block
@@ -178,6 +207,15 @@ reiser4_internal __u64 reiser4_grabbed_b
 	return get_super_private(super)->blocks_grabbed;
 }
 
+reiser4_internal void
+reiser4_set_grabbed_blocks(const struct super_block *super, __u64 nr)
+{
+	assert("zam-514", super != NULL);
+	assert("zam-515", is_reiser4_super(super));
+
+	get_super_private(super)->blocks_grabbed = nr;
+}
+
 reiser4_internal __u64 flush_reserved (const struct super_block *super)
 {
 	assert ("vpf-285", super != NULL);
@@ -186,6 +224,15 @@ reiser4_internal __u64 flush_reserved (c
 	return get_super_private(super)->blocks_flush_reserved;
 }
 
+reiser4_internal void
+set_flush_reserved (const struct super_block *super, __u64 nr)
+{
+	assert ("vpf-282", super != NULL);
+	assert ("vpf-283", is_reiser4_super (super));
+
+	get_super_private(super)->blocks_flush_reserved = nr;
+}
+
 /* get/set value of/to counter of fake allocated formatted blocks */
 reiser4_internal __u64 reiser4_fake_allocated(const struct super_block *super)
 {
@@ -195,6 +242,15 @@ reiser4_internal __u64 reiser4_fake_allo
 	return get_super_private(super)->blocks_fake_allocated;
 }
 
+reiser4_internal void
+reiser4_set_fake_allocated(const struct super_block *super, __u64 nr)
+{
+	assert("zam-518", super != NULL);
+	assert("zam-519", is_reiser4_super(super));
+
+	get_super_private(super)->blocks_fake_allocated = nr;
+}
+
 /* get/set value of/to counter of fake allocated unformatted blocks */
 reiser4_internal __u64
 reiser4_fake_allocated_unformatted(const struct super_block *super)
@@ -205,6 +261,16 @@ reiser4_fake_allocated_unformatted(const
 	return get_super_private(super)->blocks_fake_allocated_unformatted;
 }
 
+reiser4_internal void
+reiser4_set_fake_allocated_unformatted(const struct super_block *super, __u64 nr)
+{
+	assert("zam-518", super != NULL);
+	assert("zam-519", is_reiser4_super(super));
+
+	get_super_private(super)->blocks_fake_allocated_unformatted = nr;
+}
+
+
 /* get/set value of/to counter of clustered blocks */
 reiser4_internal __u64 reiser4_clustered_blocks(const struct super_block *super)
 {
@@ -214,6 +280,15 @@ reiser4_internal __u64 reiser4_clustered
 	return get_super_private(super)->blocks_clustered;
 }
 
+reiser4_internal void
+reiser4_set_clustered_blocks(const struct super_block *super, __u64 nr)
+{
+	assert("edward-603", super != NULL);
+	assert("edward-604", is_reiser4_super(super));
+
+	get_super_private(super)->blocks_clustered = nr;
+}
+
 /* space allocator used by this file system */
 reiser4_internal reiser4_space_allocator *
 get_space_allocator(const struct super_block * super)
diff -puN super.h~profile-stat-trace-repacker super.h
--- reiser4/super.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/super.h	2005-02-01 11:51:12.000000000 +0300
@@ -10,8 +10,11 @@
 #include "debug.h"
 #include "tree.h"
 #include "context.h"
+#include "log.h"
+#include "lnode.h"
 #include "entd.h"
 #include "plugin/plugin.h"
+#include "prof.h"
 #include "wander.h"
 
 #include "plugin/space/space_allocator.h"
@@ -66,6 +69,20 @@ typedef enum {
 	REISER4_DONT_LOAD_BITMAP = 6
 } reiser4_fs_flag;
 
+#if REISER4_STATS
+
+/*
+ * Object to export per-level stat-counters through sysfs. See stats.[ch] and
+ * kattr.[ch]
+ */
+typedef struct reiser4_level_stats_kobj {
+	struct fs_kobject kobj;   /* file system kobject exported for each
+				   * level */
+	int level;                /* tree level */
+} reiser4_level_stats_kobj;
+
+#endif
+
 /*
  * VFS related operation vectors.
  *
@@ -219,6 +236,9 @@ struct reiser4_super_info_data {
 	__u32 log_flags;
 	__u32 oid_to_log;
 
+	/* file where tracing goes (if enabled). */
+	reiser4_log_file log_file;
+
 	/* per-fs debugging flags. This is bitmask populated from
 	   reiser4_debug_flags enum. */
 	__u32 debug_flags;
@@ -305,16 +325,39 @@ struct reiser4_super_info_data {
 	/* dir_cursor_info see plugin/dir/dir.[ch] for more details */
 	d_cursor_info d_info;
 
+#if REISER4_USE_SYSFS
+	/* kobject representing this file system. It is visible as
+	 * /sys/fs/reiser4/<devname>. All other kobjects for this file system
+	 * (statistical counters, tunables, etc.) are below it in sysfs
+	 * hierarchy. */
+	struct fs_kobject kobj;
+#endif
+#if REISER4_STATS
+	/* Statistical counters. reiser4_stat is empty data-type unless
+	   REISER4_STATS is set. See stats.[ch] for details. */
+	reiser4_stat *stats;
+	/* kobject for statistical counters. Visible as
+	 * /sys/fs/reiser4/<devname>/stats */
+	struct fs_kobject stats_kobj;
+	/* kobjects for per-level statistical counters. Each level is visible
+	   as /sys/fs/reiser4/<devname>/stats-NN */
+	reiser4_level_stats_kobj level[REISER4_MAX_ZTREE_HEIGHT];
+#endif
 #ifdef CONFIG_REISER4_BADBLOCKS
 	/* Alternative master superblock offset (in bytes) */
 	unsigned long altsuper;
 #endif
+#if REISER4_LOG
+	/* last disk block IO was performed against by this file system. Used
+	 * by tree tracing code to track seeks. */
+	reiser4_block_nr last_touched;
+#endif
 #if REISER4_DEBUG
 	/* minimum used blocks value (includes super blocks, bitmap blocks and
 	 * other fs reserved areas), depends on fs format and fs size. */
 	__u64 min_blocks_used;
-	/* number of space allocated by kmalloc. For debugging. */
-	int kmallocs;
+	/* amount of space allocated by kmalloc. For debugging. */
+	int kmalloc_allocated;
 
 	/*
 	 * when debugging is on, all jnodes (including znodes, bitmaps, etc.)
@@ -456,23 +499,31 @@ static inline void spin_unlock_eflush(co
 
 
 extern __u64 flush_reserved        ( const struct super_block*);
+extern void  set_flush_reserved    ( const struct super_block*, __u64 nr );
 extern int reiser4_is_set(const struct super_block *super, reiser4_fs_flag f);
 extern long statfs_type(const struct super_block *super);
+extern int reiser4_blksize(const struct super_block *super);
 extern __u64 reiser4_block_count(const struct super_block *super);
 extern void reiser4_set_block_count(const struct super_block *super, __u64 nr);
 extern __u64 reiser4_data_blocks(const struct super_block *super);
 extern void reiser4_set_data_blocks(const struct super_block *super, __u64 nr);
 extern __u64 reiser4_free_blocks(const struct super_block *super);
 extern void reiser4_set_free_blocks(const struct super_block *super, __u64 nr);
+extern void reiser4_inc_free_blocks(const struct super_block *super);
 extern __u32 reiser4_mkfs_id(const struct super_block *super);
 extern void reiser4_set_mkfs_id(const struct super_block *super, __u32 id);
 
 extern __u64 reiser4_free_committed_blocks(const struct super_block *super);
+extern void reiser4_set_free_committed_blocks(const struct super_block *super, __u64 nr);
 
 extern __u64 reiser4_grabbed_blocks(const struct super_block *);
+extern void reiser4_set_grabbed_blocks(const struct super_block *, __u64 nr);
 extern __u64 reiser4_fake_allocated(const struct super_block *);
+extern void reiser4_set_fake_allocated(const struct super_block *, __u64 nr);
 extern __u64 reiser4_fake_allocated_unformatted(const struct super_block *);
+extern void reiser4_set_fake_allocated_unformatted(const struct super_block *, __u64 nr);
 extern __u64 reiser4_clustered_blocks(const struct super_block *);
+extern void reiser4_set_clustered_blocks(const struct super_block *, __u64 nr);
 
 extern long reiser4_reserved_blocks(const struct super_block *super, uid_t uid, gid_t gid);
 
@@ -503,8 +554,10 @@ long oids_used(const struct super_block 
 long oids_free(const struct super_block *);
 
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 void print_fs_info(const char *prefix, const struct super_block *);
+#else
+#define print_fs_info(p,s) noop
 #endif
 
 #if REISER4_DEBUG
diff -puN tap.c~profile-stat-trace-repacker tap.c
--- reiser4/tap.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/tap.c	2005-02-01 11:51:12.000000000 +0300
@@ -151,7 +151,7 @@ tap_move(tap_t * tap, lock_handle * targ
  * move @tap to @target. Acquire lock on @target, if @tap was already
  * loaded.
  */
-static int
+reiser4_internal int
 tap_to(tap_t * tap, znode * target)
 {
 	int result;
@@ -282,7 +282,7 @@ go_prev_unit(tap_t * tap)
  * @shift times apply @actor to the @tap. This is used to move @tap by
  * @shift units (or items, or nodes) in either direction.
  */
-static int
+reiser4_internal int
 rewind_to(tap_t * tap, go_actor_t actor, int shift)
 {
 	int result;
@@ -320,10 +320,9 @@ rewind_left(tap_t * tap, int shift)
 	return rewind_to(tap, go_prev_unit, shift);
 }
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 /** debugging function: print @tap content in human readable form */
-static void
-print_tap(const char * prefix, const tap_t * tap)
+reiser4_internal void print_tap(const char * prefix, const tap_t * tap)
 {
 	if (tap == NULL) {
 		printk("%s: null tap\n", prefix);
@@ -334,7 +333,11 @@ print_tap(const char * prefix, const tap
 	       lock_mode_name(tap->mode));
 	print_coord("\tcoord", tap->coord, 0);
 }
+#else
+#define print_tap(prefix, tap) noop
+#endif
 
+#if REISER4_DEBUG
 /** check [tap-sane] invariant */
 static int tap_invariant(const tap_t * tap)
 {
diff -puN tap.h~profile-stat-trace-repacker tap.h
--- reiser4/tap.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/tap.h	2005-02-01 11:51:12.000000000 +0300
@@ -44,11 +44,13 @@ extern void tap_monitor(tap_t * tap);
 extern void tap_copy(tap_t * dst, tap_t * src);
 extern void tap_done(tap_t * tap);
 extern int tap_move(tap_t * tap, lock_handle * target);
+extern int tap_to(tap_t * tap, znode * target);
 extern int tap_to_coord(tap_t * tap, coord_t * target);
 
 extern int go_dir_el(tap_t * tap, sideof dir, int units_p);
 extern int go_next_unit(tap_t * tap);
 extern int go_prev_unit(tap_t * tap);
+extern int rewind_to(tap_t * tap, go_actor_t actor, int shift);
 extern int rewind_right(tap_t * tap, int shift);
 extern int rewind_left(tap_t * tap, int shift);
 
diff -puN tree.c~profile-stat-trace-repacker tree.c
--- reiser4/tree.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/tree.c	2005-02-01 11:51:12.000000000 +0300
@@ -186,6 +186,7 @@
 #include "carry_ops.h"
 #include "tap.h"
 #include "tree.h"
+#include "log.h"
 #include "vfs_ops.h"
 #include "page_cache.h"
 #include "super.h"
@@ -205,8 +206,6 @@ const reiser4_block_nr UBER_TREE_ADDR = 
 
 #define CUT_TREE_MIN_ITERATIONS 64
 
-static int find_child_by_addr(znode * parent, znode * child, coord_t * result);
-
 /* return node plugin of coord->node */
 reiser4_internal node_plugin *
 node_plugin_by_coord(const coord_t * coord)
@@ -297,6 +296,7 @@ insert_with_carry_by_coord(coord_t * coo
 		lowest_level.tracked = lh;
 	}
 
+	ON_STATS(lowest_level.level_no = znode_get_level(coord->node));
 	result = carry(&lowest_level, 0);
 	done_carry_pool(pool);
 
@@ -352,6 +352,7 @@ paste_with_carry(coord_t * coord /* coor
 		lowest_level.tracked = lh;
 	}
 
+	ON_STATS(lowest_level.level_no = znode_get_level(coord->node));
 	result = carry(&lowest_level, 0);
 	done_carry_pool(pool);
 
@@ -387,6 +388,8 @@ insert_by_coord(coord_t * coord	/* coord
 	assert("vs-249", data->length >= 0);
 	assert("nikita-1191", znode_is_write_locked(coord->node));
 
+	write_tree_log(znode_get_tree(coord->node), tree_insert, key, data, coord, flags);
+
 	node = coord->node;
 	coord_clear_iplug(coord);
 	result = zload(node);
@@ -423,6 +426,7 @@ insert_by_coord(coord_t * coord	/* coord
 		   - node plugin agrees with this
 
 		*/
+		reiser4_stat_inc(tree.fast_insert);
 		result = node_plugin_by_node(node)->create_item(coord, key, data, NULL);
 		znode_make_dirty(node);
 	} else {
@@ -478,6 +482,8 @@ insert_into_item(coord_t * coord /* coor
 
 	assert("nikita-1480", iplug == data->iplug);
 
+	write_tree_log(znode_get_tree(coord->node), tree_paste, key, data, coord, flags);
+
 	size_change = space_needed(coord->node, coord, data, 0);
 	if (size_change > (int) znode_free_space(coord->node) &&
 	    (flags & COPI_DONT_SHIFT_LEFT) && (flags & COPI_DONT_SHIFT_RIGHT) && (flags & COPI_DONT_ALLOCATE)) {
@@ -505,6 +511,7 @@ insert_into_item(coord_t * coord /* coor
 	    coord->unit_pos != 0 && nplug->fast_paste != NULL &&
 	    nplug->fast_paste(coord) &&
 	    iplug->b.fast_paste != NULL && iplug->b.fast_paste(coord)) {
+		reiser4_stat_inc(tree.fast_paste);
 		if (size_change > 0)
 			nplug->change_item_size(coord, size_change);
 		/* NOTE-NIKITA: huh? where @key is used? */
@@ -589,6 +596,7 @@ insert_flow(coord_t * coord, lock_handle
 	lowest_level.track_type = CARRY_TRACK_CHANGE;
 	lowest_level.tracked = lh;
 
+	ON_STATS(lowest_level.level_no = znode_get_level(coord->node));
 	result = carry(&lowest_level, 0);
 	done_carry_pool(pool);
 
@@ -805,6 +813,7 @@ check_tree_pointer(const coord_t * point
 			iplug->s.internal.down_link(pointer, NULL, &addr);
 			/* check that cached value is correct */
 			if (disk_addr_eq(&addr, znode_get_block(child))) {
+				reiser4_stat_inc(tree.pos_in_parent_hit);
 				return NS_FOUND;
 			}
 		}
@@ -877,12 +886,14 @@ find_child_ptr(znode * parent /* parent 
 	/* fast path. Try to use cached value. Lock tree to keep
 	   node->pos_in_parent and pos->*_blocknr consistent. */
 	if (child->in_parent.item_pos + 1 != 0) {
+		reiser4_stat_inc(tree.pos_in_parent_set);
 		parent_coord_to_coord(&child->in_parent, result);
 		if (check_tree_pointer(result, child) == NS_FOUND) {
 			RUNLOCK_TREE(tree);
 			return NS_FOUND;
 		}
 
+		reiser4_stat_inc(tree.pos_in_parent_miss);
 		child->in_parent.item_pos = (unsigned short)~0;
 	}
 	RUNLOCK_TREE(tree);
@@ -918,7 +929,7 @@ find_child_ptr(znode * parent /* parent 
    numbers in them with that of @child.
 
 */
-static int
+reiser4_internal int
 find_child_by_addr(znode * parent /* parent znode, passed locked */ ,
 		   znode * child /* child znode, passed locked */ ,
 		   coord_t * result /* where result is stored in */ )
@@ -954,6 +965,18 @@ is_disk_addr_unallocated(const reiser4_b
 	return (*addr & REISER4_BLOCKNR_STATUS_BIT_MASK) == REISER4_UNALLOCATED_STATUS_VALUE;
 }
 
+/* convert unallocated disk address to the memory address
+
+   FIXME: This needs a big comment. */
+reiser4_internal void *
+unallocated_disk_addr_to_ptr(const reiser4_block_nr * addr	/* address to
+								 * convert */ )
+{
+	assert("nikita-1688", addr != NULL);
+	assert("nikita-1689", is_disk_addr_unallocated(addr));
+	return (void *) (long) (*addr << 1);
+}
+
 /* returns true if removing bytes of given range of key [from_key, to_key]
    causes removing of whole item @from */
 static int
@@ -1253,6 +1276,7 @@ cut_node_content(coord_t *from, coord_t 
 	op->u.cut_or_kill.is_cut = 1;
 	op->u.cut_or_kill.u.cut = &cut_data;
 
+	ON_STATS(lowest_level.level_no = znode_get_level(from->node));
 	result = carry(&lowest_level, 0);
 	done_carry_pool(pool);
 
@@ -1334,6 +1358,7 @@ kill_node_content(coord_t * from /* coor
 	op->u.cut_or_kill.is_cut = 0;
 	op->u.cut_or_kill.u.kill = &kdata;
 
+	ON_STATS(lowest_level.level_no = znode_get_level(from->node));
 	result = carry(&lowest_level, 0);
 
 	done_carry_pool(pool);
@@ -1681,6 +1706,7 @@ cut_tree_object(reiser4_tree * tree, con
 	if (smallest_removed_p == NULL)
 		smallest_removed_p = &smallest_removed;
 
+	write_tree_log(tree, tree_cut, from_key, to_key);
 	init_lh(&lock);
 
 	do {
diff -puN tree.h~profile-stat-trace-repacker tree.h
--- reiser4/tree.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/tree.h	2005-02-01 11:51:12.000000000 +0300
@@ -406,28 +406,37 @@ extern int delete_node(znode * node, rei
 extern int check_tree_pointer(const coord_t * pointer, const znode * child);
 extern int find_new_child_ptr(znode * parent, znode * child UNUSED_ARG, znode * left, coord_t * result);
 extern int find_child_ptr(znode * parent, znode * child, coord_t * result);
+extern int find_child_by_addr(znode * parent, znode * child, coord_t * result);
 extern int set_child_delimiting_keys(znode * parent, const coord_t * in_parent, znode *child);
 extern znode *child_znode(const coord_t * in_parent, znode * parent, int incore_p, int setup_dkeys_p);
 
 extern int cbk_cache_init(cbk_cache * cache);
 extern void cbk_cache_done(cbk_cache * cache);
 extern void cbk_cache_invalidate(const znode * node, reiser4_tree * tree);
+extern void cbk_cache_add(const znode * node);
 
+extern const char *bias_name(lookup_bias bias);
 extern char *sprint_address(const reiser4_block_nr * block);
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 extern void print_coord_content(const char *prefix, coord_t * p);
 extern void print_address(const char *prefix, const reiser4_block_nr * block);
 extern void print_tree_rec(const char *prefix, reiser4_tree * tree, __u32 flags);
+extern void print_cbk_slot(const char *prefix, const cbk_cache_slot * slot);
+extern void print_cbk_cache(const char *prefix, const cbk_cache * cache);
 #else
 #define print_coord_content(p, c) noop
 #define print_address(p, b) noop
+#define print_tree_rec(p, f, t) noop
+#define print_cbk_slot(p, s) noop
+#define print_cbk_cache(p, c) noop
 #endif
 
 extern void forget_znode(lock_handle * handle);
 extern int deallocate_znode(znode * node);
 
 extern int is_disk_addr_unallocated(const reiser4_block_nr * addr);
+extern void *unallocated_disk_addr_to_ptr(const reiser4_block_nr * addr);
 
 /* struct used internally to pack all numerous arguments of tree lookup.
     Used to avoid passing a lot of arguments to helper functions. */
@@ -515,6 +524,7 @@ RW_LOCK_FUNCTIONS(dk, reiser4_tree, dk_l
 #endif
 
 /* estimate api. Implementation is in estimate.c */
+reiser4_block_nr estimate_internal_amount(reiser4_block_nr childen, tree_level);
 reiser4_block_nr estimate_one_insert_item(reiser4_tree *);
 reiser4_block_nr estimate_one_insert_into_item(reiser4_tree *);
 reiser4_block_nr estimate_insert_flow(tree_level);
diff -puN tree_walk.c~profile-stat-trace-repacker tree_walk.c
--- reiser4/tree_walk.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/tree_walk.c	2005-02-01 11:51:12.000000000 +0300
@@ -70,6 +70,8 @@ lock_neighbor(
 	assert("umka-237", tree != NULL);
 	assert("umka-301", rw_tree_is_locked(tree));
 
+	reiser4_stat_inc_at_level(znode_get_level(node), znode.lock_neighbor);
+
 	if (flags & GN_TRY_LOCK)
 		req |= ZNODE_LOCK_NONBLOCK;
 	if (flags & GN_SAME_ATOM)
@@ -78,6 +80,8 @@ lock_neighbor(
 	/* get neighbor's address by using of sibling link, quit while loop
 	   (and return) if link is not available. */
 	while (1) {
+		reiser4_stat_inc_at_level(znode_get_level(node),
+					  znode.lock_neighbor_iteration);
 		neighbor = GET_NODE_BY_PTR_OFFSET(node, ptr_offset);
 
 		/* return -E_NO_NEIGHBOR if parent or side pointer is NULL or if
@@ -191,8 +195,7 @@ lock_side_neighbor(lock_handle * result,
 	return ret;
 }
 
-#if REISER4_DEBUG
-
+#if REISER4_DEBUG_SIBLING_LIST
 int check_sibling_list(znode * node)
 {
 	znode *scan;
@@ -227,7 +230,6 @@ int check_sibling_list(znode * node)
 	}
 	return 1;
 }
-
 #endif
 
 /* Znode sibling pointers maintenence. */
@@ -692,6 +694,7 @@ again:
 		znode *child = (h == 0) ? node : path[h - 1].node;
 		znode *parent = path[h].node;
 
+		reiser4_stat_inc_at_level(h + LEAF_LEVEL, sibling_search);
 		ret = zload(parent);
 		if (ret)
 			break;
diff -puN tree_walk.h~profile-stat-trace-repacker tree_walk.h
--- reiser4/tree_walk.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/tree_walk.h	2005-02-01 11:51:12.000000000 +0300
@@ -98,7 +98,7 @@ struct tree_walk_actor {
 };
 extern int tree_walk(const reiser4_key *, int, struct tree_walk_actor *, void *);
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_SIBLING_LIST
 int check_sibling_list(znode * node);
 #else
 #define check_sibling_list(n) (1)
diff -puN txnmgr.c~profile-stat-trace-repacker txnmgr.c
--- reiser4/txnmgr.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/txnmgr.c	2005-02-01 11:51:12.000000000 +0300
@@ -232,6 +232,7 @@ year old --- define all technical terms 
 #include "reiser4.h"
 #include "vfs_ops.h"
 #include "inode.h"
+#include "prof.h"
 #include "flush.h"
 
 #include <asm/atomic.h>
@@ -411,7 +412,7 @@ atom_init(txn_atom * atom)
 
 	assert("umka-173", atom != NULL);
 
-	memset(atom, 0, sizeof (txn_atom));
+	xmemset(atom, 0, sizeof (txn_atom));
 
 	atom->stage = ASTAGE_FREE;
 	atom->start_time = jiffies;
@@ -542,7 +543,7 @@ txn_restart_current(void)
 /* Get the atom belonging to a txnh, which is not locked.  Return txnh locked. Locks atom, if atom
    is not NULL.  This performs the necessary spin_trylock to break the lock-ordering cycle.  May
    return NULL. */
-static txn_atom *
+reiser4_internal txn_atom *
 txnh_get_atom(txn_handle * txnh)
 {
 	txn_atom *atom;
@@ -781,6 +782,7 @@ atom_begin_andlock(txn_atom ** atom_allo
 
 	/* Check if both atom pointers are still NULL... */
 	if (node->atom != NULL || txnh->atom != NULL) {
+		ON_TRACE(TRACE_TXN, "alloc atom race\n");
 		/* NOTE-NIKITA probably it is rather better to free
 		 * atom_alloc here than thread it up to try_capture(). */
 
@@ -788,6 +790,7 @@ atom_begin_andlock(txn_atom ** atom_allo
 		UNLOCK_JNODE(node);
 		spin_unlock_txnmgr(mgr);
 
+		reiser4_stat_inc(txnmgr.restart.atom_begin);
 		return ERR_PTR(-E_REPEAT);
 	}
 
@@ -800,7 +803,7 @@ atom_begin_andlock(txn_atom ** atom_allo
 
 	/* Take the atom and txnmgr lock. No checks for lock ordering, because
 	   @atom is new and inaccessible for others. */
-	spin_lock_atom_no_ord(atom);
+	spin_lock_atom_no_ord(atom, 0, 0);
 
 	atom_list_push_back(&mgr->atoms_list, atom);
 	atom->atom_id = mgr->id_count++;
@@ -814,6 +817,8 @@ atom_begin_andlock(txn_atom ** atom_allo
 
 	atom->stage = ASTAGE_CAPTURE_FUSE;
 
+	ON_TRACE(TRACE_TXN, "begin atom %u\n", atom->atom_id);
+
 	return atom;
 }
 
@@ -848,6 +853,9 @@ atom_free(txn_atom * atom)
 	txn_mgr *mgr = &get_super_private(reiser4_get_current_sb())->tmgr;
 
 	assert("umka-188", atom != NULL);
+
+	ON_TRACE(TRACE_TXN, "free atom %u\n", atom->atom_id);
+
 	assert("jmacd-18", spin_atom_is_locked(atom));
 
 	/* Remove from the txn_mgr's atom list */
@@ -1067,12 +1075,57 @@ static int submit_wb_list (void)
 	dispatch_wb_list(fq->atom, fq);
 	UNLOCK_ATOM(fq->atom);
 
+	/* trace_mark(flush); */
+	write_current_logf(WRITE_IO_LOG, "mark=flush");
+
 	ret = write_fq(fq, NULL, 1);
 	fq_put(fq);
 
 	return ret;
 }
 
+#if 0
+
+/* when during system call inode is "captured" (by reiser4_mark_inode_dirty) - blocks grabbed for stat data update are
+   moved to atom's flush_reserved bucket. On commit time (right before updating stat datas of all captured inodes) those
+   blocks are moved to grabbed. This function is used to calculate number of blocks reserved for stat data update when
+   those blocks get moved back and forwward between buckets of grabbed and flush_reserved blocks */
+static reiser4_block_nr reserved_for_sd_update(struct inode *inode)
+{
+	return inode_file_plugin(inode)->estimate.update(inode);
+}
+
+static void atom_update_stat_data(txn_atom **atom)
+{
+	jnode *j;
+
+	assert("vs-1241", spin_atom_is_locked(*atom));
+	assert("vs-1616", capture_list_empty(&(*atom)->inodes));
+
+	while (!capture_list_empty(&(*atom)->inodes)) {
+		struct inode *inode;
+
+		j = capture_list_front(&((*atom)->inodes));
+
+		inode = inode_by_reiser4_inode(container_of(j, reiser4_inode, inode_jnode));
+
+		/* move blocks grabbed for stat data update back from atom's
+		 * flush_reserved to grabbed */
+		flush_reserved2grabbed(*atom, reserved_for_sd_update(inode));
+
+		capture_list_remove_clean(j);
+		capture_list_push_back(ATOM_CLEAN_LIST(*atom), j);
+		UNLOCK_ATOM(*atom);
+
+		/* FIXME: it is not clear what to do if update sd fails. A warning will be issued (nikita-2221) */
+		reiser4_update_sd(inode);
+		*atom = get_current_atom_locked();
+	}
+
+	assert("vs-1231", capture_list_empty(&((*atom)->inodes)));
+}
+#endif
+
 /* Wait completion of all writes, re-submit atom writeback list if needed. */
 static int current_atom_complete_writes (void)
 {
@@ -1131,6 +1184,12 @@ static int commit_current_atom (long *nr
 	assert("nikita-3184",
 	       get_current_super_private()->delete_sema_owner != current);
 
+	ON_TRACE(TRACE_TXN, "atom %u trying to commit %u: CAPTURE_WAIT\n",
+		 (*atom)->atom_id, current->pid);
+
+	/* call reiser4_update_sd for all atom's inodes */
+	/*atom_update_stat_data(atom);*/
+
 	for (flushiters = 0 ;; ++ flushiters) {
 		ret = flush_current_atom(JNODE_FLUSH_WRITE_BLOCKS | JNODE_FLUSH_COMMIT, nr_submitted, atom);
 		if (ret != -E_REPEAT)
@@ -1157,6 +1216,7 @@ static int commit_current_atom (long *nr
 
 	if (!atom_can_be_committed(*atom)) {
 		UNLOCK_ATOM(*atom);
+		reiser4_stat_inc(txnmgr.restart.cannot_commit);
 		return RETERR(-E_REPEAT);
 	}
 
@@ -1166,6 +1226,9 @@ static int commit_current_atom (long *nr
 	atom_set_stage(*atom, ASTAGE_PRE_COMMIT);
 	ON_DEBUG(((*atom)->committer = current));
 
+	ON_TRACE(TRACE_TXN, "commit atom %u: PRE_COMMIT\n", (*atom)->atom_id);
+	ON_TRACE(TRACE_FLUSH, "everything flushed atom %u: PRE_COMMIT\n", (*atom)->atom_id);
+
 	UNLOCK_ATOM(*atom);
 
 	ret = current_atom_complete_writes();
@@ -1174,6 +1237,9 @@ static int commit_current_atom (long *nr
 
 	assert ("zam-906", capture_list_empty(ATOM_WB_LIST(*atom)));
 
+	ON_TRACE(TRACE_FLUSH, "everything written back atom %u\n",
+		 (*atom)->atom_id);
+
 	/* isolate critical code path which should be executed by only one
 	 * thread using tmgr semaphore */
 	down(&sbinfo->tmgr.commit_semaphore);
@@ -1211,6 +1277,8 @@ static int commit_current_atom (long *nr
 	BUG_ON((*atom)->capture_count != 0);
 	assert("jmacd-1071", spin_atom_is_locked(*atom));
 
+	ON_TRACE(TRACE_TXN, "commit atom finished %u refcount %d\n",
+		 (*atom)->atom_id, atomic_read(&(*atom)->refcount));
 	return ret;
 }
 
@@ -1243,6 +1311,23 @@ static int force_commit_atom_nolock (txn
 	return 0;
 }
 
+/* externally visible function which takes all necessary locks and commits
+ * current atom */
+reiser4_internal int txnmgr_force_commit_current_atom (void)
+{
+	txn_handle * txnh = get_current_context()->trans;
+	txn_atom * atom;
+
+	atom = txnh_get_atom(txnh);
+
+	if (atom == NULL) {
+		UNLOCK_TXNH(txnh);
+		return 0;
+	}
+
+	return force_commit_atom_nolock(txnh);
+}
+
 /* Called to force commit of any outstanding atoms.  @commit_all_atoms controls
  * should we commit all atoms including new ones which are created after this
  * functions is called. */
@@ -1565,8 +1650,9 @@ reiser4_internal void atom_wait_event(tx
 	atomic_inc(&atom->refcount);
 	UNLOCK_ATOM(atom);
 
+	/* assert("nikita-3056", commit_check_locks()); */
 	prepare_to_sleep(_wlinks._lock_stack);
-	go_to_sleep(_wlinks._lock_stack);
+	go_to_sleep(_wlinks._lock_stack, ADD_TO_SLEPT_IN_WAIT_EVENT);
 
 	LOCK_ATOM (atom);
 	fwaitfor_list_remove(&_wlinks);
@@ -1643,6 +1729,11 @@ try_commit_txnh(commit_data *cd)
 	if (cd->atom->stage == ASTAGE_DONE)
 		return 0;
 
+	ON_TRACE(TRACE_TXN,
+		 "commit_txnh: atom %u failed %u; txnh_count %u; should_commit %u\n",
+		 cd->atom->atom_id, cd->failed, cd->atom->txnh_count,
+		 atom_should_commit(cd->atom));
+
 	if (cd->failed)
 		return 0;
 
@@ -1693,6 +1784,7 @@ try_commit_txnh(commit_data *cd)
 				cd->atom->nr_waiters++;
 				cd->wait = 1;
 				atom_wait_event(cd->atom);
+				reiser4_stat_inc(txnmgr.restart.should_wait);
 				result = RETERR(-E_REPEAT);
 			} else {
 				result = 0;
@@ -1710,6 +1802,7 @@ try_commit_txnh(commit_data *cd)
 			if (result == 0) {
 				UNLOCK_ATOM(cd->atom);
 				cd->preflush = 0;
+				reiser4_stat_inc(txnmgr.restart.flush);
 				result = RETERR(-E_REPEAT);
 			} else	/* Atoms wasn't flushed
 				 * completely. Rinse. Repeat. */
@@ -1746,7 +1839,7 @@ commit_txnh(txn_handle * txnh)
 	commit_data cd;
 	assert("umka-192", txnh != NULL);
 
-	memset(&cd, 0, sizeof cd);
+	xmemset(&cd, 0, sizeof cd);
 	cd.txnh = txnh;
 	cd.preflush = 10;
 
@@ -1763,6 +1856,9 @@ commit_txnh(txn_handle * txnh)
 
 	txnh_list_remove(txnh);
 
+	ON_TRACE(TRACE_TXN, "close txnh atom %u refcount %d\n",
+		 cd.atom->atom_id, atomic_read(&cd.atom->refcount));
+
 	UNLOCK_TXNH(txnh);
 	atom_dec_and_unlock(cd.atom);
 	/* if we don't want to do a commit (TXNH_DONT_COMMIT is set, probably
@@ -1840,6 +1936,20 @@ try_capture_block(txn_handle * txnh, jno
 
 	txnh_atom = txnh->atom;
 
+	if (REISER4_STATS) {
+		if (block_atom != NULL && txnh_atom != NULL)
+			if (block_atom == txnh_atom)
+				reiser4_stat_inc(txnmgr.capture_equal);
+			else
+				reiser4_stat_inc(txnmgr.capture_both);
+		else if (block_atom != NULL && txnh_atom == NULL)
+			reiser4_stat_inc(txnmgr.capture_block);
+		else if (block_atom == NULL && txnh_atom != NULL)
+			reiser4_stat_inc(txnmgr.capture_txnh);
+		else
+			reiser4_stat_inc(txnmgr.capture_none);
+	}
+
 	if (txnh_atom != NULL && block_atom == txnh_atom) {
 		UNLOCK_TXNH(txnh);
 		return 0;
@@ -1989,7 +2099,7 @@ try_capture_block(txn_handle * txnh, jno
 	return 0;
 }
 
-static txn_capture
+reiser4_internal txn_capture
 build_capture_mode(jnode * node, znode_lock_mode lock_mode, txn_capture flags)
 {
 	txn_capture cap_mode;
@@ -2230,6 +2340,8 @@ fuse_not_fused_lock_owners(txn_handle * 
 		   inside capture_fuse_into()
 		*/
 		capture_fuse_into(atomf, atomh);
+
+		reiser4_stat_inc(txnmgr.restart.fuse_lock_owners_fused);
 		return RETERR(-E_REPEAT);
 	}
 
@@ -2240,6 +2352,7 @@ fail:
 		UNLOCK_TXNH(txnh);
 		RUNLOCK_ZLOCK(&node->lock);
 		spin_unlock_znode(node);
+		reiser4_stat_inc(txnmgr.restart.fuse_lock_owners);
 		return RETERR(-E_REPEAT);
 	}
 
@@ -2395,6 +2508,9 @@ capture_assign_txnh_nolock(txn_atom * at
 	assert("nikita-3540", atom_isopen(atom));
 
 	atomic_inc(&atom->refcount);
+
+	ON_TRACE(TRACE_TXN, "assign txnh atom %u refcount %d\n", atom->atom_id, atomic_read(&atom->refcount));
+
 	txnh->atom = atom;
 	txnh_list_push_back(&atom->txnh_list, txnh);
 	atom->txnh_count += 1;
@@ -2424,6 +2540,8 @@ capture_assign_block_nolock(txn_atom * a
 	ON_DEBUG(count_jnode(atom, node, NOT_CAPTURED, CLEAN_LIST, 1));
 
 	LOCK_CNT_INC(t_refs);
+
+	ON_TRACE(TRACE_TXN, "capture %p for atom %u (captured %u)\n", node, atom->atom_id, atom->capture_count);
 }
 
 #if REISER4_COPY_ON_CAPTURE
@@ -2556,7 +2674,7 @@ znode_make_dirty(znode * z)
 		/* assert("nikita-3292",
 		       !PageWriteback(page) || ZF_ISSET(z, JNODE_WRITEBACK)); */
 		page_cache_get(page);
-
+		ON_DEBUG_MODIFY(znode_set_checksum(ZJNODE(z), 1));
 		/* jnode lock is not needed for the rest of
 		 * znode_set_dirty(). */
 		UNLOCK_JNODE(node);
@@ -2864,6 +2982,7 @@ trylock_throttle(txn_atom *atom, txn_han
 
 	if (unlikely(trylock_wait(atom, txnh, node) != 0)) {
 		atom_dec_and_unlock(atom);
+		reiser4_stat_inc(txnmgr.restart.trylock_throttle);
 		return RETERR(-E_REPEAT);
 	} else
 		return 0;
@@ -2889,6 +3008,7 @@ capture_assign_block(txn_handle * txnh, 
 	if (result != 0) {
 		/* this avoid busy loop, but we return -E_REPEAT anyway to
 		 * simplify things. */
+		reiser4_stat_inc(txnmgr.restart.assign_block);
 		return result;
 	} else {
 		assert("jmacd-19", atom_isopen(atom));
@@ -2964,6 +3084,7 @@ capture_assign_txnh(jnode * node, txn_ha
 			UNLOCK_TXNH(txnh);
 			UNLOCK_JNODE(node);
 			atom_dec_and_unlock(atom);
+			reiser4_stat_inc(txnmgr.restart.assign_txnh);
 			return RETERR(-E_REPEAT);
 		} else {
 			/* atom still has a jnode on its list (node->atom ==
@@ -3139,6 +3260,9 @@ capture_fuse_wait(jnode * node, txn_hand
 			UNLOCK_ATOM(atomh);
 		}
 
+		ON_TRACE(TRACE_TXN, "thread %u nonblocking on atom %u\n", current->pid, atomf->atom_id);
+
+		reiser4_stat_inc(txnmgr.restart.fuse_wait_nonblock);
 		return RETERR(-E_BLOCK);
 	}
 
@@ -3157,13 +3281,22 @@ capture_fuse_wait(jnode * node, txn_hand
 		UNLOCK_ATOM(atomh);
 	}
 
+	ON_TRACE(TRACE_TXN, "thread %u waitfor %u waiting %u\n", current->pid,
+		 atomf->atom_id, atomh ? atomh->atom_id : 0);
+
 	/* Go to sleep. */
 	UNLOCK_TXNH(txnh);
 
 	ret = prepare_to_sleep(wlinks._lock_stack);
-	if (ret == 0) {
-		go_to_sleep(wlinks._lock_stack);
+	if (ret != 0) {
+		ON_TRACE(TRACE_TXN, "thread %u deadlock blocking on atom %u\n", current->pid, atomf->atom_id);
+	} else {
+		go_to_sleep(wlinks._lock_stack, ADD_TO_SLEPT_IN_WAIT_ATOM);
+
+		reiser4_stat_inc(txnmgr.restart.fuse_wait_slept);
 		ret = RETERR(-E_REPEAT);
+		ON_TRACE(TRACE_TXN, "thread %u wakeup %u waiting %u\n",
+			 current->pid, atomf->atom_id, atomh ? atomh->atom_id : 0);
 	}
 
 	/* Remove from the waitfor list. */
@@ -3245,6 +3378,7 @@ capture_init_fusion_locked(jnode * node,
 	}
 
 	/* Atoms are unlocked in capture_fuse_into.  No locks held. */
+	reiser4_stat_inc(txnmgr.restart.init_fusion_fused);
 	return RETERR(-E_REPEAT);
 }
 
@@ -3260,12 +3394,15 @@ static int
 capture_init_fusion(jnode * node, txn_handle * txnh, txn_capture mode, int can_coc)
 {
 	/* Have to perform two trylocks here. */
-	if (likely(spin_trylock_atom(node->atom))) {
+	if (likely(spin_trylock_atom(node->atom)))
 		if (likely(spin_trylock_atom(txnh->atom)))
 			return capture_init_fusion_locked(node, txnh, mode, can_coc);
 		else {
 			UNLOCK_ATOM(node->atom);
+			reiser4_stat_inc(txnmgr.restart.init_fusion_atomh);
 		}
+	else {
+		reiser4_stat_inc(txnmgr.restart.init_fusion_atomf);
 	}
 
 	UNLOCK_JNODE(node);
@@ -3349,6 +3486,8 @@ capture_fuse_into(txn_atom * small, txn_
 	assert("jmacd-201", atom_isopen(small));
 	assert("jmacd-202", atom_isopen(large));
 
+	ON_TRACE(TRACE_TXN, "fuse atom %u into %u\n", small->atom_id, large->atom_id);
+
 	/* Splice and update the per-level dirty jnode lists */
 	for (level = 0; level < REAL_MAX_ZTREE_HEIGHT + 1; level += 1) {
 		zcount += capture_fuse_jnode_lists(large, ATOM_DIRTY_LIST(large, level), ATOM_DIRTY_LIST(small, level));
@@ -4027,6 +4166,8 @@ capture_copy(jnode * node, txn_handle * 
 	reiser4_stat_inc(coc.forbidden);
 	return capture_fuse_wait(node, txnh, atomf, atomh, mode);
 #else
+	ON_TRACE(TRACE_TXN, "capture_copy: fuse wait\n");
+
 	return capture_fuse_wait(node, txnh, atomf, atomh, mode);
 
 #endif
@@ -4055,6 +4196,10 @@ reiser4_internal void uncapture_block(jn
 	assert("jmacd-1023", atom_is_protected(atom));
 #endif
 
+	/*ON_TRACE (TRACE_TXN, "un-capture %p from atom %u (captured %u)\n",
+	 * node, atom->atom_id, atom->capture_count); */
+
+ 	ON_DEBUG_MODIFY(znode_set_checksum(node, 1));
 	JF_CLR(node, JNODE_DIRTY);
 	JF_CLR(node, JNODE_RELOC);
 	JF_CLR(node, JNODE_OVRWR);
@@ -4100,6 +4245,33 @@ insert_into_atom_ovrwr_list(txn_atom * a
 	ON_DEBUG(count_jnode(atom, node, NODE_LIST(node), OVRWR_LIST, 1));
 }
 
+/* return 1 if two dirty jnodes belong to one atom, 0 - otherwise */
+reiser4_internal int
+jnodes_of_one_atom(jnode * j1, jnode * j2)
+{
+	int ret = 0;
+	int finish = 0;
+
+	assert("zam-9003", j1 != j2);
+	/*assert ("zam-9004", jnode_check_dirty (j1)); */
+	assert("zam-9005", jnode_check_dirty(j2));
+
+	do {
+		LOCK_JNODE(j1);
+		assert("zam-9001", j1->atom != NULL);
+		if (spin_trylock_jnode(j2)) {
+			assert("zam-9002", j2->atom != NULL);
+			ret = (j2->atom == j1->atom);
+			finish = 1;
+
+			UNLOCK_JNODE(j2);
+		}
+		UNLOCK_JNODE(j1);
+	} while (!finish);
+
+	return ret;
+}
+
 /* when atom becomes that big, commit it as soon as possible. This was found
  * to be most effective by testing. */
 reiser4_internal unsigned int
@@ -4108,7 +4280,8 @@ txnmgr_get_max_atom_size(struct super_bl
 	return totalram_pages / 4;
 }
 
-#if REISER4_DEBUG
+
+#if REISER4_DEBUG_OUTPUT
 
 reiser4_internal void
 info_atom(const char *prefix, const txn_atom * atom)
@@ -4124,6 +4297,36 @@ info_atom(const char *prefix, const txn_
 	       atom->capture_count, atom->stage, atom->start_time, atom->flushed);
 }
 
+
+reiser4_internal void
+print_atom(const char *prefix, txn_atom * atom)
+{
+	jnode *pos_in_atom;
+	char list[32];
+	int level;
+
+	assert("umka-229", atom != NULL);
+
+	info_atom(prefix, atom);
+
+	for (level = 0; level < REAL_MAX_ZTREE_HEIGHT + 1; level += 1) {
+
+		sprintf(list, "capture level %d", level);
+
+		for (pos_in_atom = capture_list_front(ATOM_DIRTY_LIST(atom, level));
+		     !capture_list_end(ATOM_DIRTY_LIST(atom, level), pos_in_atom);
+		     pos_in_atom = capture_list_next(pos_in_atom)) {
+
+			info_jnode(list, pos_in_atom);
+			printk("\n");
+		}
+	}
+
+	for_all_type_safe_list(capture, ATOM_CLEAN_LIST(atom), pos_in_atom) {
+		info_jnode("clean", pos_in_atom);
+		printk("\n");
+	}
+}
 #endif
 
 static int count_deleted_blocks_actor (
diff -puN txnmgr.h~profile-stat-trace-repacker txnmgr.h
--- reiser4/txnmgr.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/txnmgr.h	2005-02-01 11:51:12.000000000 +0300
@@ -460,6 +460,7 @@ extern long txn_end(reiser4_context * co
 extern void txn_restart(reiser4_context * context);
 extern void txn_restart_current(void);
 
+extern int txnmgr_force_commit_current_atom(void);
 extern int txnmgr_force_commit_all(struct super_block *, int);
 extern int current_atom_should_commit(void);
 
@@ -475,6 +476,10 @@ extern void atom_set_stage(txn_atom *ato
 extern int same_slum_check(jnode * base, jnode * check, int alloc_check, int alloc_value);
 extern void atom_dec_and_unlock(txn_atom * atom);
 
+extern txn_capture build_capture_mode(jnode           * node,
+				      znode_lock_mode   lock_mode,
+				      txn_capture       flags);
+
 extern int try_capture(jnode * node, znode_lock_mode mode, txn_capture flags, int can_coc);
 extern int try_capture_page_to_invalidate(struct page *pg);
 
@@ -485,6 +490,7 @@ extern void uncapture_jnode(jnode *);
 extern int capture_inode(struct inode *);
 extern int uncapture_inode(struct inode *);
 
+extern txn_atom *txnh_get_atom(txn_handle * txnh);
 extern txn_atom *get_current_atom_locked_nocheck(void);
 
 #define atom_is_protected(atom) (spin_atom_is_locked(atom) || (atom)->stage >= ASTAGE_PRE_COMMIT)
@@ -509,6 +515,8 @@ extern void atom_send_event(txn_atom *);
 extern void insert_into_atom_ovrwr_list(txn_atom * atom, jnode * node);
 extern int capture_super_block(struct super_block *s);
 
+extern int jnodes_of_one_atom(jnode *, jnode *);
+
 /* See the comment on the function blocknrset.c:blocknr_set_add for the
    calling convention of these three routines. */
 extern void blocknr_set_init(blocknr_set * bset);
@@ -597,6 +605,7 @@ struct flush_queue {
 };
 
 extern int fq_by_atom(txn_atom *, flush_queue_t **);
+extern int fq_by_atom_gfp(txn_atom *, flush_queue_t **, int);
 extern int fq_by_jnode(jnode *, flush_queue_t **);
 extern int fq_by_jnode_gfp(jnode *, flush_queue_t **, int);
 extern void fq_put_nolock(flush_queue_t *);
@@ -628,10 +637,13 @@ void protected_jnodes_init(protected_jno
 void protected_jnodes_done(protected_jnodes *list);
 void invalidate_list(capture_list_head * head);
 
-#if REISER4_DEBUG
+/* Debugging */
+#if REISER4_DEBUG_OUTPUT
+void print_atom(const char *prefix, txn_atom * atom);
 void info_atom(const char *prefix, const txn_atom * atom);
 #else
-#define info_atom(p,a) noop
+#define       print_atom(p,a) noop
+#define       info_atom(p,a) noop
 #endif
 
 # endif				/* __REISER4_TXNMGR_H__ */
diff -puN type_safe_hash.h~profile-stat-trace-repacker type_safe_hash.h
--- reiser4/type_safe_hash.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/type_safe_hash.h	2005-02-01 11:51:12.000000000 +0300
@@ -8,6 +8,7 @@
 #define __REISER4_TYPE_SAFE_HASH_H__
 
 #include "debug.h"
+#include "stats.h"
 
 #include <asm/errno.h>
 /* Step 1: Use TYPE_SAFE_HASH_DECLARE() to define the TABLE and LINK objects
@@ -22,6 +23,7 @@ struct PREFIX##_hash_table_             
 {                                                                                             \
   ITEM_TYPE  **_table;                                                                        \
   __u32        _buckets;                                                                      \
+  tshash_stat *_stats;                                                                        \
 };                                                                                            \
                                                                                               \
 struct PREFIX##_hash_link_                                                                    \
@@ -85,15 +87,17 @@ PREFIX##_check_hash (PREFIX##_hash_table
 											\
 static __inline__ int									\
 PREFIX##_hash_init (PREFIX##_hash_table *hash,						\
-		    __u32                buckets)					\
+		    __u32                buckets,					\
+		    tshash_stat         *stats) 					\
 {											\
   hash->_table   = (ITEM_TYPE**) KMALLOC (sizeof (ITEM_TYPE*) * buckets);		\
   hash->_buckets = buckets;								\
+  hash->_stats = stats; 								\
   if (hash->_table == NULL)								\
     {											\
       return RETERR(-ENOMEM);								\
     }											\
-  memset (hash->_table, 0, sizeof (ITEM_TYPE*) * buckets);				\
+  xmemset (hash->_table, 0, sizeof (ITEM_TYPE*) * buckets);				\
   ON_DEBUG(printk(#PREFIX "_hash_table: %i buckets\n", buckets));			\
   return 0;										\
 }											\
@@ -132,11 +136,13 @@ PREFIX##_hash_find_index (PREFIX##_hash_
   ITEM_TYPE *item;									\
 											\
   PREFIX##_check_hash(hash, hash_index);						\
+  TSHASH_LOOKUP(hash->_stats);								\
 											\
   for (item  = hash->_table[hash_index];						\
        item != NULL;									\
        item  = item->LINK_NAME._next)							\
     {											\
+      TSHASH_SCANNED(hash->_stats);							\
       prefetch(item->LINK_NAME._next);							\
       prefetch(item->LINK_NAME._next + offsetof(ITEM_TYPE, KEY_NAME));			\
       if (EQ_FUNC (& item->KEY_NAME, find_key))						\
@@ -156,8 +162,10 @@ PREFIX##_hash_find_index_lru (PREFIX##_h
   ITEM_TYPE ** item = &hash->_table[hash_index];                                        \
 											\
   PREFIX##_check_hash(hash, hash_index);						\
+  TSHASH_LOOKUP(hash->_stats);								\
                                                                                         \
   while (*item != NULL) {                                                               \
+    TSHASH_SCANNED(hash->_stats);							\
     prefetch(&(*item)->LINK_NAME._next);						\
     if (EQ_FUNC (&(*item)->KEY_NAME, find_key)) {                                       \
       ITEM_TYPE *found; 								\
@@ -181,8 +189,10 @@ PREFIX##_hash_remove_index (PREFIX##_has
   ITEM_TYPE ** hash_item_p = &hash->_table[hash_index];                                 \
 											\
   PREFIX##_check_hash(hash, hash_index);						\
+  TSHASH_REMOVE(hash->_stats);								\
                                                                                         \
   while (*hash_item_p != NULL) {                                                        \
+    TSHASH_SCANNED(hash->_stats);							\
     prefetch(&(*hash_item_p)->LINK_NAME._next);						\
     if (*hash_item_p == del_item) {                                                     \
       *hash_item_p = (*hash_item_p)->LINK_NAME._next;                                   \
@@ -199,6 +209,7 @@ PREFIX##_hash_insert_index (PREFIX##_has
 			    ITEM_TYPE           *ins_item)				\
 {											\
   PREFIX##_check_hash(hash, hash_index);						\
+  TSHASH_INSERT(hash->_stats);								\
 											\
   ins_item->LINK_NAME._next = hash->_table[hash_index];					\
   hash->_table[hash_index]  = ins_item;							\
@@ -210,6 +221,7 @@ PREFIX##_hash_insert_index_rcu (PREFIX##
 			        ITEM_TYPE           *ins_item)				\
 {											\
   PREFIX##_check_hash(hash, hash_index);						\
+  TSHASH_INSERT(hash->_stats);								\
 											\
   ins_item->LINK_NAME._next = hash->_table[hash_index];					\
   smp_wmb();    									\
diff -puN vfs_ops.c~profile-stat-trace-repacker vfs_ops.c
--- reiser4/vfs_ops.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/vfs_ops.c	2005-02-01 11:51:12.000000000 +0300
@@ -21,14 +21,18 @@
 #include "znode.h"
 #include "block_alloc.h"
 #include "tree.h"
+#include "log.h"
 #include "vfs_ops.h"
 #include "inode.h"
 #include "page_cache.h"
 #include "ktxnmgrd.h"
 #include "super.h"
 #include "reiser4.h"
+#include "kattr.h"
 #include "entd.h"
 #include "emergency_flush.h"
+#include "prof.h"
+#include "repacker.h"
 #include "init_super.h"
 #include "status_flags.h"
 #include "flush.h"
@@ -87,6 +91,7 @@ reiser4_statfs(struct super_block *super
 	assert("nikita-409", statfs != NULL);
 
 	init_context(&ctx, super);
+	reiser4_stat_inc(vfs_calls.statfs);
 
 	statfs->f_type = statfs_type(super);
 	statfs->f_bsize = super->s_blocksize;
@@ -270,11 +275,12 @@ reiser4_get_dentry_fsdata(struct dentry 
 	assert("nikita-1365", dentry != NULL);
 
 	if (dentry->d_fsdata == NULL) {
+		reiser4_stat_inc(vfs_calls.private_data_alloc);
 		dentry->d_fsdata = kmem_cache_alloc(dentry_fsdata_slab,
 						    GFP_KERNEL);
 		if (dentry->d_fsdata == NULL)
 			return ERR_PTR(RETERR(-ENOMEM));
-		memset(dentry->d_fsdata, 0, sizeof (reiser4_dentry_fsdata));
+		xmemset(dentry->d_fsdata, 0, sizeof (reiser4_dentry_fsdata));
 	}
 	return dentry->d_fsdata;
 }
@@ -332,7 +338,7 @@ create_fsdata(struct file *file, int gfp
 
 	fsdata = kmem_cache_alloc(file_fsdata_slab, gfp);
 	if (fsdata != NULL) {
-		memset(fsdata, 0, sizeof *fsdata);
+		xmemset(fsdata, 0, sizeof *fsdata);
 		fsdata->ra1.max_window_size = VM_MAX_READAHEAD * 1024;
 		fsdata->back = file;
 		readdir_list_clean(fsdata);
@@ -352,6 +358,7 @@ reiser4_get_file_fsdata(struct file *f	/
 		reiser4_file_fsdata *fsdata;
 		struct inode *inode;
 
+		reiser4_stat_inc(vfs_calls.private_data_alloc);
 		fsdata = create_fsdata(f, GFP_KERNEL);
 		if (fsdata == NULL)
 			return ERR_PTR(RETERR(-ENOMEM));
@@ -467,6 +474,7 @@ reiser4_alloc_inode(struct super_block *
 	reiser4_inode_object *obj;
 
 	assert("nikita-1696", super != NULL);
+	reiser4_stat_inc_at(super, vfs_calls.alloc_inode);
 	obj = kmem_cache_alloc(inode_cache, SLAB_KERNEL);
 	if (obj != NULL) {
 		reiser4_inode *info;
@@ -500,6 +508,8 @@ reiser4_destroy_inode(struct inode *inod
 {
 	reiser4_inode *info;
 
+	reiser4_stat_inc_at(inode->i_sb, vfs_calls.destroy_inode);
+
 	info = reiser4_inode_data(inode);
 
 	assert("vs-1220", inode_has_no_jnodes(info));
@@ -642,6 +652,7 @@ reiser4_delete_inode(struct inode *objec
 	reiser4_context ctx;
 
 	init_context(&ctx, object->i_sb);
+	reiser4_stat_inc(vfs_calls.delete_inode);
 	if (is_inode_loaded(object)) {
 		file_plugin *fplug;
 
@@ -1041,6 +1052,16 @@ do {						\
 		}
 	});
 
+#if REISER4_LOG
+	PUSH_OPT({
+		.name = "log_file",
+		.type = OPT_STRING,
+		.u = {
+			.string = &log_file_name
+		}
+	});
+#endif
+
 	sbinfo->tmgr.atom_max_size = txnmgr_get_max_atom_size(s);
 	sbinfo->tmgr.atom_max_age = REISER4_ATOM_MAX_AGE / HZ;
 	sbinfo->tmgr.atom_max_flushers = ATOM_MAX_FLUSHERS;
@@ -1084,6 +1105,12 @@ do {						\
 		warning("nikita-2497", "optimal_io_size is too small");
 		return RETERR(-EINVAL);
 	}
+#if REISER4_LOG
+	if (log_file_name != NULL)
+		result = open_log_file(s, log_file_name, REISER4_TRACE_BUF_SIZE, &sbinfo->log_file);
+	else
+		sbinfo->log_file.type = log_to_bucket;
+#endif
 
 	/* disable single-threaded flush as it leads to deadlock */
 	sbinfo->fs_flags |= (1 << REISER4_MTFLUSH);
@@ -1108,6 +1135,79 @@ reiser4_show_options(struct seq_file *m,
 	return 0;
 }
 
+/*
+ * Lock profiling code.
+ *
+ * see spin_macros.h and spinprof.[ch]
+ *
+ */
+
+/* defined profiling regions for spin lock types */
+DEFINE_SPIN_PROFREGIONS(epoch);
+DEFINE_SPIN_PROFREGIONS(jnode);
+DEFINE_SPIN_PROFREGIONS(jload);
+DEFINE_SPIN_PROFREGIONS(stack);
+DEFINE_SPIN_PROFREGIONS(super);
+DEFINE_SPIN_PROFREGIONS(atom);
+DEFINE_SPIN_PROFREGIONS(txnh);
+DEFINE_SPIN_PROFREGIONS(txnmgr);
+DEFINE_SPIN_PROFREGIONS(ktxnmgrd);
+DEFINE_SPIN_PROFREGIONS(inode_object);
+DEFINE_SPIN_PROFREGIONS(fq);
+DEFINE_SPIN_PROFREGIONS(super_eflush);
+
+/* define profiling regions for read-write locks */
+DEFINE_RW_PROFREGIONS(zlock);
+DEFINE_RW_PROFREGIONS(dk);
+DEFINE_RW_PROFREGIONS(tree);
+DEFINE_RW_PROFREGIONS(cbk_cache);
+
+/* register profiling regions defined above */
+static int register_profregions(void)
+{
+	register_super_eflush_profregion();
+	register_epoch_profregion();
+	register_jnode_profregion();
+	register_jload_profregion();
+	register_stack_profregion();
+	register_super_profregion();
+	register_atom_profregion();
+	register_txnh_profregion();
+	register_txnmgr_profregion();
+	register_ktxnmgrd_profregion();
+	register_inode_object_profregion();
+	register_fq_profregion();
+
+	register_zlock_profregion();
+	register_cbk_cache_profregion();
+	register_dk_profregion();
+	register_tree_profregion();
+
+	return 0;
+}
+
+/* unregister profiling regions defined above */
+static void unregister_profregions(void)
+{
+	unregister_super_eflush_profregion();
+	unregister_epoch_profregion();
+	unregister_jload_profregion();
+	unregister_jnode_profregion();
+	unregister_stack_profregion();
+	unregister_super_profregion();
+	unregister_atom_profregion();
+	unregister_txnh_profregion();
+	unregister_txnmgr_profregion();
+	unregister_ktxnmgrd_profregion();
+	unregister_inode_object_profregion();
+	unregister_fq_profregion();
+
+	unregister_zlock_profregion();
+	unregister_cbk_cache_profregion();
+	unregister_dk_profregion();
+	unregister_tree_profregion();
+}
+
 /* ->write_super() method. Called by sync(2). */
 static void
 reiser4_write_super(struct super_block *s)
@@ -1118,6 +1218,7 @@ reiser4_write_super(struct super_block *
 	assert("vs-1700", !rofs_super(s));
 
 	init_context(&ctx, s);
+	reiser4_stat_inc(vfs_calls.write_super);
 
 	ret = capture_super_block(s);
 	if (ret != 0)
@@ -1143,7 +1244,11 @@ reiser4_put_super(struct super_block *s)
 	assert("vs-1699", sbinfo);
 
 	init_context(&context, s);
+#if defined(REISER4_REPACKER)
+	done_reiser4_repacker(s);
+#endif /* REISER4_REPACKER */
 	stop_ktxnmgrd(&sbinfo->tmgr);
+	reiser4_sysfs_done(s);
 
 	/* have disk format plugin to free its resources */
 	if (get_super_private(s)->df_plug->release)
@@ -1166,6 +1271,8 @@ reiser4_put_super(struct super_block *s)
 	/* no assertions below this line */
 	reiser4_exit_context(&context);
 
+	reiser4_stat_done(&sbinfo->stats);
+
 	kfree(sbinfo);
 	s->s_fs_info = NULL;
 }
@@ -1212,6 +1319,9 @@ typedef enum {
 	INIT_FAKES,              /* fake inode initialized */
 	INIT_JNODES,             /* jnode slab initialized */
 	INIT_EFLUSH,             /* emergency flush initialized */
+	INIT_SPINPROF,           /* spin lock profiling initialized */
+	INIT_SYSFS,              /* sysfs exports initialized */
+	INIT_LNODES,             /* lnodes initialized */
 	INIT_FQS,                /* flush queues initialized */
 	INIT_DENTRY_FSDATA,      /* dentry_fsdata slab initialized */
 	INIT_FILE_FSDATA,        /* file_fsdata slab initialized */
@@ -1240,6 +1350,9 @@ shutdown_reiser4(void)
 	DONE_IF(INIT_FILE_FSDATA, done_file_fsdata());
 	DONE_IF(INIT_DENTRY_FSDATA, done_dentry_fsdata());
 	DONE_IF(INIT_FQS, done_fqs());
+	DONE_IF(INIT_LNODES, lnodes_done());
+	DONE_IF(INIT_SYSFS, reiser4_sysfs_done_once());
+	DONE_IF(INIT_SPINPROF, unregister_profregions());
 	DONE_IF(INIT_EFLUSH, eflush_done());
 	DONE_IF(INIT_JNODES, jnode_done_static());
 	DONE_IF(INIT_FAKES,;);
@@ -1286,12 +1399,17 @@ init_reiser4(void)
 	CHECK_INIT_RESULT(init_fakes());
 	CHECK_INIT_RESULT(jnode_init_static());
 	CHECK_INIT_RESULT(eflush_init());
+	CHECK_INIT_RESULT(register_profregions());
+	CHECK_INIT_RESULT(reiser4_sysfs_init_once());
+	CHECK_INIT_RESULT(lnodes_init());
 	CHECK_INIT_RESULT(init_fqs());
 	CHECK_INIT_RESULT(init_dentry_fsdata());
 	CHECK_INIT_RESULT(init_file_fsdata());
 	CHECK_INIT_RESULT(d_cursor_init());
 	CHECK_INIT_RESULT(register_filesystem(&reiser4_fs_type));
 
+	calibrate_prof();
+
 	assert("nikita-2515", init_stage == INIT_FS_REGISTERED);
 	return 0;
 #undef CHECK_INIT_RESULT
diff -puN wander.c~profile-stat-trace-repacker wander.c
--- reiser4/wander.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/wander.c	2005-02-01 11:51:12.000000000 +0300
@@ -212,7 +212,7 @@ struct commit_handle {
 static void
 init_commit_handle(struct commit_handle *ch, txn_atom * atom)
 {
-	memset(ch, 0, sizeof (struct commit_handle));
+	xmemset(ch, 0, sizeof (struct commit_handle));
 	capture_list_init(&ch->tx_list);
 
 	ch->atom = atom;
@@ -306,8 +306,8 @@ format_tx_head(struct commit_handle *ch)
 	assert("zam-460", header != NULL);
 	assert("zam-462", ch->super->s_blocksize >= sizeof (struct tx_header));
 
-	memset(jdata(tx_head), 0, (size_t) ch->super->s_blocksize);
-	memcpy(jdata(tx_head), TX_HEADER_MAGIC, TX_HEADER_MAGIC_SIZE);
+	xmemset(jdata(tx_head), 0, (size_t) ch->super->s_blocksize);
+	xmemcpy(jdata(tx_head), TX_HEADER_MAGIC, TX_HEADER_MAGIC_SIZE);
 
 	cputod32((__u32) ch->tx_size, &header->total);
 	cputod64(get_super_private(ch->super)->last_committed_tx, &header->prev_tx);
@@ -336,9 +336,10 @@ format_wander_record(struct commit_handl
 	assert("zam-465", LRH != NULL);
 	assert("zam-463", ch->super->s_blocksize > sizeof (struct wander_record_header));
 
-	memset(jdata(node), 0, (size_t) ch->super->s_blocksize);
-	memcpy(jdata(node), WANDER_RECORD_MAGIC, WANDER_RECORD_MAGIC_SIZE);
+	xmemset(jdata(node), 0, (size_t) ch->super->s_blocksize);
+	xmemcpy(jdata(node), WANDER_RECORD_MAGIC, WANDER_RECORD_MAGIC_SIZE);
 
+//      cputod64((__u64)reiser4_trans_id(super), &h->id);
 	cputod32((__u32) ch->tx_size, &LRH->total);
 	cputod32((__u32) serial, &LRH->serial);
 	cputod64((__u64) * jnode_get_block(next), &LRH->next_block);
@@ -1078,6 +1079,10 @@ get_overwrite_set(struct commit_handle *
 	while (!capture_list_end(ch->overwrite_set, cur)) {
 		jnode *next = capture_list_next(cur);
 
+		if (jnode_is_znode(cur) && znode_above_root(JZNODE(cur))) {
+			ON_TRACE(TRACE_LOG, "fake znode found , WANDER=(%d)\n", JF_ISSET(cur, JNODE_OVRWR));
+		}
+
 		/* Count bitmap locks for getting correct statistics what number
 		 * of blocks were cleared by the transaction commit. */
 		if (jnode_get_type(cur) == JNODE_BITMAP)
@@ -1189,6 +1194,10 @@ write_jnodes_to_disk_extent(capture_list
 	assert("zam-570", nr > 0);
 
 	block = *block_p;
+
+	ON_TRACE (TRACE_IO_W, "write of %d blocks starting from %llu\n",
+		  nr, (unsigned long long)block);
+
 	max_blocks = bdev_get_queue(super->s_bdev)->max_sectors >> (super->s_blocksize_bits - 9);
 
 	while (nr > 0) {
@@ -1225,13 +1234,18 @@ write_jnodes_to_disk_extent(capture_list
 			}
 
 			LOCK_JNODE(cur);
-			assert("nikita-3166", pg->mapping == jnode_get_mapping(cur));
+			ON_DEBUG_MODIFY(znode_set_checksum(cur, 1));
+			assert("nikita-3166",
+			       pg->mapping == jnode_get_mapping(cur));
 			assert("zam-912", !JF_ISSET(cur, JNODE_WRITEBACK));
 			assert("nikita-3165", !jnode_is_releasable(cur));
 			JF_SET(cur, JNODE_WRITEBACK);
 			JF_CLR(cur, JNODE_DIRTY);
 			UNLOCK_JNODE(cur);
 
+			if (REISER4_STATS && !PageDirty(pg))
+				reiser4_stat_inc(pages_clean);
+
 			set_page_writeback(pg);
                         if (for_reclaim)
 				ent_writes_page(super, pg);
@@ -1260,6 +1274,7 @@ write_jnodes_to_disk_extent(capture_list
 			update_blocknr_hint_default (super, &block);
 			block += 1;
 		} else {
+			reiser4_stat_inc(txnmgr.empty_bio);
 			bio_put(bio);
 		}
 		nr -= nr_used;
@@ -1508,11 +1523,17 @@ free_not_assigned:
 reiser4_internal int reiser4_write_logs(long * nr_submitted)
 {
 	txn_atom *atom;
+
 	struct super_block *super = reiser4_get_current_sb();
 	reiser4_super_info_data *sbinfo = get_super_private(super);
+
 	struct commit_handle ch;
+
 	int ret;
 
+#if REISER4_STATS
+	unsigned long commit_start_time = jiffies;
+#endif
 	writeout_mode_enable();
 
 	/* block allocator may add j-nodes to the clean_list */
@@ -1540,6 +1561,9 @@ reiser4_internal int reiser4_write_logs(
 	atom_send_event(atom);
 	UNLOCK_ATOM(atom);
 
+	/* trace_mark(wander); */
+	write_current_logf(WRITE_IO_LOG, "mark=wander\n");
+
 	if (REISER4_DEBUG) {
 		 int level;
 
@@ -1572,6 +1596,8 @@ reiser4_internal int reiser4_write_logs(
 	 * submitted to disk. */
 	*nr_submitted += ch.overwrite_set_size - ch.nr_bitmap;
 
+	ON_TRACE(TRACE_LOG, "commit atom (id = %u, count = %u)\n", atom->atom_id, atom->capture_count);
+
 	/* count all records needed for storing of the wandered set */
 	get_tx_size(&ch);
 
@@ -1616,11 +1642,22 @@ reiser4_internal int reiser4_write_logs(
 	if (ret)
 		goto up_and_ret;
 
+	ON_TRACE(TRACE_LOG, "overwrite set (%u blocks) written to wandered locations\n", ch.overwrite_set_size);
+
 	if ((ret = update_journal_header(&ch)))
 		goto up_and_ret;
 
+	ON_TRACE(TRACE_LOG,
+		 "journal header updated (tx head at block %s)\n",
+		 sprint_address(jnode_get_block(capture_list_front(&ch.tx_list))));
+
+	reiser4_stat_inc(txnmgr.commits);
+
 	UNDER_SPIN_VOID(atom, atom, atom_set_stage(atom, ASTAGE_POST_COMMIT));
 
+	/* trace_mark(ovrwr); */
+	write_current_logf(WRITE_IO_LOG, "mark=ovrwr\n");
+
 	post_commit_hook();
 
 	{
@@ -1650,11 +1687,20 @@ reiser4_internal int reiser4_write_logs(
 	if (ret)
 		goto up_and_ret;
 
+	ON_TRACE(TRACE_LOG, "overwrite set written in place\n");
+
 	if ((ret = update_journal_footer(&ch)))
 		goto up_and_ret;
 
+	ON_TRACE(TRACE_LOG,
+		 "journal footer updated (tx head at block %s)\n",
+		 sprint_address(jnode_get_block(capture_list_front(&ch.tx_list))));
+
 	post_write_back_hook();
 
+	reiser4_stat_inc(txnmgr.post_commit_writes);
+	reiser4_stat_add(txnmgr.time_spent_in_commits, jiffies - commit_start_time);
+
 up_and_ret:
 	if (ret) {
 		/* there could be fq attached to current atom; the only way to
@@ -1941,6 +1987,8 @@ replay_oldest_transaction(struct super_b
 		return 0;
 	}
 
+	ON_TRACE(TRACE_REPLAY, "not flushed transactions found.");
+
 	prev_tx = sbinfo->last_committed_tx;
 
 	/* searching for oldest not flushed transaction */
@@ -1976,6 +2024,10 @@ replay_oldest_transaction(struct super_b
 	total = d32tocpu(&T->total);
 	log_rec_block = d64tocpu(&T->next_block);
 
+	ON_TRACE(TRACE_REPLAY,
+		 "not flushed transaction found (head block %s, %u wander records)\n",
+		 sprint_address(jnode_get_block(tx_head)), total);
+
 	pin_jnode_data(tx_head);
 	jrelse(tx_head);
 
@@ -2097,6 +2149,8 @@ reiser4_journal_replay(struct super_bloc
 	while ((ret = replay_oldest_transaction(s)) == -E_REPEAT)
 		nr_tx_replayed++;
 
+	ON_TRACE(TRACE_REPLAY, "%d transactions replayed ret = %d", nr_tx_replayed, ret);
+
 	return ret;
 }
 /* load journal control block (either journal header or journal footer block) */
diff -puN znode.c~profile-stat-trace-repacker znode.c
--- reiser4/znode.c~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/znode.c	2005-02-01 11:51:12.000000000 +0300
@@ -154,16 +154,13 @@
 #include "tree_walk.h"
 #include "super.h"
 #include "reiser4.h"
+#include "prof.h"
 
 #include <linux/pagemap.h>
 #include <linux/spinlock.h>
 #include <linux/slab.h>
 #include <linux/err.h>
 
-static z_hash_table *get_htable(reiser4_tree *, const reiser4_block_nr * const blocknr);
-static z_hash_table *znode_get_htable(const znode *);
-static void zdrop(znode *);
-
 /* hash table support */
 
 /* compare two block numbers for equality. Used by hash-table macros */
@@ -235,10 +232,12 @@ znodes_tree_init(reiser4_tree * tree /* 
 
 	rw_dk_init(tree);
 
-	result = z_hash_init(&tree->zhash_table, REISER4_ZNODE_HASH_TABLE_SIZE);
+	result = z_hash_init(&tree->zhash_table, REISER4_ZNODE_HASH_TABLE_SIZE,
+			     reiser4_stat(tree->super, hashes.znode));
 	if (result != 0)
 		return result;
-	result = z_hash_init(&tree->zfake_table, REISER4_ZNODE_HASH_TABLE_SIZE);
+	result = z_hash_init(&tree->zfake_table, REISER4_ZNODE_HASH_TABLE_SIZE,
+			     reiser4_stat(tree->super, hashes.zfake));
 	return result;
 }
 
@@ -250,6 +249,7 @@ extern void jnode_done(jnode * node, rei
 reiser4_internal void
 zfree(znode * node /* znode to free */ )
 {
+	trace_stamp(TRACE_ZNODES);
 	assert("nikita-465", node != NULL);
 	assert("nikita-2120", znode_page(node) == NULL);
 	assert("nikita-2301", owners_list_empty(&node->lock.owners));
@@ -266,7 +266,7 @@ zfree(znode * node /* znode to free */ )
 	/* not yet phash_jnode_destroy(ZJNODE(node)); */
 
 	/* poison memory. */
-	ON_DEBUG(memset(node, 0xde, sizeof *node));
+	ON_DEBUG(xmemset(node, 0xde, sizeof *node));
 	kmem_cache_free(znode_slab, node);
 }
 
@@ -283,6 +283,9 @@ znodes_tree_done(reiser4_tree * tree /* 
 
 	assert("nikita-795", tree != NULL);
 
+	IF_TRACE(TRACE_ZWEB, UNDER_RW_VOID(tree, tree, read,
+					   print_znodes("umount", tree)));
+
 	ztable = &tree->zhash_table;
 
 	for_all_in_htable(ztable, z, node, next) {
@@ -314,6 +317,7 @@ zalloc(int gfp_flag /* allocation flag *
 {
 	znode *node;
 
+	trace_stamp(TRACE_ZNODES);
 	node = kmem_cache_alloc(znode_slab, gfp_flag);
 	return node;
 }
@@ -328,13 +332,14 @@ zinit(znode * node, const znode * parent
 	assert("nikita-466", node != NULL);
 	assert("umka-268", current_tree != NULL);
 
-	memset(node, 0, sizeof *node);
+	xmemset(node, 0, sizeof *node);
 
 	assert("umka-051", tree != NULL);
 
 	jnode_init(&node->zjnode, tree, JNODE_FORMATTED_BLOCK);
 	reiser4_init_lock(&node->lock);
 	init_parent_coord(&node->in_parent, parent);
+	ON_DEBUG_MODIFY(node->cksum = 0);
 }
 
 /*
@@ -368,7 +373,7 @@ znode_remove(znode * node /* znode to re
 /* zdrop() -- Remove znode from the tree.
 
    This is called when znode is removed from the memory. */
-static void
+reiser4_internal void
 zdrop(znode * node /* znode to finish with */ )
 {
 	jdrop(ZJNODE(node));
@@ -424,6 +429,8 @@ zlook(reiser4_tree * tree, const reiser4
 	__u32         hash;
 	z_hash_table *htable;
 
+	trace_stamp(TRACE_ZNODES);
+
 	assert("jmacd-506", tree != NULL);
 	assert("jmacd-507", blocknr != NULL);
 
@@ -444,7 +451,7 @@ zlook(reiser4_tree * tree, const reiser4
 
 /* return hash table where znode with block @blocknr is (or should be)
  * stored */
-static z_hash_table *
+reiser4_internal z_hash_table *
 get_htable(reiser4_tree * tree, const reiser4_block_nr * const blocknr)
 {
 	z_hash_table *table;
@@ -456,7 +463,7 @@ get_htable(reiser4_tree * tree, const re
 }
 
 /* return hash table where znode @node is (or should be) stored */
-static z_hash_table *
+reiser4_internal z_hash_table *
 znode_get_htable(const znode *node)
 {
 	return get_htable(znode_get_tree(node), znode_get_block(node));
@@ -483,6 +490,8 @@ zget(reiser4_tree * tree,
 
 	z_hash_table *zth;
 
+	trace_stamp(TRACE_ZNODES);
+
 	assert("jmacd-512", tree != NULL);
 	assert("jmacd-513", blocknr != NULL);
 	assert("jmacd-514", level < REISER4_MAX_ZTREE_HEIGHT);
@@ -595,10 +604,10 @@ znode_guess_plugin(const znode * node	/*
 			if ((plugin->u.node.guess != NULL) && plugin->u.node.guess(node))
 				return plugin;
 		}
+#endif
 		warning("nikita-1057", "Cannot guess node plugin");
 		print_znode("node", node);
 		return NULL;
-#endif
 	}
 }
 
@@ -643,6 +652,7 @@ zload_ra(znode * node /* znode to load *
 		formatted_readahead(node, info);
 
 	result = jload(ZJNODE(node));
+	ON_DEBUG_MODIFY(znode_pre_write(node));
 	assert("nikita-1378", znode_invariant(node));
 	return result;
 }
@@ -793,8 +803,7 @@ znode_above_root(const znode * node /* z
 
 /* check that @node is root---that its block number is recorder in the tree as
    that of root node */
-#if REISER4_DEBUG
-static int
+reiser4_internal int
 znode_is_true_root(const znode * node /* znode to query */ )
 {
 	assert("umka-060", node != NULL);
@@ -802,7 +811,6 @@ znode_is_true_root(const znode * node /*
 
 	return disk_addr_eq(znode_get_block(node), &znode_get_tree(node)->root_block);
 }
-#endif
 
 /* check that @node is root */
 reiser4_internal int
@@ -830,11 +838,94 @@ znode_build_version(reiser4_tree * tree)
 	return UNDER_SPIN(epoch, tree, ++tree->znode_epoch);
 }
 
+/*
+ * relocate znode to the new block number @blk. Caller keeps @node and @parent
+ * long-term locked, and loaded.
+ */
+static int
+relocate_locked(znode * node, znode * parent, reiser4_block_nr * blk)
+{
+	coord_t  inparent;
+	int      result;
+
+	assert("nikita-3127", node != NULL);
+	assert("nikita-3128", parent != NULL);
+	assert("nikita-3129", blk != NULL);
+	assert("nikita-3130", znode_is_any_locked(node));
+	assert("nikita-3131", znode_is_any_locked(parent));
+	assert("nikita-3132", znode_is_loaded(node));
+	assert("nikita-3133", znode_is_loaded(parent));
+
+	result = find_child_ptr(parent, node, &inparent);
+	if (result == NS_FOUND) {
+		int grabbed;
+
+		grabbed = get_current_context()->grabbed_blocks;
+		/* for a node and its parent */
+		result = reiser4_grab_space_force((__u64)2, BA_RESERVED);
+		if (result == 0) {
+			item_plugin *iplug;
+
+			iplug = item_plugin_by_coord(&inparent);
+			assert("nikita-3126", iplug->f.update != NULL);
+			iplug->f.update(&inparent, blk);
+			znode_make_dirty(inparent.node);
+			result = znode_rehash(node, blk);
+		}
+		grabbed2free_mark(grabbed);
+	} else
+		result = RETERR(-EIO);
+	return result;
+}
+
+/*
+ * relocate znode to the new block number @blk. Used for speculative
+ * relocation of bad blocks.
+ */
+reiser4_internal int
+znode_relocate(znode * node, reiser4_block_nr * blk)
+{
+	lock_handle lh;
+	int         result;
+
+	assert("nikita-3120", node != NULL);
+	assert("nikita-3121", atomic_read(&ZJNODE(node)->x_count) > 0);
+	assert("nikita-3122", blk != NULL);
+	assert("nikita-3123", lock_stack_isclean(get_current_lock_stack()));
+	assert("nikita-3124", schedulable());
+	assert("nikita-3125", !znode_is_root(node));
+
+	init_lh(&lh);
+	result = longterm_lock_znode(&lh, node,
+				     ZNODE_READ_LOCK, ZNODE_LOCK_LOPRI);
+	if (result == 0) {
+		lock_handle parent;
+
+		result = reiser4_get_parent(&parent, node, ZNODE_READ_LOCK, 1);
+		if (result == 0) {
+			result = zload(node);
+			if (result == 0) {
+				result = zload(parent.node);
+				if (result == 0) {
+					result = relocate_locked(node,
+								 parent.node,
+								 blk);
+					zrelse(parent.node);
+				}
+				zrelse(node);
+			}
+			done_lh(&parent);
+		}
+		done_lh(&lh);
+	}
+	return result;
+}
+
 reiser4_internal void
 init_load_count(load_count * dh)
 {
 	assert("nikita-2105", dh != NULL);
-	memset(dh, 0, sizeof *dh);
+	xmemset(dh, 0, sizeof *dh);
 }
 
 reiser4_internal void
@@ -848,7 +939,18 @@ done_load_count(load_count * dh)
 	}
 }
 
-static int
+reiser4_internal int
+incr_load_count_znode(load_count * dh, znode * node)
+{
+	assert("nikita-2107", dh != NULL);
+	assert("nikita-2158", node != NULL);
+	assert("nikita-2109", ergo(dh->node != NULL, (dh->node == node) || (dh->d_ref == 0)));
+
+	dh->node = node;
+	return incr_load_count(dh);
+}
+
+reiser4_internal int
 incr_load_count(load_count * dh)
 {
 	int result;
@@ -863,17 +965,6 @@ incr_load_count(load_count * dh)
 }
 
 reiser4_internal int
-incr_load_count_znode(load_count * dh, znode * node)
-{
-	assert("nikita-2107", dh != NULL);
-	assert("nikita-2158", node != NULL);
-	assert("nikita-2109", ergo(dh->node != NULL, (dh->node == node) || (dh->d_ref == 0)));
-
-	dh->node = node;
-	return incr_load_count(dh);
-}
-
-reiser4_internal int
 incr_load_count_jnode(load_count * dh, jnode * node)
 {
 	if (jnode_is_znode(node)) {
@@ -939,7 +1030,7 @@ init_parent_coord(parent_coord_t * pcoor
 }
 
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_NODE_INVARIANT
 int jnode_invariant_f(const jnode * node, char const **msg);
 
 /* debugging aid: znode invariant */
@@ -1021,7 +1112,13 @@ znode_invariant_f(const znode * node /* 
 		 * invariant */
 		/* unfortunately, zlock is unordered w.r.t. jnode_lock, so we
 		 * cannot check this. */
+		/*
+		UNDER_RW(zlock, (zlock *)&node->lock,
+			 read, _ergo(!znode_is_wlocked(node),
+				     znode_at_read(node))) &&
+		*/
 		/* [znode-refs] invariant */
+
 		/* only referenced znode can be long-term locked */
 		_ergo(znode_is_locked(node),
 		      atomic_read(&ZJNODE(node)->x_count) != 0);
@@ -1048,22 +1145,125 @@ znode_invariant(const znode * node /* zn
 	spin_unlock_znode((znode *) node);
 	return result;
 }
+/* REISER4_DEBUG_NODE_INVARIANT */
+#endif
 
-/* debugging aid: output human readable information about @node */
-static void
-info_znode(const char *prefix /* prefix to print */ ,
-	   const znode * node /* node to print */ )
+/*
+ * Node dirtying debug.
+ *
+ * Whenever formatted node is modified, it should be marked dirty (through
+ * call to znode_make_dirty()) before exclusive long term lock (necessary to
+ * modify node) is released. This is critical for correct operation of seal.c
+ * code.
+ *
+ * As this is an error easy to make, special debugging mode was implemented to
+ * catch it.
+ *
+ * In this mode new field ->cksum is added to znode. This field contains
+ * checksum (adler32) of znode content calculated when znode is loaded into
+ * memory and re-calculated whenever znode_make_dirty() is called on it.
+ *
+ * Whenever long term lock on znode is released, and znode wasn't marked
+ * dirty, checksum of its content is calculated and compared with value stored
+ * in ->cksum. If they differ, call to znode_make_dirty() is missing.
+ *
+ * This debugging mode (tunable though fs/Kconfig) is very CPU consuming and
+ * hence, unsuitable for normal operation.
+ *
+ */
+
+#if REISER4_DEBUG_MODIFY
+__u32 znode_checksum(const znode * node)
 {
-	if (node == NULL) {
-		return;
+	int i, size = znode_size(node);
+	__u32 l = 0;
+	__u32 h = 0;
+	const char *data = page_address(znode_page(node));
+
+	/* Checksum is similar to adler32... */
+	for (i = 0; i < size; i += 1) {
+		l += data[i];
+		h += l;
 	}
-	info_jnode(prefix, ZJNODE(node));
-	if (!jnode_is_znode(ZJNODE(node)))
-		return;
 
-	printk("c_count: %i, readers: %i, items: %i\n",
-	       node->c_count, node->lock.nr_readers, node->nr_items);
+	return (h << 16) | (l & 0xffff);
+}
+
+static inline int znode_has_data(const znode *z)
+{
+	return znode_page(z) != NULL && page_address(znode_page(z)) == zdata(z);
+}
+
+void znode_set_checksum(jnode * node, int locked_p)
+{
+	if (jnode_is_znode(node)) {
+		znode *z;
+
+		z = JZNODE(node);
+
+		if (!locked_p)
+			LOCK_JNODE(node);
+		if (znode_has_data(z))
+			z->cksum = znode_checksum(z);
+		else
+			z->cksum = 0;
+		if (!locked_p)
+			UNLOCK_JNODE(node);
+	}
+}
+
+void
+znode_pre_write(znode * node)
+{
+	assert("umka-066", node != NULL);
+
+	spin_lock_znode(node);
+	if (znode_has_data(node)) {
+		if (node->cksum == 0 && !znode_is_dirty(node))
+			node->cksum = znode_checksum(node);
+	}
+	spin_unlock_znode(node);
+}
+
+void
+znode_post_write(znode * node)
+{
+	__u32 cksum;
+
+	assert("umka-067", node != NULL);
+
+	if (znode_has_data(node)) {
+		cksum = znode_checksum(node);
+
+		if (cksum != node->cksum && node->cksum != 0)
+			reiser4_panic("jmacd-1081",
+				      "changed znode is not dirty: %llu",
+				      node->zjnode.blocknr);
+	}
+}
+
+int
+znode_at_read(const znode * node)
+{
+	__u32 cksum;
+
+	assert("umka-067", node != NULL);
+
+	if (znode_has_data(node)) {
+		cksum = znode_checksum((znode *)node);
+
+		if (cksum != node->cksum && node->cksum != 0) {
+			reiser4_panic("nikita-3561",
+				      "znode is changed: %llu",
+				      node->zjnode.blocknr);
+			return 0;
+		}
+	}
+	return 1;
 }
+#endif
+
+#if REISER4_DEBUG_OUTPUT
 
 /* debugging aid: output more human readable information about @node that
    info_znode(). */
@@ -1087,6 +1287,22 @@ print_znode(const char *prefix /* prefix
 	printk("\n");
 }
 
+/* debugging aid: output human readable information about @node */
+reiser4_internal void
+info_znode(const char *prefix /* prefix to print */ ,
+	   const znode * node /* node to print */ )
+{
+	if (node == NULL) {
+		return;
+	}
+	info_jnode(prefix, ZJNODE(node));
+	if (!jnode_is_znode(ZJNODE(node)))
+		return;
+
+	printk("c_count: %i, readers: %i, items: %i\n",
+	       node->c_count, node->lock.nr_readers, node->nr_items);
+}
+
 /* print all znodes in @tree */
 reiser4_internal void
 print_znodes(const char *prefix, reiser4_tree * tree)
@@ -1118,6 +1334,9 @@ print_znodes(const char *prefix, reiser4
 	if (tree_lock_taken)
 		WUNLOCK_TREE(tree);
 }
+#endif
+
+#if defined(REISER4_DEBUG) || defined(REISER4_DEBUG_MODIFY) || defined(REISER4_DEBUG_OUTPUT)
 
 /* return non-0 iff data are loaded into znode */
 reiser4_internal int
@@ -1127,13 +1346,15 @@ znode_is_loaded(const znode * node /* zn
 	return jnode_is_loaded(ZJNODE(node));
 }
 
+#endif
+
+#if REISER4_DEBUG
 reiser4_internal unsigned long
 znode_times_locked(const znode *z)
 {
 	return z->times_locked;
 }
-
-#endif /* REISER4_DEBUG */
+#endif
 
 /* Make Linus happy.
    Local variables:
diff -puN znode.h~profile-stat-trace-repacker znode.h
--- reiser4/znode.h~profile-stat-trace-repacker	2005-02-01 11:51:11.000000000 +0300
+++ reiser4-vs/znode.h	2005-02-01 11:51:12.000000000 +0300
@@ -142,13 +142,21 @@ struct znode {
 	/* number of items in this node. This field is modified by node
 	 * plugin. */
 	__u16 nr_items;
+#if REISER4_DEBUG_MODIFY
+	/* In debugging mode, used to detect loss of znode_set_dirty()
+	   notification. */
+	spinlock_t cksum_lock;
+	__u32 cksum;
+#endif
 
 #if REISER4_DEBUG
 	void *creator;
 	reiser4_key first_key;
 	unsigned long times_locked;
 #endif
-
+#if REISER4_STATS
+	int last_lookup_pos;
+#endif
 } __attribute__((aligned(16)));
 
 /* In general I think these macros should not be exposed. */
@@ -217,6 +225,8 @@ extern void znode_remove(znode *, reiser
 extern znode *znode_parent(const znode * node);
 extern znode *znode_parent_nolock(const znode * node);
 extern int znode_above_root(const znode * node);
+extern int znode_is_true_root(const znode * node);
+extern void zdrop(znode * node);
 extern int znodes_init(void);
 extern int znodes_done(void);
 extern int znodes_tree_init(reiser4_tree * ztree);
@@ -230,19 +240,26 @@ extern int znode_just_created(const znod
 
 extern void zfree(znode * node);
 
-/*
+#if REISER4_DEBUG_MODIFY
+extern void znode_pre_write(znode * node);
+extern void znode_post_write(znode * node);
+extern void znode_set_checksum(jnode * node, int locked_p);
+extern int  znode_at_read(const znode * node);
+#else
 #define znode_pre_write(n) noop
 #define znode_post_write(n) noop
 #define znode_set_checksum(n, l) noop
 #define znode_at_read(n) (1)
-*/
+#endif
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_OUTPUT
 extern void print_znode(const char *prefix, const znode * node);
+extern void info_znode(const char *prefix, const znode * node);
 extern void print_znodes(const char *prefix, reiser4_tree * tree);
 extern void print_lock_stack(const char *prefix, lock_stack * owner);
 #else
 #define print_znode( p, n ) noop
+#define info_znode( p, n ) noop
 #define print_znodes( p, t ) noop
 #define print_lock_stack( p, o ) noop
 #endif
@@ -270,7 +287,12 @@ extern void print_lock_stack(const char 
 
 #if REISER4_DEBUG
 extern int znode_x_count_is_protected(const znode * node);
+#endif
+
+#if REISER4_DEBUG_NODE_INVARIANT
 extern int znode_invariant(const znode * node);
+#else
+#define znode_invariant(n) (1)
 #endif
 
 /* acquire reference to @node */
@@ -344,8 +366,14 @@ znode_rip_check(reiser4_tree *tree, znod
 int znode_is_loaded(const znode * node /* znode to query */ );
 #endif
 
+extern z_hash_table *get_htable(reiser4_tree * tree,
+				const reiser4_block_nr * const blocknr);
+extern z_hash_table *znode_get_htable(const znode *node);
+
 extern __u64 znode_build_version(reiser4_tree * tree);
 
+extern int znode_relocate(znode * node, reiser4_block_nr * blk);
+
 /* Data-handles.  A data handle object manages pairing calls to zload() and zrelse().  We
    must load the data for a node in many places.  We could do this by simply calling
    zload() everywhere, the difficulty arises when we must release the loaded data by
@@ -361,6 +389,7 @@ typedef struct load_count {
 
 extern void init_load_count(load_count * lc);	/* Initialize a load_count set the current node to NULL. */
 extern void done_load_count(load_count * dh);	/* Finalize a load_count: call zrelse() if necessary */
+extern int incr_load_count(load_count * dh);	/* Call zload() on the current node. */
 extern int incr_load_count_znode(load_count * dh, znode * node);	/* Set the argument znode to the current node, call zload(). */
 extern int incr_load_count_jnode(load_count * dh, jnode * node);	/* If the argument jnode is formatted, do the same as
 									   * incr_load_count_znode, otherwise do nothing (unformatted nodes
@@ -414,7 +443,7 @@ extern void copy_load_count(load_count *
 })
 
 
-#if REISER4_DEBUG
+#if REISER4_DEBUG_SPIN_LOCKS
 #define STORE_COUNTERS						\
 	lock_counters_info __entry_counters = *lock_counters()
 #define CHECK_COUNTERS						\

_
